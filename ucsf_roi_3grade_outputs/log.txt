2024/03/04 00:14:08 - INFO - root -   Num train examples = 400
2024/03/04 00:14:08 - INFO - root -   Num val examples = 45
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.0181818176060915
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.036363635212183
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.05454545468091965
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.072727270424366
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.09090908616781235
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.10909091681241989
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.12727272510528564
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.1454545557498932
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.16363637149333954
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.1818181872367859
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.20000000298023224
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Use checkpoint: False
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Checkpoint number: [0]
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.13333334028720856
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.2666666507720947
2024/03/04 00:14:08 - INFO - models.uniformerv2_model -   Drop path rate: 0.4000000059604645
2024/03/04 00:14:08 - INFO - root -   backend = nccl
2024/03/04 00:14:08 - INFO - root -   batch_size = 2
2024/03/04 00:14:08 - INFO - root -   dropout = 0.5
2024/03/04 00:14:08 - INFO - root -   epochs = 300
2024/03/04 00:14:08 - INFO - root -   eval_freq = 5
2024/03/04 00:14:08 - INFO - root -   focal_loss = False
2024/03/04 00:14:08 - INFO - root -   input_size = 128
2024/03/04 00:14:08 - INFO - root -   is_pretrained = False
2024/03/04 00:14:08 - INFO - root -   label_smooth = False
2024/03/04 00:14:08 - INFO - root -   local_rank = -1
2024/03/04 00:14:08 - INFO - root -   lr = 1e-05
2024/03/04 00:14:08 - INFO - root -   lr_decay_rate = 0.1
2024/03/04 00:14:08 - INFO - root -   lr_steps = [50, 100]
2024/03/04 00:14:08 - INFO - root -   lr_type = cosine
2024/03/04 00:14:08 - INFO - root -   model_depth = 34
2024/03/04 00:14:08 - INFO - root -   model_name = resnet50
2024/03/04 00:14:08 - INFO - root -   momentum = 0.9
2024/03/04 00:14:08 - INFO - root -   num_classes = 3
2024/03/04 00:14:08 - INFO - root -   output = ./ucsf_roi_3grade_outputs
2024/03/04 00:14:08 - INFO - root -   print_freq = 20
2024/03/04 00:14:08 - INFO - root -   resume = 
2024/03/04 00:14:08 - INFO - root -   start_epoch = 0
2024/03/04 00:14:08 - INFO - root -   train_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_train_patients.txt
2024/03/04 00:14:08 - INFO - root -   tune_from = 
2024/03/04 00:14:08 - INFO - root -   val_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_val_patients.txt
2024/03/04 00:14:08 - INFO - root -   warmup_epoch = 20
2024/03/04 00:14:08 - INFO - root -   warmup_multiplier = 100
2024/03/04 00:14:08 - INFO - root -   weight_decay = 0.0005
2024/03/04 00:14:08 - INFO - root -   workers = 16
2024/03/04 00:14:30 - INFO - root -   Epoch: [0/300][0/200], lr: 0.00000010 	 loss = 1.9473(1.9473)
2024/03/04 00:14:38 - INFO - root -   Epoch: [0/300][20/200], lr: 0.00000010 	 loss = 0.7913(1.1321)
2024/03/04 00:14:50 - INFO - root -   Epoch: [0/300][40/200], lr: 0.00000010 	 loss = 0.7765(1.0816)
2024/03/04 00:15:06 - INFO - root -   Epoch: [0/300][60/200], lr: 0.00000010 	 loss = 0.5311(0.9861)
2024/03/04 00:15:25 - INFO - root -   Epoch: [0/300][80/200], lr: 0.00000010 	 loss = 0.3874(0.9651)
2024/03/04 00:15:38 - INFO - root -   Epoch: [0/300][100/200], lr: 0.00000010 	 loss = 0.8229(0.9322)
2024/03/04 00:15:50 - INFO - root -   Epoch: [0/300][120/200], lr: 0.00000010 	 loss = 1.9252(0.8967)
2024/03/04 00:16:02 - INFO - root -   Epoch: [0/300][140/200], lr: 0.00000010 	 loss = 1.2045(0.8694)
2024/03/04 00:16:24 - INFO - root -   Epoch: [0/300][160/200], lr: 0.00000010 	 loss = 0.2604(0.8515)
2024/03/04 00:16:42 - INFO - root -   Epoch: [0/300][180/200], lr: 0.00000010 	 loss = 0.3482(0.8556)
2024/03/04 00:16:49 - INFO - root -   Epoch: [0/300] 	 loss = 0.8610
2024/03/04 00:16:49 - INFO - root -   train_accuracy = 0.6375
2024/03/04 00:17:03 - INFO - root -   Epoch: [1/300][0/200], lr: 0.00000010 	 loss = 1.8115(1.8115)
2024/03/04 00:17:16 - INFO - root -   Epoch: [1/300][20/200], lr: 0.00000010 	 loss = 0.2432(0.8150)
2024/03/04 00:17:33 - INFO - root -   Epoch: [1/300][40/200], lr: 0.00000010 	 loss = 0.5516(0.6959)
2024/03/04 00:17:42 - INFO - root -   Epoch: [1/300][60/200], lr: 0.00000010 	 loss = 0.2031(0.7117)
2024/03/04 00:18:03 - INFO - root -   Epoch: [1/300][80/200], lr: 0.00000010 	 loss = 1.3630(0.7363)
2024/03/04 00:18:23 - INFO - root -   Epoch: [1/300][100/200], lr: 0.00000010 	 loss = 0.4885(0.7250)
2024/03/04 00:18:36 - INFO - root -   Epoch: [1/300][120/200], lr: 0.00000010 	 loss = 2.6336(0.6942)
2024/03/04 00:18:48 - INFO - root -   Epoch: [1/300][140/200], lr: 0.00000010 	 loss = 1.2600(0.7001)
2024/03/04 00:18:59 - INFO - root -   Epoch: [1/300][160/200], lr: 0.00000010 	 loss = 0.2340(0.7020)
2024/03/04 00:19:10 - INFO - root -   Epoch: [1/300][180/200], lr: 0.00000010 	 loss = 0.4135(0.7358)
2024/03/04 00:19:18 - INFO - root -   Epoch: [1/300] 	 loss = 0.7280
2024/03/04 00:19:18 - INFO - root -   train_accuracy = 0.7675
2024/03/04 00:19:19 - INFO - root -   Epoch: [2/300][0/200], lr: 0.00000010 	 loss = 0.9796(0.9796)
2024/03/04 00:19:51 - INFO - root -   Epoch: [2/300][20/200], lr: 0.00000010 	 loss = 0.1697(0.8649)
2024/03/04 00:20:03 - INFO - root -   Epoch: [2/300][40/200], lr: 0.00000010 	 loss = 0.6186(0.7136)
2024/03/04 00:20:23 - INFO - root -   Epoch: [2/300][60/200], lr: 0.00000010 	 loss = 0.1389(0.6643)
2024/03/04 00:20:31 - INFO - root -   Epoch: [2/300][80/200], lr: 0.00000010 	 loss = 1.5857(0.6837)
2024/03/04 00:20:39 - INFO - root -   Epoch: [2/300][100/200], lr: 0.00000010 	 loss = 0.1128(0.6713)
2024/03/04 00:21:10 - INFO - root -   Epoch: [2/300][120/200], lr: 0.00000010 	 loss = 2.5870(0.6480)
2024/03/04 00:21:24 - INFO - root -   Epoch: [2/300][140/200], lr: 0.00000010 	 loss = 1.7121(0.6675)
2024/03/04 00:21:48 - INFO - root -   Epoch: [2/300][160/200], lr: 0.00000010 	 loss = 0.3395(0.6714)
2024/03/04 00:21:55 - INFO - root -   Epoch: [2/300][180/200], lr: 0.00000010 	 loss = 0.2295(0.6716)
2024/03/04 00:22:05 - INFO - root -   Epoch: [2/300] 	 loss = 0.6715
2024/03/04 00:22:05 - INFO - root -   train_accuracy = 0.7875
2024/03/04 00:22:17 - INFO - root -   Epoch: [3/300][0/200], lr: 0.00000011 	 loss = 2.0227(2.0227)
2024/03/04 00:22:44 - INFO - root -   Epoch: [3/300][20/200], lr: 0.00000011 	 loss = 0.2193(1.0053)
2024/03/04 00:22:54 - INFO - root -   Epoch: [3/300][40/200], lr: 0.00000011 	 loss = 0.1719(0.7429)
2024/03/04 00:23:14 - INFO - root -   Epoch: [3/300][60/200], lr: 0.00000011 	 loss = 0.1312(0.7461)
2024/03/04 00:23:24 - INFO - root -   Epoch: [3/300][80/200], lr: 0.00000011 	 loss = 1.3596(0.7412)
2024/03/04 00:23:56 - INFO - root -   Epoch: [3/300][100/200], lr: 0.00000011 	 loss = 0.0900(0.7013)
2024/03/04 00:24:04 - INFO - root -   Epoch: [3/300][120/200], lr: 0.00000011 	 loss = 2.5325(0.6617)
2024/03/04 00:24:12 - INFO - root -   Epoch: [3/300][140/200], lr: 0.00000011 	 loss = 1.1911(0.6745)
2024/03/04 00:24:33 - INFO - root -   Epoch: [3/300][160/200], lr: 0.00000011 	 loss = 0.1935(0.6723)
2024/03/04 00:24:53 - INFO - root -   Epoch: [3/300][180/200], lr: 0.00000011 	 loss = 0.1955(0.6701)
2024/03/04 00:25:01 - INFO - root -   Epoch: [3/300] 	 loss = 0.6733
2024/03/04 00:25:01 - INFO - root -   train_accuracy = 0.8000
2024/03/04 00:25:17 - INFO - root -   Epoch: [4/300][0/200], lr: 0.00000011 	 loss = 1.3185(1.3185)
2024/03/04 00:25:39 - INFO - root -   Epoch: [4/300][20/200], lr: 0.00000011 	 loss = 0.7076(0.8786)
2024/03/04 00:25:56 - INFO - root -   Epoch: [4/300][40/200], lr: 0.00000011 	 loss = 0.2710(0.6299)
2024/03/04 00:26:06 - INFO - root -   Epoch: [4/300][60/200], lr: 0.00000011 	 loss = 0.1151(0.5917)
2024/03/04 00:26:30 - INFO - root -   Epoch: [4/300][80/200], lr: 0.00000011 	 loss = 0.9012(0.5930)
2024/03/04 00:26:38 - INFO - root -   Epoch: [4/300][100/200], lr: 0.00000011 	 loss = 0.3320(0.5835)
2024/03/04 00:27:02 - INFO - root -   Epoch: [4/300][120/200], lr: 0.00000011 	 loss = 2.1000(0.5677)
2024/03/04 00:27:15 - INFO - root -   Epoch: [4/300][140/200], lr: 0.00000011 	 loss = 1.0666(0.5847)
2024/03/04 00:27:43 - INFO - root -   Epoch: [4/300][160/200], lr: 0.00000011 	 loss = 0.1385(0.5910)
2024/03/04 00:27:55 - INFO - root -   Epoch: [4/300][180/200], lr: 0.00000011 	 loss = 0.1604(0.6069)
2024/03/04 00:28:03 - INFO - root -   Epoch: [4/300] 	 loss = 0.6272
2024/03/04 00:28:08 - INFO - root -   precision = 0.8222
2024/03/04 00:28:08 - INFO - root -   eval_loss = 0.6286
2024/03/04 00:28:08 - INFO - root -   eval_acc = 0.8222
2024/03/04 00:28:09 - INFO - root -   train_accuracy = 0.7925
2024/03/04 00:28:11 - INFO - root -   Epoch: [5/300][0/200], lr: 0.00000011 	 loss = 1.0514(1.0514)
2024/03/04 00:28:37 - INFO - root -   Epoch: [5/300][20/200], lr: 0.00000011 	 loss = 0.2491(0.8331)
2024/03/04 00:28:44 - INFO - root -   Epoch: [5/300][40/200], lr: 0.00000011 	 loss = 0.1556(0.6387)
2024/03/04 00:29:11 - INFO - root -   Epoch: [5/300][60/200], lr: 0.00000011 	 loss = 0.1046(0.6355)
2024/03/04 00:29:19 - INFO - root -   Epoch: [5/300][80/200], lr: 0.00000011 	 loss = 0.6252(0.6562)
2024/03/04 00:29:32 - INFO - root -   Epoch: [5/300][100/200], lr: 0.00000011 	 loss = 0.1682(0.6409)
2024/03/04 00:29:50 - INFO - root -   Epoch: [5/300][120/200], lr: 0.00000011 	 loss = 3.1017(0.6176)
2024/03/04 00:29:58 - INFO - root -   Epoch: [5/300][140/200], lr: 0.00000011 	 loss = 2.1104(0.6416)
2024/03/04 00:30:09 - INFO - root -   Epoch: [5/300][160/200], lr: 0.00000011 	 loss = 0.2005(0.6493)
2024/03/04 00:30:24 - INFO - root -   Epoch: [5/300][180/200], lr: 0.00000011 	 loss = 0.3619(0.6627)
2024/03/04 00:30:32 - INFO - root -   Epoch: [5/300] 	 loss = 0.6632
2024/03/04 00:30:32 - INFO - root -   train_accuracy = 0.7900
2024/03/04 00:30:53 - INFO - root -   Epoch: [6/300][0/200], lr: 0.00000011 	 loss = 1.5408(1.5408)
2024/03/04 00:31:06 - INFO - root -   Epoch: [6/300][20/200], lr: 0.00000011 	 loss = 0.1433(0.7575)
2024/03/04 00:31:14 - INFO - root -   Epoch: [6/300][40/200], lr: 0.00000011 	 loss = 0.1524(0.5730)
2024/03/04 00:31:28 - INFO - root -   Epoch: [6/300][60/200], lr: 0.00000011 	 loss = 0.2902(0.5764)
2024/03/04 00:31:36 - INFO - root -   Epoch: [6/300][80/200], lr: 0.00000011 	 loss = 2.0301(0.5954)
2024/03/04 00:31:55 - INFO - root -   Epoch: [6/300][100/200], lr: 0.00000011 	 loss = 0.3206(0.5890)
2024/03/04 00:32:04 - INFO - root -   Epoch: [6/300][120/200], lr: 0.00000011 	 loss = 2.0467(0.5639)
2024/03/04 00:32:27 - INFO - root -   Epoch: [6/300][140/200], lr: 0.00000011 	 loss = 0.9530(0.5828)
2024/03/04 00:32:35 - INFO - root -   Epoch: [6/300][160/200], lr: 0.00000011 	 loss = 0.1344(0.5886)
2024/03/04 00:32:55 - INFO - root -   Epoch: [6/300][180/200], lr: 0.00000011 	 loss = 0.1096(0.6138)
2024/03/04 00:33:02 - INFO - root -   Epoch: [6/300] 	 loss = 0.6205
2024/03/04 00:33:02 - INFO - root -   train_accuracy = 0.7925
2024/03/04 00:33:16 - INFO - root -   Epoch: [7/300][0/200], lr: 0.00000012 	 loss = 1.5456(1.5456)
2024/03/04 00:33:29 - INFO - root -   Epoch: [7/300][20/200], lr: 0.00000012 	 loss = 0.1351(0.8283)
2024/03/04 00:33:37 - INFO - root -   Epoch: [7/300][40/200], lr: 0.00000012 	 loss = 0.4031(0.6709)
2024/03/04 00:34:04 - INFO - root -   Epoch: [7/300][60/200], lr: 0.00000012 	 loss = 0.0982(0.6278)
2024/03/04 00:34:20 - INFO - root -   Epoch: [7/300][80/200], lr: 0.00000012 	 loss = 1.4621(0.6525)
2024/03/04 00:34:28 - INFO - root -   Epoch: [7/300][100/200], lr: 0.00000012 	 loss = 0.1626(0.6127)
2024/03/04 00:34:43 - INFO - root -   Epoch: [7/300][120/200], lr: 0.00000012 	 loss = 1.5333(0.5906)
2024/03/04 00:34:58 - INFO - root -   Epoch: [7/300][140/200], lr: 0.00000012 	 loss = 1.6023(0.5875)
2024/03/04 00:35:16 - INFO - root -   Epoch: [7/300][160/200], lr: 0.00000012 	 loss = 0.1842(0.5883)
2024/03/04 00:35:25 - INFO - root -   Epoch: [7/300][180/200], lr: 0.00000012 	 loss = 0.2983(0.6026)
2024/03/04 00:35:33 - INFO - root -   Epoch: [7/300] 	 loss = 0.5998
2024/03/04 00:35:33 - INFO - root -   train_accuracy = 0.8000
2024/03/04 00:35:34 - INFO - root -   Epoch: [8/300][0/200], lr: 0.00000012 	 loss = 1.6763(1.6763)
2024/03/04 00:36:06 - INFO - root -   Epoch: [8/300][20/200], lr: 0.00000012 	 loss = 0.3250(0.9232)
2024/03/04 00:36:16 - INFO - root -   Epoch: [8/300][40/200], lr: 0.00000012 	 loss = 0.1704(0.6661)
2024/03/04 00:36:44 - INFO - root -   Epoch: [8/300][60/200], lr: 0.00000012 	 loss = 0.1580(0.6287)
2024/03/04 00:36:52 - INFO - root -   Epoch: [8/300][80/200], lr: 0.00000012 	 loss = 1.5784(0.6286)
2024/03/04 00:37:22 - INFO - root -   Epoch: [8/300][100/200], lr: 0.00000012 	 loss = 0.1023(0.5925)
2024/03/04 00:37:30 - INFO - root -   Epoch: [8/300][120/200], lr: 0.00000012 	 loss = 2.9564(0.5791)
2024/03/04 00:37:50 - INFO - root -   Epoch: [8/300][140/200], lr: 0.00000012 	 loss = 1.8938(0.6014)
2024/03/04 00:37:58 - INFO - root -   Epoch: [8/300][160/200], lr: 0.00000012 	 loss = 0.1489(0.6131)
2024/03/04 00:38:16 - INFO - root -   Epoch: [8/300][180/200], lr: 0.00000012 	 loss = 0.3441(0.6203)
2024/03/04 00:38:25 - INFO - root -   Epoch: [8/300] 	 loss = 0.6194
2024/03/04 00:38:25 - INFO - root -   train_accuracy = 0.8050
2024/03/04 00:38:48 - INFO - root -   Epoch: [9/300][0/200], lr: 0.00000012 	 loss = 0.7607(0.7607)
2024/03/04 00:38:59 - INFO - root -   Epoch: [9/300][20/200], lr: 0.00000012 	 loss = 0.1214(0.5399)
2024/03/04 00:39:16 - INFO - root -   Epoch: [9/300][40/200], lr: 0.00000012 	 loss = 0.1888(0.5092)
2024/03/04 00:39:28 - INFO - root -   Epoch: [9/300][60/200], lr: 0.00000012 	 loss = 0.0439(0.5335)
2024/03/04 00:39:50 - INFO - root -   Epoch: [9/300][80/200], lr: 0.00000012 	 loss = 1.4173(0.5487)
2024/03/04 00:39:57 - INFO - root -   Epoch: [9/300][100/200], lr: 0.00000012 	 loss = 0.0773(0.5323)
2024/03/04 00:40:13 - INFO - root -   Epoch: [9/300][120/200], lr: 0.00000012 	 loss = 2.6008(0.5129)
2024/03/04 00:40:26 - INFO - root -   Epoch: [9/300][140/200], lr: 0.00000012 	 loss = 2.1271(0.5543)
2024/03/04 00:40:45 - INFO - root -   Epoch: [9/300][160/200], lr: 0.00000012 	 loss = 0.2839(0.5613)
2024/03/04 00:40:55 - INFO - root -   Epoch: [9/300][180/200], lr: 0.00000012 	 loss = 0.2337(0.5739)
2024/03/04 00:41:05 - INFO - root -   Epoch: [9/300] 	 loss = 0.5786
2024/03/04 00:41:08 - INFO - root -   precision = 0.7778
2024/03/04 00:41:08 - INFO - root -   eval_loss = 0.6831
2024/03/04 00:41:08 - INFO - root -   eval_acc = 0.7778
2024/03/04 00:41:09 - INFO - root -   train_accuracy = 0.8150
2024/03/04 00:41:12 - INFO - root -   Epoch: [10/300][0/200], lr: 0.00000012 	 loss = 0.5590(0.5590)
2024/03/04 00:41:46 - INFO - root -   Epoch: [10/300][20/200], lr: 0.00000012 	 loss = 0.2965(0.8673)
2024/03/04 00:42:00 - INFO - root -   Epoch: [10/300][40/200], lr: 0.00000012 	 loss = 0.1469(0.6672)
2024/03/04 00:42:08 - INFO - root -   Epoch: [10/300][60/200], lr: 0.00000012 	 loss = 0.0152(0.6336)
2024/03/04 00:42:20 - INFO - root -   Epoch: [10/300][80/200], lr: 0.00000012 	 loss = 2.2166(0.6176)
2024/03/04 00:42:36 - INFO - root -   Epoch: [10/300][100/200], lr: 0.00000012 	 loss = 0.4003(0.6007)
2024/03/04 00:42:54 - INFO - root -   Epoch: [10/300][120/200], lr: 0.00000012 	 loss = 2.9809(0.5781)
2024/03/04 00:43:19 - INFO - root -   Epoch: [10/300][140/200], lr: 0.00000012 	 loss = 1.1659(0.5952)
2024/03/04 00:43:29 - INFO - root -   Epoch: [10/300][160/200], lr: 0.00000012 	 loss = 0.1167(0.5884)
2024/03/04 00:43:50 - INFO - root -   Epoch: [10/300][180/200], lr: 0.00000012 	 loss = 0.2348(0.6066)
2024/03/04 00:43:57 - INFO - root -   Epoch: [10/300] 	 loss = 0.5961
2024/03/04 00:43:57 - INFO - root -   train_accuracy = 0.8100
2024/03/04 00:44:12 - INFO - root -   Epoch: [11/300][0/200], lr: 0.00000013 	 loss = 1.2346(1.2346)
2024/03/04 00:44:36 - INFO - root -   Epoch: [11/300][20/200], lr: 0.00000013 	 loss = 0.6407(0.7600)
2024/03/04 00:44:48 - INFO - root -   Epoch: [11/300][40/200], lr: 0.00000013 	 loss = 0.3979(0.6017)
2024/03/04 00:45:08 - INFO - root -   Epoch: [11/300][60/200], lr: 0.00000013 	 loss = 0.1039(0.5643)
2024/03/04 00:45:25 - INFO - root -   Epoch: [11/300][80/200], lr: 0.00000013 	 loss = 0.7896(0.6029)
2024/03/04 00:45:39 - INFO - root -   Epoch: [11/300][100/200], lr: 0.00000013 	 loss = 0.1110(0.5709)
2024/03/04 00:45:55 - INFO - root -   Epoch: [11/300][120/200], lr: 0.00000013 	 loss = 2.5901(0.5589)
2024/03/04 00:46:04 - INFO - root -   Epoch: [11/300][140/200], lr: 0.00000013 	 loss = 1.6698(0.5705)
2024/03/04 00:46:24 - INFO - root -   Epoch: [11/300][160/200], lr: 0.00000013 	 loss = 0.1305(0.5883)
2024/03/04 00:46:39 - INFO - root -   Epoch: [11/300][180/200], lr: 0.00000013 	 loss = 0.1309(0.5938)
2024/03/04 00:46:47 - INFO - root -   Epoch: [11/300] 	 loss = 0.5984
2024/03/04 00:46:47 - INFO - root -   train_accuracy = 0.8075
2024/03/04 00:47:07 - INFO - root -   Epoch: [12/300][0/200], lr: 0.00000013 	 loss = 1.1522(1.1522)
2024/03/04 00:47:28 - INFO - root -   Epoch: [12/300][20/200], lr: 0.00000013 	 loss = 0.4047(0.7468)
2024/03/04 00:47:35 - INFO - root -   Epoch: [12/300][40/200], lr: 0.00000013 	 loss = 0.6033(0.5680)
2024/03/04 00:47:55 - INFO - root -   Epoch: [12/300][60/200], lr: 0.00000013 	 loss = 0.2908(0.5374)
2024/03/04 00:48:07 - INFO - root -   Epoch: [12/300][80/200], lr: 0.00000013 	 loss = 1.7172(0.5900)
2024/03/04 00:48:26 - INFO - root -   Epoch: [12/300][100/200], lr: 0.00000013 	 loss = 0.4580(0.5735)
2024/03/04 00:48:51 - INFO - root -   Epoch: [12/300][120/200], lr: 0.00000013 	 loss = 1.5303(0.5510)
2024/03/04 00:49:07 - INFO - root -   Epoch: [12/300][140/200], lr: 0.00000013 	 loss = 2.0330(0.5678)
2024/03/04 00:49:17 - INFO - root -   Epoch: [12/300][160/200], lr: 0.00000013 	 loss = 0.0421(0.5549)
2024/03/04 00:49:32 - INFO - root -   Epoch: [12/300][180/200], lr: 0.00000013 	 loss = 0.5566(0.5690)
2024/03/04 00:49:40 - INFO - root -   Epoch: [12/300] 	 loss = 0.5729
2024/03/04 00:49:40 - INFO - root -   train_accuracy = 0.8250
2024/03/04 00:49:55 - INFO - root -   Epoch: [13/300][0/200], lr: 0.00000013 	 loss = 1.0470(1.0470)
2024/03/04 00:50:20 - INFO - root -   Epoch: [13/300][20/200], lr: 0.00000013 	 loss = 0.1379(0.6642)
2024/03/04 00:50:33 - INFO - root -   Epoch: [13/300][40/200], lr: 0.00000013 	 loss = 0.4111(0.5622)
2024/03/04 00:50:45 - INFO - root -   Epoch: [13/300][60/200], lr: 0.00000013 	 loss = 0.0637(0.5921)
2024/03/04 00:51:06 - INFO - root -   Epoch: [13/300][80/200], lr: 0.00000013 	 loss = 0.6792(0.5674)
2024/03/04 00:51:14 - INFO - root -   Epoch: [13/300][100/200], lr: 0.00000013 	 loss = 0.2529(0.5494)
2024/03/04 00:51:33 - INFO - root -   Epoch: [13/300][120/200], lr: 0.00000013 	 loss = 2.7017(0.5329)
2024/03/04 00:51:49 - INFO - root -   Epoch: [13/300][140/200], lr: 0.00000013 	 loss = 1.3858(0.5512)
2024/03/04 00:52:02 - INFO - root -   Epoch: [13/300][160/200], lr: 0.00000013 	 loss = 0.2682(0.5527)
2024/03/04 00:52:15 - INFO - root -   Epoch: [13/300][180/200], lr: 0.00000013 	 loss = 0.5369(0.5700)
2024/03/04 00:52:23 - INFO - root -   Epoch: [13/300] 	 loss = 0.5697
2024/03/04 00:52:23 - INFO - root -   train_accuracy = 0.8050
2024/03/04 00:52:24 - INFO - root -   Epoch: [14/300][0/200], lr: 0.00000013 	 loss = 0.6928(0.6928)
2024/03/04 00:52:51 - INFO - root -   Epoch: [14/300][20/200], lr: 0.00000013 	 loss = 0.4947(0.7966)
2024/03/04 00:53:01 - INFO - root -   Epoch: [14/300][40/200], lr: 0.00000013 	 loss = 0.1176(0.6031)
2024/03/04 00:53:13 - INFO - root -   Epoch: [14/300][60/200], lr: 0.00000013 	 loss = 0.1353(0.5877)
2024/03/04 00:53:26 - INFO - root -   Epoch: [14/300][80/200], lr: 0.00000013 	 loss = 1.8816(0.5808)
2024/03/04 00:53:53 - INFO - root -   Epoch: [14/300][100/200], lr: 0.00000013 	 loss = 0.0984(0.5609)
2024/03/04 00:54:02 - INFO - root -   Epoch: [14/300][120/200], lr: 0.00000013 	 loss = 2.3367(0.5447)
2024/03/04 00:54:15 - INFO - root -   Epoch: [14/300][140/200], lr: 0.00000013 	 loss = 1.2275(0.5561)
2024/03/04 00:54:32 - INFO - root -   Epoch: [14/300][160/200], lr: 0.00000013 	 loss = 0.0548(0.5515)
2024/03/04 00:54:49 - INFO - root -   Epoch: [14/300][180/200], lr: 0.00000013 	 loss = 0.5529(0.5584)
2024/03/04 00:55:01 - INFO - root -   Epoch: [14/300] 	 loss = 0.5650
2024/03/04 00:55:04 - INFO - root -   precision = 0.7778
2024/03/04 00:55:04 - INFO - root -   eval_loss = 0.7307
2024/03/04 00:55:04 - INFO - root -   eval_acc = 0.7778
2024/03/04 00:55:05 - INFO - root -   train_accuracy = 0.7975
2024/03/04 00:55:06 - INFO - root -   Epoch: [15/300][0/200], lr: 0.00000014 	 loss = 0.9321(0.9321)
2024/03/04 00:55:33 - INFO - root -   Epoch: [15/300][20/200], lr: 0.00000014 	 loss = 0.7654(0.6984)
2024/03/04 00:55:50 - INFO - root -   Epoch: [15/300][40/200], lr: 0.00000014 	 loss = 0.6351(0.6182)
2024/03/04 00:56:02 - INFO - root -   Epoch: [15/300][60/200], lr: 0.00000014 	 loss = 0.0544(0.5860)
2024/03/04 00:56:10 - INFO - root -   Epoch: [15/300][80/200], lr: 0.00000014 	 loss = 1.0253(0.5375)
2024/03/04 00:56:37 - INFO - root -   Epoch: [15/300][100/200], lr: 0.00000014 	 loss = 0.3635(0.5386)
2024/03/04 00:56:52 - INFO - root -   Epoch: [15/300][120/200], lr: 0.00000014 	 loss = 2.0365(0.5347)
2024/03/04 00:57:09 - INFO - root -   Epoch: [15/300][140/200], lr: 0.00000014 	 loss = 1.6320(0.5449)
2024/03/04 00:57:26 - INFO - root -   Epoch: [15/300][160/200], lr: 0.00000014 	 loss = 0.0726(0.5421)
2024/03/04 00:57:40 - INFO - root -   Epoch: [15/300][180/200], lr: 0.00000014 	 loss = 0.3544(0.5476)
2024/03/04 00:57:48 - INFO - root -   Epoch: [15/300] 	 loss = 0.5463
2024/03/04 00:57:48 - INFO - root -   train_accuracy = 0.8200
2024/03/04 00:58:02 - INFO - root -   Epoch: [16/300][0/200], lr: 0.00000014 	 loss = 1.0563(1.0563)
2024/03/04 00:58:12 - INFO - root -   Epoch: [16/300][20/200], lr: 0.00000014 	 loss = 0.7844(0.8285)
2024/03/04 00:58:28 - INFO - root -   Epoch: [16/300][40/200], lr: 0.00000014 	 loss = 0.5100(0.6528)
2024/03/04 00:58:44 - INFO - root -   Epoch: [16/300][60/200], lr: 0.00000014 	 loss = 0.0445(0.6126)
2024/03/04 00:58:58 - INFO - root -   Epoch: [16/300][80/200], lr: 0.00000014 	 loss = 1.5547(0.6414)
2024/03/04 00:59:18 - INFO - root -   Epoch: [16/300][100/200], lr: 0.00000014 	 loss = 0.1757(0.6171)
2024/03/04 00:59:26 - INFO - root -   Epoch: [16/300][120/200], lr: 0.00000014 	 loss = 2.4120(0.5936)
2024/03/04 00:59:43 - INFO - root -   Epoch: [16/300][140/200], lr: 0.00000014 	 loss = 1.6797(0.6006)
2024/03/04 00:59:55 - INFO - root -   Epoch: [16/300][160/200], lr: 0.00000014 	 loss = 0.2337(0.5837)
2024/03/04 01:00:14 - INFO - root -   Epoch: [16/300][180/200], lr: 0.00000014 	 loss = 0.2471(0.6006)
2024/03/04 01:00:21 - INFO - root -   Epoch: [16/300] 	 loss = 0.6014
2024/03/04 01:00:21 - INFO - root -   train_accuracy = 0.8125
2024/03/04 01:00:23 - INFO - root -   Epoch: [17/300][0/200], lr: 0.00000014 	 loss = 1.2462(1.2462)
2024/03/04 01:00:58 - INFO - root -   Epoch: [17/300][20/200], lr: 0.00000014 	 loss = 0.4419(0.7324)
2024/03/04 01:01:14 - INFO - root -   Epoch: [17/300][40/200], lr: 0.00000014 	 loss = 0.2005(0.5482)
2024/03/04 01:01:29 - INFO - root -   Epoch: [17/300][60/200], lr: 0.00000014 	 loss = 0.2228(0.5555)
2024/03/04 01:01:45 - INFO - root -   Epoch: [17/300][80/200], lr: 0.00000014 	 loss = 1.0571(0.5459)
2024/03/04 01:01:56 - INFO - root -   Epoch: [17/300][100/200], lr: 0.00000014 	 loss = 0.1075(0.5493)
2024/03/04 01:02:22 - INFO - root -   Epoch: [17/300][120/200], lr: 0.00000014 	 loss = 2.5338(0.5286)
2024/03/04 01:02:32 - INFO - root -   Epoch: [17/300][140/200], lr: 0.00000014 	 loss = 1.7054(0.5499)
2024/03/04 01:02:54 - INFO - root -   Epoch: [17/300][160/200], lr: 0.00000014 	 loss = 0.2965(0.5495)
2024/03/04 01:03:02 - INFO - root -   Epoch: [17/300][180/200], lr: 0.00000014 	 loss = 0.4750(0.5672)
2024/03/04 01:03:09 - INFO - root -   Epoch: [17/300] 	 loss = 0.5720
2024/03/04 01:03:09 - INFO - root -   train_accuracy = 0.8150
2024/03/04 01:03:25 - INFO - root -   Epoch: [18/300][0/200], lr: 0.00000014 	 loss = 1.8030(1.8030)
2024/03/04 01:03:37 - INFO - root -   Epoch: [18/300][20/200], lr: 0.00000014 	 loss = 0.4575(0.7111)
2024/03/04 01:03:45 - INFO - root -   Epoch: [18/300][40/200], lr: 0.00000014 	 loss = 0.0964(0.5787)
2024/03/04 01:03:59 - INFO - root -   Epoch: [18/300][60/200], lr: 0.00000014 	 loss = 0.1790(0.5749)
2024/03/04 01:04:12 - INFO - root -   Epoch: [18/300][80/200], lr: 0.00000014 	 loss = 1.4114(0.5975)
2024/03/04 01:04:39 - INFO - root -   Epoch: [18/300][100/200], lr: 0.00000014 	 loss = 0.2328(0.5879)
2024/03/04 01:04:55 - INFO - root -   Epoch: [18/300][120/200], lr: 0.00000014 	 loss = 2.3954(0.5580)
2024/03/04 01:05:03 - INFO - root -   Epoch: [18/300][140/200], lr: 0.00000014 	 loss = 2.2779(0.5675)
2024/03/04 01:05:19 - INFO - root -   Epoch: [18/300][160/200], lr: 0.00000014 	 loss = 0.0697(0.5574)
2024/03/04 01:05:27 - INFO - root -   Epoch: [18/300][180/200], lr: 0.00000014 	 loss = 0.8197(0.5645)
2024/03/04 01:05:35 - INFO - root -   Epoch: [18/300] 	 loss = 0.5610
2024/03/04 01:05:35 - INFO - root -   train_accuracy = 0.8100
2024/03/04 01:05:50 - INFO - root -   Epoch: [19/300][0/200], lr: 0.00000015 	 loss = 0.7102(0.7102)
2024/03/04 01:06:11 - INFO - root -   Epoch: [19/300][20/200], lr: 0.00000015 	 loss = 0.3230(0.7164)
2024/03/04 01:06:19 - INFO - root -   Epoch: [19/300][40/200], lr: 0.00000015 	 loss = 0.1772(0.5352)
2024/03/04 01:06:28 - INFO - root -   Epoch: [19/300][60/200], lr: 0.00000015 	 loss = 0.0716(0.5009)
2024/03/04 01:06:46 - INFO - root -   Epoch: [19/300][80/200], lr: 0.00000015 	 loss = 1.4783(0.5196)
2024/03/04 01:07:01 - INFO - root -   Epoch: [19/300][100/200], lr: 0.00000015 	 loss = 0.3206(0.5232)
2024/03/04 01:07:10 - INFO - root -   Epoch: [19/300][120/200], lr: 0.00000015 	 loss = 2.2853(0.5099)
2024/03/04 01:07:30 - INFO - root -   Epoch: [19/300][140/200], lr: 0.00000015 	 loss = 1.3067(0.5153)
2024/03/04 01:07:41 - INFO - root -   Epoch: [19/300][160/200], lr: 0.00000015 	 loss = 0.0546(0.5205)
2024/03/04 01:07:55 - INFO - root -   Epoch: [19/300][180/200], lr: 0.00000015 	 loss = 0.4225(0.5266)
2024/03/04 01:08:03 - INFO - root -   Epoch: [19/300] 	 loss = 0.5297
2024/03/04 01:08:07 - INFO - root -   precision = 0.7556
2024/03/04 01:08:07 - INFO - root -   eval_loss = 0.7695
2024/03/04 01:08:07 - INFO - root -   eval_acc = 0.7556
2024/03/04 01:08:08 - INFO - root -   train_accuracy = 0.8300
2024/03/04 01:08:09 - INFO - root -   Epoch: [20/300][0/200], lr: 0.00000015 	 loss = 1.2576(1.2576)
2024/03/04 01:08:43 - INFO - root -   Epoch: [20/300][20/200], lr: 0.00000015 	 loss = 0.3383(0.7652)
2024/03/04 01:08:55 - INFO - root -   Epoch: [20/300][40/200], lr: 0.00000015 	 loss = 0.2527(0.6061)
2024/03/04 01:09:20 - INFO - root -   Epoch: [20/300][60/200], lr: 0.00000015 	 loss = 0.2464(0.5978)
2024/03/04 01:09:31 - INFO - root -   Epoch: [20/300][80/200], lr: 0.00000015 	 loss = 1.7196(0.5853)
2024/03/04 01:09:52 - INFO - root -   Epoch: [20/300][100/200], lr: 0.00000015 	 loss = 0.2371(0.5693)
2024/03/04 01:10:06 - INFO - root -   Epoch: [20/300][120/200], lr: 0.00000015 	 loss = 2.8170(0.5630)
2024/03/04 01:10:18 - INFO - root -   Epoch: [20/300][140/200], lr: 0.00000015 	 loss = 2.2825(0.5827)
2024/03/04 01:10:28 - INFO - root -   Epoch: [20/300][160/200], lr: 0.00000015 	 loss = 0.2838(0.5766)
2024/03/04 01:10:45 - INFO - root -   Epoch: [20/300][180/200], lr: 0.00000015 	 loss = 0.0707(0.5807)
2024/03/04 01:10:53 - INFO - root -   Epoch: [20/300] 	 loss = 0.5790
2024/03/04 01:10:53 - INFO - root -   train_accuracy = 0.8225
2024/03/04 01:11:12 - INFO - root -   Epoch: [21/300][0/200], lr: 0.00000015 	 loss = 1.8537(1.8537)
2024/03/04 01:11:23 - INFO - root -   Epoch: [21/300][20/200], lr: 0.00000015 	 loss = 0.8828(0.7622)
2024/03/04 01:11:35 - INFO - root -   Epoch: [21/300][40/200], lr: 0.00000015 	 loss = 0.8724(0.6577)
2024/03/04 01:11:58 - INFO - root -   Epoch: [21/300][60/200], lr: 0.00000015 	 loss = 0.1301(0.6122)
2024/03/04 01:12:09 - INFO - root -   Epoch: [21/300][80/200], lr: 0.00000015 	 loss = 1.6041(0.6079)
2024/03/04 01:12:29 - INFO - root -   Epoch: [21/300][100/200], lr: 0.00000015 	 loss = 0.0860(0.6104)
2024/03/04 01:12:37 - INFO - root -   Epoch: [21/300][120/200], lr: 0.00000015 	 loss = 3.2678(0.5875)
2024/03/04 01:12:56 - INFO - root -   Epoch: [21/300][140/200], lr: 0.00000015 	 loss = 1.7279(0.5848)
2024/03/04 01:13:15 - INFO - root -   Epoch: [21/300][160/200], lr: 0.00000015 	 loss = 0.0877(0.5806)
2024/03/04 01:13:24 - INFO - root -   Epoch: [21/300][180/200], lr: 0.00000015 	 loss = 0.2751(0.5938)
2024/03/04 01:13:31 - INFO - root -   Epoch: [21/300] 	 loss = 0.5892
2024/03/04 01:13:31 - INFO - root -   train_accuracy = 0.8000
2024/03/04 01:13:44 - INFO - root -   Epoch: [22/300][0/200], lr: 0.00000015 	 loss = 1.7065(1.7065)
2024/03/04 01:13:59 - INFO - root -   Epoch: [22/300][20/200], lr: 0.00000015 	 loss = 0.6829(0.7734)
2024/03/04 01:14:15 - INFO - root -   Epoch: [22/300][40/200], lr: 0.00000015 	 loss = 0.1218(0.5905)
2024/03/04 01:14:31 - INFO - root -   Epoch: [22/300][60/200], lr: 0.00000015 	 loss = 0.1758(0.5765)
2024/03/04 01:14:39 - INFO - root -   Epoch: [22/300][80/200], lr: 0.00000015 	 loss = 0.9118(0.5708)
2024/03/04 01:14:52 - INFO - root -   Epoch: [22/300][100/200], lr: 0.00000015 	 loss = 0.2128(0.5659)
2024/03/04 01:15:11 - INFO - root -   Epoch: [22/300][120/200], lr: 0.00000015 	 loss = 2.3530(0.5432)
2024/03/04 01:15:19 - INFO - root -   Epoch: [22/300][140/200], lr: 0.00000015 	 loss = 0.4934(0.5308)
2024/03/04 01:15:51 - INFO - root -   Epoch: [22/300][160/200], lr: 0.00000015 	 loss = 0.4841(0.5355)
2024/03/04 01:15:59 - INFO - root -   Epoch: [22/300][180/200], lr: 0.00000015 	 loss = 0.3020(0.5556)
2024/03/04 01:16:07 - INFO - root -   Epoch: [22/300] 	 loss = 0.5578
2024/03/04 01:16:07 - INFO - root -   train_accuracy = 0.8350
2024/03/04 01:16:08 - INFO - root -   Epoch: [23/300][0/200], lr: 0.00000016 	 loss = 1.1681(1.1681)
2024/03/04 01:16:33 - INFO - root -   Epoch: [23/300][20/200], lr: 0.00000016 	 loss = 0.6132(0.6778)
2024/03/04 01:16:42 - INFO - root -   Epoch: [23/300][40/200], lr: 0.00000016 	 loss = 0.1106(0.5393)
2024/03/04 01:16:58 - INFO - root -   Epoch: [23/300][60/200], lr: 0.00000016 	 loss = 0.1358(0.5120)
2024/03/04 01:17:06 - INFO - root -   Epoch: [23/300][80/200], lr: 0.00000016 	 loss = 1.3118(0.5594)
2024/03/04 01:17:22 - INFO - root -   Epoch: [23/300][100/200], lr: 0.00000016 	 loss = 0.3761(0.5468)
2024/03/04 01:17:44 - INFO - root -   Epoch: [23/300][120/200], lr: 0.00000016 	 loss = 1.8840(0.5204)
2024/03/04 01:17:59 - INFO - root -   Epoch: [23/300][140/200], lr: 0.00000016 	 loss = 2.4477(0.5524)
2024/03/04 01:18:21 - INFO - root -   Epoch: [23/300][160/200], lr: 0.00000016 	 loss = 0.0368(0.5599)
2024/03/04 01:18:29 - INFO - root -   Epoch: [23/300][180/200], lr: 0.00000016 	 loss = 0.1323(0.5639)
2024/03/04 01:18:37 - INFO - root -   Epoch: [23/300] 	 loss = 0.5675
2024/03/04 01:18:37 - INFO - root -   train_accuracy = 0.8025
2024/03/04 01:18:50 - INFO - root -   Epoch: [24/300][0/200], lr: 0.00000016 	 loss = 1.5189(1.5189)
2024/03/04 01:19:07 - INFO - root -   Epoch: [24/300][20/200], lr: 0.00000016 	 loss = 0.6651(0.6808)
2024/03/04 01:19:15 - INFO - root -   Epoch: [24/300][40/200], lr: 0.00000016 	 loss = 0.4705(0.5365)
2024/03/04 01:19:26 - INFO - root -   Epoch: [24/300][60/200], lr: 0.00000016 	 loss = 0.0443(0.4863)
2024/03/04 01:19:42 - INFO - root -   Epoch: [24/300][80/200], lr: 0.00000016 	 loss = 2.4326(0.5375)
2024/03/04 01:20:01 - INFO - root -   Epoch: [24/300][100/200], lr: 0.00000016 	 loss = 0.4079(0.5232)
2024/03/04 01:20:15 - INFO - root -   Epoch: [24/300][120/200], lr: 0.00000016 	 loss = 2.9813(0.5372)
2024/03/04 01:20:33 - INFO - root -   Epoch: [24/300][140/200], lr: 0.00000016 	 loss = 1.9883(0.5505)
2024/03/04 01:20:54 - INFO - root -   Epoch: [24/300][160/200], lr: 0.00000016 	 loss = 0.1727(0.5432)
2024/03/04 01:21:09 - INFO - root -   Epoch: [24/300][180/200], lr: 0.00000016 	 loss = 1.0003(0.5426)
2024/03/04 01:21:16 - INFO - root -   Epoch: [24/300] 	 loss = 0.5462
2024/03/04 01:21:20 - INFO - root -   precision = 0.7778
2024/03/04 01:21:20 - INFO - root -   eval_loss = 0.7976
2024/03/04 01:21:20 - INFO - root -   eval_acc = 0.7778
2024/03/04 01:21:21 - INFO - root -   train_accuracy = 0.8250
2024/03/04 01:21:43 - INFO - root -   Epoch: [25/300][0/200], lr: 0.00000016 	 loss = 0.9225(0.9225)
2024/03/04 01:22:00 - INFO - root -   Epoch: [25/300][20/200], lr: 0.00000016 	 loss = 0.7475(0.6442)
2024/03/04 01:22:08 - INFO - root -   Epoch: [25/300][40/200], lr: 0.00000016 	 loss = 0.2527(0.5556)
2024/03/04 01:22:30 - INFO - root -   Epoch: [25/300][60/200], lr: 0.00000016 	 loss = 0.0569(0.5563)
2024/03/04 01:22:38 - INFO - root -   Epoch: [25/300][80/200], lr: 0.00000016 	 loss = 1.2806(0.5456)
2024/03/04 01:22:50 - INFO - root -   Epoch: [25/300][100/200], lr: 0.00000016 	 loss = 0.1266(0.5122)
2024/03/04 01:23:01 - INFO - root -   Epoch: [25/300][120/200], lr: 0.00000016 	 loss = 3.1285(0.5159)
2024/03/04 01:23:15 - INFO - root -   Epoch: [25/300][140/200], lr: 0.00000016 	 loss = 1.9650(0.5301)
2024/03/04 01:23:34 - INFO - root -   Epoch: [25/300][160/200], lr: 0.00000016 	 loss = 0.1392(0.5164)
2024/03/04 01:23:42 - INFO - root -   Epoch: [25/300][180/200], lr: 0.00000016 	 loss = 0.4118(0.5230)
2024/03/04 01:23:55 - INFO - root -   Epoch: [25/300] 	 loss = 0.5222
2024/03/04 01:23:55 - INFO - root -   train_accuracy = 0.8250
2024/03/04 01:24:09 - INFO - root -   Epoch: [26/300][0/200], lr: 0.00000016 	 loss = 0.6949(0.6949)
2024/03/04 01:24:24 - INFO - root -   Epoch: [26/300][20/200], lr: 0.00000016 	 loss = 0.4966(0.7106)
2024/03/04 01:24:51 - INFO - root -   Epoch: [26/300][40/200], lr: 0.00000016 	 loss = 0.2266(0.6040)
2024/03/04 01:25:14 - INFO - root -   Epoch: [26/300][60/200], lr: 0.00000016 	 loss = 0.2285(0.6151)
2024/03/04 01:25:22 - INFO - root -   Epoch: [26/300][80/200], lr: 0.00000016 	 loss = 1.3811(0.5859)
2024/03/04 01:25:37 - INFO - root -   Epoch: [26/300][100/200], lr: 0.00000016 	 loss = 0.3518(0.5736)
2024/03/04 01:25:53 - INFO - root -   Epoch: [26/300][120/200], lr: 0.00000016 	 loss = 1.8712(0.5461)
2024/03/04 01:26:01 - INFO - root -   Epoch: [26/300][140/200], lr: 0.00000016 	 loss = 2.4695(0.5767)
2024/03/04 01:26:28 - INFO - root -   Epoch: [26/300][160/200], lr: 0.00000016 	 loss = 0.6578(0.5716)
2024/03/04 01:26:36 - INFO - root -   Epoch: [26/300][180/200], lr: 0.00000016 	 loss = 0.0538(0.5816)
2024/03/04 01:26:44 - INFO - root -   Epoch: [26/300] 	 loss = 0.5798
2024/03/04 01:26:44 - INFO - root -   train_accuracy = 0.7950
2024/03/04 01:27:11 - INFO - root -   Epoch: [27/300][0/200], lr: 0.00000017 	 loss = 1.4964(1.4964)
2024/03/04 01:27:19 - INFO - root -   Epoch: [27/300][20/200], lr: 0.00000017 	 loss = 0.3300(0.6004)
2024/03/04 01:27:44 - INFO - root -   Epoch: [27/300][40/200], lr: 0.00000017 	 loss = 0.2083(0.5374)
2024/03/04 01:27:56 - INFO - root -   Epoch: [27/300][60/200], lr: 0.00000017 	 loss = 0.0775(0.5525)
2024/03/04 01:28:14 - INFO - root -   Epoch: [27/300][80/200], lr: 0.00000017 	 loss = 1.0879(0.5520)
2024/03/04 01:28:26 - INFO - root -   Epoch: [27/300][100/200], lr: 0.00000017 	 loss = 0.0901(0.5486)
2024/03/04 01:28:46 - INFO - root -   Epoch: [27/300][120/200], lr: 0.00000017 	 loss = 2.3164(0.5329)
2024/03/04 01:29:02 - INFO - root -   Epoch: [27/300][140/200], lr: 0.00000017 	 loss = 1.7752(0.5334)
2024/03/04 01:29:09 - INFO - root -   Epoch: [27/300][160/200], lr: 0.00000017 	 loss = 0.1533(0.5384)
2024/03/04 01:29:26 - INFO - root -   Epoch: [27/300][180/200], lr: 0.00000017 	 loss = 0.2051(0.5498)
2024/03/04 01:29:34 - INFO - root -   Epoch: [27/300] 	 loss = 0.5431
2024/03/04 01:29:34 - INFO - root -   train_accuracy = 0.8100
2024/03/04 01:29:50 - INFO - root -   Epoch: [28/300][0/200], lr: 0.00000017 	 loss = 0.7096(0.7096)
2024/03/04 01:30:05 - INFO - root -   Epoch: [28/300][20/200], lr: 0.00000017 	 loss = 0.7922(0.5775)
2024/03/04 01:30:21 - INFO - root -   Epoch: [28/300][40/200], lr: 0.00000017 	 loss = 0.2278(0.5226)
2024/03/04 01:30:41 - INFO - root -   Epoch: [28/300][60/200], lr: 0.00000017 	 loss = 0.0296(0.5153)
2024/03/04 01:30:49 - INFO - root -   Epoch: [28/300][80/200], lr: 0.00000017 	 loss = 1.2192(0.5288)
2024/03/04 01:31:10 - INFO - root -   Epoch: [28/300][100/200], lr: 0.00000017 	 loss = 0.0884(0.5297)
2024/03/04 01:31:32 - INFO - root -   Epoch: [28/300][120/200], lr: 0.00000017 	 loss = 1.9269(0.4979)
2024/03/04 01:31:39 - INFO - root -   Epoch: [28/300][140/200], lr: 0.00000017 	 loss = 1.4535(0.5177)
2024/03/04 01:31:52 - INFO - root -   Epoch: [28/300][160/200], lr: 0.00000017 	 loss = 0.1495(0.5050)
2024/03/04 01:32:03 - INFO - root -   Epoch: [28/300][180/200], lr: 0.00000017 	 loss = 0.4769(0.5077)
2024/03/04 01:32:11 - INFO - root -   Epoch: [28/300] 	 loss = 0.5140
2024/03/04 01:32:11 - INFO - root -   train_accuracy = 0.8300
2024/03/04 01:32:12 - INFO - root -   Epoch: [29/300][0/200], lr: 0.00000017 	 loss = 1.0153(1.0153)
2024/03/04 01:32:44 - INFO - root -   Epoch: [29/300][20/200], lr: 0.00000017 	 loss = 0.2085(0.5343)
2024/03/04 01:33:02 - INFO - root -   Epoch: [29/300][40/200], lr: 0.00000017 	 loss = 0.4483(0.4444)
2024/03/04 01:33:14 - INFO - root -   Epoch: [29/300][60/200], lr: 0.00000017 	 loss = 0.0412(0.4882)
2024/03/04 01:33:28 - INFO - root -   Epoch: [29/300][80/200], lr: 0.00000017 	 loss = 1.1813(0.5047)
2024/03/04 01:33:43 - INFO - root -   Epoch: [29/300][100/200], lr: 0.00000017 	 loss = 0.0705(0.4857)
2024/03/04 01:33:53 - INFO - root -   Epoch: [29/300][120/200], lr: 0.00000017 	 loss = 1.9652(0.4833)
2024/03/04 01:34:09 - INFO - root -   Epoch: [29/300][140/200], lr: 0.00000017 	 loss = 1.3900(0.5030)
2024/03/04 01:34:29 - INFO - root -   Epoch: [29/300][160/200], lr: 0.00000017 	 loss = 0.1321(0.5052)
2024/03/04 01:34:43 - INFO - root -   Epoch: [29/300][180/200], lr: 0.00000017 	 loss = 0.1776(0.5078)
2024/03/04 01:34:50 - INFO - root -   Epoch: [29/300] 	 loss = 0.5030
2024/03/04 01:34:54 - INFO - root -   precision = 0.7333
2024/03/04 01:34:54 - INFO - root -   eval_loss = 0.8288
2024/03/04 01:34:54 - INFO - root -   eval_acc = 0.7333
2024/03/04 01:34:55 - INFO - root -   train_accuracy = 0.8325
2024/03/04 01:35:10 - INFO - root -   Epoch: [30/300][0/200], lr: 0.00000017 	 loss = 1.3116(1.3116)
2024/03/04 01:35:32 - INFO - root -   Epoch: [30/300][20/200], lr: 0.00000017 	 loss = 0.2211(0.7116)
2024/03/04 01:35:54 - INFO - root -   Epoch: [30/300][40/200], lr: 0.00000017 	 loss = 0.3830(0.5852)
2024/03/04 01:36:03 - INFO - root -   Epoch: [30/300][60/200], lr: 0.00000017 	 loss = 0.0515(0.5218)
2024/03/04 01:36:20 - INFO - root -   Epoch: [30/300][80/200], lr: 0.00000017 	 loss = 1.3302(0.5140)
2024/03/04 01:36:28 - INFO - root -   Epoch: [30/300][100/200], lr: 0.00000017 	 loss = 0.1034(0.4965)
2024/03/04 01:36:43 - INFO - root -   Epoch: [30/300][120/200], lr: 0.00000017 	 loss = 2.6656(0.4911)
2024/03/04 01:36:51 - INFO - root -   Epoch: [30/300][140/200], lr: 0.00000017 	 loss = 2.4029(0.5153)
2024/03/04 01:37:11 - INFO - root -   Epoch: [30/300][160/200], lr: 0.00000017 	 loss = 0.4163(0.5148)
2024/03/04 01:37:23 - INFO - root -   Epoch: [30/300][180/200], lr: 0.00000017 	 loss = 0.2480(0.5242)
2024/03/04 01:37:30 - INFO - root -   Epoch: [30/300] 	 loss = 0.5180
2024/03/04 01:37:30 - INFO - root -   train_accuracy = 0.8150
2024/03/04 01:37:33 - INFO - root -   Epoch: [31/300][0/200], lr: 0.00000018 	 loss = 0.2189(0.2189)
2024/03/04 01:38:06 - INFO - root -   Epoch: [31/300][20/200], lr: 0.00000018 	 loss = 0.5692(0.7319)
2024/03/04 01:38:14 - INFO - root -   Epoch: [31/300][40/200], lr: 0.00000018 	 loss = 0.7327(0.5645)
2024/03/04 01:38:22 - INFO - root -   Epoch: [31/300][60/200], lr: 0.00000018 	 loss = 0.0922(0.5001)
2024/03/04 01:38:34 - INFO - root -   Epoch: [31/300][80/200], lr: 0.00000018 	 loss = 0.6203(0.5018)
2024/03/04 01:38:47 - INFO - root -   Epoch: [31/300][100/200], lr: 0.00000018 	 loss = 0.0876(0.5048)
2024/03/04 01:38:57 - INFO - root -   Epoch: [31/300][120/200], lr: 0.00000018 	 loss = 2.0509(0.4997)
2024/03/04 01:39:20 - INFO - root -   Epoch: [31/300][140/200], lr: 0.00000018 	 loss = 2.3629(0.5312)
2024/03/04 01:39:28 - INFO - root -   Epoch: [31/300][160/200], lr: 0.00000018 	 loss = 0.0788(0.5255)
2024/03/04 01:39:41 - INFO - root -   Epoch: [31/300][180/200], lr: 0.00000018 	 loss = 0.5888(0.5426)
2024/03/04 01:39:48 - INFO - root -   Epoch: [31/300] 	 loss = 0.5359
2024/03/04 01:39:48 - INFO - root -   train_accuracy = 0.8250
2024/03/04 01:40:15 - INFO - root -   Epoch: [32/300][0/200], lr: 0.00000018 	 loss = 1.4178(1.4178)
2024/03/04 01:40:25 - INFO - root -   Epoch: [32/300][20/200], lr: 0.00000018 	 loss = 0.6911(0.5337)
2024/03/04 01:40:40 - INFO - root -   Epoch: [32/300][40/200], lr: 0.00000018 	 loss = 0.1596(0.4534)
2024/03/04 01:40:59 - INFO - root -   Epoch: [32/300][60/200], lr: 0.00000018 	 loss = 0.0602(0.4875)
2024/03/04 01:41:08 - INFO - root -   Epoch: [32/300][80/200], lr: 0.00000018 	 loss = 1.8760(0.5383)
2024/03/04 01:41:26 - INFO - root -   Epoch: [32/300][100/200], lr: 0.00000018 	 loss = 0.2290(0.5202)
2024/03/04 01:41:37 - INFO - root -   Epoch: [32/300][120/200], lr: 0.00000018 	 loss = 1.5383(0.4942)
2024/03/04 01:42:01 - INFO - root -   Epoch: [32/300][140/200], lr: 0.00000018 	 loss = 1.4553(0.5078)
2024/03/04 01:42:14 - INFO - root -   Epoch: [32/300][160/200], lr: 0.00000018 	 loss = 0.1198(0.5094)
2024/03/04 01:42:27 - INFO - root -   Epoch: [32/300][180/200], lr: 0.00000018 	 loss = 0.0915(0.5089)
2024/03/04 01:42:35 - INFO - root -   Epoch: [32/300] 	 loss = 0.5107
2024/03/04 01:42:35 - INFO - root -   train_accuracy = 0.8275
2024/03/04 01:42:36 - INFO - root -   Epoch: [33/300][0/200], lr: 0.00000018 	 loss = 0.6273(0.6273)
2024/03/04 01:43:12 - INFO - root -   Epoch: [33/300][20/200], lr: 0.00000018 	 loss = 0.3059(0.6391)
2024/03/04 01:43:20 - INFO - root -   Epoch: [33/300][40/200], lr: 0.00000018 	 loss = 0.7988(0.5470)
2024/03/04 01:43:32 - INFO - root -   Epoch: [33/300][60/200], lr: 0.00000018 	 loss = 0.3132(0.5710)
2024/03/04 01:43:46 - INFO - root -   Epoch: [33/300][80/200], lr: 0.00000018 	 loss = 1.6339(0.5553)
2024/03/04 01:44:04 - INFO - root -   Epoch: [33/300][100/200], lr: 0.00000018 	 loss = 0.1072(0.5289)
2024/03/04 01:44:24 - INFO - root -   Epoch: [33/300][120/200], lr: 0.00000018 	 loss = 2.2075(0.5059)
2024/03/04 01:44:33 - INFO - root -   Epoch: [33/300][140/200], lr: 0.00000018 	 loss = 1.6153(0.5357)
2024/03/04 01:44:48 - INFO - root -   Epoch: [33/300][160/200], lr: 0.00000018 	 loss = 0.2276(0.5332)
2024/03/04 01:45:01 - INFO - root -   Epoch: [33/300][180/200], lr: 0.00000018 	 loss = 0.8290(0.5380)
2024/03/04 01:45:09 - INFO - root -   Epoch: [33/300] 	 loss = 0.5253
2024/03/04 01:45:09 - INFO - root -   train_accuracy = 0.8200
2024/03/04 01:45:11 - INFO - root -   Epoch: [34/300][0/200], lr: 0.00000018 	 loss = 0.9809(0.9809)
2024/03/04 01:45:31 - INFO - root -   Epoch: [34/300][20/200], lr: 0.00000018 	 loss = 0.4730(0.7549)
2024/03/04 01:45:42 - INFO - root -   Epoch: [34/300][40/200], lr: 0.00000018 	 loss = 0.1366(0.5757)
2024/03/04 01:45:53 - INFO - root -   Epoch: [34/300][60/200], lr: 0.00000018 	 loss = 0.0828(0.5522)
2024/03/04 01:46:07 - INFO - root -   Epoch: [34/300][80/200], lr: 0.00000018 	 loss = 1.8109(0.5437)
2024/03/04 01:46:29 - INFO - root -   Epoch: [34/300][100/200], lr: 0.00000018 	 loss = 0.0999(0.5096)
2024/03/04 01:46:48 - INFO - root -   Epoch: [34/300][120/200], lr: 0.00000018 	 loss = 1.6884(0.5107)
2024/03/04 01:46:56 - INFO - root -   Epoch: [34/300][140/200], lr: 0.00000018 	 loss = 2.0057(0.5247)
2024/03/04 01:47:11 - INFO - root -   Epoch: [34/300][160/200], lr: 0.00000018 	 loss = 0.6938(0.5062)
2024/03/04 01:47:20 - INFO - root -   Epoch: [34/300][180/200], lr: 0.00000018 	 loss = 0.2298(0.5200)
2024/03/04 01:47:30 - INFO - root -   Epoch: [34/300] 	 loss = 0.5101
2024/03/04 01:47:34 - INFO - root -   precision = 0.7333
2024/03/04 01:47:34 - INFO - root -   eval_loss = 0.8553
2024/03/04 01:47:34 - INFO - root -   eval_acc = 0.7333
2024/03/04 01:47:35 - INFO - root -   train_accuracy = 0.8175
2024/03/04 01:47:37 - INFO - root -   Epoch: [35/300][0/200], lr: 0.00000019 	 loss = 1.1397(1.1397)
2024/03/04 01:48:10 - INFO - root -   Epoch: [35/300][20/200], lr: 0.00000019 	 loss = 0.8272(0.6675)
2024/03/04 01:48:24 - INFO - root -   Epoch: [35/300][40/200], lr: 0.00000019 	 loss = 0.5026(0.4931)
2024/03/04 01:48:46 - INFO - root -   Epoch: [35/300][60/200], lr: 0.00000019 	 loss = 0.0440(0.5053)
2024/03/04 01:49:01 - INFO - root -   Epoch: [35/300][80/200], lr: 0.00000019 	 loss = 1.4407(0.4699)
2024/03/04 01:49:10 - INFO - root -   Epoch: [35/300][100/200], lr: 0.00000019 	 loss = 0.1353(0.4747)
2024/03/04 01:49:26 - INFO - root -   Epoch: [35/300][120/200], lr: 0.00000019 	 loss = 2.6280(0.4671)
2024/03/04 01:49:50 - INFO - root -   Epoch: [35/300][140/200], lr: 0.00000019 	 loss = 2.3348(0.4752)
2024/03/04 01:49:58 - INFO - root -   Epoch: [35/300][160/200], lr: 0.00000019 	 loss = 0.1254(0.4601)
2024/03/04 01:50:06 - INFO - root -   Epoch: [35/300][180/200], lr: 0.00000019 	 loss = 0.2601(0.4715)
2024/03/04 01:50:13 - INFO - root -   Epoch: [35/300] 	 loss = 0.4664
2024/03/04 01:50:13 - INFO - root -   train_accuracy = 0.8400
2024/03/04 01:50:15 - INFO - root -   Epoch: [36/300][0/200], lr: 0.00000019 	 loss = 1.0447(1.0447)
2024/03/04 01:50:42 - INFO - root -   Epoch: [36/300][20/200], lr: 0.00000019 	 loss = 0.1246(0.7021)
2024/03/04 01:50:52 - INFO - root -   Epoch: [36/300][40/200], lr: 0.00000019 	 loss = 0.8741(0.5936)
2024/03/04 01:51:08 - INFO - root -   Epoch: [36/300][60/200], lr: 0.00000019 	 loss = 0.0722(0.5545)
2024/03/04 01:51:18 - INFO - root -   Epoch: [36/300][80/200], lr: 0.00000019 	 loss = 1.1916(0.5497)
2024/03/04 01:51:44 - INFO - root -   Epoch: [36/300][100/200], lr: 0.00000019 	 loss = 0.1241(0.5452)
2024/03/04 01:51:58 - INFO - root -   Epoch: [36/300][120/200], lr: 0.00000019 	 loss = 1.8187(0.5127)
2024/03/04 01:52:17 - INFO - root -   Epoch: [36/300][140/200], lr: 0.00000019 	 loss = 1.8260(0.5350)
2024/03/04 01:52:32 - INFO - root -   Epoch: [36/300][160/200], lr: 0.00000019 	 loss = 0.2265(0.5421)
2024/03/04 01:52:47 - INFO - root -   Epoch: [36/300][180/200], lr: 0.00000019 	 loss = 0.0651(0.5579)
2024/03/04 01:52:55 - INFO - root -   Epoch: [36/300] 	 loss = 0.5590
2024/03/04 01:52:55 - INFO - root -   train_accuracy = 0.8125
2024/03/04 01:52:56 - INFO - root -   Epoch: [37/300][0/200], lr: 0.00000019 	 loss = 0.6962(0.6962)
2024/03/04 01:53:19 - INFO - root -   Epoch: [37/300][20/200], lr: 0.00000019 	 loss = 0.2990(0.5590)
2024/03/04 01:53:35 - INFO - root -   Epoch: [37/300][40/200], lr: 0.00000019 	 loss = 1.1651(0.5188)
2024/03/04 01:53:50 - INFO - root -   Epoch: [37/300][60/200], lr: 0.00000019 	 loss = 0.5822(0.5106)
2024/03/04 01:54:14 - INFO - root -   Epoch: [37/300][80/200], lr: 0.00000019 	 loss = 2.0005(0.5321)
2024/03/04 01:54:23 - INFO - root -   Epoch: [37/300][100/200], lr: 0.00000019 	 loss = 0.2406(0.5260)
2024/03/04 01:54:34 - INFO - root -   Epoch: [37/300][120/200], lr: 0.00000019 	 loss = 1.8002(0.4971)
2024/03/04 01:54:52 - INFO - root -   Epoch: [37/300][140/200], lr: 0.00000019 	 loss = 2.0656(0.5280)
2024/03/04 01:55:09 - INFO - root -   Epoch: [37/300][160/200], lr: 0.00000019 	 loss = 0.1783(0.5218)
2024/03/04 01:55:16 - INFO - root -   Epoch: [37/300][180/200], lr: 0.00000019 	 loss = 0.0922(0.5266)
2024/03/04 01:55:24 - INFO - root -   Epoch: [37/300] 	 loss = 0.5342
2024/03/04 01:55:24 - INFO - root -   train_accuracy = 0.8125
2024/03/04 01:55:50 - INFO - root -   Epoch: [38/300][0/200], lr: 0.00000019 	 loss = 2.0460(2.0460)
2024/03/04 01:55:58 - INFO - root -   Epoch: [38/300][20/200], lr: 0.00000019 	 loss = 0.9247(0.8581)
2024/03/04 01:56:12 - INFO - root -   Epoch: [38/300][40/200], lr: 0.00000019 	 loss = 0.2635(0.6474)
2024/03/04 01:56:26 - INFO - root -   Epoch: [38/300][60/200], lr: 0.00000019 	 loss = 0.1520(0.5726)
2024/03/04 01:56:39 - INFO - root -   Epoch: [38/300][80/200], lr: 0.00000019 	 loss = 1.1735(0.5655)
2024/03/04 01:56:57 - INFO - root -   Epoch: [38/300][100/200], lr: 0.00000019 	 loss = 0.0854(0.5459)
2024/03/04 01:57:20 - INFO - root -   Epoch: [38/300][120/200], lr: 0.00000019 	 loss = 3.5900(0.5390)
2024/03/04 01:57:28 - INFO - root -   Epoch: [38/300][140/200], lr: 0.00000019 	 loss = 2.5681(0.5490)
2024/03/04 01:57:41 - INFO - root -   Epoch: [38/300][160/200], lr: 0.00000019 	 loss = 0.6902(0.5438)
2024/03/04 01:57:59 - INFO - root -   Epoch: [38/300][180/200], lr: 0.00000019 	 loss = 0.0579(0.5539)
2024/03/04 01:58:07 - INFO - root -   Epoch: [38/300] 	 loss = 0.5561
2024/03/04 01:58:07 - INFO - root -   train_accuracy = 0.8225
2024/03/04 01:58:24 - INFO - root -   Epoch: [39/300][0/200], lr: 0.00000020 	 loss = 1.8433(1.8433)
2024/03/04 01:58:37 - INFO - root -   Epoch: [39/300][20/200], lr: 0.00000020 	 loss = 0.7249(0.7637)
2024/03/04 01:58:55 - INFO - root -   Epoch: [39/300][40/200], lr: 0.00000020 	 loss = 0.1894(0.5765)
2024/03/04 01:59:14 - INFO - root -   Epoch: [39/300][60/200], lr: 0.00000020 	 loss = 0.2518(0.5387)
2024/03/04 01:59:26 - INFO - root -   Epoch: [39/300][80/200], lr: 0.00000020 	 loss = 0.4059(0.5315)
2024/03/04 01:59:37 - INFO - root -   Epoch: [39/300][100/200], lr: 0.00000020 	 loss = 0.2324(0.5239)
2024/03/04 01:59:51 - INFO - root -   Epoch: [39/300][120/200], lr: 0.00000020 	 loss = 1.8643(0.5196)
2024/03/04 02:00:05 - INFO - root -   Epoch: [39/300][140/200], lr: 0.00000020 	 loss = 1.4311(0.5400)
2024/03/04 02:00:24 - INFO - root -   Epoch: [39/300][160/200], lr: 0.00000020 	 loss = 0.0246(0.5389)
2024/03/04 02:00:43 - INFO - root -   Epoch: [39/300][180/200], lr: 0.00000020 	 loss = 0.5779(0.5385)
2024/03/04 02:00:51 - INFO - root -   Epoch: [39/300] 	 loss = 0.5319
2024/03/04 02:00:55 - INFO - root -   precision = 0.7556
2024/03/04 02:00:55 - INFO - root -   eval_loss = 0.8802
2024/03/04 02:00:55 - INFO - root -   eval_acc = 0.7556
2024/03/04 02:00:56 - INFO - root -   train_accuracy = 0.8175
2024/03/04 02:00:57 - INFO - root -   Epoch: [40/300][0/200], lr: 0.00000020 	 loss = 1.1850(1.1850)
2024/03/04 02:01:27 - INFO - root -   Epoch: [40/300][20/200], lr: 0.00000020 	 loss = 0.6906(0.6692)
2024/03/04 02:01:37 - INFO - root -   Epoch: [40/300][40/200], lr: 0.00000020 	 loss = 0.2963(0.5416)
2024/03/04 02:01:57 - INFO - root -   Epoch: [40/300][60/200], lr: 0.00000020 	 loss = 0.1548(0.5035)
2024/03/04 02:02:06 - INFO - root -   Epoch: [40/300][80/200], lr: 0.00000020 	 loss = 1.0874(0.5017)
2024/03/04 02:02:28 - INFO - root -   Epoch: [40/300][100/200], lr: 0.00000020 	 loss = 0.0386(0.4914)
2024/03/04 02:02:40 - INFO - root -   Epoch: [40/300][120/200], lr: 0.00000020 	 loss = 2.6593(0.4724)
2024/03/04 02:03:10 - INFO - root -   Epoch: [40/300][140/200], lr: 0.00000020 	 loss = 1.5744(0.4791)
2024/03/04 02:03:18 - INFO - root -   Epoch: [40/300][160/200], lr: 0.00000020 	 loss = 0.5261(0.5058)
2024/03/04 02:03:32 - INFO - root -   Epoch: [40/300][180/200], lr: 0.00000020 	 loss = 0.0648(0.5055)
2024/03/04 02:03:39 - INFO - root -   Epoch: [40/300] 	 loss = 0.5142
2024/03/04 02:03:39 - INFO - root -   train_accuracy = 0.8100
2024/03/04 02:03:51 - INFO - root -   Epoch: [41/300][0/200], lr: 0.00000020 	 loss = 1.8316(1.8316)
2024/03/04 02:04:08 - INFO - root -   Epoch: [41/300][20/200], lr: 0.00000020 	 loss = 0.1148(0.7121)
2024/03/04 02:04:26 - INFO - root -   Epoch: [41/300][40/200], lr: 0.00000020 	 loss = 0.2178(0.5587)
2024/03/04 02:04:36 - INFO - root -   Epoch: [41/300][60/200], lr: 0.00000020 	 loss = 0.0423(0.5447)
2024/03/04 02:04:50 - INFO - root -   Epoch: [41/300][80/200], lr: 0.00000020 	 loss = 1.2437(0.5347)
2024/03/04 02:05:09 - INFO - root -   Epoch: [41/300][100/200], lr: 0.00000020 	 loss = 0.1574(0.5135)
2024/03/04 02:05:21 - INFO - root -   Epoch: [41/300][120/200], lr: 0.00000020 	 loss = 2.0076(0.4875)
2024/03/04 02:05:42 - INFO - root -   Epoch: [41/300][140/200], lr: 0.00000020 	 loss = 2.0112(0.4989)
2024/03/04 02:05:51 - INFO - root -   Epoch: [41/300][160/200], lr: 0.00000020 	 loss = 0.2200(0.4955)
2024/03/04 02:06:07 - INFO - root -   Epoch: [41/300][180/200], lr: 0.00000020 	 loss = 0.0470(0.5000)
2024/03/04 02:06:15 - INFO - root -   Epoch: [41/300] 	 loss = 0.4941
2024/03/04 02:06:15 - INFO - root -   train_accuracy = 0.8300
2024/03/04 02:06:29 - INFO - root -   Epoch: [42/300][0/200], lr: 0.00000020 	 loss = 1.0699(1.0699)
2024/03/04 02:06:53 - INFO - root -   Epoch: [42/300][20/200], lr: 0.00000020 	 loss = 0.4794(0.6788)
2024/03/04 02:07:10 - INFO - root -   Epoch: [42/300][40/200], lr: 0.00000020 	 loss = 0.2746(0.5645)
2024/03/04 02:07:18 - INFO - root -   Epoch: [42/300][60/200], lr: 0.00000020 	 loss = 0.0520(0.5194)
2024/03/04 02:07:36 - INFO - root -   Epoch: [42/300][80/200], lr: 0.00000020 	 loss = 0.7963(0.5148)
2024/03/04 02:07:58 - INFO - root -   Epoch: [42/300][100/200], lr: 0.00000020 	 loss = 0.1973(0.5020)
2024/03/04 02:08:07 - INFO - root -   Epoch: [42/300][120/200], lr: 0.00000020 	 loss = 1.5785(0.4885)
2024/03/04 02:08:27 - INFO - root -   Epoch: [42/300][140/200], lr: 0.00000020 	 loss = 1.6827(0.5072)
2024/03/04 02:08:35 - INFO - root -   Epoch: [42/300][160/200], lr: 0.00000020 	 loss = 0.1908(0.5015)
2024/03/04 02:08:46 - INFO - root -   Epoch: [42/300][180/200], lr: 0.00000020 	 loss = 0.6561(0.5084)
2024/03/04 02:08:54 - INFO - root -   Epoch: [42/300] 	 loss = 0.4997
2024/03/04 02:08:54 - INFO - root -   train_accuracy = 0.8250
2024/03/04 02:08:55 - INFO - root -   Epoch: [43/300][0/200], lr: 0.00000021 	 loss = 1.0204(1.0204)
2024/03/04 02:09:19 - INFO - root -   Epoch: [43/300][20/200], lr: 0.00000021 	 loss = 1.0544(0.7369)
2024/03/04 02:09:27 - INFO - root -   Epoch: [43/300][40/200], lr: 0.00000021 	 loss = 0.3110(0.5698)
2024/03/04 02:09:48 - INFO - root -   Epoch: [43/300][60/200], lr: 0.00000021 	 loss = 0.4310(0.5414)
2024/03/04 02:09:56 - INFO - root -   Epoch: [43/300][80/200], lr: 0.00000021 	 loss = 2.0342(0.5641)
2024/03/04 02:10:09 - INFO - root -   Epoch: [43/300][100/200], lr: 0.00000021 	 loss = 0.0929(0.5364)
2024/03/04 02:10:28 - INFO - root -   Epoch: [43/300][120/200], lr: 0.00000021 	 loss = 2.5820(0.5232)
2024/03/04 02:10:42 - INFO - root -   Epoch: [43/300][140/200], lr: 0.00000021 	 loss = 3.1147(0.5509)
2024/03/04 02:10:53 - INFO - root -   Epoch: [43/300][160/200], lr: 0.00000021 	 loss = 0.6330(0.5453)
2024/03/04 02:11:04 - INFO - root -   Epoch: [43/300][180/200], lr: 0.00000021 	 loss = 0.2718(0.5494)
2024/03/04 02:11:16 - INFO - root -   Epoch: [43/300] 	 loss = 0.5544
2024/03/04 02:11:16 - INFO - root -   train_accuracy = 0.7950
2024/03/04 02:11:17 - INFO - root -   Epoch: [44/300][0/200], lr: 0.00000021 	 loss = 0.9378(0.9378)
2024/03/04 02:12:02 - INFO - root -   Epoch: [44/300][20/200], lr: 0.00000021 	 loss = 0.5259(0.6985)
2024/03/04 02:12:14 - INFO - root -   Epoch: [44/300][40/200], lr: 0.00000021 	 loss = 0.7416(0.5174)
2024/03/04 02:12:33 - INFO - root -   Epoch: [44/300][60/200], lr: 0.00000021 	 loss = 0.1772(0.4712)
2024/03/04 02:12:43 - INFO - root -   Epoch: [44/300][80/200], lr: 0.00000021 	 loss = 1.5174(0.4798)
2024/03/04 02:12:50 - INFO - root -   Epoch: [44/300][100/200], lr: 0.00000021 	 loss = 0.0893(0.4645)
2024/03/04 02:13:07 - INFO - root -   Epoch: [44/300][120/200], lr: 0.00000021 	 loss = 1.8575(0.4660)
2024/03/04 02:13:21 - INFO - root -   Epoch: [44/300][140/200], lr: 0.00000021 	 loss = 2.0219(0.4800)
2024/03/04 02:13:29 - INFO - root -   Epoch: [44/300][160/200], lr: 0.00000021 	 loss = 0.1551(0.4937)
2024/03/04 02:13:39 - INFO - root -   Epoch: [44/300][180/200], lr: 0.00000021 	 loss = 0.0862(0.4902)
2024/03/04 02:13:46 - INFO - root -   Epoch: [44/300] 	 loss = 0.4928
2024/03/04 02:13:50 - INFO - root -   precision = 0.7333
2024/03/04 02:13:50 - INFO - root -   eval_loss = 0.9228
2024/03/04 02:13:50 - INFO - root -   eval_acc = 0.7333
2024/03/04 02:13:51 - INFO - root -   train_accuracy = 0.8325
2024/03/04 02:14:12 - INFO - root -   Epoch: [45/300][0/200], lr: 0.00000021 	 loss = 1.7917(1.7917)
2024/03/04 02:14:30 - INFO - root -   Epoch: [45/300][20/200], lr: 0.00000021 	 loss = 0.3777(0.6427)
2024/03/04 02:14:42 - INFO - root -   Epoch: [45/300][40/200], lr: 0.00000021 	 loss = 0.3997(0.4791)
2024/03/04 02:15:07 - INFO - root -   Epoch: [45/300][60/200], lr: 0.00000021 	 loss = 0.3083(0.5338)
2024/03/04 02:15:24 - INFO - root -   Epoch: [45/300][80/200], lr: 0.00000021 	 loss = 1.7692(0.5771)
2024/03/04 02:15:34 - INFO - root -   Epoch: [45/300][100/200], lr: 0.00000021 	 loss = 0.1324(0.5577)
2024/03/04 02:15:52 - INFO - root -   Epoch: [45/300][120/200], lr: 0.00000021 	 loss = 1.1575(0.5299)
2024/03/04 02:16:05 - INFO - root -   Epoch: [45/300][140/200], lr: 0.00000021 	 loss = 1.6018(0.5465)
2024/03/04 02:16:27 - INFO - root -   Epoch: [45/300][160/200], lr: 0.00000021 	 loss = 0.0709(0.5355)
2024/03/04 02:16:35 - INFO - root -   Epoch: [45/300][180/200], lr: 0.00000021 	 loss = 0.0480(0.5392)
2024/03/04 02:16:42 - INFO - root -   Epoch: [45/300] 	 loss = 0.5389
2024/03/04 02:16:42 - INFO - root -   train_accuracy = 0.8200
2024/03/04 02:16:58 - INFO - root -   Epoch: [46/300][0/200], lr: 0.00000021 	 loss = 1.6435(1.6435)
2024/03/04 02:17:11 - INFO - root -   Epoch: [46/300][20/200], lr: 0.00000021 	 loss = 0.3404(0.5963)
2024/03/04 02:17:27 - INFO - root -   Epoch: [46/300][40/200], lr: 0.00000021 	 loss = 0.7049(0.5228)
2024/03/04 02:17:42 - INFO - root -   Epoch: [46/300][60/200], lr: 0.00000021 	 loss = 0.0755(0.4841)
2024/03/04 02:17:51 - INFO - root -   Epoch: [46/300][80/200], lr: 0.00000021 	 loss = 1.4631(0.4746)
2024/03/04 02:18:12 - INFO - root -   Epoch: [46/300][100/200], lr: 0.00000021 	 loss = 0.1384(0.4781)
2024/03/04 02:18:23 - INFO - root -   Epoch: [46/300][120/200], lr: 0.00000021 	 loss = 1.6641(0.4743)
2024/03/04 02:18:38 - INFO - root -   Epoch: [46/300][140/200], lr: 0.00000021 	 loss = 1.5939(0.4970)
2024/03/04 02:18:51 - INFO - root -   Epoch: [46/300][160/200], lr: 0.00000021 	 loss = 0.1704(0.4995)
2024/03/04 02:19:11 - INFO - root -   Epoch: [46/300][180/200], lr: 0.00000021 	 loss = 0.1763(0.5156)
2024/03/04 02:19:19 - INFO - root -   Epoch: [46/300] 	 loss = 0.5129
2024/03/04 02:19:19 - INFO - root -   train_accuracy = 0.8425
2024/03/04 02:19:21 - INFO - root -   Epoch: [47/300][0/200], lr: 0.00000022 	 loss = 1.6571(1.6571)
2024/03/04 02:19:50 - INFO - root -   Epoch: [47/300][20/200], lr: 0.00000022 	 loss = 0.3943(0.6692)
2024/03/04 02:19:58 - INFO - root -   Epoch: [47/300][40/200], lr: 0.00000022 	 loss = 0.5373(0.5489)
2024/03/04 02:20:06 - INFO - root -   Epoch: [47/300][60/200], lr: 0.00000022 	 loss = 0.0847(0.5401)
2024/03/04 02:20:36 - INFO - root -   Epoch: [47/300][80/200], lr: 0.00000022 	 loss = 1.5119(0.5667)
2024/03/04 02:20:56 - INFO - root -   Epoch: [47/300][100/200], lr: 0.00000022 	 loss = 0.2497(0.5455)
2024/03/04 02:21:04 - INFO - root -   Epoch: [47/300][120/200], lr: 0.00000022 	 loss = 1.8997(0.5168)
2024/03/04 02:21:16 - INFO - root -   Epoch: [47/300][140/200], lr: 0.00000022 	 loss = 1.9129(0.5222)
2024/03/04 02:21:35 - INFO - root -   Epoch: [47/300][160/200], lr: 0.00000022 	 loss = 0.1705(0.5156)
2024/03/04 02:21:53 - INFO - root -   Epoch: [47/300][180/200], lr: 0.00000022 	 loss = 0.1750(0.5117)
2024/03/04 02:22:00 - INFO - root -   Epoch: [47/300] 	 loss = 0.5002
2024/03/04 02:22:00 - INFO - root -   train_accuracy = 0.8200
2024/03/04 02:22:01 - INFO - root -   Epoch: [48/300][0/200], lr: 0.00000022 	 loss = 0.7533(0.7533)
2024/03/04 02:22:29 - INFO - root -   Epoch: [48/300][20/200], lr: 0.00000022 	 loss = 0.2746(0.5940)
2024/03/04 02:22:37 - INFO - root -   Epoch: [48/300][40/200], lr: 0.00000022 	 loss = 0.2812(0.5016)
2024/03/04 02:22:49 - INFO - root -   Epoch: [48/300][60/200], lr: 0.00000022 	 loss = 0.0550(0.5062)
2024/03/04 02:23:06 - INFO - root -   Epoch: [48/300][80/200], lr: 0.00000022 	 loss = 1.0939(0.5153)
2024/03/04 02:23:25 - INFO - root -   Epoch: [48/300][100/200], lr: 0.00000022 	 loss = 0.0870(0.4818)
2024/03/04 02:23:35 - INFO - root -   Epoch: [48/300][120/200], lr: 0.00000022 	 loss = 2.0109(0.4722)
2024/03/04 02:23:51 - INFO - root -   Epoch: [48/300][140/200], lr: 0.00000022 	 loss = 0.8877(0.4756)
2024/03/04 02:24:05 - INFO - root -   Epoch: [48/300][160/200], lr: 0.00000022 	 loss = 0.0748(0.4782)
2024/03/04 02:24:26 - INFO - root -   Epoch: [48/300][180/200], lr: 0.00000022 	 loss = 0.3190(0.4878)
2024/03/04 02:24:34 - INFO - root -   Epoch: [48/300] 	 loss = 0.4835
2024/03/04 02:24:34 - INFO - root -   train_accuracy = 0.8200
2024/03/04 02:24:35 - INFO - root -   Epoch: [49/300][0/200], lr: 0.00000022 	 loss = 0.7747(0.7747)
2024/03/04 02:25:07 - INFO - root -   Epoch: [49/300][20/200], lr: 0.00000022 	 loss = 0.0809(0.7206)
2024/03/04 02:25:15 - INFO - root -   Epoch: [49/300][40/200], lr: 0.00000022 	 loss = 0.4782(0.5355)
2024/03/04 02:25:41 - INFO - root -   Epoch: [49/300][60/200], lr: 0.00000022 	 loss = 0.1376(0.5148)
2024/03/04 02:25:52 - INFO - root -   Epoch: [49/300][80/200], lr: 0.00000022 	 loss = 1.8143(0.5142)
2024/03/04 02:26:02 - INFO - root -   Epoch: [49/300][100/200], lr: 0.00000022 	 loss = 0.1134(0.4863)
2024/03/04 02:26:17 - INFO - root -   Epoch: [49/300][120/200], lr: 0.00000022 	 loss = 3.1110(0.4839)
2024/03/04 02:26:27 - INFO - root -   Epoch: [49/300][140/200], lr: 0.00000022 	 loss = 2.4115(0.4929)
2024/03/04 02:26:48 - INFO - root -   Epoch: [49/300][160/200], lr: 0.00000022 	 loss = 0.3455(0.4840)
2024/03/04 02:26:56 - INFO - root -   Epoch: [49/300][180/200], lr: 0.00000022 	 loss = 0.4945(0.5042)
2024/03/04 02:27:04 - INFO - root -   Epoch: [49/300] 	 loss = 0.4917
2024/03/04 02:27:08 - INFO - root -   precision = 0.7333
2024/03/04 02:27:08 - INFO - root -   eval_loss = 0.9503
2024/03/04 02:27:08 - INFO - root -   eval_acc = 0.7333
2024/03/04 02:27:09 - INFO - root -   train_accuracy = 0.8425
2024/03/04 02:27:34 - INFO - root -   Epoch: [50/300][0/200], lr: 0.00000022 	 loss = 1.4592(1.4592)
2024/03/04 02:27:42 - INFO - root -   Epoch: [50/300][20/200], lr: 0.00000022 	 loss = 0.2107(0.5668)
2024/03/04 02:27:58 - INFO - root -   Epoch: [50/300][40/200], lr: 0.00000022 	 loss = 0.6650(0.5013)
2024/03/04 02:28:06 - INFO - root -   Epoch: [50/300][60/200], lr: 0.00000022 	 loss = 0.0754(0.5107)
2024/03/04 02:28:26 - INFO - root -   Epoch: [50/300][80/200], lr: 0.00000022 	 loss = 1.6105(0.5491)
2024/03/04 02:28:39 - INFO - root -   Epoch: [50/300][100/200], lr: 0.00000022 	 loss = 0.0219(0.5321)
2024/03/04 02:28:56 - INFO - root -   Epoch: [50/300][120/200], lr: 0.00000022 	 loss = 2.8923(0.5088)
2024/03/04 02:29:12 - INFO - root -   Epoch: [50/300][140/200], lr: 0.00000022 	 loss = 1.9800(0.5230)
2024/03/04 02:29:21 - INFO - root -   Epoch: [50/300][160/200], lr: 0.00000022 	 loss = 0.3288(0.5245)
2024/03/04 02:29:35 - INFO - root -   Epoch: [50/300][180/200], lr: 0.00000022 	 loss = 0.4415(0.5317)
2024/03/04 02:29:43 - INFO - root -   Epoch: [50/300] 	 loss = 0.5343
2024/03/04 02:29:43 - INFO - root -   train_accuracy = 0.8175
2024/03/04 02:29:58 - INFO - root -   Epoch: [51/300][0/200], lr: 0.00000023 	 loss = 0.6173(0.6173)
2024/03/04 02:30:08 - INFO - root -   Epoch: [51/300][20/200], lr: 0.00000023 	 loss = 0.4665(0.5473)
2024/03/04 02:30:16 - INFO - root -   Epoch: [51/300][40/200], lr: 0.00000023 	 loss = 0.6225(0.4758)
2024/03/04 02:30:38 - INFO - root -   Epoch: [51/300][60/200], lr: 0.00000023 	 loss = 0.4685(0.4760)
2024/03/04 02:30:46 - INFO - root -   Epoch: [51/300][80/200], lr: 0.00000023 	 loss = 1.3874(0.4762)
2024/03/04 02:31:06 - INFO - root -   Epoch: [51/300][100/200], lr: 0.00000023 	 loss = 0.0343(0.4669)
2024/03/04 02:31:14 - INFO - root -   Epoch: [51/300][120/200], lr: 0.00000023 	 loss = 1.3048(0.4410)
2024/03/04 02:31:28 - INFO - root -   Epoch: [51/300][140/200], lr: 0.00000023 	 loss = 2.0323(0.4569)
2024/03/04 02:31:51 - INFO - root -   Epoch: [51/300][160/200], lr: 0.00000023 	 loss = 0.2092(0.4621)
2024/03/04 02:31:59 - INFO - root -   Epoch: [51/300][180/200], lr: 0.00000023 	 loss = 0.0866(0.4714)
2024/03/04 02:32:07 - INFO - root -   Epoch: [51/300] 	 loss = 0.4855
2024/03/04 02:32:07 - INFO - root -   train_accuracy = 0.8325
2024/03/04 02:32:22 - INFO - root -   Epoch: [52/300][0/200], lr: 0.00000023 	 loss = 1.8137(1.8137)
2024/03/04 02:32:40 - INFO - root -   Epoch: [52/300][20/200], lr: 0.00000023 	 loss = 0.4497(0.6721)
2024/03/04 02:32:48 - INFO - root -   Epoch: [52/300][40/200], lr: 0.00000023 	 loss = 0.4310(0.5422)
2024/03/04 02:33:05 - INFO - root -   Epoch: [52/300][60/200], lr: 0.00000023 	 loss = 0.0257(0.5386)
2024/03/04 02:33:23 - INFO - root -   Epoch: [52/300][80/200], lr: 0.00000023 	 loss = 1.6483(0.5580)
2024/03/04 02:33:43 - INFO - root -   Epoch: [52/300][100/200], lr: 0.00000023 	 loss = 0.1885(0.5619)
2024/03/04 02:33:53 - INFO - root -   Epoch: [52/300][120/200], lr: 0.00000023 	 loss = 1.4593(0.5331)
2024/03/04 02:34:11 - INFO - root -   Epoch: [52/300][140/200], lr: 0.00000023 	 loss = 1.5099(0.5503)
2024/03/04 02:34:27 - INFO - root -   Epoch: [52/300][160/200], lr: 0.00000023 	 loss = 0.0621(0.5384)
2024/03/04 02:34:43 - INFO - root -   Epoch: [52/300][180/200], lr: 0.00000023 	 loss = 0.4367(0.5333)
2024/03/04 02:34:50 - INFO - root -   Epoch: [52/300] 	 loss = 0.5365
2024/03/04 02:34:50 - INFO - root -   train_accuracy = 0.8250
2024/03/04 02:35:05 - INFO - root -   Epoch: [53/300][0/200], lr: 0.00000023 	 loss = 0.5794(0.5794)
2024/03/04 02:35:22 - INFO - root -   Epoch: [53/300][20/200], lr: 0.00000023 	 loss = 0.4649(0.7188)
2024/03/04 02:35:39 - INFO - root -   Epoch: [53/300][40/200], lr: 0.00000023 	 loss = 0.9361(0.6394)
2024/03/04 02:35:47 - INFO - root -   Epoch: [53/300][60/200], lr: 0.00000023 	 loss = 0.0260(0.5590)
2024/03/04 02:36:12 - INFO - root -   Epoch: [53/300][80/200], lr: 0.00000023 	 loss = 0.9593(0.5502)
2024/03/04 02:36:27 - INFO - root -   Epoch: [53/300][100/200], lr: 0.00000023 	 loss = 0.0629(0.5295)
2024/03/04 02:36:43 - INFO - root -   Epoch: [53/300][120/200], lr: 0.00000023 	 loss = 3.5013(0.5195)
2024/03/04 02:37:01 - INFO - root -   Epoch: [53/300][140/200], lr: 0.00000023 	 loss = 1.8514(0.5336)
2024/03/04 02:37:18 - INFO - root -   Epoch: [53/300][160/200], lr: 0.00000023 	 loss = 0.1468(0.5160)
2024/03/04 02:37:26 - INFO - root -   Epoch: [53/300][180/200], lr: 0.00000023 	 loss = 0.1926(0.5173)
2024/03/04 02:37:34 - INFO - root -   Epoch: [53/300] 	 loss = 0.5202
2024/03/04 02:37:34 - INFO - root -   train_accuracy = 0.8200
2024/03/04 02:37:35 - INFO - root -   Epoch: [54/300][0/200], lr: 0.00000023 	 loss = 0.8111(0.8111)
2024/03/04 02:37:53 - INFO - root -   Epoch: [54/300][20/200], lr: 0.00000023 	 loss = 0.5448(0.5726)
2024/03/04 02:38:07 - INFO - root -   Epoch: [54/300][40/200], lr: 0.00000023 	 loss = 0.4207(0.5002)
2024/03/04 02:38:30 - INFO - root -   Epoch: [54/300][60/200], lr: 0.00000023 	 loss = 0.0508(0.5269)
2024/03/04 02:38:38 - INFO - root -   Epoch: [54/300][80/200], lr: 0.00000023 	 loss = 1.1345(0.5403)
2024/03/04 02:38:53 - INFO - root -   Epoch: [54/300][100/200], lr: 0.00000023 	 loss = 0.1763(0.5309)
2024/03/04 02:39:05 - INFO - root -   Epoch: [54/300][120/200], lr: 0.00000023 	 loss = 1.8432(0.5076)
2024/03/04 02:39:14 - INFO - root -   Epoch: [54/300][140/200], lr: 0.00000023 	 loss = 1.3419(0.5244)
2024/03/04 02:39:29 - INFO - root -   Epoch: [54/300][160/200], lr: 0.00000023 	 loss = 0.4191(0.5128)
2024/03/04 02:39:39 - INFO - root -   Epoch: [54/300][180/200], lr: 0.00000023 	 loss = 0.8626(0.5253)
2024/03/04 02:39:47 - INFO - root -   Epoch: [54/300] 	 loss = 0.5151
2024/03/04 02:39:50 - INFO - root -   precision = 0.7333
2024/03/04 02:39:50 - INFO - root -   eval_loss = 0.9630
2024/03/04 02:39:50 - INFO - root -   eval_acc = 0.7333
2024/03/04 02:39:51 - INFO - root -   train_accuracy = 0.8175
2024/03/04 02:40:04 - INFO - root -   Epoch: [55/300][0/200], lr: 0.00000024 	 loss = 1.6262(1.6262)
2024/03/04 02:40:21 - INFO - root -   Epoch: [55/300][20/200], lr: 0.00000024 	 loss = 0.3603(0.6317)
2024/03/04 02:40:36 - INFO - root -   Epoch: [55/300][40/200], lr: 0.00000024 	 loss = 0.2415(0.4822)
2024/03/04 02:40:54 - INFO - root -   Epoch: [55/300][60/200], lr: 0.00000024 	 loss = 0.1682(0.5057)
2024/03/04 02:41:08 - INFO - root -   Epoch: [55/300][80/200], lr: 0.00000024 	 loss = 2.4819(0.5732)
2024/03/04 02:41:26 - INFO - root -   Epoch: [55/300][100/200], lr: 0.00000024 	 loss = 0.0483(0.5419)
2024/03/04 02:41:40 - INFO - root -   Epoch: [55/300][120/200], lr: 0.00000024 	 loss = 1.4921(0.5028)
2024/03/04 02:41:50 - INFO - root -   Epoch: [55/300][140/200], lr: 0.00000024 	 loss = 0.7658(0.4874)
2024/03/04 02:42:04 - INFO - root -   Epoch: [55/300][160/200], lr: 0.00000024 	 loss = 0.1400(0.4866)
2024/03/04 02:42:12 - INFO - root -   Epoch: [55/300][180/200], lr: 0.00000024 	 loss = 0.4456(0.4860)
2024/03/04 02:42:20 - INFO - root -   Epoch: [55/300] 	 loss = 0.4813
2024/03/04 02:42:20 - INFO - root -   train_accuracy = 0.8150
2024/03/04 02:42:22 - INFO - root -   Epoch: [56/300][0/200], lr: 0.00000024 	 loss = 0.8787(0.8787)
2024/03/04 02:42:47 - INFO - root -   Epoch: [56/300][20/200], lr: 0.00000024 	 loss = 1.1126(0.5875)
2024/03/04 02:43:09 - INFO - root -   Epoch: [56/300][40/200], lr: 0.00000024 	 loss = 0.3284(0.4472)
2024/03/04 02:43:17 - INFO - root -   Epoch: [56/300][60/200], lr: 0.00000024 	 loss = 0.3847(0.4476)
2024/03/04 02:43:25 - INFO - root -   Epoch: [56/300][80/200], lr: 0.00000024 	 loss = 1.6446(0.5010)
2024/03/04 02:43:53 - INFO - root -   Epoch: [56/300][100/200], lr: 0.00000024 	 loss = 0.1481(0.5142)
2024/03/04 02:44:01 - INFO - root -   Epoch: [56/300][120/200], lr: 0.00000024 	 loss = 2.2286(0.5044)
2024/03/04 02:44:09 - INFO - root -   Epoch: [56/300][140/200], lr: 0.00000024 	 loss = 2.1909(0.5058)
2024/03/04 02:44:36 - INFO - root -   Epoch: [56/300][160/200], lr: 0.00000024 	 loss = 0.0748(0.4950)
2024/03/04 02:44:43 - INFO - root -   Epoch: [56/300][180/200], lr: 0.00000024 	 loss = 0.2646(0.4951)
2024/03/04 02:44:51 - INFO - root -   Epoch: [56/300] 	 loss = 0.4835
2024/03/04 02:44:51 - INFO - root -   train_accuracy = 0.8300
2024/03/04 02:44:52 - INFO - root -   Epoch: [57/300][0/200], lr: 0.00000024 	 loss = 1.4796(1.4796)
2024/03/04 02:45:27 - INFO - root -   Epoch: [57/300][20/200], lr: 0.00000024 	 loss = 0.4305(0.7123)
2024/03/04 02:45:50 - INFO - root -   Epoch: [57/300][40/200], lr: 0.00000024 	 loss = 0.1001(0.6387)
2024/03/04 02:46:00 - INFO - root -   Epoch: [57/300][60/200], lr: 0.00000024 	 loss = 0.1100(0.5589)
2024/03/04 02:46:23 - INFO - root -   Epoch: [57/300][80/200], lr: 0.00000024 	 loss = 1.7375(0.5809)
2024/03/04 02:46:35 - INFO - root -   Epoch: [57/300][100/200], lr: 0.00000024 	 loss = 0.1516(0.5581)
2024/03/04 02:46:47 - INFO - root -   Epoch: [57/300][120/200], lr: 0.00000024 	 loss = 2.3256(0.5387)
2024/03/04 02:47:05 - INFO - root -   Epoch: [57/300][140/200], lr: 0.00000024 	 loss = 2.1390(0.5607)
2024/03/04 02:47:13 - INFO - root -   Epoch: [57/300][160/200], lr: 0.00000024 	 loss = 0.2595(0.5455)
2024/03/04 02:47:21 - INFO - root -   Epoch: [57/300][180/200], lr: 0.00000024 	 loss = 0.0456(0.5270)
2024/03/04 02:47:30 - INFO - root -   Epoch: [57/300] 	 loss = 0.5140
2024/03/04 02:47:30 - INFO - root -   train_accuracy = 0.8475
2024/03/04 02:47:33 - INFO - root -   Epoch: [58/300][0/200], lr: 0.00000024 	 loss = 0.6751(0.6751)
2024/03/04 02:47:58 - INFO - root -   Epoch: [58/300][20/200], lr: 0.00000024 	 loss = 0.2261(0.5200)
2024/03/04 02:48:06 - INFO - root -   Epoch: [58/300][40/200], lr: 0.00000024 	 loss = 0.1906(0.4448)
2024/03/04 02:48:34 - INFO - root -   Epoch: [58/300][60/200], lr: 0.00000024 	 loss = 0.0723(0.4756)
2024/03/04 02:48:49 - INFO - root -   Epoch: [58/300][80/200], lr: 0.00000024 	 loss = 2.1572(0.5048)
2024/03/04 02:49:03 - INFO - root -   Epoch: [58/300][100/200], lr: 0.00000024 	 loss = 0.0475(0.4878)
2024/03/04 02:49:24 - INFO - root -   Epoch: [58/300][120/200], lr: 0.00000024 	 loss = 1.0900(0.4709)
2024/03/04 02:49:32 - INFO - root -   Epoch: [58/300][140/200], lr: 0.00000024 	 loss = 0.6316(0.4762)
2024/03/04 02:49:56 - INFO - root -   Epoch: [58/300][160/200], lr: 0.00000024 	 loss = 0.0812(0.4737)
2024/03/04 02:50:09 - INFO - root -   Epoch: [58/300][180/200], lr: 0.00000024 	 loss = 0.3338(0.4904)
2024/03/04 02:50:17 - INFO - root -   Epoch: [58/300] 	 loss = 0.4944
2024/03/04 02:50:17 - INFO - root -   train_accuracy = 0.8325
2024/03/04 02:50:19 - INFO - root -   Epoch: [59/300][0/200], lr: 0.00000025 	 loss = 1.5712(1.5712)
2024/03/04 02:50:55 - INFO - root -   Epoch: [59/300][20/200], lr: 0.00000025 	 loss = 0.8299(0.6879)
2024/03/04 02:51:13 - INFO - root -   Epoch: [59/300][40/200], lr: 0.00000025 	 loss = 0.4892(0.6141)
2024/03/04 02:51:36 - INFO - root -   Epoch: [59/300][60/200], lr: 0.00000025 	 loss = 0.0370(0.5954)
2024/03/04 02:51:45 - INFO - root -   Epoch: [59/300][80/200], lr: 0.00000025 	 loss = 1.6961(0.5695)
2024/03/04 02:52:08 - INFO - root -   Epoch: [59/300][100/200], lr: 0.00000025 	 loss = 0.0763(0.5391)
2024/03/04 02:52:23 - INFO - root -   Epoch: [59/300][120/200], lr: 0.00000025 	 loss = 0.9333(0.5152)
2024/03/04 02:52:32 - INFO - root -   Epoch: [59/300][140/200], lr: 0.00000025 	 loss = 1.0141(0.5273)
2024/03/04 02:52:51 - INFO - root -   Epoch: [59/300][160/200], lr: 0.00000025 	 loss = 0.0281(0.5216)
2024/03/04 02:53:04 - INFO - root -   Epoch: [59/300][180/200], lr: 0.00000025 	 loss = 0.5084(0.5278)
2024/03/04 02:53:12 - INFO - root -   Epoch: [59/300] 	 loss = 0.5180
2024/03/04 02:53:16 - INFO - root -   precision = 0.7333
2024/03/04 02:53:16 - INFO - root -   eval_loss = 0.9867
2024/03/04 02:53:16 - INFO - root -   eval_acc = 0.7333
2024/03/04 02:53:17 - INFO - root -   train_accuracy = 0.8150
2024/03/04 02:53:37 - INFO - root -   Epoch: [60/300][0/200], lr: 0.00000025 	 loss = 1.4777(1.4777)
2024/03/04 02:53:45 - INFO - root -   Epoch: [60/300][20/200], lr: 0.00000025 	 loss = 0.2206(0.5694)
2024/03/04 02:54:01 - INFO - root -   Epoch: [60/300][40/200], lr: 0.00000025 	 loss = 0.3538(0.4689)
2024/03/04 02:54:16 - INFO - root -   Epoch: [60/300][60/200], lr: 0.00000025 	 loss = 0.0562(0.5048)
2024/03/04 02:54:24 - INFO - root -   Epoch: [60/300][80/200], lr: 0.00000025 	 loss = 1.8394(0.5272)
2024/03/04 02:54:44 - INFO - root -   Epoch: [60/300][100/200], lr: 0.00000025 	 loss = 0.0885(0.5300)
2024/03/04 02:54:58 - INFO - root -   Epoch: [60/300][120/200], lr: 0.00000025 	 loss = 2.7532(0.5195)
2024/03/04 02:55:08 - INFO - root -   Epoch: [60/300][140/200], lr: 0.00000025 	 loss = 2.5826(0.5408)
2024/03/04 02:55:27 - INFO - root -   Epoch: [60/300][160/200], lr: 0.00000025 	 loss = 0.1372(0.5405)
2024/03/04 02:55:47 - INFO - root -   Epoch: [60/300][180/200], lr: 0.00000025 	 loss = 0.0834(0.5299)
2024/03/04 02:55:54 - INFO - root -   Epoch: [60/300] 	 loss = 0.5225
2024/03/04 02:55:54 - INFO - root -   train_accuracy = 0.8300
2024/03/04 02:55:56 - INFO - root -   Epoch: [61/300][0/200], lr: 0.00000025 	 loss = 1.0323(1.0323)
2024/03/04 02:56:21 - INFO - root -   Epoch: [61/300][20/200], lr: 0.00000025 	 loss = 0.5643(0.5806)
2024/03/04 02:56:33 - INFO - root -   Epoch: [61/300][40/200], lr: 0.00000025 	 loss = 0.2530(0.5117)
2024/03/04 02:56:45 - INFO - root -   Epoch: [61/300][60/200], lr: 0.00000025 	 loss = 0.0407(0.5142)
2024/03/04 02:56:56 - INFO - root -   Epoch: [61/300][80/200], lr: 0.00000025 	 loss = 1.2192(0.5179)
2024/03/04 02:57:08 - INFO - root -   Epoch: [61/300][100/200], lr: 0.00000025 	 loss = 0.1051(0.4887)
2024/03/04 02:57:28 - INFO - root -   Epoch: [61/300][120/200], lr: 0.00000025 	 loss = 2.2331(0.4745)
2024/03/04 02:57:36 - INFO - root -   Epoch: [61/300][140/200], lr: 0.00000025 	 loss = 1.6376(0.4829)
2024/03/04 02:58:01 - INFO - root -   Epoch: [61/300][160/200], lr: 0.00000025 	 loss = 0.1721(0.4847)
2024/03/04 02:58:09 - INFO - root -   Epoch: [61/300][180/200], lr: 0.00000025 	 loss = 0.5395(0.4961)
2024/03/04 02:58:16 - INFO - root -   Epoch: [61/300] 	 loss = 0.5039
2024/03/04 02:58:16 - INFO - root -   train_accuracy = 0.8350
2024/03/04 02:58:18 - INFO - root -   Epoch: [62/300][0/200], lr: 0.00000025 	 loss = 1.3916(1.3916)
2024/03/04 02:58:56 - INFO - root -   Epoch: [62/300][20/200], lr: 0.00000025 	 loss = 0.4854(0.6788)
2024/03/04 02:59:04 - INFO - root -   Epoch: [62/300][40/200], lr: 0.00000025 	 loss = 0.3081(0.5367)
2024/03/04 02:59:24 - INFO - root -   Epoch: [62/300][60/200], lr: 0.00000025 	 loss = 0.1321(0.4993)
2024/03/04 02:59:57 - INFO - root -   Epoch: [62/300][80/200], lr: 0.00000025 	 loss = 1.5181(0.5126)
2024/03/04 03:00:05 - INFO - root -   Epoch: [62/300][100/200], lr: 0.00000025 	 loss = 0.0326(0.4825)
2024/03/04 03:00:18 - INFO - root -   Epoch: [62/300][120/200], lr: 0.00000025 	 loss = 1.8395(0.4699)
2024/03/04 03:00:36 - INFO - root -   Epoch: [62/300][140/200], lr: 0.00000025 	 loss = 1.3681(0.4798)
2024/03/04 03:00:44 - INFO - root -   Epoch: [62/300][160/200], lr: 0.00000025 	 loss = 0.3301(0.4882)
2024/03/04 03:01:05 - INFO - root -   Epoch: [62/300][180/200], lr: 0.00000025 	 loss = 0.6250(0.4969)
2024/03/04 03:01:12 - INFO - root -   Epoch: [62/300] 	 loss = 0.4968
2024/03/04 03:01:12 - INFO - root -   train_accuracy = 0.8200
2024/03/04 03:01:14 - INFO - root -   Epoch: [63/300][0/200], lr: 0.00000026 	 loss = 1.3901(1.3901)
2024/03/04 03:01:41 - INFO - root -   Epoch: [63/300][20/200], lr: 0.00000026 	 loss = 0.7009(0.6472)
2024/03/04 03:02:07 - INFO - root -   Epoch: [63/300][40/200], lr: 0.00000026 	 loss = 0.8420(0.5856)
2024/03/04 03:02:24 - INFO - root -   Epoch: [63/300][60/200], lr: 0.00000026 	 loss = 0.0507(0.5783)
2024/03/04 03:02:38 - INFO - root -   Epoch: [63/300][80/200], lr: 0.00000026 	 loss = 1.5541(0.5335)
2024/03/04 03:02:53 - INFO - root -   Epoch: [63/300][100/200], lr: 0.00000026 	 loss = 0.2329(0.5310)
2024/03/04 03:03:04 - INFO - root -   Epoch: [63/300][120/200], lr: 0.00000026 	 loss = 1.5882(0.5084)
2024/03/04 03:03:25 - INFO - root -   Epoch: [63/300][140/200], lr: 0.00000026 	 loss = 2.0352(0.5341)
2024/03/04 03:03:46 - INFO - root -   Epoch: [63/300][160/200], lr: 0.00000026 	 loss = 0.2698(0.5146)
2024/03/04 03:03:57 - INFO - root -   Epoch: [63/300][180/200], lr: 0.00000026 	 loss = 0.2171(0.5317)
2024/03/04 03:04:05 - INFO - root -   Epoch: [63/300] 	 loss = 0.5327
2024/03/04 03:04:05 - INFO - root -   train_accuracy = 0.8200
2024/03/04 03:04:06 - INFO - root -   Epoch: [64/300][0/200], lr: 0.00000026 	 loss = 0.7750(0.7750)
2024/03/04 03:04:37 - INFO - root -   Epoch: [64/300][20/200], lr: 0.00000026 	 loss = 0.0889(0.6896)
2024/03/04 03:04:55 - INFO - root -   Epoch: [64/300][40/200], lr: 0.00000026 	 loss = 0.3760(0.5467)
2024/03/04 03:05:03 - INFO - root -   Epoch: [64/300][60/200], lr: 0.00000026 	 loss = 0.0483(0.4810)
2024/03/04 03:05:16 - INFO - root -   Epoch: [64/300][80/200], lr: 0.00000026 	 loss = 1.3180(0.4838)
2024/03/04 03:05:33 - INFO - root -   Epoch: [64/300][100/200], lr: 0.00000026 	 loss = 0.1064(0.4824)
2024/03/04 03:05:43 - INFO - root -   Epoch: [64/300][120/200], lr: 0.00000026 	 loss = 2.2377(0.4806)
2024/03/04 03:06:08 - INFO - root -   Epoch: [64/300][140/200], lr: 0.00000026 	 loss = 1.5195(0.4975)
2024/03/04 03:06:22 - INFO - root -   Epoch: [64/300][160/200], lr: 0.00000026 	 loss = 0.1141(0.4927)
2024/03/04 03:06:46 - INFO - root -   Epoch: [64/300][180/200], lr: 0.00000026 	 loss = 0.7334(0.5123)
2024/03/04 03:06:53 - INFO - root -   Epoch: [64/300] 	 loss = 0.5079
2024/03/04 03:06:57 - INFO - root -   precision = 0.7333
2024/03/04 03:06:57 - INFO - root -   eval_loss = 1.0090
2024/03/04 03:06:57 - INFO - root -   eval_acc = 0.7333
2024/03/04 03:06:58 - INFO - root -   train_accuracy = 0.8275
2024/03/04 03:07:21 - INFO - root -   Epoch: [65/300][0/200], lr: 0.00000026 	 loss = 0.8754(0.8754)
2024/03/04 03:07:39 - INFO - root -   Epoch: [65/300][20/200], lr: 0.00000026 	 loss = 0.1390(0.6110)
2024/03/04 03:07:47 - INFO - root -   Epoch: [65/300][40/200], lr: 0.00000026 	 loss = 0.4986(0.5217)
2024/03/04 03:08:05 - INFO - root -   Epoch: [65/300][60/200], lr: 0.00000026 	 loss = 0.0266(0.4852)
2024/03/04 03:08:23 - INFO - root -   Epoch: [65/300][80/200], lr: 0.00000026 	 loss = 0.8146(0.5043)
2024/03/04 03:08:38 - INFO - root -   Epoch: [65/300][100/200], lr: 0.00000026 	 loss = 0.1003(0.4981)
2024/03/04 03:08:46 - INFO - root -   Epoch: [65/300][120/200], lr: 0.00000026 	 loss = 1.6745(0.4755)
2024/03/04 03:08:54 - INFO - root -   Epoch: [65/300][140/200], lr: 0.00000026 	 loss = 1.3808(0.4806)
2024/03/04 03:09:14 - INFO - root -   Epoch: [65/300][160/200], lr: 0.00000026 	 loss = 0.4925(0.4775)
2024/03/04 03:09:22 - INFO - root -   Epoch: [65/300][180/200], lr: 0.00000026 	 loss = 0.4558(0.4797)
2024/03/04 03:09:31 - INFO - root -   Epoch: [65/300] 	 loss = 0.4746
2024/03/04 03:09:31 - INFO - root -   train_accuracy = 0.8425
2024/03/04 03:09:48 - INFO - root -   Epoch: [66/300][0/200], lr: 0.00000026 	 loss = 0.7589(0.7589)
2024/03/04 03:10:15 - INFO - root -   Epoch: [66/300][20/200], lr: 0.00000026 	 loss = 0.1097(0.4388)
2024/03/04 03:10:25 - INFO - root -   Epoch: [66/300][40/200], lr: 0.00000026 	 loss = 0.5442(0.4353)
2024/03/04 03:10:38 - INFO - root -   Epoch: [66/300][60/200], lr: 0.00000026 	 loss = 0.1142(0.4576)
2024/03/04 03:10:47 - INFO - root -   Epoch: [66/300][80/200], lr: 0.00000026 	 loss = 1.6957(0.4623)
2024/03/04 03:11:12 - INFO - root -   Epoch: [66/300][100/200], lr: 0.00000026 	 loss = 0.0553(0.4547)
2024/03/04 03:11:32 - INFO - root -   Epoch: [66/300][120/200], lr: 0.00000026 	 loss = 1.7738(0.4369)
2024/03/04 03:11:40 - INFO - root -   Epoch: [66/300][140/200], lr: 0.00000026 	 loss = 1.5827(0.4444)
2024/03/04 03:12:01 - INFO - root -   Epoch: [66/300][160/200], lr: 0.00000026 	 loss = 0.0565(0.4524)
2024/03/04 03:12:09 - INFO - root -   Epoch: [66/300][180/200], lr: 0.00000026 	 loss = 0.3663(0.4629)
2024/03/04 03:12:17 - INFO - root -   Epoch: [66/300] 	 loss = 0.4689
2024/03/04 03:12:17 - INFO - root -   train_accuracy = 0.8350
2024/03/04 03:12:42 - INFO - root -   Epoch: [67/300][0/200], lr: 0.00000027 	 loss = 1.5154(1.5154)
2024/03/04 03:12:53 - INFO - root -   Epoch: [67/300][20/200], lr: 0.00000027 	 loss = 0.1300(0.5504)
2024/03/04 03:13:10 - INFO - root -   Epoch: [67/300][40/200], lr: 0.00000027 	 loss = 0.7205(0.4780)
2024/03/04 03:13:30 - INFO - root -   Epoch: [67/300][60/200], lr: 0.00000027 	 loss = 0.0871(0.4588)
2024/03/04 03:13:53 - INFO - root -   Epoch: [67/300][80/200], lr: 0.00000027 	 loss = 0.9176(0.4776)
2024/03/04 03:14:04 - INFO - root -   Epoch: [67/300][100/200], lr: 0.00000027 	 loss = 0.0357(0.4572)
2024/03/04 03:14:20 - INFO - root -   Epoch: [67/300][120/200], lr: 0.00000027 	 loss = 0.9283(0.4462)
2024/03/04 03:14:28 - INFO - root -   Epoch: [67/300][140/200], lr: 0.00000027 	 loss = 1.6609(0.4793)
2024/03/04 03:14:48 - INFO - root -   Epoch: [67/300][160/200], lr: 0.00000027 	 loss = 0.1751(0.4806)
2024/03/04 03:15:10 - INFO - root -   Epoch: [67/300][180/200], lr: 0.00000027 	 loss = 0.1654(0.4910)
2024/03/04 03:15:17 - INFO - root -   Epoch: [67/300] 	 loss = 0.4935
2024/03/04 03:15:17 - INFO - root -   train_accuracy = 0.8325
2024/03/04 03:15:20 - INFO - root -   Epoch: [68/300][0/200], lr: 0.00000027 	 loss = 0.7189(0.7189)
2024/03/04 03:15:48 - INFO - root -   Epoch: [68/300][20/200], lr: 0.00000027 	 loss = 0.2664(0.4970)
2024/03/04 03:16:02 - INFO - root -   Epoch: [68/300][40/200], lr: 0.00000027 	 loss = 0.2599(0.4291)
2024/03/04 03:16:18 - INFO - root -   Epoch: [68/300][60/200], lr: 0.00000027 	 loss = 0.1707(0.4328)
2024/03/04 03:16:39 - INFO - root -   Epoch: [68/300][80/200], lr: 0.00000027 	 loss = 0.9845(0.4787)
2024/03/04 03:16:47 - INFO - root -   Epoch: [68/300][100/200], lr: 0.00000027 	 loss = 0.2218(0.4631)
2024/03/04 03:17:11 - INFO - root -   Epoch: [68/300][120/200], lr: 0.00000027 	 loss = 2.1484(0.4587)
2024/03/04 03:17:19 - INFO - root -   Epoch: [68/300][140/200], lr: 0.00000027 	 loss = 1.8566(0.4505)
2024/03/04 03:17:27 - INFO - root -   Epoch: [68/300][160/200], lr: 0.00000027 	 loss = 0.0744(0.4620)
2024/03/04 03:17:48 - INFO - root -   Epoch: [68/300][180/200], lr: 0.00000027 	 loss = 0.3577(0.4831)
2024/03/04 03:17:56 - INFO - root -   Epoch: [68/300] 	 loss = 0.4849
2024/03/04 03:17:56 - INFO - root -   train_accuracy = 0.8375
2024/03/04 03:17:58 - INFO - root -   Epoch: [69/300][0/200], lr: 0.00000027 	 loss = 1.3812(1.3812)
2024/03/04 03:18:22 - INFO - root -   Epoch: [69/300][20/200], lr: 0.00000027 	 loss = 0.1431(0.4948)
2024/03/04 03:18:30 - INFO - root -   Epoch: [69/300][40/200], lr: 0.00000027 	 loss = 0.3955(0.4642)
2024/03/04 03:19:02 - INFO - root -   Epoch: [69/300][60/200], lr: 0.00000027 	 loss = 0.1090(0.4594)
2024/03/04 03:19:12 - INFO - root -   Epoch: [69/300][80/200], lr: 0.00000027 	 loss = 0.5546(0.4793)
2024/03/04 03:19:34 - INFO - root -   Epoch: [69/300][100/200], lr: 0.00000027 	 loss = 0.1481(0.4700)
2024/03/04 03:19:44 - INFO - root -   Epoch: [69/300][120/200], lr: 0.00000027 	 loss = 3.3494(0.4774)
2024/03/04 03:20:01 - INFO - root -   Epoch: [69/300][140/200], lr: 0.00000027 	 loss = 1.9518(0.5033)
2024/03/04 03:20:13 - INFO - root -   Epoch: [69/300][160/200], lr: 0.00000027 	 loss = 0.1262(0.5047)
2024/03/04 03:20:31 - INFO - root -   Epoch: [69/300][180/200], lr: 0.00000027 	 loss = 0.1790(0.5028)
2024/03/04 03:20:39 - INFO - root -   Epoch: [69/300] 	 loss = 0.5053
2024/03/04 03:20:42 - INFO - root -   precision = 0.7111
2024/03/04 03:20:42 - INFO - root -   eval_loss = 0.9538
2024/03/04 03:20:42 - INFO - root -   eval_acc = 0.7111
2024/03/04 03:20:43 - INFO - root -   train_accuracy = 0.8300
2024/03/04 03:20:56 - INFO - root -   Epoch: [70/300][0/200], lr: 0.00000027 	 loss = 1.4445(1.4445)
2024/03/04 03:21:16 - INFO - root -   Epoch: [70/300][20/200], lr: 0.00000027 	 loss = 0.3863(0.5703)
2024/03/04 03:21:37 - INFO - root -   Epoch: [70/300][40/200], lr: 0.00000027 	 loss = 0.2795(0.4428)
2024/03/04 03:21:54 - INFO - root -   Epoch: [70/300][60/200], lr: 0.00000027 	 loss = 0.0530(0.4520)
2024/03/04 03:22:04 - INFO - root -   Epoch: [70/300][80/200], lr: 0.00000027 	 loss = 1.8718(0.4839)
2024/03/04 03:22:19 - INFO - root -   Epoch: [70/300][100/200], lr: 0.00000027 	 loss = 0.0485(0.4524)
2024/03/04 03:22:38 - INFO - root -   Epoch: [70/300][120/200], lr: 0.00000027 	 loss = 2.7012(0.4596)
2024/03/04 03:22:58 - INFO - root -   Epoch: [70/300][140/200], lr: 0.00000027 	 loss = 2.0007(0.4608)
2024/03/04 03:23:06 - INFO - root -   Epoch: [70/300][160/200], lr: 0.00000027 	 loss = 0.4264(0.4645)
2024/03/04 03:23:30 - INFO - root -   Epoch: [70/300][180/200], lr: 0.00000027 	 loss = 0.3071(0.4829)
2024/03/04 03:23:38 - INFO - root -   Epoch: [70/300] 	 loss = 0.4838
2024/03/04 03:23:38 - INFO - root -   train_accuracy = 0.8250
2024/03/04 03:23:39 - INFO - root -   Epoch: [71/300][0/200], lr: 0.00000028 	 loss = 0.6396(0.6396)
2024/03/04 03:24:04 - INFO - root -   Epoch: [71/300][20/200], lr: 0.00000028 	 loss = 0.3983(0.5880)
2024/03/04 03:24:24 - INFO - root -   Epoch: [71/300][40/200], lr: 0.00000028 	 loss = 0.1817(0.4635)
2024/03/04 03:24:47 - INFO - root -   Epoch: [71/300][60/200], lr: 0.00000028 	 loss = 0.0518(0.4557)
2024/03/04 03:24:55 - INFO - root -   Epoch: [71/300][80/200], lr: 0.00000028 	 loss = 1.2995(0.4521)
2024/03/04 03:25:15 - INFO - root -   Epoch: [71/300][100/200], lr: 0.00000028 	 loss = 0.0298(0.4212)
2024/03/04 03:25:26 - INFO - root -   Epoch: [71/300][120/200], lr: 0.00000028 	 loss = 1.5113(0.4212)
2024/03/04 03:25:41 - INFO - root -   Epoch: [71/300][140/200], lr: 0.00000028 	 loss = 0.8142(0.4117)
2024/03/04 03:25:56 - INFO - root -   Epoch: [71/300][160/200], lr: 0.00000028 	 loss = 0.2847(0.4176)
2024/03/04 03:26:08 - INFO - root -   Epoch: [71/300][180/200], lr: 0.00000028 	 loss = 1.1839(0.4355)
2024/03/04 03:26:16 - INFO - root -   Epoch: [71/300] 	 loss = 0.4337
2024/03/04 03:26:16 - INFO - root -   train_accuracy = 0.8425
2024/03/04 03:26:31 - INFO - root -   Epoch: [72/300][0/200], lr: 0.00000028 	 loss = 0.7124(0.7124)
2024/03/04 03:26:47 - INFO - root -   Epoch: [72/300][20/200], lr: 0.00000028 	 loss = 0.1441(0.6787)
2024/03/04 03:27:11 - INFO - root -   Epoch: [72/300][40/200], lr: 0.00000028 	 loss = 0.5301(0.5848)
2024/03/04 03:27:33 - INFO - root -   Epoch: [72/300][60/200], lr: 0.00000028 	 loss = 0.1187(0.5705)
2024/03/04 03:27:53 - INFO - root -   Epoch: [72/300][80/200], lr: 0.00000028 	 loss = 1.8846(0.5958)
2024/03/04 03:28:07 - INFO - root -   Epoch: [72/300][100/200], lr: 0.00000028 	 loss = 0.0642(0.5776)
2024/03/04 03:28:22 - INFO - root -   Epoch: [72/300][120/200], lr: 0.00000028 	 loss = 1.3276(0.5638)
2024/03/04 03:28:33 - INFO - root -   Epoch: [72/300][140/200], lr: 0.00000028 	 loss = 1.8414(0.5600)
2024/03/04 03:28:59 - INFO - root -   Epoch: [72/300][160/200], lr: 0.00000028 	 loss = 0.1927(0.5649)
2024/03/04 03:29:12 - INFO - root -   Epoch: [72/300][180/200], lr: 0.00000028 	 loss = 1.2555(0.5630)
2024/03/04 03:29:20 - INFO - root -   Epoch: [72/300] 	 loss = 0.5505
2024/03/04 03:29:20 - INFO - root -   train_accuracy = 0.8100
2024/03/04 03:29:21 - INFO - root -   Epoch: [73/300][0/200], lr: 0.00000028 	 loss = 1.0158(1.0158)
2024/03/04 03:29:53 - INFO - root -   Epoch: [73/300][20/200], lr: 0.00000028 	 loss = 0.1564(0.5318)
2024/03/04 03:30:01 - INFO - root -   Epoch: [73/300][40/200], lr: 0.00000028 	 loss = 0.3627(0.4752)
2024/03/04 03:30:25 - INFO - root -   Epoch: [73/300][60/200], lr: 0.00000028 	 loss = 0.1775(0.4769)
2024/03/04 03:30:41 - INFO - root -   Epoch: [73/300][80/200], lr: 0.00000028 	 loss = 1.5324(0.5138)
2024/03/04 03:30:59 - INFO - root -   Epoch: [73/300][100/200], lr: 0.00000028 	 loss = 0.0715(0.5061)
2024/03/04 03:31:11 - INFO - root -   Epoch: [73/300][120/200], lr: 0.00000028 	 loss = 1.6274(0.4891)
2024/03/04 03:31:28 - INFO - root -   Epoch: [73/300][140/200], lr: 0.00000028 	 loss = 2.4650(0.4926)
2024/03/04 03:31:37 - INFO - root -   Epoch: [73/300][160/200], lr: 0.00000028 	 loss = 0.1836(0.4854)
2024/03/04 03:31:45 - INFO - root -   Epoch: [73/300][180/200], lr: 0.00000028 	 loss = 0.6975(0.4726)
2024/03/04 03:31:53 - INFO - root -   Epoch: [73/300] 	 loss = 0.4728
2024/03/04 03:31:53 - INFO - root -   train_accuracy = 0.8350
2024/03/04 03:31:54 - INFO - root -   Epoch: [74/300][0/200], lr: 0.00000028 	 loss = 1.1180(1.1180)
2024/03/04 03:32:23 - INFO - root -   Epoch: [74/300][20/200], lr: 0.00000028 	 loss = 0.4013(0.5385)
2024/03/04 03:32:35 - INFO - root -   Epoch: [74/300][40/200], lr: 0.00000028 	 loss = 0.0953(0.4438)
2024/03/04 03:32:45 - INFO - root -   Epoch: [74/300][60/200], lr: 0.00000028 	 loss = 0.0420(0.4354)
2024/03/04 03:32:58 - INFO - root -   Epoch: [74/300][80/200], lr: 0.00000028 	 loss = 2.3408(0.4696)
2024/03/04 03:33:18 - INFO - root -   Epoch: [74/300][100/200], lr: 0.00000028 	 loss = 0.0687(0.4518)
2024/03/04 03:33:32 - INFO - root -   Epoch: [74/300][120/200], lr: 0.00000028 	 loss = 2.4381(0.4740)
2024/03/04 03:33:54 - INFO - root -   Epoch: [74/300][140/200], lr: 0.00000028 	 loss = 1.7035(0.4863)
2024/03/04 03:34:04 - INFO - root -   Epoch: [74/300][160/200], lr: 0.00000028 	 loss = 0.3493(0.4762)
2024/03/04 03:34:17 - INFO - root -   Epoch: [74/300][180/200], lr: 0.00000028 	 loss = 0.2059(0.4825)
2024/03/04 03:34:25 - INFO - root -   Epoch: [74/300] 	 loss = 0.4854
2024/03/04 03:34:28 - INFO - root -   precision = 0.7111
2024/03/04 03:34:28 - INFO - root -   eval_loss = 1.0266
2024/03/04 03:34:28 - INFO - root -   eval_acc = 0.7111
2024/03/04 03:34:29 - INFO - root -   train_accuracy = 0.8400
2024/03/04 03:34:46 - INFO - root -   Epoch: [75/300][0/200], lr: 0.00000029 	 loss = 0.9086(0.9086)
2024/03/04 03:35:00 - INFO - root -   Epoch: [75/300][20/200], lr: 0.00000029 	 loss = 0.3873(0.5031)
2024/03/04 03:35:11 - INFO - root -   Epoch: [75/300][40/200], lr: 0.00000029 	 loss = 0.1886(0.4343)
2024/03/04 03:35:34 - INFO - root -   Epoch: [75/300][60/200], lr: 0.00000029 	 loss = 0.0600(0.4148)
2024/03/04 03:35:47 - INFO - root -   Epoch: [75/300][80/200], lr: 0.00000029 	 loss = 1.7070(0.4424)
2024/03/04 03:35:55 - INFO - root -   Epoch: [75/300][100/200], lr: 0.00000029 	 loss = 0.0733(0.4052)
2024/03/04 03:36:22 - INFO - root -   Epoch: [75/300][120/200], lr: 0.00000029 	 loss = 1.4600(0.4024)
2024/03/04 03:36:30 - INFO - root -   Epoch: [75/300][140/200], lr: 0.00000029 	 loss = 1.6122(0.4363)
2024/03/04 03:36:50 - INFO - root -   Epoch: [75/300][160/200], lr: 0.00000029 	 loss = 0.4419(0.4409)
2024/03/04 03:37:04 - INFO - root -   Epoch: [75/300][180/200], lr: 0.00000029 	 loss = 0.3230(0.4493)
2024/03/04 03:37:12 - INFO - root -   Epoch: [75/300] 	 loss = 0.4491
2024/03/04 03:37:12 - INFO - root -   train_accuracy = 0.8350
2024/03/04 03:37:15 - INFO - root -   Epoch: [76/300][0/200], lr: 0.00000029 	 loss = 0.8888(0.8888)
2024/03/04 03:37:48 - INFO - root -   Epoch: [76/300][20/200], lr: 0.00000029 	 loss = 0.1243(0.5063)
2024/03/04 03:38:07 - INFO - root -   Epoch: [76/300][40/200], lr: 0.00000029 	 loss = 0.2839(0.4351)
2024/03/04 03:38:14 - INFO - root -   Epoch: [76/300][60/200], lr: 0.00000029 	 loss = 0.0684(0.4956)
2024/03/04 03:38:35 - INFO - root -   Epoch: [76/300][80/200], lr: 0.00000029 	 loss = 1.7876(0.5398)
2024/03/04 03:38:49 - INFO - root -   Epoch: [76/300][100/200], lr: 0.00000029 	 loss = 0.0389(0.4941)
2024/03/04 03:39:10 - INFO - root -   Epoch: [76/300][120/200], lr: 0.00000029 	 loss = 1.5388(0.4799)
2024/03/04 03:39:27 - INFO - root -   Epoch: [76/300][140/200], lr: 0.00000029 	 loss = 1.9333(0.5013)
2024/03/04 03:39:39 - INFO - root -   Epoch: [76/300][160/200], lr: 0.00000029 	 loss = 0.4506(0.5132)
2024/03/04 03:39:58 - INFO - root -   Epoch: [76/300][180/200], lr: 0.00000029 	 loss = 0.4231(0.5123)
2024/03/04 03:40:06 - INFO - root -   Epoch: [76/300] 	 loss = 0.5105
2024/03/04 03:40:06 - INFO - root -   train_accuracy = 0.8100
2024/03/04 03:40:07 - INFO - root -   Epoch: [77/300][0/200], lr: 0.00000029 	 loss = 1.1688(1.1688)
2024/03/04 03:40:28 - INFO - root -   Epoch: [77/300][20/200], lr: 0.00000029 	 loss = 0.5791(0.5560)
2024/03/04 03:40:45 - INFO - root -   Epoch: [77/300][40/200], lr: 0.00000029 	 loss = 0.3619(0.4869)
2024/03/04 03:40:53 - INFO - root -   Epoch: [77/300][60/200], lr: 0.00000029 	 loss = 0.0719(0.4700)
2024/03/04 03:41:15 - INFO - root -   Epoch: [77/300][80/200], lr: 0.00000029 	 loss = 0.9750(0.4658)
2024/03/04 03:41:25 - INFO - root -   Epoch: [77/300][100/200], lr: 0.00000029 	 loss = 0.2884(0.4654)
2024/03/04 03:41:50 - INFO - root -   Epoch: [77/300][120/200], lr: 0.00000029 	 loss = 1.8075(0.4506)
2024/03/04 03:42:10 - INFO - root -   Epoch: [77/300][140/200], lr: 0.00000029 	 loss = 1.8089(0.4811)
2024/03/04 03:42:19 - INFO - root -   Epoch: [77/300][160/200], lr: 0.00000029 	 loss = 0.1734(0.4765)
2024/03/04 03:42:43 - INFO - root -   Epoch: [77/300][180/200], lr: 0.00000029 	 loss = 0.1115(0.4767)
2024/03/04 03:42:50 - INFO - root -   Epoch: [77/300] 	 loss = 0.4735
2024/03/04 03:42:50 - INFO - root -   train_accuracy = 0.8375
2024/03/04 03:42:52 - INFO - root -   Epoch: [78/300][0/200], lr: 0.00000029 	 loss = 1.4539(1.4539)
2024/03/04 03:43:19 - INFO - root -   Epoch: [78/300][20/200], lr: 0.00000029 	 loss = 0.1329(0.4951)
2024/03/04 03:43:28 - INFO - root -   Epoch: [78/300][40/200], lr: 0.00000029 	 loss = 0.1377(0.4387)
2024/03/04 03:43:45 - INFO - root -   Epoch: [78/300][60/200], lr: 0.00000029 	 loss = 0.0117(0.4236)
2024/03/04 03:43:54 - INFO - root -   Epoch: [78/300][80/200], lr: 0.00000029 	 loss = 1.6632(0.4701)
2024/03/04 03:44:02 - INFO - root -   Epoch: [78/300][100/200], lr: 0.00000029 	 loss = 0.1379(0.4438)
2024/03/04 03:44:22 - INFO - root -   Epoch: [78/300][120/200], lr: 0.00000029 	 loss = 2.6690(0.4424)
2024/03/04 03:44:35 - INFO - root -   Epoch: [78/300][140/200], lr: 0.00000029 	 loss = 2.7169(0.4592)
2024/03/04 03:44:55 - INFO - root -   Epoch: [78/300][160/200], lr: 0.00000029 	 loss = 0.0712(0.4556)
2024/03/04 03:45:18 - INFO - root -   Epoch: [78/300][180/200], lr: 0.00000029 	 loss = 0.0752(0.4686)
2024/03/04 03:45:26 - INFO - root -   Epoch: [78/300] 	 loss = 0.4731
2024/03/04 03:45:26 - INFO - root -   train_accuracy = 0.8400
2024/03/04 03:45:40 - INFO - root -   Epoch: [79/300][0/200], lr: 0.00000030 	 loss = 1.7956(1.7956)
2024/03/04 03:45:58 - INFO - root -   Epoch: [79/300][20/200], lr: 0.00000030 	 loss = 0.1671(0.6475)
2024/03/04 03:46:12 - INFO - root -   Epoch: [79/300][40/200], lr: 0.00000030 	 loss = 0.3099(0.5081)
2024/03/04 03:46:23 - INFO - root -   Epoch: [79/300][60/200], lr: 0.00000030 	 loss = 0.0981(0.4957)
2024/03/04 03:46:42 - INFO - root -   Epoch: [79/300][80/200], lr: 0.00000030 	 loss = 1.2356(0.4841)
2024/03/04 03:47:00 - INFO - root -   Epoch: [79/300][100/200], lr: 0.00000030 	 loss = 0.0203(0.4682)
2024/03/04 03:47:13 - INFO - root -   Epoch: [79/300][120/200], lr: 0.00000030 	 loss = 1.4825(0.4662)
2024/03/04 03:47:29 - INFO - root -   Epoch: [79/300][140/200], lr: 0.00000030 	 loss = 2.1954(0.4878)
2024/03/04 03:47:47 - INFO - root -   Epoch: [79/300][160/200], lr: 0.00000030 	 loss = 0.1490(0.4909)
2024/03/04 03:47:58 - INFO - root -   Epoch: [79/300][180/200], lr: 0.00000030 	 loss = 0.2935(0.4897)
2024/03/04 03:48:09 - INFO - root -   Epoch: [79/300] 	 loss = 0.4955
2024/03/04 03:48:13 - INFO - root -   precision = 0.7111
2024/03/04 03:48:13 - INFO - root -   eval_loss = 1.0650
2024/03/04 03:48:13 - INFO - root -   eval_acc = 0.7111
2024/03/04 03:48:14 - INFO - root -   train_accuracy = 0.8300
2024/03/04 03:48:15 - INFO - root -   Epoch: [80/300][0/200], lr: 0.00000030 	 loss = 0.5593(0.5593)
2024/03/04 03:48:37 - INFO - root -   Epoch: [80/300][20/200], lr: 0.00000030 	 loss = 0.1747(0.5153)
2024/03/04 03:48:52 - INFO - root -   Epoch: [80/300][40/200], lr: 0.00000030 	 loss = 0.1302(0.4271)
2024/03/04 03:49:04 - INFO - root -   Epoch: [80/300][60/200], lr: 0.00000030 	 loss = 0.0750(0.4237)
2024/03/04 03:49:12 - INFO - root -   Epoch: [80/300][80/200], lr: 0.00000030 	 loss = 1.0835(0.4525)
2024/03/04 03:49:26 - INFO - root -   Epoch: [80/300][100/200], lr: 0.00000030 	 loss = 0.0281(0.4252)
2024/03/04 03:49:36 - INFO - root -   Epoch: [80/300][120/200], lr: 0.00000030 	 loss = 1.3532(0.4152)
2024/03/04 03:49:52 - INFO - root -   Epoch: [80/300][140/200], lr: 0.00000030 	 loss = 1.6477(0.4258)
2024/03/04 03:50:03 - INFO - root -   Epoch: [80/300][160/200], lr: 0.00000030 	 loss = 0.1559(0.4252)
2024/03/04 03:50:18 - INFO - root -   Epoch: [80/300][180/200], lr: 0.00000030 	 loss = 0.4352(0.4364)
2024/03/04 03:50:29 - INFO - root -   Epoch: [80/300] 	 loss = 0.4417
2024/03/04 03:50:29 - INFO - root -   train_accuracy = 0.8300
2024/03/04 03:50:44 - INFO - root -   Epoch: [81/300][0/200], lr: 0.00000030 	 loss = 0.9757(0.9757)
2024/03/04 03:50:59 - INFO - root -   Epoch: [81/300][20/200], lr: 0.00000030 	 loss = 0.0788(0.5140)
2024/03/04 03:51:15 - INFO - root -   Epoch: [81/300][40/200], lr: 0.00000030 	 loss = 0.3074(0.4494)
2024/03/04 03:51:33 - INFO - root -   Epoch: [81/300][60/200], lr: 0.00000030 	 loss = 0.0182(0.4456)
2024/03/04 03:51:41 - INFO - root -   Epoch: [81/300][80/200], lr: 0.00000030 	 loss = 0.6788(0.4643)
2024/03/04 03:51:59 - INFO - root -   Epoch: [81/300][100/200], lr: 0.00000030 	 loss = 0.2871(0.4466)
2024/03/04 03:52:15 - INFO - root -   Epoch: [81/300][120/200], lr: 0.00000030 	 loss = 1.4089(0.4463)
2024/03/04 03:52:29 - INFO - root -   Epoch: [81/300][140/200], lr: 0.00000030 	 loss = 1.5322(0.4585)
2024/03/04 03:52:46 - INFO - root -   Epoch: [81/300][160/200], lr: 0.00000030 	 loss = 0.1431(0.4507)
2024/03/04 03:52:57 - INFO - root -   Epoch: [81/300][180/200], lr: 0.00000030 	 loss = 1.4616(0.4568)
2024/03/04 03:53:05 - INFO - root -   Epoch: [81/300] 	 loss = 0.4647
2024/03/04 03:53:05 - INFO - root -   train_accuracy = 0.8225
2024/03/04 03:53:17 - INFO - root -   Epoch: [82/300][0/200], lr: 0.00000030 	 loss = 1.8504(1.8504)
2024/03/04 03:53:29 - INFO - root -   Epoch: [82/300][20/200], lr: 0.00000030 	 loss = 0.1253(0.5685)
2024/03/04 03:53:41 - INFO - root -   Epoch: [82/300][40/200], lr: 0.00000030 	 loss = 0.1770(0.4883)
2024/03/04 03:54:02 - INFO - root -   Epoch: [82/300][60/200], lr: 0.00000030 	 loss = 0.0295(0.4834)
2024/03/04 03:54:23 - INFO - root -   Epoch: [82/300][80/200], lr: 0.00000030 	 loss = 1.7093(0.4855)
2024/03/04 03:54:31 - INFO - root -   Epoch: [82/300][100/200], lr: 0.00000030 	 loss = 0.3114(0.4676)
2024/03/04 03:54:46 - INFO - root -   Epoch: [82/300][120/200], lr: 0.00000030 	 loss = 1.0210(0.4468)
2024/03/04 03:55:09 - INFO - root -   Epoch: [82/300][140/200], lr: 0.00000030 	 loss = 2.1633(0.4721)
2024/03/04 03:55:34 - INFO - root -   Epoch: [82/300][160/200], lr: 0.00000030 	 loss = 0.1109(0.5085)
2024/03/04 03:55:42 - INFO - root -   Epoch: [82/300][180/200], lr: 0.00000030 	 loss = 0.2056(0.5173)
2024/03/04 03:55:51 - INFO - root -   Epoch: [82/300] 	 loss = 0.5165
2024/03/04 03:55:51 - INFO - root -   train_accuracy = 0.8250
2024/03/04 03:55:53 - INFO - root -   Epoch: [83/300][0/200], lr: 0.00000031 	 loss = 0.7179(0.7179)
2024/03/04 03:56:27 - INFO - root -   Epoch: [83/300][20/200], lr: 0.00000031 	 loss = 0.2032(0.4930)
2024/03/04 03:56:46 - INFO - root -   Epoch: [83/300][40/200], lr: 0.00000031 	 loss = 0.9298(0.4311)
2024/03/04 03:56:55 - INFO - root -   Epoch: [83/300][60/200], lr: 0.00000031 	 loss = 0.1255(0.4111)
2024/03/04 03:57:10 - INFO - root -   Epoch: [83/300][80/200], lr: 0.00000031 	 loss = 1.5387(0.4103)
2024/03/04 03:57:30 - INFO - root -   Epoch: [83/300][100/200], lr: 0.00000031 	 loss = 0.0244(0.3945)
2024/03/04 03:57:38 - INFO - root -   Epoch: [83/300][120/200], lr: 0.00000031 	 loss = 2.9028(0.3937)
2024/03/04 03:57:59 - INFO - root -   Epoch: [83/300][140/200], lr: 0.00000031 	 loss = 2.6229(0.4026)
2024/03/04 03:58:18 - INFO - root -   Epoch: [83/300][160/200], lr: 0.00000031 	 loss = 0.5609(0.4166)
2024/03/04 03:58:26 - INFO - root -   Epoch: [83/300][180/200], lr: 0.00000031 	 loss = 0.7360(0.4419)
2024/03/04 03:58:33 - INFO - root -   Epoch: [83/300] 	 loss = 0.4409
2024/03/04 03:58:33 - INFO - root -   train_accuracy = 0.8350
2024/03/04 03:58:55 - INFO - root -   Epoch: [84/300][0/200], lr: 0.00000031 	 loss = 2.0199(2.0199)
2024/03/04 03:59:10 - INFO - root -   Epoch: [84/300][20/200], lr: 0.00000031 	 loss = 0.0813(0.7140)
2024/03/04 03:59:18 - INFO - root -   Epoch: [84/300][40/200], lr: 0.00000031 	 loss = 0.3301(0.5619)
2024/03/04 03:59:38 - INFO - root -   Epoch: [84/300][60/200], lr: 0.00000031 	 loss = 0.1524(0.4940)
2024/03/04 03:59:49 - INFO - root -   Epoch: [84/300][80/200], lr: 0.00000031 	 loss = 1.6255(0.5012)
2024/03/04 04:00:07 - INFO - root -   Epoch: [84/300][100/200], lr: 0.00000031 	 loss = 0.2355(0.4861)
2024/03/04 04:00:24 - INFO - root -   Epoch: [84/300][120/200], lr: 0.00000031 	 loss = 1.4630(0.4626)
2024/03/04 04:00:32 - INFO - root -   Epoch: [84/300][140/200], lr: 0.00000031 	 loss = 1.4349(0.4568)
2024/03/04 04:00:40 - INFO - root -   Epoch: [84/300][160/200], lr: 0.00000031 	 loss = 0.1298(0.4551)
2024/03/04 04:00:57 - INFO - root -   Epoch: [84/300][180/200], lr: 0.00000031 	 loss = 0.2052(0.4620)
2024/03/04 04:01:05 - INFO - root -   Epoch: [84/300] 	 loss = 0.4552
2024/03/04 04:01:08 - INFO - root -   precision = 0.7333
2024/03/04 04:01:08 - INFO - root -   eval_loss = 1.0619
2024/03/04 04:01:08 - INFO - root -   eval_acc = 0.7333
2024/03/04 04:01:09 - INFO - root -   train_accuracy = 0.8200
2024/03/04 04:01:11 - INFO - root -   Epoch: [85/300][0/200], lr: 0.00000031 	 loss = 0.6704(0.6704)
2024/03/04 04:01:43 - INFO - root -   Epoch: [85/300][20/200], lr: 0.00000031 	 loss = 0.0996(0.5500)
2024/03/04 04:02:01 - INFO - root -   Epoch: [85/300][40/200], lr: 0.00000031 	 loss = 0.2956(0.4730)
2024/03/04 04:02:09 - INFO - root -   Epoch: [85/300][60/200], lr: 0.00000031 	 loss = 0.0633(0.4597)
2024/03/04 04:02:24 - INFO - root -   Epoch: [85/300][80/200], lr: 0.00000031 	 loss = 1.4186(0.4852)
2024/03/04 04:02:32 - INFO - root -   Epoch: [85/300][100/200], lr: 0.00000031 	 loss = 0.0721(0.4669)
2024/03/04 04:02:47 - INFO - root -   Epoch: [85/300][120/200], lr: 0.00000031 	 loss = 1.5837(0.4401)
2024/03/04 04:03:11 - INFO - root -   Epoch: [85/300][140/200], lr: 0.00000031 	 loss = 1.4496(0.4363)
2024/03/04 04:03:19 - INFO - root -   Epoch: [85/300][160/200], lr: 0.00000031 	 loss = 0.0361(0.4261)
2024/03/04 04:03:39 - INFO - root -   Epoch: [85/300][180/200], lr: 0.00000031 	 loss = 0.0767(0.4332)
2024/03/04 04:03:46 - INFO - root -   Epoch: [85/300] 	 loss = 0.4331
2024/03/04 04:03:46 - INFO - root -   train_accuracy = 0.8425
2024/03/04 04:03:49 - INFO - root -   Epoch: [86/300][0/200], lr: 0.00000031 	 loss = 0.3878(0.3878)
2024/03/04 04:04:28 - INFO - root -   Epoch: [86/300][20/200], lr: 0.00000031 	 loss = 0.2311(0.4579)
2024/03/04 04:04:36 - INFO - root -   Epoch: [86/300][40/200], lr: 0.00000031 	 loss = 0.0802(0.3605)
2024/03/04 04:04:43 - INFO - root -   Epoch: [86/300][60/200], lr: 0.00000031 	 loss = 0.0365(0.3922)
2024/03/04 04:04:58 - INFO - root -   Epoch: [86/300][80/200], lr: 0.00000031 	 loss = 1.2343(0.4038)
2024/03/04 04:05:12 - INFO - root -   Epoch: [86/300][100/200], lr: 0.00000031 	 loss = 0.0192(0.3962)
2024/03/04 04:05:35 - INFO - root -   Epoch: [86/300][120/200], lr: 0.00000031 	 loss = 3.2718(0.4149)
2024/03/04 04:05:43 - INFO - root -   Epoch: [86/300][140/200], lr: 0.00000031 	 loss = 2.0407(0.4358)
2024/03/04 04:05:52 - INFO - root -   Epoch: [86/300][160/200], lr: 0.00000031 	 loss = 0.0537(0.4333)
2024/03/04 04:06:10 - INFO - root -   Epoch: [86/300][180/200], lr: 0.00000031 	 loss = 0.1357(0.4270)
2024/03/04 04:06:18 - INFO - root -   Epoch: [86/300] 	 loss = 0.4350
2024/03/04 04:06:18 - INFO - root -   train_accuracy = 0.8525
2024/03/04 04:06:31 - INFO - root -   Epoch: [87/300][0/200], lr: 0.00000032 	 loss = 0.9200(0.9200)
2024/03/04 04:06:42 - INFO - root -   Epoch: [87/300][20/200], lr: 0.00000032 	 loss = 0.0261(0.5109)
2024/03/04 04:07:02 - INFO - root -   Epoch: [87/300][40/200], lr: 0.00000032 	 loss = 0.3124(0.4146)
2024/03/04 04:07:11 - INFO - root -   Epoch: [87/300][60/200], lr: 0.00000032 	 loss = 0.0125(0.4237)
2024/03/04 04:07:36 - INFO - root -   Epoch: [87/300][80/200], lr: 0.00000032 	 loss = 0.5669(0.4138)
2024/03/04 04:07:47 - INFO - root -   Epoch: [87/300][100/200], lr: 0.00000032 	 loss = 0.0166(0.3974)
2024/03/04 04:07:55 - INFO - root -   Epoch: [87/300][120/200], lr: 0.00000032 	 loss = 2.3420(0.4076)
2024/03/04 04:08:18 - INFO - root -   Epoch: [87/300][140/200], lr: 0.00000032 	 loss = 1.4362(0.4250)
2024/03/04 04:08:28 - INFO - root -   Epoch: [87/300][160/200], lr: 0.00000032 	 loss = 0.1485(0.4267)
2024/03/04 04:08:39 - INFO - root -   Epoch: [87/300][180/200], lr: 0.00000032 	 loss = 0.6062(0.4481)
2024/03/04 04:08:47 - INFO - root -   Epoch: [87/300] 	 loss = 0.4526
2024/03/04 04:08:47 - INFO - root -   train_accuracy = 0.8175
2024/03/04 04:09:00 - INFO - root -   Epoch: [88/300][0/200], lr: 0.00000032 	 loss = 0.7783(0.7783)
2024/03/04 04:09:16 - INFO - root -   Epoch: [88/300][20/200], lr: 0.00000032 	 loss = 0.0852(0.6307)
2024/03/04 04:09:24 - INFO - root -   Epoch: [88/300][40/200], lr: 0.00000032 	 loss = 0.1894(0.4570)
2024/03/04 04:09:45 - INFO - root -   Epoch: [88/300][60/200], lr: 0.00000032 	 loss = 0.2256(0.4453)
2024/03/04 04:09:53 - INFO - root -   Epoch: [88/300][80/200], lr: 0.00000032 	 loss = 1.9937(0.4794)
2024/03/04 04:10:10 - INFO - root -   Epoch: [88/300][100/200], lr: 0.00000032 	 loss = 0.1335(0.4669)
2024/03/04 04:10:29 - INFO - root -   Epoch: [88/300][120/200], lr: 0.00000032 	 loss = 1.7076(0.4556)
2024/03/04 04:10:42 - INFO - root -   Epoch: [88/300][140/200], lr: 0.00000032 	 loss = 1.8158(0.4580)
2024/03/04 04:10:51 - INFO - root -   Epoch: [88/300][160/200], lr: 0.00000032 	 loss = 0.2772(0.4461)
2024/03/04 04:11:21 - INFO - root -   Epoch: [88/300][180/200], lr: 0.00000032 	 loss = 0.4922(0.4531)
2024/03/04 04:11:29 - INFO - root -   Epoch: [88/300] 	 loss = 0.4671
2024/03/04 04:11:29 - INFO - root -   train_accuracy = 0.8300
2024/03/04 04:11:30 - INFO - root -   Epoch: [89/300][0/200], lr: 0.00000032 	 loss = 1.0523(1.0523)
2024/03/04 04:11:57 - INFO - root -   Epoch: [89/300][20/200], lr: 0.00000032 	 loss = 0.0236(0.5817)
2024/03/04 04:12:04 - INFO - root -   Epoch: [89/300][40/200], lr: 0.00000032 	 loss = 0.4202(0.5068)
2024/03/04 04:12:28 - INFO - root -   Epoch: [89/300][60/200], lr: 0.00000032 	 loss = 0.0639(0.4581)
2024/03/04 04:12:36 - INFO - root -   Epoch: [89/300][80/200], lr: 0.00000032 	 loss = 0.8374(0.4604)
2024/03/04 04:12:50 - INFO - root -   Epoch: [89/300][100/200], lr: 0.00000032 	 loss = 0.1688(0.4407)
2024/03/04 04:13:07 - INFO - root -   Epoch: [89/300][120/200], lr: 0.00000032 	 loss = 1.9496(0.4173)
2024/03/04 04:13:28 - INFO - root -   Epoch: [89/300][140/200], lr: 0.00000032 	 loss = 1.3827(0.4221)
2024/03/04 04:13:46 - INFO - root -   Epoch: [89/300][160/200], lr: 0.00000032 	 loss = 0.7353(0.4392)
2024/03/04 04:14:07 - INFO - root -   Epoch: [89/300][180/200], lr: 0.00000032 	 loss = 0.7792(0.4407)
2024/03/04 04:14:15 - INFO - root -   Epoch: [89/300] 	 loss = 0.4434
2024/03/04 04:14:18 - INFO - root -   precision = 0.7111
2024/03/04 04:14:18 - INFO - root -   eval_loss = 1.1166
2024/03/04 04:14:18 - INFO - root -   eval_acc = 0.7111
2024/03/04 04:14:19 - INFO - root -   train_accuracy = 0.8275
2024/03/04 04:14:34 - INFO - root -   Epoch: [90/300][0/200], lr: 0.00000032 	 loss = 1.8333(1.8333)
2024/03/04 04:15:00 - INFO - root -   Epoch: [90/300][20/200], lr: 0.00000032 	 loss = 0.1173(0.5519)
2024/03/04 04:15:11 - INFO - root -   Epoch: [90/300][40/200], lr: 0.00000032 	 loss = 0.4102(0.4538)
2024/03/04 04:15:26 - INFO - root -   Epoch: [90/300][60/200], lr: 0.00000032 	 loss = 0.0519(0.4519)
2024/03/04 04:15:42 - INFO - root -   Epoch: [90/300][80/200], lr: 0.00000032 	 loss = 1.7576(0.4427)
2024/03/04 04:15:57 - INFO - root -   Epoch: [90/300][100/200], lr: 0.00000032 	 loss = 0.0865(0.4349)
2024/03/04 04:16:25 - INFO - root -   Epoch: [90/300][120/200], lr: 0.00000032 	 loss = 2.3073(0.4259)
2024/03/04 04:16:35 - INFO - root -   Epoch: [90/300][140/200], lr: 0.00000032 	 loss = 1.9974(0.4336)
2024/03/04 04:16:51 - INFO - root -   Epoch: [90/300][160/200], lr: 0.00000032 	 loss = 0.1405(0.4601)
2024/03/04 04:17:09 - INFO - root -   Epoch: [90/300][180/200], lr: 0.00000032 	 loss = 0.6147(0.4712)
2024/03/04 04:17:16 - INFO - root -   Epoch: [90/300] 	 loss = 0.4656
2024/03/04 04:17:16 - INFO - root -   train_accuracy = 0.8325
2024/03/04 04:17:35 - INFO - root -   Epoch: [91/300][0/200], lr: 0.00000033 	 loss = 0.8391(0.8391)
2024/03/04 04:17:51 - INFO - root -   Epoch: [91/300][20/200], lr: 0.00000033 	 loss = 0.3822(0.5208)
2024/03/04 04:18:06 - INFO - root -   Epoch: [91/300][40/200], lr: 0.00000033 	 loss = 0.1688(0.4549)
2024/03/04 04:18:26 - INFO - root -   Epoch: [91/300][60/200], lr: 0.00000033 	 loss = 0.0391(0.4392)
2024/03/04 04:18:40 - INFO - root -   Epoch: [91/300][80/200], lr: 0.00000033 	 loss = 1.5214(0.4575)
2024/03/04 04:18:54 - INFO - root -   Epoch: [91/300][100/200], lr: 0.00000033 	 loss = 0.0342(0.4342)
2024/03/04 04:19:10 - INFO - root -   Epoch: [91/300][120/200], lr: 0.00000033 	 loss = 1.6659(0.4282)
2024/03/04 04:19:25 - INFO - root -   Epoch: [91/300][140/200], lr: 0.00000033 	 loss = 1.7540(0.4479)
2024/03/04 04:19:33 - INFO - root -   Epoch: [91/300][160/200], lr: 0.00000033 	 loss = 0.2743(0.4328)
2024/03/04 04:19:51 - INFO - root -   Epoch: [91/300][180/200], lr: 0.00000033 	 loss = 0.2267(0.4334)
2024/03/04 04:19:58 - INFO - root -   Epoch: [91/300] 	 loss = 0.4260
2024/03/04 04:19:58 - INFO - root -   train_accuracy = 0.8475
2024/03/04 04:20:00 - INFO - root -   Epoch: [92/300][0/200], lr: 0.00000033 	 loss = 1.1901(1.1901)
2024/03/04 04:20:27 - INFO - root -   Epoch: [92/300][20/200], lr: 0.00000033 	 loss = 0.0618(0.4608)
2024/03/04 04:20:38 - INFO - root -   Epoch: [92/300][40/200], lr: 0.00000033 	 loss = 0.3875(0.3665)
2024/03/04 04:20:51 - INFO - root -   Epoch: [92/300][60/200], lr: 0.00000033 	 loss = 0.0384(0.3698)
2024/03/04 04:21:15 - INFO - root -   Epoch: [92/300][80/200], lr: 0.00000033 	 loss = 1.6813(0.3979)
2024/03/04 04:21:23 - INFO - root -   Epoch: [92/300][100/200], lr: 0.00000033 	 loss = 0.0696(0.4041)
2024/03/04 04:21:31 - INFO - root -   Epoch: [92/300][120/200], lr: 0.00000033 	 loss = 1.1277(0.3998)
2024/03/04 04:21:39 - INFO - root -   Epoch: [92/300][140/200], lr: 0.00000033 	 loss = 1.2849(0.3996)
2024/03/04 04:22:08 - INFO - root -   Epoch: [92/300][160/200], lr: 0.00000033 	 loss = 0.0330(0.4027)
2024/03/04 04:22:27 - INFO - root -   Epoch: [92/300][180/200], lr: 0.00000033 	 loss = 0.0823(0.4143)
2024/03/04 04:22:34 - INFO - root -   Epoch: [92/300] 	 loss = 0.4220
2024/03/04 04:22:34 - INFO - root -   train_accuracy = 0.8450
2024/03/04 04:22:50 - INFO - root -   Epoch: [93/300][0/200], lr: 0.00000033 	 loss = 0.8179(0.8179)
2024/03/04 04:23:07 - INFO - root -   Epoch: [93/300][20/200], lr: 0.00000033 	 loss = 0.2120(0.6495)
2024/03/04 04:23:15 - INFO - root -   Epoch: [93/300][40/200], lr: 0.00000033 	 loss = 0.2910(0.4931)
2024/03/04 04:23:38 - INFO - root -   Epoch: [93/300][60/200], lr: 0.00000033 	 loss = 0.2357(0.4910)
2024/03/04 04:23:51 - INFO - root -   Epoch: [93/300][80/200], lr: 0.00000033 	 loss = 1.4972(0.4982)
2024/03/04 04:24:11 - INFO - root -   Epoch: [93/300][100/200], lr: 0.00000033 	 loss = 0.0056(0.4722)
2024/03/04 04:24:25 - INFO - root -   Epoch: [93/300][120/200], lr: 0.00000033 	 loss = 0.9498(0.4529)
2024/03/04 04:24:37 - INFO - root -   Epoch: [93/300][140/200], lr: 0.00000033 	 loss = 1.1542(0.4729)
2024/03/04 04:24:50 - INFO - root -   Epoch: [93/300][160/200], lr: 0.00000033 	 loss = 0.1996(0.4608)
2024/03/04 04:25:05 - INFO - root -   Epoch: [93/300][180/200], lr: 0.00000033 	 loss = 0.3234(0.4652)
2024/03/04 04:25:13 - INFO - root -   Epoch: [93/300] 	 loss = 0.4627
2024/03/04 04:25:13 - INFO - root -   train_accuracy = 0.8375
2024/03/04 04:25:33 - INFO - root -   Epoch: [94/300][0/200], lr: 0.00000033 	 loss = 1.1579(1.1579)
2024/03/04 04:25:41 - INFO - root -   Epoch: [94/300][20/200], lr: 0.00000033 	 loss = 0.3458(0.5932)
2024/03/04 04:25:51 - INFO - root -   Epoch: [94/300][40/200], lr: 0.00000033 	 loss = 0.6221(0.4499)
2024/03/04 04:26:14 - INFO - root -   Epoch: [94/300][60/200], lr: 0.00000033 	 loss = 0.2307(0.4352)
2024/03/04 04:26:25 - INFO - root -   Epoch: [94/300][80/200], lr: 0.00000033 	 loss = 0.5155(0.4487)
2024/03/04 04:26:45 - INFO - root -   Epoch: [94/300][100/200], lr: 0.00000033 	 loss = 0.0648(0.4358)
2024/03/04 04:27:05 - INFO - root -   Epoch: [94/300][120/200], lr: 0.00000033 	 loss = 0.9574(0.4364)
2024/03/04 04:27:20 - INFO - root -   Epoch: [94/300][140/200], lr: 0.00000033 	 loss = 1.0419(0.4464)
2024/03/04 04:27:28 - INFO - root -   Epoch: [94/300][160/200], lr: 0.00000033 	 loss = 0.1382(0.4426)
2024/03/04 04:27:49 - INFO - root -   Epoch: [94/300][180/200], lr: 0.00000033 	 loss = 0.3026(0.4380)
2024/03/04 04:28:03 - INFO - root -   Epoch: [94/300] 	 loss = 0.4481
2024/03/04 04:28:06 - INFO - root -   precision = 0.7111
2024/03/04 04:28:06 - INFO - root -   eval_loss = 1.2158
2024/03/04 04:28:06 - INFO - root -   eval_acc = 0.7111
2024/03/04 04:28:07 - INFO - root -   train_accuracy = 0.8325
2024/03/04 04:28:22 - INFO - root -   Epoch: [95/300][0/200], lr: 0.00000034 	 loss = 1.0343(1.0343)
2024/03/04 04:28:37 - INFO - root -   Epoch: [95/300][20/200], lr: 0.00000034 	 loss = 0.2427(0.4970)
2024/03/04 04:28:45 - INFO - root -   Epoch: [95/300][40/200], lr: 0.00000034 	 loss = 0.4074(0.4103)
2024/03/04 04:29:00 - INFO - root -   Epoch: [95/300][60/200], lr: 0.00000034 	 loss = 0.0811(0.4179)
2024/03/04 04:29:12 - INFO - root -   Epoch: [95/300][80/200], lr: 0.00000034 	 loss = 1.1318(0.4589)
2024/03/04 04:29:20 - INFO - root -   Epoch: [95/300][100/200], lr: 0.00000034 	 loss = 0.0841(0.4302)
2024/03/04 04:29:36 - INFO - root -   Epoch: [95/300][120/200], lr: 0.00000034 	 loss = 0.7847(0.4089)
2024/03/04 04:29:47 - INFO - root -   Epoch: [95/300][140/200], lr: 0.00000034 	 loss = 1.9768(0.4178)
2024/03/04 04:30:04 - INFO - root -   Epoch: [95/300][160/200], lr: 0.00000034 	 loss = 0.2608(0.4272)
2024/03/04 04:30:26 - INFO - root -   Epoch: [95/300][180/200], lr: 0.00000034 	 loss = 0.9056(0.4208)
2024/03/04 04:30:33 - INFO - root -   Epoch: [95/300] 	 loss = 0.4170
2024/03/04 04:30:33 - INFO - root -   train_accuracy = 0.8475
2024/03/04 04:30:45 - INFO - root -   Epoch: [96/300][0/200], lr: 0.00000034 	 loss = 0.4617(0.4617)
2024/03/04 04:31:03 - INFO - root -   Epoch: [96/300][20/200], lr: 0.00000034 	 loss = 0.1074(0.4694)
2024/03/04 04:31:15 - INFO - root -   Epoch: [96/300][40/200], lr: 0.00000034 	 loss = 0.1335(0.4181)
2024/03/04 04:31:28 - INFO - root -   Epoch: [96/300][60/200], lr: 0.00000034 	 loss = 0.0158(0.4105)
2024/03/04 04:31:37 - INFO - root -   Epoch: [96/300][80/200], lr: 0.00000034 	 loss = 1.5494(0.4340)
2024/03/04 04:31:45 - INFO - root -   Epoch: [96/300][100/200], lr: 0.00000034 	 loss = 0.0186(0.4040)
2024/03/04 04:31:55 - INFO - root -   Epoch: [96/300][120/200], lr: 0.00000034 	 loss = 0.6666(0.3760)
2024/03/04 04:32:15 - INFO - root -   Epoch: [96/300][140/200], lr: 0.00000034 	 loss = 1.4684(0.3873)
2024/03/04 04:32:24 - INFO - root -   Epoch: [96/300][160/200], lr: 0.00000034 	 loss = 0.1956(0.3832)
2024/03/04 04:32:32 - INFO - root -   Epoch: [96/300][180/200], lr: 0.00000034 	 loss = 0.3835(0.3779)
2024/03/04 04:32:39 - INFO - root -   Epoch: [96/300] 	 loss = 0.3814
2024/03/04 04:32:39 - INFO - root -   train_accuracy = 0.8625
2024/03/04 04:32:56 - INFO - root -   Epoch: [97/300][0/200], lr: 0.00000034 	 loss = 1.2015(1.2015)
2024/03/04 04:33:16 - INFO - root -   Epoch: [97/300][20/200], lr: 0.00000034 	 loss = 0.0902(0.5101)
2024/03/04 04:33:27 - INFO - root -   Epoch: [97/300][40/200], lr: 0.00000034 	 loss = 0.0351(0.4105)
2024/03/04 04:33:35 - INFO - root -   Epoch: [97/300][60/200], lr: 0.00000034 	 loss = 0.0194(0.4339)
2024/03/04 04:33:53 - INFO - root -   Epoch: [97/300][80/200], lr: 0.00000034 	 loss = 1.2124(0.4466)
2024/03/04 04:34:14 - INFO - root -   Epoch: [97/300][100/200], lr: 0.00000034 	 loss = 0.0054(0.4356)
2024/03/04 04:34:25 - INFO - root -   Epoch: [97/300][120/200], lr: 0.00000034 	 loss = 1.1888(0.4242)
2024/03/04 04:34:51 - INFO - root -   Epoch: [97/300][140/200], lr: 0.00000034 	 loss = 2.0926(0.4381)
2024/03/04 04:34:59 - INFO - root -   Epoch: [97/300][160/200], lr: 0.00000034 	 loss = 0.0865(0.4295)
2024/03/04 04:35:07 - INFO - root -   Epoch: [97/300][180/200], lr: 0.00000034 	 loss = 1.1888(0.4286)
2024/03/04 04:35:20 - INFO - root -   Epoch: [97/300] 	 loss = 0.4266
2024/03/04 04:35:20 - INFO - root -   train_accuracy = 0.8350
2024/03/04 04:35:37 - INFO - root -   Epoch: [98/300][0/200], lr: 0.00000034 	 loss = 2.3534(2.3534)
2024/03/04 04:35:54 - INFO - root -   Epoch: [98/300][20/200], lr: 0.00000034 	 loss = 0.1761(0.5722)
2024/03/04 04:36:11 - INFO - root -   Epoch: [98/300][40/200], lr: 0.00000034 	 loss = 0.5927(0.4800)
2024/03/04 04:36:19 - INFO - root -   Epoch: [98/300][60/200], lr: 0.00000034 	 loss = 0.0696(0.4877)
2024/03/04 04:36:42 - INFO - root -   Epoch: [98/300][80/200], lr: 0.00000034 	 loss = 0.8875(0.4583)
2024/03/04 04:36:59 - INFO - root -   Epoch: [98/300][100/200], lr: 0.00000034 	 loss = 0.0491(0.4543)
2024/03/04 04:37:20 - INFO - root -   Epoch: [98/300][120/200], lr: 0.00000034 	 loss = 1.0541(0.4547)
2024/03/04 04:37:29 - INFO - root -   Epoch: [98/300][140/200], lr: 0.00000034 	 loss = 1.3587(0.4511)
2024/03/04 04:37:50 - INFO - root -   Epoch: [98/300][160/200], lr: 0.00000034 	 loss = 0.1299(0.4525)
2024/03/04 04:38:01 - INFO - root -   Epoch: [98/300][180/200], lr: 0.00000034 	 loss = 0.4743(0.4505)
2024/03/04 04:38:08 - INFO - root -   Epoch: [98/300] 	 loss = 0.4544
2024/03/04 04:38:08 - INFO - root -   train_accuracy = 0.8325
2024/03/04 04:38:12 - INFO - root -   Epoch: [99/300][0/200], lr: 0.00000035 	 loss = 1.1183(1.1183)
2024/03/04 04:38:37 - INFO - root -   Epoch: [99/300][20/200], lr: 0.00000035 	 loss = 0.1924(0.6358)
2024/03/04 04:38:54 - INFO - root -   Epoch: [99/300][40/200], lr: 0.00000035 	 loss = 0.3281(0.5030)
2024/03/04 04:39:06 - INFO - root -   Epoch: [99/300][60/200], lr: 0.00000035 	 loss = 0.0985(0.4897)
2024/03/04 04:39:14 - INFO - root -   Epoch: [99/300][80/200], lr: 0.00000035 	 loss = 1.9503(0.4932)
2024/03/04 04:39:29 - INFO - root -   Epoch: [99/300][100/200], lr: 0.00000035 	 loss = 0.0472(0.4746)
2024/03/04 04:39:46 - INFO - root -   Epoch: [99/300][120/200], lr: 0.00000035 	 loss = 0.8541(0.4524)
2024/03/04 04:39:58 - INFO - root -   Epoch: [99/300][140/200], lr: 0.00000035 	 loss = 0.9494(0.4495)
2024/03/04 04:40:06 - INFO - root -   Epoch: [99/300][160/200], lr: 0.00000035 	 loss = 0.0205(0.4315)
2024/03/04 04:40:24 - INFO - root -   Epoch: [99/300][180/200], lr: 0.00000035 	 loss = 0.0575(0.4425)
2024/03/04 04:40:32 - INFO - root -   Epoch: [99/300] 	 loss = 0.4364
2024/03/04 04:40:35 - INFO - root -   precision = 0.7111
2024/03/04 04:40:35 - INFO - root -   eval_loss = 1.2039
2024/03/04 04:40:35 - INFO - root -   eval_acc = 0.7111
2024/03/04 04:40:36 - INFO - root -   train_accuracy = 0.8525
2024/03/04 04:40:38 - INFO - root -   Epoch: [100/300][0/200], lr: 0.00000035 	 loss = 0.3779(0.3779)
2024/03/04 04:41:07 - INFO - root -   Epoch: [100/300][20/200], lr: 0.00000035 	 loss = 0.2083(0.5027)
2024/03/04 04:41:20 - INFO - root -   Epoch: [100/300][40/200], lr: 0.00000035 	 loss = 0.1072(0.3890)
2024/03/04 04:41:51 - INFO - root -   Epoch: [100/300][60/200], lr: 0.00000035 	 loss = 0.1069(0.4289)
2024/03/04 04:41:59 - INFO - root -   Epoch: [100/300][80/200], lr: 0.00000035 	 loss = 0.5549(0.4412)
2024/03/04 04:42:17 - INFO - root -   Epoch: [100/300][100/200], lr: 0.00000035 	 loss = 0.1224(0.4330)
2024/03/04 04:42:29 - INFO - root -   Epoch: [100/300][120/200], lr: 0.00000035 	 loss = 1.4389(0.4418)
2024/03/04 04:42:48 - INFO - root -   Epoch: [100/300][140/200], lr: 0.00000035 	 loss = 2.5305(0.4634)
2024/03/04 04:42:57 - INFO - root -   Epoch: [100/300][160/200], lr: 0.00000035 	 loss = 0.3129(0.4484)
2024/03/04 04:43:16 - INFO - root -   Epoch: [100/300][180/200], lr: 0.00000035 	 loss = 0.0116(0.4287)
2024/03/04 04:43:24 - INFO - root -   Epoch: [100/300] 	 loss = 0.4258
2024/03/04 04:43:24 - INFO - root -   train_accuracy = 0.8425
2024/03/04 04:43:26 - INFO - root -   Epoch: [101/300][0/200], lr: 0.00000035 	 loss = 0.5544(0.5544)
2024/03/04 04:44:01 - INFO - root -   Epoch: [101/300][20/200], lr: 0.00000035 	 loss = 0.0917(0.5848)
2024/03/04 04:44:15 - INFO - root -   Epoch: [101/300][40/200], lr: 0.00000035 	 loss = 0.1085(0.4477)
2024/03/04 04:44:27 - INFO - root -   Epoch: [101/300][60/200], lr: 0.00000035 	 loss = 0.1550(0.4143)
2024/03/04 04:44:42 - INFO - root -   Epoch: [101/300][80/200], lr: 0.00000035 	 loss = 1.5597(0.4196)
2024/03/04 04:44:52 - INFO - root -   Epoch: [101/300][100/200], lr: 0.00000035 	 loss = 0.0395(0.4058)
2024/03/04 04:45:17 - INFO - root -   Epoch: [101/300][120/200], lr: 0.00000035 	 loss = 2.2971(0.3986)
2024/03/04 04:45:30 - INFO - root -   Epoch: [101/300][140/200], lr: 0.00000035 	 loss = 1.3122(0.4084)
2024/03/04 04:45:46 - INFO - root -   Epoch: [101/300][160/200], lr: 0.00000035 	 loss = 0.1625(0.4031)
2024/03/04 04:46:02 - INFO - root -   Epoch: [101/300][180/200], lr: 0.00000035 	 loss = 0.2247(0.4056)
2024/03/04 04:46:09 - INFO - root -   Epoch: [101/300] 	 loss = 0.4164
2024/03/04 04:46:09 - INFO - root -   train_accuracy = 0.8425
2024/03/04 04:46:23 - INFO - root -   Epoch: [102/300][0/200], lr: 0.00000035 	 loss = 0.1846(0.1846)
2024/03/04 04:46:32 - INFO - root -   Epoch: [102/300][20/200], lr: 0.00000035 	 loss = 0.1080(0.3819)
2024/03/04 04:46:50 - INFO - root -   Epoch: [102/300][40/200], lr: 0.00000035 	 loss = 0.1536(0.3877)
2024/03/04 04:47:11 - INFO - root -   Epoch: [102/300][60/200], lr: 0.00000035 	 loss = 0.0366(0.3729)
2024/03/04 04:47:19 - INFO - root -   Epoch: [102/300][80/200], lr: 0.00000035 	 loss = 1.0478(0.3905)
2024/03/04 04:47:34 - INFO - root -   Epoch: [102/300][100/200], lr: 0.00000035 	 loss = 0.0124(0.3897)
2024/03/04 04:48:02 - INFO - root -   Epoch: [102/300][120/200], lr: 0.00000035 	 loss = 2.0473(0.3977)
2024/03/04 04:48:10 - INFO - root -   Epoch: [102/300][140/200], lr: 0.00000035 	 loss = 1.0884(0.3950)
2024/03/04 04:48:26 - INFO - root -   Epoch: [102/300][160/200], lr: 0.00000035 	 loss = 0.0551(0.3888)
2024/03/04 04:48:36 - INFO - root -   Epoch: [102/300][180/200], lr: 0.00000035 	 loss = 0.1981(0.3931)
2024/03/04 04:48:49 - INFO - root -   Epoch: [102/300] 	 loss = 0.4135
2024/03/04 04:48:49 - INFO - root -   train_accuracy = 0.8550
2024/03/04 04:48:50 - INFO - root -   Epoch: [103/300][0/200], lr: 0.00000035 	 loss = 0.2011(0.2011)
2024/03/04 04:49:17 - INFO - root -   Epoch: [103/300][20/200], lr: 0.00000035 	 loss = 0.6322(0.4758)
2024/03/04 04:49:41 - INFO - root -   Epoch: [103/300][40/200], lr: 0.00000035 	 loss = 0.8266(0.3933)
2024/03/04 04:49:56 - INFO - root -   Epoch: [103/300][60/200], lr: 0.00000035 	 loss = 0.5881(0.3922)
2024/03/04 04:50:04 - INFO - root -   Epoch: [103/300][80/200], lr: 0.00000035 	 loss = 0.7034(0.3770)
2024/03/04 04:50:20 - INFO - root -   Epoch: [103/300][100/200], lr: 0.00000035 	 loss = 0.0162(0.3739)
2024/03/04 04:50:44 - INFO - root -   Epoch: [103/300][120/200], lr: 0.00000035 	 loss = 3.0954(0.3896)
2024/03/04 04:50:52 - INFO - root -   Epoch: [103/300][140/200], lr: 0.00000035 	 loss = 1.5723(0.4051)
2024/03/04 04:51:10 - INFO - root -   Epoch: [103/300][160/200], lr: 0.00000035 	 loss = 0.1908(0.3878)
2024/03/04 04:51:25 - INFO - root -   Epoch: [103/300][180/200], lr: 0.00000035 	 loss = 0.5328(0.3879)
2024/03/04 04:51:33 - INFO - root -   Epoch: [103/300] 	 loss = 0.3900
2024/03/04 04:51:33 - INFO - root -   train_accuracy = 0.8600
2024/03/04 04:51:35 - INFO - root -   Epoch: [104/300][0/200], lr: 0.00000036 	 loss = 0.2461(0.2461)
2024/03/04 04:52:02 - INFO - root -   Epoch: [104/300][20/200], lr: 0.00000036 	 loss = 0.6953(0.4510)
2024/03/04 04:52:21 - INFO - root -   Epoch: [104/300][40/200], lr: 0.00000036 	 loss = 0.1247(0.3966)
2024/03/04 04:52:39 - INFO - root -   Epoch: [104/300][60/200], lr: 0.00000036 	 loss = 0.0089(0.3952)
2024/03/04 04:52:47 - INFO - root -   Epoch: [104/300][80/200], lr: 0.00000036 	 loss = 2.3774(0.3883)
2024/03/04 04:53:02 - INFO - root -   Epoch: [104/300][100/200], lr: 0.00000036 	 loss = 0.0115(0.3889)
2024/03/04 04:53:12 - INFO - root -   Epoch: [104/300][120/200], lr: 0.00000036 	 loss = 1.0792(0.3927)
2024/03/04 04:53:24 - INFO - root -   Epoch: [104/300][140/200], lr: 0.00000036 	 loss = 0.9437(0.3953)
2024/03/04 04:53:46 - INFO - root -   Epoch: [104/300][160/200], lr: 0.00000036 	 loss = 0.5592(0.3831)
2024/03/04 04:54:09 - INFO - root -   Epoch: [104/300][180/200], lr: 0.00000036 	 loss = 0.0968(0.4040)
2024/03/04 04:54:17 - INFO - root -   Epoch: [104/300] 	 loss = 0.4057
2024/03/04 04:54:21 - INFO - root -   precision = 0.7111
2024/03/04 04:54:21 - INFO - root -   eval_loss = 1.3071
2024/03/04 04:54:21 - INFO - root -   eval_acc = 0.7111
2024/03/04 04:54:22 - INFO - root -   train_accuracy = 0.8600
2024/03/04 04:54:24 - INFO - root -   Epoch: [105/300][0/200], lr: 0.00000036 	 loss = 2.0174(2.0174)
2024/03/04 04:54:53 - INFO - root -   Epoch: [105/300][20/200], lr: 0.00000036 	 loss = 0.2637(0.6751)
2024/03/04 04:55:06 - INFO - root -   Epoch: [105/300][40/200], lr: 0.00000036 	 loss = 0.2803(0.4760)
2024/03/04 04:55:23 - INFO - root -   Epoch: [105/300][60/200], lr: 0.00000036 	 loss = 0.0269(0.4212)
2024/03/04 04:55:31 - INFO - root -   Epoch: [105/300][80/200], lr: 0.00000036 	 loss = 0.7394(0.4074)
2024/03/04 04:55:51 - INFO - root -   Epoch: [105/300][100/200], lr: 0.00000036 	 loss = 0.0790(0.4078)
2024/03/04 04:56:10 - INFO - root -   Epoch: [105/300][120/200], lr: 0.00000036 	 loss = 3.8794(0.4153)
2024/03/04 04:56:24 - INFO - root -   Epoch: [105/300][140/200], lr: 0.00000036 	 loss = 0.8685(0.4103)
2024/03/04 04:56:43 - INFO - root -   Epoch: [105/300][160/200], lr: 0.00000036 	 loss = 0.1347(0.4058)
2024/03/04 04:56:51 - INFO - root -   Epoch: [105/300][180/200], lr: 0.00000036 	 loss = 0.3436(0.4165)
2024/03/04 04:56:59 - INFO - root -   Epoch: [105/300] 	 loss = 0.4217
2024/03/04 04:56:59 - INFO - root -   train_accuracy = 0.8375
2024/03/04 04:57:10 - INFO - root -   Epoch: [106/300][0/200], lr: 0.00000036 	 loss = 1.0148(1.0148)
2024/03/04 04:57:23 - INFO - root -   Epoch: [106/300][20/200], lr: 0.00000036 	 loss = 0.2139(0.4187)
2024/03/04 04:57:42 - INFO - root -   Epoch: [106/300][40/200], lr: 0.00000036 	 loss = 0.2135(0.3712)
2024/03/04 04:58:08 - INFO - root -   Epoch: [106/300][60/200], lr: 0.00000036 	 loss = 0.0444(0.3868)
2024/03/04 04:58:16 - INFO - root -   Epoch: [106/300][80/200], lr: 0.00000036 	 loss = 1.0120(0.3990)
2024/03/04 04:58:35 - INFO - root -   Epoch: [106/300][100/200], lr: 0.00000036 	 loss = 0.1984(0.3711)
2024/03/04 04:58:54 - INFO - root -   Epoch: [106/300][120/200], lr: 0.00000036 	 loss = 1.4006(0.3690)
2024/03/04 04:59:19 - INFO - root -   Epoch: [106/300][140/200], lr: 0.00000036 	 loss = 1.2628(0.3687)
2024/03/04 04:59:31 - INFO - root -   Epoch: [106/300][160/200], lr: 0.00000036 	 loss = 0.1392(0.3750)
2024/03/04 04:59:46 - INFO - root -   Epoch: [106/300][180/200], lr: 0.00000036 	 loss = 0.3209(0.3741)
2024/03/04 04:59:54 - INFO - root -   Epoch: [106/300] 	 loss = 0.3640
2024/03/04 04:59:54 - INFO - root -   train_accuracy = 0.8725
2024/03/04 04:59:55 - INFO - root -   Epoch: [107/300][0/200], lr: 0.00000036 	 loss = 0.3226(0.3226)
2024/03/04 05:00:27 - INFO - root -   Epoch: [107/300][20/200], lr: 0.00000036 	 loss = 0.0275(0.3262)
2024/03/04 05:00:39 - INFO - root -   Epoch: [107/300][40/200], lr: 0.00000036 	 loss = 0.0945(0.3181)
2024/03/04 05:00:58 - INFO - root -   Epoch: [107/300][60/200], lr: 0.00000036 	 loss = 0.0163(0.3194)
2024/03/04 05:01:06 - INFO - root -   Epoch: [107/300][80/200], lr: 0.00000036 	 loss = 1.0056(0.3936)
2024/03/04 05:01:24 - INFO - root -   Epoch: [107/300][100/200], lr: 0.00000036 	 loss = 0.0630(0.3745)
2024/03/04 05:01:55 - INFO - root -   Epoch: [107/300][120/200], lr: 0.00000036 	 loss = 2.1457(0.4042)
2024/03/04 05:02:03 - INFO - root -   Epoch: [107/300][140/200], lr: 0.00000036 	 loss = 0.7711(0.4036)
2024/03/04 05:02:20 - INFO - root -   Epoch: [107/300][160/200], lr: 0.00000036 	 loss = 0.5630(0.3969)
2024/03/04 05:02:31 - INFO - root -   Epoch: [107/300][180/200], lr: 0.00000036 	 loss = 0.4906(0.4038)
2024/03/04 05:02:38 - INFO - root -   Epoch: [107/300] 	 loss = 0.4000
2024/03/04 05:02:38 - INFO - root -   train_accuracy = 0.8525
2024/03/04 05:02:55 - INFO - root -   Epoch: [108/300][0/200], lr: 0.00000037 	 loss = 1.6289(1.6289)
2024/03/04 05:03:03 - INFO - root -   Epoch: [108/300][20/200], lr: 0.00000037 	 loss = 0.2830(0.5228)
2024/03/04 05:03:20 - INFO - root -   Epoch: [108/300][40/200], lr: 0.00000037 	 loss = 0.7540(0.4572)
2024/03/04 05:03:30 - INFO - root -   Epoch: [108/300][60/200], lr: 0.00000037 	 loss = 0.1414(0.4239)
2024/03/04 05:03:46 - INFO - root -   Epoch: [108/300][80/200], lr: 0.00000037 	 loss = 1.5195(0.4164)
2024/03/04 05:04:01 - INFO - root -   Epoch: [108/300][100/200], lr: 0.00000037 	 loss = 0.0934(0.4093)
2024/03/04 05:04:16 - INFO - root -   Epoch: [108/300][120/200], lr: 0.00000037 	 loss = 1.5129(0.3859)
2024/03/04 05:04:35 - INFO - root -   Epoch: [108/300][140/200], lr: 0.00000037 	 loss = 1.0218(0.3903)
2024/03/04 05:04:57 - INFO - root -   Epoch: [108/300][160/200], lr: 0.00000037 	 loss = 0.3522(0.3872)
2024/03/04 05:05:05 - INFO - root -   Epoch: [108/300][180/200], lr: 0.00000037 	 loss = 0.7061(0.3845)
2024/03/04 05:05:12 - INFO - root -   Epoch: [108/300] 	 loss = 0.3838
2024/03/04 05:05:12 - INFO - root -   train_accuracy = 0.8625
2024/03/04 05:05:13 - INFO - root -   Epoch: [109/300][0/200], lr: 0.00000037 	 loss = 0.2206(0.2206)
2024/03/04 05:05:47 - INFO - root -   Epoch: [109/300][20/200], lr: 0.00000037 	 loss = 0.2125(0.6111)
2024/03/04 05:05:55 - INFO - root -   Epoch: [109/300][40/200], lr: 0.00000037 	 loss = 0.1097(0.4735)
2024/03/04 05:06:19 - INFO - root -   Epoch: [109/300][60/200], lr: 0.00000037 	 loss = 0.1782(0.4184)
2024/03/04 05:06:27 - INFO - root -   Epoch: [109/300][80/200], lr: 0.00000037 	 loss = 1.7472(0.4222)
2024/03/04 05:06:40 - INFO - root -   Epoch: [109/300][100/200], lr: 0.00000037 	 loss = 0.0067(0.4418)
2024/03/04 05:07:01 - INFO - root -   Epoch: [109/300][120/200], lr: 0.00000037 	 loss = 1.1914(0.4215)
2024/03/04 05:07:10 - INFO - root -   Epoch: [109/300][140/200], lr: 0.00000037 	 loss = 3.2227(0.4335)
2024/03/04 05:07:30 - INFO - root -   Epoch: [109/300][160/200], lr: 0.00000037 	 loss = 0.5097(0.4412)
2024/03/04 05:07:45 - INFO - root -   Epoch: [109/300][180/200], lr: 0.00000037 	 loss = 0.5306(0.4400)
2024/03/04 05:07:53 - INFO - root -   Epoch: [109/300] 	 loss = 0.4421
2024/03/04 05:07:56 - INFO - root -   precision = 0.7111
2024/03/04 05:07:56 - INFO - root -   eval_loss = 1.3319
2024/03/04 05:07:56 - INFO - root -   eval_acc = 0.7111
2024/03/04 05:07:57 - INFO - root -   train_accuracy = 0.8450
2024/03/04 05:07:59 - INFO - root -   Epoch: [110/300][0/200], lr: 0.00000037 	 loss = 0.3099(0.3099)
2024/03/04 05:08:34 - INFO - root -   Epoch: [110/300][20/200], lr: 0.00000037 	 loss = 0.1039(0.4586)
2024/03/04 05:08:49 - INFO - root -   Epoch: [110/300][40/200], lr: 0.00000037 	 loss = 0.1644(0.4150)
2024/03/04 05:09:03 - INFO - root -   Epoch: [110/300][60/200], lr: 0.00000037 	 loss = 0.0873(0.4051)
2024/03/04 05:09:26 - INFO - root -   Epoch: [110/300][80/200], lr: 0.00000037 	 loss = 1.3202(0.4125)
2024/03/04 05:09:35 - INFO - root -   Epoch: [110/300][100/200], lr: 0.00000037 	 loss = 0.0294(0.3920)
2024/03/04 05:09:52 - INFO - root -   Epoch: [110/300][120/200], lr: 0.00000037 	 loss = 1.5306(0.3949)
2024/03/04 05:10:10 - INFO - root -   Epoch: [110/300][140/200], lr: 0.00000037 	 loss = 0.9904(0.3885)
2024/03/04 05:10:25 - INFO - root -   Epoch: [110/300][160/200], lr: 0.00000037 	 loss = 0.0775(0.3981)
2024/03/04 05:10:44 - INFO - root -   Epoch: [110/300][180/200], lr: 0.00000037 	 loss = 0.4082(0.3921)
2024/03/04 05:10:52 - INFO - root -   Epoch: [110/300] 	 loss = 0.3910
2024/03/04 05:10:52 - INFO - root -   train_accuracy = 0.8600
2024/03/04 05:10:53 - INFO - root -   Epoch: [111/300][0/200], lr: 0.00000037 	 loss = 0.4467(0.4467)
2024/03/04 05:11:28 - INFO - root -   Epoch: [111/300][20/200], lr: 0.00000037 	 loss = 0.0541(0.6488)
2024/03/04 05:11:35 - INFO - root -   Epoch: [111/300][40/200], lr: 0.00000037 	 loss = 0.0693(0.4597)
2024/03/04 05:11:53 - INFO - root -   Epoch: [111/300][60/200], lr: 0.00000037 	 loss = 0.1453(0.4150)
2024/03/04 05:12:18 - INFO - root -   Epoch: [111/300][80/200], lr: 0.00000037 	 loss = 0.5076(0.4313)
2024/03/04 05:12:31 - INFO - root -   Epoch: [111/300][100/200], lr: 0.00000037 	 loss = 0.0072(0.4280)
2024/03/04 05:12:59 - INFO - root -   Epoch: [111/300][120/200], lr: 0.00000037 	 loss = 2.3847(0.4125)
2024/03/04 05:13:11 - INFO - root -   Epoch: [111/300][140/200], lr: 0.00000037 	 loss = 1.7260(0.4182)
2024/03/04 05:13:23 - INFO - root -   Epoch: [111/300][160/200], lr: 0.00000037 	 loss = 0.1479(0.4385)
2024/03/04 05:13:30 - INFO - root -   Epoch: [111/300][180/200], lr: 0.00000037 	 loss = 0.1079(0.4486)
2024/03/04 05:13:38 - INFO - root -   Epoch: [111/300] 	 loss = 0.4315
2024/03/04 05:13:38 - INFO - root -   train_accuracy = 0.8500
2024/03/04 05:14:01 - INFO - root -   Epoch: [112/300][0/200], lr: 0.00000038 	 loss = 1.2037(1.2037)
2024/03/04 05:14:09 - INFO - root -   Epoch: [112/300][20/200], lr: 0.00000038 	 loss = 0.1148(0.5781)
2024/03/04 05:14:29 - INFO - root -   Epoch: [112/300][40/200], lr: 0.00000038 	 loss = 0.1950(0.4249)
2024/03/04 05:14:47 - INFO - root -   Epoch: [112/300][60/200], lr: 0.00000038 	 loss = 0.0258(0.3975)
2024/03/04 05:15:10 - INFO - root -   Epoch: [112/300][80/200], lr: 0.00000038 	 loss = 1.1169(0.3860)
2024/03/04 05:15:26 - INFO - root -   Epoch: [112/300][100/200], lr: 0.00000038 	 loss = 0.0081(0.3752)
2024/03/04 05:15:34 - INFO - root -   Epoch: [112/300][120/200], lr: 0.00000038 	 loss = 2.1258(0.3852)
2024/03/04 05:15:52 - INFO - root -   Epoch: [112/300][140/200], lr: 0.00000038 	 loss = 0.2307(0.3763)
2024/03/04 05:16:07 - INFO - root -   Epoch: [112/300][160/200], lr: 0.00000038 	 loss = 0.1421(0.3862)
2024/03/04 05:16:19 - INFO - root -   Epoch: [112/300][180/200], lr: 0.00000038 	 loss = 1.0514(0.3897)
2024/03/04 05:16:26 - INFO - root -   Epoch: [112/300] 	 loss = 0.3937
2024/03/04 05:16:26 - INFO - root -   train_accuracy = 0.8500
2024/03/04 05:16:29 - INFO - root -   Epoch: [113/300][0/200], lr: 0.00000038 	 loss = 0.8338(0.8338)
2024/03/04 05:16:58 - INFO - root -   Epoch: [113/300][20/200], lr: 0.00000038 	 loss = 0.1594(0.5068)
2024/03/04 05:17:06 - INFO - root -   Epoch: [113/300][40/200], lr: 0.00000038 	 loss = 0.2752(0.4015)
2024/03/04 05:17:22 - INFO - root -   Epoch: [113/300][60/200], lr: 0.00000038 	 loss = 0.1396(0.4181)
2024/03/04 05:17:43 - INFO - root -   Epoch: [113/300][80/200], lr: 0.00000038 	 loss = 0.5186(0.4022)
2024/03/04 05:17:54 - INFO - root -   Epoch: [113/300][100/200], lr: 0.00000038 	 loss = 0.0188(0.3783)
2024/03/04 05:18:13 - INFO - root -   Epoch: [113/300][120/200], lr: 0.00000038 	 loss = 1.9823(0.3649)
2024/03/04 05:18:21 - INFO - root -   Epoch: [113/300][140/200], lr: 0.00000038 	 loss = 0.2779(0.3507)
2024/03/04 05:18:42 - INFO - root -   Epoch: [113/300][160/200], lr: 0.00000038 	 loss = 0.1018(0.3633)
2024/03/04 05:18:51 - INFO - root -   Epoch: [113/300][180/200], lr: 0.00000038 	 loss = 0.0353(0.3649)
2024/03/04 05:19:00 - INFO - root -   Epoch: [113/300] 	 loss = 0.3625
2024/03/04 05:19:00 - INFO - root -   train_accuracy = 0.8625
2024/03/04 05:19:03 - INFO - root -   Epoch: [114/300][0/200], lr: 0.00000038 	 loss = 0.3451(0.3451)
2024/03/04 05:19:33 - INFO - root -   Epoch: [114/300][20/200], lr: 0.00000038 	 loss = 0.0086(0.5144)
2024/03/04 05:19:43 - INFO - root -   Epoch: [114/300][40/200], lr: 0.00000038 	 loss = 0.0186(0.4231)
2024/03/04 05:20:07 - INFO - root -   Epoch: [114/300][60/200], lr: 0.00000038 	 loss = 0.0024(0.3768)
2024/03/04 05:20:15 - INFO - root -   Epoch: [114/300][80/200], lr: 0.00000038 	 loss = 1.3691(0.3855)
2024/03/04 05:20:38 - INFO - root -   Epoch: [114/300][100/200], lr: 0.00000038 	 loss = 0.0411(0.3516)
2024/03/04 05:20:46 - INFO - root -   Epoch: [114/300][120/200], lr: 0.00000038 	 loss = 1.3416(0.3445)
2024/03/04 05:21:12 - INFO - root -   Epoch: [114/300][140/200], lr: 0.00000038 	 loss = 0.7322(0.3615)
2024/03/04 05:21:20 - INFO - root -   Epoch: [114/300][160/200], lr: 0.00000038 	 loss = 0.0608(0.3555)
2024/03/04 05:21:35 - INFO - root -   Epoch: [114/300][180/200], lr: 0.00000038 	 loss = 0.0580(0.3473)
2024/03/04 05:21:44 - INFO - root -   Epoch: [114/300] 	 loss = 0.3471
2024/03/04 05:21:47 - INFO - root -   precision = 0.7111
2024/03/04 05:21:47 - INFO - root -   eval_loss = 1.4251
2024/03/04 05:21:47 - INFO - root -   eval_acc = 0.7111
2024/03/04 05:21:48 - INFO - root -   train_accuracy = 0.8800
2024/03/04 05:22:07 - INFO - root -   Epoch: [115/300][0/200], lr: 0.00000038 	 loss = 1.2129(1.2129)
2024/03/04 05:22:19 - INFO - root -   Epoch: [115/300][20/200], lr: 0.00000038 	 loss = 1.0498(0.5129)
2024/03/04 05:22:27 - INFO - root -   Epoch: [115/300][40/200], lr: 0.00000038 	 loss = 0.0566(0.3365)
2024/03/04 05:22:43 - INFO - root -   Epoch: [115/300][60/200], lr: 0.00000038 	 loss = 0.0115(0.3476)
2024/03/04 05:23:02 - INFO - root -   Epoch: [115/300][80/200], lr: 0.00000038 	 loss = 1.9572(0.3842)
2024/03/04 05:23:21 - INFO - root -   Epoch: [115/300][100/200], lr: 0.00000038 	 loss = 0.0041(0.3708)
2024/03/04 05:23:38 - INFO - root -   Epoch: [115/300][120/200], lr: 0.00000038 	 loss = 0.9782(0.3519)
2024/03/04 05:23:59 - INFO - root -   Epoch: [115/300][140/200], lr: 0.00000038 	 loss = 0.4228(0.3768)
2024/03/04 05:24:10 - INFO - root -   Epoch: [115/300][160/200], lr: 0.00000038 	 loss = 0.8440(0.3919)
2024/03/04 05:24:26 - INFO - root -   Epoch: [115/300][180/200], lr: 0.00000038 	 loss = 0.1416(0.4048)
2024/03/04 05:24:34 - INFO - root -   Epoch: [115/300] 	 loss = 0.3932
2024/03/04 05:24:34 - INFO - root -   train_accuracy = 0.8375
2024/03/04 05:24:45 - INFO - root -   Epoch: [116/300][0/200], lr: 0.00000039 	 loss = 0.8080(0.8080)
2024/03/04 05:24:57 - INFO - root -   Epoch: [116/300][20/200], lr: 0.00000039 	 loss = 0.0318(0.4800)
2024/03/04 05:25:15 - INFO - root -   Epoch: [116/300][40/200], lr: 0.00000039 	 loss = 0.0386(0.3833)
2024/03/04 05:25:23 - INFO - root -   Epoch: [116/300][60/200], lr: 0.00000039 	 loss = 0.0441(0.3874)
2024/03/04 05:25:44 - INFO - root -   Epoch: [116/300][80/200], lr: 0.00000039 	 loss = 0.9261(0.3913)
2024/03/04 05:26:00 - INFO - root -   Epoch: [116/300][100/200], lr: 0.00000039 	 loss = 0.1581(0.3682)
2024/03/04 05:26:13 - INFO - root -   Epoch: [116/300][120/200], lr: 0.00000039 	 loss = 2.7471(0.3651)
2024/03/04 05:26:29 - INFO - root -   Epoch: [116/300][140/200], lr: 0.00000039 	 loss = 2.0201(0.3654)
2024/03/04 05:26:40 - INFO - root -   Epoch: [116/300][160/200], lr: 0.00000039 	 loss = 0.1737(0.3765)
2024/03/04 05:26:48 - INFO - root -   Epoch: [116/300][180/200], lr: 0.00000039 	 loss = 0.1945(0.3655)
2024/03/04 05:26:59 - INFO - root -   Epoch: [116/300] 	 loss = 0.3784
2024/03/04 05:26:59 - INFO - root -   train_accuracy = 0.8575
2024/03/04 05:27:01 - INFO - root -   Epoch: [117/300][0/200], lr: 0.00000039 	 loss = 0.4726(0.4726)
2024/03/04 05:27:31 - INFO - root -   Epoch: [117/300][20/200], lr: 0.00000039 	 loss = 0.1796(0.3964)
2024/03/04 05:27:43 - INFO - root -   Epoch: [117/300][40/200], lr: 0.00000039 	 loss = 0.0461(0.4119)
2024/03/04 05:27:54 - INFO - root -   Epoch: [117/300][60/200], lr: 0.00000039 	 loss = 0.0017(0.3584)
2024/03/04 05:28:12 - INFO - root -   Epoch: [117/300][80/200], lr: 0.00000039 	 loss = 1.9965(0.3679)
2024/03/04 05:28:35 - INFO - root -   Epoch: [117/300][100/200], lr: 0.00000039 	 loss = 0.0115(0.3683)
2024/03/04 05:28:50 - INFO - root -   Epoch: [117/300][120/200], lr: 0.00000039 	 loss = 1.3905(0.3553)
2024/03/04 05:29:10 - INFO - root -   Epoch: [117/300][140/200], lr: 0.00000039 	 loss = 1.7409(0.3555)
2024/03/04 05:29:22 - INFO - root -   Epoch: [117/300][160/200], lr: 0.00000039 	 loss = 0.5146(0.3640)
2024/03/04 05:29:38 - INFO - root -   Epoch: [117/300][180/200], lr: 0.00000039 	 loss = 0.0822(0.3574)
2024/03/04 05:29:46 - INFO - root -   Epoch: [117/300] 	 loss = 0.3726
2024/03/04 05:29:46 - INFO - root -   train_accuracy = 0.8675
2024/03/04 05:29:49 - INFO - root -   Epoch: [118/300][0/200], lr: 0.00000039 	 loss = 0.7974(0.7974)
2024/03/04 05:30:16 - INFO - root -   Epoch: [118/300][20/200], lr: 0.00000039 	 loss = 0.1230(0.3468)
2024/03/04 05:30:33 - INFO - root -   Epoch: [118/300][40/200], lr: 0.00000039 	 loss = 0.1725(0.4024)
2024/03/04 05:30:48 - INFO - root -   Epoch: [118/300][60/200], lr: 0.00000039 	 loss = 0.0103(0.3927)
2024/03/04 05:30:59 - INFO - root -   Epoch: [118/300][80/200], lr: 0.00000039 	 loss = 0.6907(0.4181)
2024/03/04 05:31:18 - INFO - root -   Epoch: [118/300][100/200], lr: 0.00000039 	 loss = 0.0460(0.4014)
2024/03/04 05:31:41 - INFO - root -   Epoch: [118/300][120/200], lr: 0.00000039 	 loss = 2.3260(0.4055)
2024/03/04 05:31:49 - INFO - root -   Epoch: [118/300][140/200], lr: 0.00000039 	 loss = 2.0754(0.4324)
2024/03/04 05:32:07 - INFO - root -   Epoch: [118/300][160/200], lr: 0.00000039 	 loss = 0.1686(0.4261)
2024/03/04 05:32:16 - INFO - root -   Epoch: [118/300][180/200], lr: 0.00000039 	 loss = 0.1664(0.4191)
2024/03/04 05:32:24 - INFO - root -   Epoch: [118/300] 	 loss = 0.4061
2024/03/04 05:32:24 - INFO - root -   train_accuracy = 0.8650
2024/03/04 05:32:25 - INFO - root -   Epoch: [119/300][0/200], lr: 0.00000039 	 loss = 0.5131(0.5131)
2024/03/04 05:32:43 - INFO - root -   Epoch: [119/300][20/200], lr: 0.00000039 	 loss = 0.0173(0.2971)
2024/03/04 05:33:00 - INFO - root -   Epoch: [119/300][40/200], lr: 0.00000039 	 loss = 0.8396(0.3306)
2024/03/04 05:33:14 - INFO - root -   Epoch: [119/300][60/200], lr: 0.00000039 	 loss = 0.2484(0.3138)
2024/03/04 05:33:30 - INFO - root -   Epoch: [119/300][80/200], lr: 0.00000039 	 loss = 1.5803(0.3604)
2024/03/04 05:33:46 - INFO - root -   Epoch: [119/300][100/200], lr: 0.00000039 	 loss = 0.0143(0.3453)
2024/03/04 05:33:57 - INFO - root -   Epoch: [119/300][120/200], lr: 0.00000039 	 loss = 1.1185(0.3534)
2024/03/04 05:34:18 - INFO - root -   Epoch: [119/300][140/200], lr: 0.00000039 	 loss = 0.4084(0.3636)
2024/03/04 05:34:32 - INFO - root -   Epoch: [119/300][160/200], lr: 0.00000039 	 loss = 0.4593(0.3540)
2024/03/04 05:34:43 - INFO - root -   Epoch: [119/300][180/200], lr: 0.00000039 	 loss = 0.0270(0.3708)
2024/03/04 05:34:50 - INFO - root -   Epoch: [119/300] 	 loss = 0.3640
2024/03/04 05:34:54 - INFO - root -   precision = 0.7111
2024/03/04 05:34:54 - INFO - root -   eval_loss = 1.4331
2024/03/04 05:34:54 - INFO - root -   eval_acc = 0.7111
2024/03/04 05:34:55 - INFO - root -   train_accuracy = 0.8725
2024/03/04 05:34:57 - INFO - root -   Epoch: [120/300][0/200], lr: 0.00000040 	 loss = 0.4799(0.4799)
2024/03/04 05:35:27 - INFO - root -   Epoch: [120/300][20/200], lr: 0.00000040 	 loss = 0.1183(0.4875)
2024/03/04 05:35:54 - INFO - root -   Epoch: [120/300][40/200], lr: 0.00000040 	 loss = 0.2518(0.3921)
2024/03/04 05:36:05 - INFO - root -   Epoch: [120/300][60/200], lr: 0.00000040 	 loss = 0.1066(0.4529)
2024/03/04 05:36:19 - INFO - root -   Epoch: [120/300][80/200], lr: 0.00000040 	 loss = 1.6002(0.4522)
2024/03/04 05:36:37 - INFO - root -   Epoch: [120/300][100/200], lr: 0.00000040 	 loss = 0.1076(0.4316)
2024/03/04 05:36:45 - INFO - root -   Epoch: [120/300][120/200], lr: 0.00000040 	 loss = 1.5789(0.4271)
2024/03/04 05:36:53 - INFO - root -   Epoch: [120/300][140/200], lr: 0.00000040 	 loss = 0.3547(0.4061)
2024/03/04 05:37:09 - INFO - root -   Epoch: [120/300][160/200], lr: 0.00000040 	 loss = 0.1150(0.3926)
2024/03/04 05:37:24 - INFO - root -   Epoch: [120/300][180/200], lr: 0.00000040 	 loss = 0.0810(0.3954)
2024/03/04 05:37:32 - INFO - root -   Epoch: [120/300] 	 loss = 0.3921
2024/03/04 05:37:32 - INFO - root -   train_accuracy = 0.8475
2024/03/04 05:37:34 - INFO - root -   Epoch: [121/300][0/200], lr: 0.00000040 	 loss = 1.7153(1.7153)
2024/03/04 05:38:00 - INFO - root -   Epoch: [121/300][20/200], lr: 0.00000040 	 loss = 0.0325(0.4274)
2024/03/04 05:38:13 - INFO - root -   Epoch: [121/300][40/200], lr: 0.00000040 	 loss = 0.0611(0.3211)
2024/03/04 05:38:31 - INFO - root -   Epoch: [121/300][60/200], lr: 0.00000040 	 loss = 0.1033(0.3418)
2024/03/04 05:38:46 - INFO - root -   Epoch: [121/300][80/200], lr: 0.00000040 	 loss = 0.6844(0.3928)
2024/03/04 05:38:54 - INFO - root -   Epoch: [121/300][100/200], lr: 0.00000040 	 loss = 0.0034(0.3803)
2024/03/04 05:39:02 - INFO - root -   Epoch: [121/300][120/200], lr: 0.00000040 	 loss = 1.5180(0.3712)
2024/03/04 05:39:22 - INFO - root -   Epoch: [121/300][140/200], lr: 0.00000040 	 loss = 0.6672(0.3630)
2024/03/04 05:39:32 - INFO - root -   Epoch: [121/300][160/200], lr: 0.00000040 	 loss = 0.1610(0.3619)
2024/03/04 05:39:47 - INFO - root -   Epoch: [121/300][180/200], lr: 0.00000040 	 loss = 0.9489(0.3837)
2024/03/04 05:39:55 - INFO - root -   Epoch: [121/300] 	 loss = 0.3715
2024/03/04 05:39:55 - INFO - root -   train_accuracy = 0.8500
2024/03/04 05:39:56 - INFO - root -   Epoch: [122/300][0/200], lr: 0.00000040 	 loss = 0.5334(0.5334)
2024/03/04 05:40:24 - INFO - root -   Epoch: [122/300][20/200], lr: 0.00000040 	 loss = 0.3563(0.4775)
2024/03/04 05:40:38 - INFO - root -   Epoch: [122/300][40/200], lr: 0.00000040 	 loss = 0.0188(0.3763)
2024/03/04 05:41:00 - INFO - root -   Epoch: [122/300][60/200], lr: 0.00000040 	 loss = 0.0251(0.3737)
2024/03/04 05:41:08 - INFO - root -   Epoch: [122/300][80/200], lr: 0.00000040 	 loss = 1.0863(0.3643)
2024/03/04 05:41:29 - INFO - root -   Epoch: [122/300][100/200], lr: 0.00000040 	 loss = 0.0060(0.3351)
2024/03/04 05:41:46 - INFO - root -   Epoch: [122/300][120/200], lr: 0.00000040 	 loss = 1.8701(0.3357)
2024/03/04 05:42:00 - INFO - root -   Epoch: [122/300][140/200], lr: 0.00000040 	 loss = 0.4203(0.3469)
2024/03/04 05:42:08 - INFO - root -   Epoch: [122/300][160/200], lr: 0.00000040 	 loss = 0.0756(0.3556)
2024/03/04 05:42:38 - INFO - root -   Epoch: [122/300][180/200], lr: 0.00000040 	 loss = 0.1390(0.3770)
2024/03/04 05:42:46 - INFO - root -   Epoch: [122/300] 	 loss = 0.3839
2024/03/04 05:42:46 - INFO - root -   train_accuracy = 0.8525
2024/03/04 05:43:11 - INFO - root -   Epoch: [123/300][0/200], lr: 0.00000040 	 loss = 1.5769(1.5769)
2024/03/04 05:43:21 - INFO - root -   Epoch: [123/300][20/200], lr: 0.00000040 	 loss = 0.0125(0.4596)
2024/03/04 05:43:34 - INFO - root -   Epoch: [123/300][40/200], lr: 0.00000040 	 loss = 0.2220(0.3752)
2024/03/04 05:43:49 - INFO - root -   Epoch: [123/300][60/200], lr: 0.00000040 	 loss = 0.0047(0.3484)
2024/03/04 05:44:02 - INFO - root -   Epoch: [123/300][80/200], lr: 0.00000040 	 loss = 1.1176(0.3516)
2024/03/04 05:44:17 - INFO - root -   Epoch: [123/300][100/200], lr: 0.00000040 	 loss = 0.0192(0.3620)
2024/03/04 05:44:27 - INFO - root -   Epoch: [123/300][120/200], lr: 0.00000040 	 loss = 2.6917(0.3632)
2024/03/04 05:44:44 - INFO - root -   Epoch: [123/300][140/200], lr: 0.00000040 	 loss = 2.8986(0.3940)
2024/03/04 05:44:52 - INFO - root -   Epoch: [123/300][160/200], lr: 0.00000040 	 loss = 0.0795(0.3761)
2024/03/04 05:45:07 - INFO - root -   Epoch: [123/300][180/200], lr: 0.00000040 	 loss = 0.5215(0.3791)
2024/03/04 05:45:15 - INFO - root -   Epoch: [123/300] 	 loss = 0.3811
2024/03/04 05:45:15 - INFO - root -   train_accuracy = 0.8600
2024/03/04 05:45:44 - INFO - root -   Epoch: [124/300][0/200], lr: 0.00000041 	 loss = 0.8004(0.8004)
2024/03/04 05:45:52 - INFO - root -   Epoch: [124/300][20/200], lr: 0.00000041 	 loss = 0.1474(0.4967)
2024/03/04 05:46:10 - INFO - root -   Epoch: [124/300][40/200], lr: 0.00000041 	 loss = 0.1573(0.3899)
2024/03/04 05:46:32 - INFO - root -   Epoch: [124/300][60/200], lr: 0.00000041 	 loss = 0.2380(0.3633)
2024/03/04 05:46:44 - INFO - root -   Epoch: [124/300][80/200], lr: 0.00000041 	 loss = 0.7832(0.3625)
2024/03/04 05:47:05 - INFO - root -   Epoch: [124/300][100/200], lr: 0.00000041 	 loss = 0.0622(0.3445)
2024/03/04 05:47:13 - INFO - root -   Epoch: [124/300][120/200], lr: 0.00000041 	 loss = 1.2907(0.3565)
2024/03/04 05:47:32 - INFO - root -   Epoch: [124/300][140/200], lr: 0.00000041 	 loss = 1.0967(0.3764)
2024/03/04 05:47:45 - INFO - root -   Epoch: [124/300][160/200], lr: 0.00000041 	 loss = 0.0324(0.3858)
2024/03/04 05:47:59 - INFO - root -   Epoch: [124/300][180/200], lr: 0.00000041 	 loss = 0.2410(0.3880)
2024/03/04 05:48:07 - INFO - root -   Epoch: [124/300] 	 loss = 0.3758
2024/03/04 05:48:11 - INFO - root -   precision = 0.7111
2024/03/04 05:48:11 - INFO - root -   eval_loss = 1.4816
2024/03/04 05:48:11 - INFO - root -   eval_acc = 0.7111
2024/03/04 05:48:12 - INFO - root -   train_accuracy = 0.8550
2024/03/04 05:48:25 - INFO - root -   Epoch: [125/300][0/200], lr: 0.00000041 	 loss = 0.4255(0.4255)
2024/03/04 05:48:36 - INFO - root -   Epoch: [125/300][20/200], lr: 0.00000041 	 loss = 0.0057(0.3927)
2024/03/04 05:48:51 - INFO - root -   Epoch: [125/300][40/200], lr: 0.00000041 	 loss = 0.0155(0.3159)
2024/03/04 05:49:03 - INFO - root -   Epoch: [125/300][60/200], lr: 0.00000041 	 loss = 0.0088(0.3322)
2024/03/04 05:49:15 - INFO - root -   Epoch: [125/300][80/200], lr: 0.00000041 	 loss = 1.4830(0.3541)
2024/03/04 05:49:36 - INFO - root -   Epoch: [125/300][100/200], lr: 0.00000041 	 loss = 0.0046(0.3442)
2024/03/04 05:49:44 - INFO - root -   Epoch: [125/300][120/200], lr: 0.00000041 	 loss = 0.9629(0.3570)
2024/03/04 05:49:52 - INFO - root -   Epoch: [125/300][140/200], lr: 0.00000041 	 loss = 0.5090(0.3476)
2024/03/04 05:50:13 - INFO - root -   Epoch: [125/300][160/200], lr: 0.00000041 	 loss = 0.0527(0.3669)
2024/03/04 05:50:29 - INFO - root -   Epoch: [125/300][180/200], lr: 0.00000041 	 loss = 0.0567(0.3674)
2024/03/04 05:50:37 - INFO - root -   Epoch: [125/300] 	 loss = 0.3714
2024/03/04 05:50:37 - INFO - root -   train_accuracy = 0.8550
2024/03/04 05:50:50 - INFO - root -   Epoch: [126/300][0/200], lr: 0.00000041 	 loss = 0.2988(0.2988)
2024/03/04 05:51:12 - INFO - root -   Epoch: [126/300][20/200], lr: 0.00000041 	 loss = 0.1514(0.5543)
2024/03/04 05:51:20 - INFO - root -   Epoch: [126/300][40/200], lr: 0.00000041 	 loss = 0.3422(0.4340)
2024/03/04 05:51:40 - INFO - root -   Epoch: [126/300][60/200], lr: 0.00000041 	 loss = 0.0114(0.3774)
2024/03/04 05:51:48 - INFO - root -   Epoch: [126/300][80/200], lr: 0.00000041 	 loss = 1.0897(0.3734)
2024/03/04 05:52:08 - INFO - root -   Epoch: [126/300][100/200], lr: 0.00000041 	 loss = 0.0187(0.3700)
2024/03/04 05:52:16 - INFO - root -   Epoch: [126/300][120/200], lr: 0.00000041 	 loss = 1.0680(0.3682)
2024/03/04 05:52:34 - INFO - root -   Epoch: [126/300][140/200], lr: 0.00000041 	 loss = 0.7358(0.3742)
2024/03/04 05:53:00 - INFO - root -   Epoch: [126/300][160/200], lr: 0.00000041 	 loss = 0.6754(0.3782)
2024/03/04 05:53:08 - INFO - root -   Epoch: [126/300][180/200], lr: 0.00000041 	 loss = 0.2476(0.3774)
2024/03/04 05:53:15 - INFO - root -   Epoch: [126/300] 	 loss = 0.3854
2024/03/04 05:53:15 - INFO - root -   train_accuracy = 0.8600
2024/03/04 05:53:31 - INFO - root -   Epoch: [127/300][0/200], lr: 0.00000041 	 loss = 1.2640(1.2640)
2024/03/04 05:53:44 - INFO - root -   Epoch: [127/300][20/200], lr: 0.00000041 	 loss = 0.0959(0.5472)
2024/03/04 05:53:52 - INFO - root -   Epoch: [127/300][40/200], lr: 0.00000041 	 loss = 0.0701(0.4302)
2024/03/04 05:54:00 - INFO - root -   Epoch: [127/300][60/200], lr: 0.00000041 	 loss = 0.1234(0.3637)
2024/03/04 05:54:21 - INFO - root -   Epoch: [127/300][80/200], lr: 0.00000041 	 loss = 1.2267(0.3844)
2024/03/04 05:54:29 - INFO - root -   Epoch: [127/300][100/200], lr: 0.00000041 	 loss = 0.0279(0.3639)
2024/03/04 05:54:47 - INFO - root -   Epoch: [127/300][120/200], lr: 0.00000041 	 loss = 0.7499(0.3424)
2024/03/04 05:55:08 - INFO - root -   Epoch: [127/300][140/200], lr: 0.00000041 	 loss = 0.4337(0.3511)
2024/03/04 05:55:23 - INFO - root -   Epoch: [127/300][160/200], lr: 0.00000041 	 loss = 0.0885(0.3805)
2024/03/04 05:55:31 - INFO - root -   Epoch: [127/300][180/200], lr: 0.00000041 	 loss = 0.0731(0.3728)
2024/03/04 05:55:39 - INFO - root -   Epoch: [127/300] 	 loss = 0.3688
2024/03/04 05:55:39 - INFO - root -   train_accuracy = 0.8450
2024/03/04 05:55:42 - INFO - root -   Epoch: [128/300][0/200], lr: 0.00000042 	 loss = 0.3186(0.3186)
2024/03/04 05:56:08 - INFO - root -   Epoch: [128/300][20/200], lr: 0.00000042 	 loss = 0.0134(0.3444)
2024/03/04 05:56:23 - INFO - root -   Epoch: [128/300][40/200], lr: 0.00000042 	 loss = 0.0801(0.2904)
2024/03/04 05:56:33 - INFO - root -   Epoch: [128/300][60/200], lr: 0.00000042 	 loss = 0.0511(0.2684)
2024/03/04 05:56:47 - INFO - root -   Epoch: [128/300][80/200], lr: 0.00000042 	 loss = 1.7834(0.3214)
2024/03/04 05:57:03 - INFO - root -   Epoch: [128/300][100/200], lr: 0.00000042 	 loss = 0.0031(0.3041)
2024/03/04 05:57:11 - INFO - root -   Epoch: [128/300][120/200], lr: 0.00000042 	 loss = 1.5270(0.3052)
2024/03/04 05:57:22 - INFO - root -   Epoch: [128/300][140/200], lr: 0.00000042 	 loss = 0.2384(0.2974)
2024/03/04 05:57:38 - INFO - root -   Epoch: [128/300][160/200], lr: 0.00000042 	 loss = 0.2491(0.3049)
2024/03/04 05:57:50 - INFO - root -   Epoch: [128/300][180/200], lr: 0.00000042 	 loss = 0.0506(0.3170)
2024/03/04 05:57:58 - INFO - root -   Epoch: [128/300] 	 loss = 0.3158
2024/03/04 05:57:58 - INFO - root -   train_accuracy = 0.8875
2024/03/04 05:57:59 - INFO - root -   Epoch: [129/300][0/200], lr: 0.00000042 	 loss = 0.3405(0.3405)
2024/03/04 05:58:25 - INFO - root -   Epoch: [129/300][20/200], lr: 0.00000042 	 loss = 0.1416(0.4833)
2024/03/04 05:58:33 - INFO - root -   Epoch: [129/300][40/200], lr: 0.00000042 	 loss = 0.0375(0.3813)
2024/03/04 05:58:56 - INFO - root -   Epoch: [129/300][60/200], lr: 0.00000042 	 loss = 0.1583(0.3887)
2024/03/04 05:59:13 - INFO - root -   Epoch: [129/300][80/200], lr: 0.00000042 	 loss = 1.7869(0.4271)
2024/03/04 05:59:32 - INFO - root -   Epoch: [129/300][100/200], lr: 0.00000042 	 loss = 0.0864(0.3996)
2024/03/04 05:59:40 - INFO - root -   Epoch: [129/300][120/200], lr: 0.00000042 	 loss = 1.2182(0.3757)
2024/03/04 05:59:51 - INFO - root -   Epoch: [129/300][140/200], lr: 0.00000042 	 loss = 1.4185(0.3819)
2024/03/04 06:00:19 - INFO - root -   Epoch: [129/300][160/200], lr: 0.00000042 	 loss = 0.0702(0.3711)
2024/03/04 06:00:28 - INFO - root -   Epoch: [129/300][180/200], lr: 0.00000042 	 loss = 0.0419(0.3869)
2024/03/04 06:00:38 - INFO - root -   Epoch: [129/300] 	 loss = 0.3879
2024/03/04 06:00:42 - INFO - root -   precision = 0.7111
2024/03/04 06:00:42 - INFO - root -   eval_loss = 1.5027
2024/03/04 06:00:42 - INFO - root -   eval_acc = 0.7111
2024/03/04 06:00:43 - INFO - root -   train_accuracy = 0.8475
2024/03/04 06:00:45 - INFO - root -   Epoch: [130/300][0/200], lr: 0.00000042 	 loss = 0.9760(0.9760)
2024/03/04 06:01:12 - INFO - root -   Epoch: [130/300][20/200], lr: 0.00000042 	 loss = 0.0607(0.5988)
2024/03/04 06:01:24 - INFO - root -   Epoch: [130/300][40/200], lr: 0.00000042 	 loss = 0.0695(0.4115)
2024/03/04 06:01:51 - INFO - root -   Epoch: [130/300][60/200], lr: 0.00000042 	 loss = 0.0891(0.3759)
2024/03/04 06:01:58 - INFO - root -   Epoch: [130/300][80/200], lr: 0.00000042 	 loss = 0.2581(0.3543)
2024/03/04 06:02:13 - INFO - root -   Epoch: [130/300][100/200], lr: 0.00000042 	 loss = 0.1666(0.3633)
2024/03/04 06:02:26 - INFO - root -   Epoch: [130/300][120/200], lr: 0.00000042 	 loss = 1.8528(0.3605)
2024/03/04 06:02:47 - INFO - root -   Epoch: [130/300][140/200], lr: 0.00000042 	 loss = 0.7365(0.3861)
2024/03/04 06:03:06 - INFO - root -   Epoch: [130/300][160/200], lr: 0.00000042 	 loss = 1.0400(0.3911)
2024/03/04 06:03:14 - INFO - root -   Epoch: [130/300][180/200], lr: 0.00000042 	 loss = 0.2181(0.3975)
2024/03/04 06:03:22 - INFO - root -   Epoch: [130/300] 	 loss = 0.3929
2024/03/04 06:03:22 - INFO - root -   train_accuracy = 0.8600
2024/03/04 06:03:23 - INFO - root -   Epoch: [131/300][0/200], lr: 0.00000042 	 loss = 0.1757(0.1757)
2024/03/04 06:04:09 - INFO - root -   Epoch: [131/300][20/200], lr: 0.00000042 	 loss = 0.0791(0.5502)
2024/03/04 06:04:25 - INFO - root -   Epoch: [131/300][40/200], lr: 0.00000042 	 loss = 0.1910(0.4188)
2024/03/04 06:04:33 - INFO - root -   Epoch: [131/300][60/200], lr: 0.00000042 	 loss = 0.1855(0.3922)
2024/03/04 06:04:44 - INFO - root -   Epoch: [131/300][80/200], lr: 0.00000042 	 loss = 0.6040(0.3815)
2024/03/04 06:04:53 - INFO - root -   Epoch: [131/300][100/200], lr: 0.00000042 	 loss = 0.2136(0.3686)
2024/03/04 06:05:13 - INFO - root -   Epoch: [131/300][120/200], lr: 0.00000042 	 loss = 2.3532(0.3660)
2024/03/04 06:05:21 - INFO - root -   Epoch: [131/300][140/200], lr: 0.00000042 	 loss = 0.7963(0.3634)
2024/03/04 06:05:43 - INFO - root -   Epoch: [131/300][160/200], lr: 0.00000042 	 loss = 0.2794(0.3552)
2024/03/04 06:05:50 - INFO - root -   Epoch: [131/300][180/200], lr: 0.00000042 	 loss = 0.5197(0.3626)
2024/03/04 06:05:58 - INFO - root -   Epoch: [131/300] 	 loss = 0.3571
2024/03/04 06:05:58 - INFO - root -   train_accuracy = 0.8650
2024/03/04 06:06:00 - INFO - root -   Epoch: [132/300][0/200], lr: 0.00000043 	 loss = 0.5161(0.5161)
2024/03/04 06:06:31 - INFO - root -   Epoch: [132/300][20/200], lr: 0.00000043 	 loss = 0.2969(0.4995)
2024/03/04 06:06:39 - INFO - root -   Epoch: [132/300][40/200], lr: 0.00000043 	 loss = 0.0679(0.3719)
2024/03/04 06:06:54 - INFO - root -   Epoch: [132/300][60/200], lr: 0.00000043 	 loss = 0.0050(0.3723)
2024/03/04 06:07:05 - INFO - root -   Epoch: [132/300][80/200], lr: 0.00000043 	 loss = 1.6753(0.3740)
2024/03/04 06:07:19 - INFO - root -   Epoch: [132/300][100/200], lr: 0.00000043 	 loss = 0.0136(0.3420)
2024/03/04 06:07:27 - INFO - root -   Epoch: [132/300][120/200], lr: 0.00000043 	 loss = 0.8851(0.3158)
2024/03/04 06:07:47 - INFO - root -   Epoch: [132/300][140/200], lr: 0.00000043 	 loss = 1.5256(0.3356)
2024/03/04 06:08:04 - INFO - root -   Epoch: [132/300][160/200], lr: 0.00000043 	 loss = 0.1332(0.3203)
2024/03/04 06:08:15 - INFO - root -   Epoch: [132/300][180/200], lr: 0.00000043 	 loss = 0.0243(0.3184)
2024/03/04 06:08:22 - INFO - root -   Epoch: [132/300] 	 loss = 0.3095
2024/03/04 06:08:22 - INFO - root -   train_accuracy = 0.8725
2024/03/04 06:08:36 - INFO - root -   Epoch: [133/300][0/200], lr: 0.00000043 	 loss = 1.3376(1.3376)
2024/03/04 06:09:04 - INFO - root -   Epoch: [133/300][20/200], lr: 0.00000043 	 loss = 0.0301(0.7198)
2024/03/04 06:09:12 - INFO - root -   Epoch: [133/300][40/200], lr: 0.00000043 	 loss = 0.0777(0.5089)
2024/03/04 06:09:29 - INFO - root -   Epoch: [133/300][60/200], lr: 0.00000043 	 loss = 0.0152(0.4734)
2024/03/04 06:09:48 - INFO - root -   Epoch: [133/300][80/200], lr: 0.00000043 	 loss = 0.3186(0.4327)
2024/03/04 06:09:56 - INFO - root -   Epoch: [133/300][100/200], lr: 0.00000043 	 loss = 0.0036(0.3920)
2024/03/04 06:10:10 - INFO - root -   Epoch: [133/300][120/200], lr: 0.00000043 	 loss = 0.6878(0.3656)
2024/03/04 06:10:23 - INFO - root -   Epoch: [133/300][140/200], lr: 0.00000043 	 loss = 0.3874(0.3610)
2024/03/04 06:10:39 - INFO - root -   Epoch: [133/300][160/200], lr: 0.00000043 	 loss = 0.0218(0.4018)
2024/03/04 06:10:47 - INFO - root -   Epoch: [133/300][180/200], lr: 0.00000043 	 loss = 0.3254(0.4029)
2024/03/04 06:10:58 - INFO - root -   Epoch: [133/300] 	 loss = 0.3934
2024/03/04 06:10:58 - INFO - root -   train_accuracy = 0.8600
2024/03/04 06:11:01 - INFO - root -   Epoch: [134/300][0/200], lr: 0.00000043 	 loss = 0.5473(0.5473)
2024/03/04 06:11:23 - INFO - root -   Epoch: [134/300][20/200], lr: 0.00000043 	 loss = 0.1100(0.3737)
2024/03/04 06:11:35 - INFO - root -   Epoch: [134/300][40/200], lr: 0.00000043 	 loss = 0.0762(0.3094)
2024/03/04 06:11:49 - INFO - root -   Epoch: [134/300][60/200], lr: 0.00000043 	 loss = 0.0832(0.3049)
2024/03/04 06:12:03 - INFO - root -   Epoch: [134/300][80/200], lr: 0.00000043 	 loss = 0.4807(0.3248)
2024/03/04 06:12:12 - INFO - root -   Epoch: [134/300][100/200], lr: 0.00000043 	 loss = 0.0016(0.3088)
2024/03/04 06:12:31 - INFO - root -   Epoch: [134/300][120/200], lr: 0.00000043 	 loss = 0.8610(0.3113)
2024/03/04 06:12:44 - INFO - root -   Epoch: [134/300][140/200], lr: 0.00000043 	 loss = 1.3576(0.3268)
2024/03/04 06:13:13 - INFO - root -   Epoch: [134/300][160/200], lr: 0.00000043 	 loss = 0.5476(0.3469)
2024/03/04 06:13:27 - INFO - root -   Epoch: [134/300][180/200], lr: 0.00000043 	 loss = 0.1748(0.3566)
2024/03/04 06:13:35 - INFO - root -   Epoch: [134/300] 	 loss = 0.3656
2024/03/04 06:13:39 - INFO - root -   precision = 0.7111
2024/03/04 06:13:39 - INFO - root -   eval_loss = 1.5242
2024/03/04 06:13:39 - INFO - root -   eval_acc = 0.7111
2024/03/04 06:13:40 - INFO - root -   train_accuracy = 0.8650
2024/03/04 06:13:56 - INFO - root -   Epoch: [135/300][0/200], lr: 0.00000043 	 loss = 1.3188(1.3188)
2024/03/04 06:14:15 - INFO - root -   Epoch: [135/300][20/200], lr: 0.00000043 	 loss = 0.1460(0.3932)
2024/03/04 06:14:28 - INFO - root -   Epoch: [135/300][40/200], lr: 0.00000043 	 loss = 0.0101(0.3785)
2024/03/04 06:14:45 - INFO - root -   Epoch: [135/300][60/200], lr: 0.00000043 	 loss = 0.0628(0.3548)
2024/03/04 06:15:07 - INFO - root -   Epoch: [135/300][80/200], lr: 0.00000043 	 loss = 0.5563(0.3830)
2024/03/04 06:15:27 - INFO - root -   Epoch: [135/300][100/200], lr: 0.00000043 	 loss = 0.3955(0.3830)
2024/03/04 06:15:38 - INFO - root -   Epoch: [135/300][120/200], lr: 0.00000043 	 loss = 1.7140(0.3885)
2024/03/04 06:15:56 - INFO - root -   Epoch: [135/300][140/200], lr: 0.00000043 	 loss = 0.8795(0.4000)
2024/03/04 06:16:17 - INFO - root -   Epoch: [135/300][160/200], lr: 0.00000043 	 loss = 0.6559(0.3988)
2024/03/04 06:16:27 - INFO - root -   Epoch: [135/300][180/200], lr: 0.00000043 	 loss = 0.0149(0.3892)
2024/03/04 06:16:35 - INFO - root -   Epoch: [135/300] 	 loss = 0.3811
2024/03/04 06:16:35 - INFO - root -   train_accuracy = 0.8775
2024/03/04 06:16:47 - INFO - root -   Epoch: [136/300][0/200], lr: 0.00000044 	 loss = 0.1942(0.1942)
2024/03/04 06:17:04 - INFO - root -   Epoch: [136/300][20/200], lr: 0.00000044 	 loss = 0.0281(0.6451)
2024/03/04 06:17:22 - INFO - root -   Epoch: [136/300][40/200], lr: 0.00000044 	 loss = 0.1806(0.5023)
2024/03/04 06:17:35 - INFO - root -   Epoch: [136/300][60/200], lr: 0.00000044 	 loss = 0.0071(0.4564)
2024/03/04 06:17:46 - INFO - root -   Epoch: [136/300][80/200], lr: 0.00000044 	 loss = 1.5485(0.4592)
2024/03/04 06:18:09 - INFO - root -   Epoch: [136/300][100/200], lr: 0.00000044 	 loss = 0.0073(0.4319)
2024/03/04 06:18:19 - INFO - root -   Epoch: [136/300][120/200], lr: 0.00000044 	 loss = 2.1041(0.4214)
2024/03/04 06:18:31 - INFO - root -   Epoch: [136/300][140/200], lr: 0.00000044 	 loss = 1.4005(0.4110)
2024/03/04 06:18:50 - INFO - root -   Epoch: [136/300][160/200], lr: 0.00000044 	 loss = 0.1795(0.3905)
2024/03/04 06:18:57 - INFO - root -   Epoch: [136/300][180/200], lr: 0.00000044 	 loss = 0.0265(0.3748)
2024/03/04 06:19:07 - INFO - root -   Epoch: [136/300] 	 loss = 0.3731
2024/03/04 06:19:07 - INFO - root -   train_accuracy = 0.8700
2024/03/04 06:19:09 - INFO - root -   Epoch: [137/300][0/200], lr: 0.00000044 	 loss = 0.6846(0.6846)
2024/03/04 06:19:39 - INFO - root -   Epoch: [137/300][20/200], lr: 0.00000044 	 loss = 0.5296(0.5475)
2024/03/04 06:19:52 - INFO - root -   Epoch: [137/300][40/200], lr: 0.00000044 	 loss = 0.3810(0.3756)
2024/03/04 06:20:12 - INFO - root -   Epoch: [137/300][60/200], lr: 0.00000044 	 loss = 0.0458(0.3494)
2024/03/04 06:20:20 - INFO - root -   Epoch: [137/300][80/200], lr: 0.00000044 	 loss = 1.4035(0.3374)
2024/03/04 06:20:48 - INFO - root -   Epoch: [137/300][100/200], lr: 0.00000044 	 loss = 0.0195(0.3331)
2024/03/04 06:20:56 - INFO - root -   Epoch: [137/300][120/200], lr: 0.00000044 	 loss = 2.0289(0.3300)
2024/03/04 06:21:13 - INFO - root -   Epoch: [137/300][140/200], lr: 0.00000044 	 loss = 0.4591(0.3325)
2024/03/04 06:21:29 - INFO - root -   Epoch: [137/300][160/200], lr: 0.00000044 	 loss = 0.0368(0.3543)
2024/03/04 06:21:37 - INFO - root -   Epoch: [137/300][180/200], lr: 0.00000044 	 loss = 0.0207(0.3542)
2024/03/04 06:21:52 - INFO - root -   Epoch: [137/300] 	 loss = 0.3487
2024/03/04 06:21:52 - INFO - root -   train_accuracy = 0.8650
2024/03/04 06:21:53 - INFO - root -   Epoch: [138/300][0/200], lr: 0.00000044 	 loss = 0.5813(0.5813)
2024/03/04 06:22:16 - INFO - root -   Epoch: [138/300][20/200], lr: 0.00000044 	 loss = 0.0113(0.3609)
2024/03/04 06:22:28 - INFO - root -   Epoch: [138/300][40/200], lr: 0.00000044 	 loss = 0.5672(0.3005)
2024/03/04 06:22:43 - INFO - root -   Epoch: [138/300][60/200], lr: 0.00000044 	 loss = 0.0097(0.2810)
2024/03/04 06:22:51 - INFO - root -   Epoch: [138/300][80/200], lr: 0.00000044 	 loss = 0.5368(0.2994)
2024/03/04 06:23:18 - INFO - root -   Epoch: [138/300][100/200], lr: 0.00000044 	 loss = 0.0387(0.2736)
2024/03/04 06:23:33 - INFO - root -   Epoch: [138/300][120/200], lr: 0.00000044 	 loss = 2.1016(0.2895)
2024/03/04 06:23:49 - INFO - root -   Epoch: [138/300][140/200], lr: 0.00000044 	 loss = 1.3497(0.3156)
2024/03/04 06:23:59 - INFO - root -   Epoch: [138/300][160/200], lr: 0.00000044 	 loss = 0.7712(0.3150)
2024/03/04 06:24:16 - INFO - root -   Epoch: [138/300][180/200], lr: 0.00000044 	 loss = 0.1165(0.3236)
2024/03/04 06:24:25 - INFO - root -   Epoch: [138/300] 	 loss = 0.3318
2024/03/04 06:24:25 - INFO - root -   train_accuracy = 0.8625
2024/03/04 06:24:40 - INFO - root -   Epoch: [139/300][0/200], lr: 0.00000044 	 loss = 0.6239(0.6239)
2024/03/04 06:25:02 - INFO - root -   Epoch: [139/300][20/200], lr: 0.00000044 	 loss = 0.0119(0.6346)
2024/03/04 06:25:17 - INFO - root -   Epoch: [139/300][40/200], lr: 0.00000044 	 loss = 0.0932(0.4495)
2024/03/04 06:25:28 - INFO - root -   Epoch: [139/300][60/200], lr: 0.00000044 	 loss = 0.0121(0.4221)
2024/03/04 06:25:37 - INFO - root -   Epoch: [139/300][80/200], lr: 0.00000044 	 loss = 0.6744(0.4306)
2024/03/04 06:25:49 - INFO - root -   Epoch: [139/300][100/200], lr: 0.00000044 	 loss = 0.0146(0.4049)
2024/03/04 06:26:01 - INFO - root -   Epoch: [139/300][120/200], lr: 0.00000044 	 loss = 2.6103(0.3839)
2024/03/04 06:26:15 - INFO - root -   Epoch: [139/300][140/200], lr: 0.00000044 	 loss = 2.6458(0.4068)
2024/03/04 06:26:23 - INFO - root -   Epoch: [139/300][160/200], lr: 0.00000044 	 loss = 0.1141(0.3909)
2024/03/04 06:26:48 - INFO - root -   Epoch: [139/300][180/200], lr: 0.00000044 	 loss = 0.0626(0.3929)
2024/03/04 06:26:55 - INFO - root -   Epoch: [139/300] 	 loss = 0.3989
2024/03/04 06:26:59 - INFO - root -   precision = 0.6889
2024/03/04 06:26:59 - INFO - root -   eval_loss = 1.5188
2024/03/04 06:26:59 - INFO - root -   eval_acc = 0.6889
2024/03/04 06:27:00 - INFO - root -   train_accuracy = 0.8550
2024/03/04 06:27:10 - INFO - root -   Epoch: [140/300][0/200], lr: 0.00000045 	 loss = 0.2640(0.2640)
2024/03/04 06:27:26 - INFO - root -   Epoch: [140/300][20/200], lr: 0.00000045 	 loss = 0.3250(0.3989)
2024/03/04 06:27:37 - INFO - root -   Epoch: [140/300][40/200], lr: 0.00000045 	 loss = 0.4975(0.3795)
2024/03/04 06:27:58 - INFO - root -   Epoch: [140/300][60/200], lr: 0.00000045 	 loss = 0.1519(0.4064)
2024/03/04 06:28:08 - INFO - root -   Epoch: [140/300][80/200], lr: 0.00000045 	 loss = 0.6792(0.4222)
2024/03/04 06:28:25 - INFO - root -   Epoch: [140/300][100/200], lr: 0.00000045 	 loss = 0.1495(0.3812)
2024/03/04 06:28:33 - INFO - root -   Epoch: [140/300][120/200], lr: 0.00000045 	 loss = 3.2582(0.3709)
2024/03/04 06:28:46 - INFO - root -   Epoch: [140/300][140/200], lr: 0.00000045 	 loss = 0.4495(0.3745)
2024/03/04 06:28:59 - INFO - root -   Epoch: [140/300][160/200], lr: 0.00000045 	 loss = 0.2493(0.3644)
2024/03/04 06:29:13 - INFO - root -   Epoch: [140/300][180/200], lr: 0.00000045 	 loss = 0.0926(0.3650)
2024/03/04 06:29:20 - INFO - root -   Epoch: [140/300] 	 loss = 0.3698
2024/03/04 06:29:20 - INFO - root -   train_accuracy = 0.8675
2024/03/04 06:29:44 - INFO - root -   Epoch: [141/300][0/200], lr: 0.00000045 	 loss = 0.5250(0.5250)
2024/03/04 06:29:52 - INFO - root -   Epoch: [141/300][20/200], lr: 0.00000045 	 loss = 0.0454(0.4423)
2024/03/04 06:30:14 - INFO - root -   Epoch: [141/300][40/200], lr: 0.00000045 	 loss = 0.0480(0.2948)
2024/03/04 06:30:22 - INFO - root -   Epoch: [141/300][60/200], lr: 0.00000045 	 loss = 0.1148(0.3148)
2024/03/04 06:30:38 - INFO - root -   Epoch: [141/300][80/200], lr: 0.00000045 	 loss = 0.4426(0.3401)
2024/03/04 06:30:51 - INFO - root -   Epoch: [141/300][100/200], lr: 0.00000045 	 loss = 0.0023(0.3214)
2024/03/04 06:31:13 - INFO - root -   Epoch: [141/300][120/200], lr: 0.00000045 	 loss = 1.2630(0.3135)
2024/03/04 06:31:25 - INFO - root -   Epoch: [141/300][140/200], lr: 0.00000045 	 loss = 1.3083(0.3148)
2024/03/04 06:31:33 - INFO - root -   Epoch: [141/300][160/200], lr: 0.00000045 	 loss = 0.2697(0.3045)
2024/03/04 06:31:57 - INFO - root -   Epoch: [141/300][180/200], lr: 0.00000045 	 loss = 0.7694(0.3130)
2024/03/04 06:32:05 - INFO - root -   Epoch: [141/300] 	 loss = 0.3284
2024/03/04 06:32:05 - INFO - root -   train_accuracy = 0.8725
2024/03/04 06:32:19 - INFO - root -   Epoch: [142/300][0/200], lr: 0.00000045 	 loss = 0.3494(0.3494)
2024/03/04 06:32:35 - INFO - root -   Epoch: [142/300][20/200], lr: 0.00000045 	 loss = 0.0190(0.3447)
2024/03/04 06:32:43 - INFO - root -   Epoch: [142/300][40/200], lr: 0.00000045 	 loss = 0.0170(0.2794)
2024/03/04 06:33:02 - INFO - root -   Epoch: [142/300][60/200], lr: 0.00000045 	 loss = 0.0078(0.3167)
2024/03/04 06:33:10 - INFO - root -   Epoch: [142/300][80/200], lr: 0.00000045 	 loss = 0.5542(0.3443)
2024/03/04 06:33:26 - INFO - root -   Epoch: [142/300][100/200], lr: 0.00000045 	 loss = 0.0064(0.3398)
2024/03/04 06:33:34 - INFO - root -   Epoch: [142/300][120/200], lr: 0.00000045 	 loss = 2.0237(0.3276)
2024/03/04 06:33:48 - INFO - root -   Epoch: [142/300][140/200], lr: 0.00000045 	 loss = 1.1094(0.3259)
2024/03/04 06:34:08 - INFO - root -   Epoch: [142/300][160/200], lr: 0.00000045 	 loss = 0.1777(0.3393)
2024/03/04 06:34:16 - INFO - root -   Epoch: [142/300][180/200], lr: 0.00000045 	 loss = 0.0097(0.3489)
2024/03/04 06:34:26 - INFO - root -   Epoch: [142/300] 	 loss = 0.3470
2024/03/04 06:34:26 - INFO - root -   train_accuracy = 0.8700
2024/03/04 06:34:29 - INFO - root -   Epoch: [143/300][0/200], lr: 0.00000045 	 loss = 0.1735(0.1735)
2024/03/04 06:34:53 - INFO - root -   Epoch: [143/300][20/200], lr: 0.00000045 	 loss = 0.0752(0.3476)
2024/03/04 06:35:12 - INFO - root -   Epoch: [143/300][40/200], lr: 0.00000045 	 loss = 0.0753(0.3478)
2024/03/04 06:35:32 - INFO - root -   Epoch: [143/300][60/200], lr: 0.00000045 	 loss = 0.0778(0.3220)
2024/03/04 06:35:50 - INFO - root -   Epoch: [143/300][80/200], lr: 0.00000045 	 loss = 0.2110(0.3173)
2024/03/04 06:35:58 - INFO - root -   Epoch: [143/300][100/200], lr: 0.00000045 	 loss = 0.0741(0.3197)
2024/03/04 06:36:22 - INFO - root -   Epoch: [143/300][120/200], lr: 0.00000045 	 loss = 1.4358(0.3085)
2024/03/04 06:36:39 - INFO - root -   Epoch: [143/300][140/200], lr: 0.00000045 	 loss = 1.4118(0.3104)
2024/03/04 06:36:48 - INFO - root -   Epoch: [143/300][160/200], lr: 0.00000045 	 loss = 0.5169(0.3221)
2024/03/04 06:36:56 - INFO - root -   Epoch: [143/300][180/200], lr: 0.00000045 	 loss = 0.1534(0.3142)
2024/03/04 06:37:06 - INFO - root -   Epoch: [143/300] 	 loss = 0.3142
2024/03/04 06:37:06 - INFO - root -   train_accuracy = 0.8850
2024/03/04 06:37:18 - INFO - root -   Epoch: [144/300][0/200], lr: 0.00000046 	 loss = 0.5103(0.5103)
2024/03/04 06:37:49 - INFO - root -   Epoch: [144/300][20/200], lr: 0.00000046 	 loss = 0.2964(0.3955)
2024/03/04 06:37:56 - INFO - root -   Epoch: [144/300][40/200], lr: 0.00000046 	 loss = 0.0098(0.3123)
2024/03/04 06:38:06 - INFO - root -   Epoch: [144/300][60/200], lr: 0.00000046 	 loss = 0.0147(0.3049)
2024/03/04 06:38:21 - INFO - root -   Epoch: [144/300][80/200], lr: 0.00000046 	 loss = 0.3978(0.2908)
2024/03/04 06:38:37 - INFO - root -   Epoch: [144/300][100/200], lr: 0.00000046 	 loss = 0.1266(0.2832)
2024/03/04 06:38:46 - INFO - root -   Epoch: [144/300][120/200], lr: 0.00000046 	 loss = 1.2767(0.2856)
2024/03/04 06:38:59 - INFO - root -   Epoch: [144/300][140/200], lr: 0.00000046 	 loss = 1.0647(0.2921)
2024/03/04 06:39:17 - INFO - root -   Epoch: [144/300][160/200], lr: 0.00000046 	 loss = 0.8202(0.3181)
2024/03/04 06:39:25 - INFO - root -   Epoch: [144/300][180/200], lr: 0.00000046 	 loss = 0.0420(0.3149)
2024/03/04 06:39:37 - INFO - root -   Epoch: [144/300] 	 loss = 0.3258
2024/03/04 06:39:41 - INFO - root -   precision = 0.6889
2024/03/04 06:39:41 - INFO - root -   eval_loss = 1.7020
2024/03/04 06:39:41 - INFO - root -   eval_acc = 0.6889
2024/03/04 06:39:42 - INFO - root -   train_accuracy = 0.8775
2024/03/04 06:39:43 - INFO - root -   Epoch: [145/300][0/200], lr: 0.00000046 	 loss = 0.6852(0.6852)
2024/03/04 06:40:08 - INFO - root -   Epoch: [145/300][20/200], lr: 0.00000046 	 loss = 0.0093(0.6306)
2024/03/04 06:40:26 - INFO - root -   Epoch: [145/300][40/200], lr: 0.00000046 	 loss = 0.3057(0.4932)
2024/03/04 06:40:34 - INFO - root -   Epoch: [145/300][60/200], lr: 0.00000046 	 loss = 0.1083(0.4777)
2024/03/04 06:40:56 - INFO - root -   Epoch: [145/300][80/200], lr: 0.00000046 	 loss = 0.4440(0.4562)
2024/03/04 06:41:03 - INFO - root -   Epoch: [145/300][100/200], lr: 0.00000046 	 loss = 0.0432(0.4203)
2024/03/04 06:41:19 - INFO - root -   Epoch: [145/300][120/200], lr: 0.00000046 	 loss = 1.2746(0.4016)
2024/03/04 06:41:29 - INFO - root -   Epoch: [145/300][140/200], lr: 0.00000046 	 loss = 0.6838(0.4087)
2024/03/04 06:41:47 - INFO - root -   Epoch: [145/300][160/200], lr: 0.00000046 	 loss = 0.1577(0.4241)
2024/03/04 06:41:59 - INFO - root -   Epoch: [145/300][180/200], lr: 0.00000046 	 loss = 0.0349(0.4143)
2024/03/04 06:42:06 - INFO - root -   Epoch: [145/300] 	 loss = 0.4183
2024/03/04 06:42:06 - INFO - root -   train_accuracy = 0.8300
2024/03/04 06:42:08 - INFO - root -   Epoch: [146/300][0/200], lr: 0.00000046 	 loss = 0.6047(0.6047)
2024/03/04 06:42:39 - INFO - root -   Epoch: [146/300][20/200], lr: 0.00000046 	 loss = 0.1378(0.5220)
2024/03/04 06:42:58 - INFO - root -   Epoch: [146/300][40/200], lr: 0.00000046 	 loss = 0.0061(0.4228)
2024/03/04 06:43:20 - INFO - root -   Epoch: [146/300][60/200], lr: 0.00000046 	 loss = 0.4940(0.4279)
2024/03/04 06:43:41 - INFO - root -   Epoch: [146/300][80/200], lr: 0.00000046 	 loss = 1.7978(0.4256)
2024/03/04 06:43:48 - INFO - root -   Epoch: [146/300][100/200], lr: 0.00000046 	 loss = 0.0814(0.3936)
2024/03/04 06:43:59 - INFO - root -   Epoch: [146/300][120/200], lr: 0.00000046 	 loss = 0.6323(0.3632)
2024/03/04 06:44:30 - INFO - root -   Epoch: [146/300][140/200], lr: 0.00000046 	 loss = 1.5891(0.3812)
2024/03/04 06:44:38 - INFO - root -   Epoch: [146/300][160/200], lr: 0.00000046 	 loss = 0.1632(0.3721)
2024/03/04 06:44:53 - INFO - root -   Epoch: [146/300][180/200], lr: 0.00000046 	 loss = 0.3103(0.3712)
2024/03/04 06:45:01 - INFO - root -   Epoch: [146/300] 	 loss = 0.3563
2024/03/04 06:45:01 - INFO - root -   train_accuracy = 0.8750
2024/03/04 06:45:04 - INFO - root -   Epoch: [147/300][0/200], lr: 0.00000046 	 loss = 0.1981(0.1981)
2024/03/04 06:45:40 - INFO - root -   Epoch: [147/300][20/200], lr: 0.00000046 	 loss = 0.0422(0.3209)
2024/03/04 06:45:49 - INFO - root -   Epoch: [147/300][40/200], lr: 0.00000046 	 loss = 0.0075(0.3044)
2024/03/04 06:46:06 - INFO - root -   Epoch: [147/300][60/200], lr: 0.00000046 	 loss = 0.1233(0.3463)
2024/03/04 06:46:26 - INFO - root -   Epoch: [147/300][80/200], lr: 0.00000046 	 loss = 0.4524(0.3441)
2024/03/04 06:46:38 - INFO - root -   Epoch: [147/300][100/200], lr: 0.00000046 	 loss = 0.1675(0.3421)
2024/03/04 06:47:01 - INFO - root -   Epoch: [147/300][120/200], lr: 0.00000046 	 loss = 1.3407(0.3187)
2024/03/04 06:47:09 - INFO - root -   Epoch: [147/300][140/200], lr: 0.00000046 	 loss = 1.3008(0.3229)
2024/03/04 06:47:22 - INFO - root -   Epoch: [147/300][160/200], lr: 0.00000046 	 loss = 0.1332(0.3417)
2024/03/04 06:47:30 - INFO - root -   Epoch: [147/300][180/200], lr: 0.00000046 	 loss = 0.3830(0.3419)
2024/03/04 06:47:38 - INFO - root -   Epoch: [147/300] 	 loss = 0.3297
2024/03/04 06:47:38 - INFO - root -   train_accuracy = 0.8775
2024/03/04 06:47:41 - INFO - root -   Epoch: [148/300][0/200], lr: 0.00000047 	 loss = 1.2876(1.2876)
2024/03/04 06:48:17 - INFO - root -   Epoch: [148/300][20/200], lr: 0.00000047 	 loss = 0.0098(0.6451)
2024/03/04 06:48:25 - INFO - root -   Epoch: [148/300][40/200], lr: 0.00000047 	 loss = 0.0152(0.4428)
2024/03/04 06:48:57 - INFO - root -   Epoch: [148/300][60/200], lr: 0.00000047 	 loss = 0.0288(0.4422)
2024/03/04 06:49:06 - INFO - root -   Epoch: [148/300][80/200], lr: 0.00000047 	 loss = 0.3829(0.4290)
2024/03/04 06:49:30 - INFO - root -   Epoch: [148/300][100/200], lr: 0.00000047 	 loss = 0.1928(0.4132)
2024/03/04 06:49:45 - INFO - root -   Epoch: [148/300][120/200], lr: 0.00000047 	 loss = 1.9097(0.3962)
2024/03/04 06:50:01 - INFO - root -   Epoch: [148/300][140/200], lr: 0.00000047 	 loss = 1.2681(0.3807)
2024/03/04 06:50:09 - INFO - root -   Epoch: [148/300][160/200], lr: 0.00000047 	 loss = 0.0286(0.3690)
2024/03/04 06:50:31 - INFO - root -   Epoch: [148/300][180/200], lr: 0.00000047 	 loss = 0.0923(0.3645)
2024/03/04 06:50:39 - INFO - root -   Epoch: [148/300] 	 loss = 0.3622
2024/03/04 06:50:39 - INFO - root -   train_accuracy = 0.8650
2024/03/04 06:50:41 - INFO - root -   Epoch: [149/300][0/200], lr: 0.00000047 	 loss = 0.3218(0.3218)
2024/03/04 06:51:13 - INFO - root -   Epoch: [149/300][20/200], lr: 0.00000047 	 loss = 0.1100(0.6416)
2024/03/04 06:51:30 - INFO - root -   Epoch: [149/300][40/200], lr: 0.00000047 	 loss = 0.3361(0.4434)
2024/03/04 06:51:38 - INFO - root -   Epoch: [149/300][60/200], lr: 0.00000047 	 loss = 0.0928(0.3750)
2024/03/04 06:52:10 - INFO - root -   Epoch: [149/300][80/200], lr: 0.00000047 	 loss = 0.4169(0.3936)
2024/03/04 06:52:18 - INFO - root -   Epoch: [149/300][100/200], lr: 0.00000047 	 loss = 0.1313(0.3679)
2024/03/04 06:52:38 - INFO - root -   Epoch: [149/300][120/200], lr: 0.00000047 	 loss = 1.2209(0.3482)
2024/03/04 06:52:56 - INFO - root -   Epoch: [149/300][140/200], lr: 0.00000047 	 loss = 2.0587(0.3486)
2024/03/04 06:53:04 - INFO - root -   Epoch: [149/300][160/200], lr: 0.00000047 	 loss = 0.2784(0.3542)
2024/03/04 06:53:22 - INFO - root -   Epoch: [149/300][180/200], lr: 0.00000047 	 loss = 0.2962(0.3689)
2024/03/04 06:53:30 - INFO - root -   Epoch: [149/300] 	 loss = 0.3609
2024/03/04 06:53:33 - INFO - root -   precision = 0.7111
2024/03/04 06:53:33 - INFO - root -   eval_loss = 1.7497
2024/03/04 06:53:33 - INFO - root -   eval_acc = 0.7111
2024/03/04 06:53:34 - INFO - root -   train_accuracy = 0.8775
2024/03/04 06:53:50 - INFO - root -   Epoch: [150/300][0/200], lr: 0.00000047 	 loss = 2.2006(2.2006)
2024/03/04 06:53:58 - INFO - root -   Epoch: [150/300][20/200], lr: 0.00000047 	 loss = 0.0707(0.4906)
2024/03/04 06:54:07 - INFO - root -   Epoch: [150/300][40/200], lr: 0.00000047 	 loss = 0.1122(0.3849)
2024/03/04 06:54:23 - INFO - root -   Epoch: [150/300][60/200], lr: 0.00000047 	 loss = 0.0275(0.3654)
2024/03/04 06:54:49 - INFO - root -   Epoch: [150/300][80/200], lr: 0.00000047 	 loss = 0.6658(0.4148)
2024/03/04 06:55:01 - INFO - root -   Epoch: [150/300][100/200], lr: 0.00000047 	 loss = 0.0015(0.4064)
2024/03/04 06:55:19 - INFO - root -   Epoch: [150/300][120/200], lr: 0.00000047 	 loss = 1.3193(0.3778)
2024/03/04 06:55:27 - INFO - root -   Epoch: [150/300][140/200], lr: 0.00000047 	 loss = 0.5248(0.3813)
2024/03/04 06:55:47 - INFO - root -   Epoch: [150/300][160/200], lr: 0.00000047 	 loss = 0.1855(0.3874)
2024/03/04 06:56:07 - INFO - root -   Epoch: [150/300][180/200], lr: 0.00000047 	 loss = 0.1563(0.3988)
2024/03/04 06:56:15 - INFO - root -   Epoch: [150/300] 	 loss = 0.3900
2024/03/04 06:56:15 - INFO - root -   train_accuracy = 0.8475
2024/03/04 06:56:31 - INFO - root -   Epoch: [151/300][0/200], lr: 0.00000047 	 loss = 0.4562(0.4562)
2024/03/04 06:56:46 - INFO - root -   Epoch: [151/300][20/200], lr: 0.00000047 	 loss = 0.0625(0.4388)
2024/03/04 06:56:54 - INFO - root -   Epoch: [151/300][40/200], lr: 0.00000047 	 loss = 0.2113(0.3695)
2024/03/04 06:57:02 - INFO - root -   Epoch: [151/300][60/200], lr: 0.00000047 	 loss = 0.0032(0.3122)
2024/03/04 06:57:22 - INFO - root -   Epoch: [151/300][80/200], lr: 0.00000047 	 loss = 1.4580(0.3112)
2024/03/04 06:57:40 - INFO - root -   Epoch: [151/300][100/200], lr: 0.00000047 	 loss = 0.1309(0.3317)
2024/03/04 06:58:03 - INFO - root -   Epoch: [151/300][120/200], lr: 0.00000047 	 loss = 0.5797(0.3190)
2024/03/04 06:58:14 - INFO - root -   Epoch: [151/300][140/200], lr: 0.00000047 	 loss = 1.3209(0.3480)
2024/03/04 06:58:35 - INFO - root -   Epoch: [151/300][160/200], lr: 0.00000047 	 loss = 0.1969(0.3416)
2024/03/04 06:58:50 - INFO - root -   Epoch: [151/300][180/200], lr: 0.00000047 	 loss = 0.1448(0.3441)
2024/03/04 06:58:58 - INFO - root -   Epoch: [151/300] 	 loss = 0.3381
2024/03/04 06:58:58 - INFO - root -   train_accuracy = 0.8775
2024/03/04 06:59:00 - INFO - root -   Epoch: [152/300][0/200], lr: 0.00000048 	 loss = 0.6300(0.6300)
2024/03/04 06:59:29 - INFO - root -   Epoch: [152/300][20/200], lr: 0.00000048 	 loss = 0.2347(0.3910)
2024/03/04 06:59:52 - INFO - root -   Epoch: [152/300][40/200], lr: 0.00000048 	 loss = 0.0800(0.2773)
2024/03/04 07:00:00 - INFO - root -   Epoch: [152/300][60/200], lr: 0.00000048 	 loss = 0.0058(0.2753)
2024/03/04 07:00:20 - INFO - root -   Epoch: [152/300][80/200], lr: 0.00000048 	 loss = 1.0243(0.2969)
2024/03/04 07:00:39 - INFO - root -   Epoch: [152/300][100/200], lr: 0.00000048 	 loss = 0.0862(0.2882)
2024/03/04 07:00:52 - INFO - root -   Epoch: [152/300][120/200], lr: 0.00000048 	 loss = 1.3258(0.2891)
2024/03/04 07:01:00 - INFO - root -   Epoch: [152/300][140/200], lr: 0.00000048 	 loss = 1.9417(0.3065)
2024/03/04 07:01:21 - INFO - root -   Epoch: [152/300][160/200], lr: 0.00000048 	 loss = 0.6651(0.3129)
2024/03/04 07:01:29 - INFO - root -   Epoch: [152/300][180/200], lr: 0.00000048 	 loss = 0.0368(0.3230)
2024/03/04 07:01:36 - INFO - root -   Epoch: [152/300] 	 loss = 0.3220
2024/03/04 07:01:36 - INFO - root -   train_accuracy = 0.8750
2024/03/04 07:01:39 - INFO - root -   Epoch: [153/300][0/200], lr: 0.00000048 	 loss = 1.0333(1.0333)
2024/03/04 07:02:05 - INFO - root -   Epoch: [153/300][20/200], lr: 0.00000048 	 loss = 0.4036(0.4200)
2024/03/04 07:02:17 - INFO - root -   Epoch: [153/300][40/200], lr: 0.00000048 	 loss = 0.1857(0.3396)
2024/03/04 07:02:37 - INFO - root -   Epoch: [153/300][60/200], lr: 0.00000048 	 loss = 0.0014(0.3298)
2024/03/04 07:02:45 - INFO - root -   Epoch: [153/300][80/200], lr: 0.00000048 	 loss = 0.5249(0.3451)
2024/03/04 07:03:02 - INFO - root -   Epoch: [153/300][100/200], lr: 0.00000048 	 loss = 0.1000(0.3472)
2024/03/04 07:03:19 - INFO - root -   Epoch: [153/300][120/200], lr: 0.00000048 	 loss = 0.8800(0.3178)
2024/03/04 07:03:33 - INFO - root -   Epoch: [153/300][140/200], lr: 0.00000048 	 loss = 0.6758(0.3301)
2024/03/04 07:03:43 - INFO - root -   Epoch: [153/300][160/200], lr: 0.00000048 	 loss = 0.0366(0.3367)
2024/03/04 07:03:51 - INFO - root -   Epoch: [153/300][180/200], lr: 0.00000048 	 loss = 0.1319(0.3246)
2024/03/04 07:03:58 - INFO - root -   Epoch: [153/300] 	 loss = 0.3269
2024/03/04 07:03:58 - INFO - root -   train_accuracy = 0.8675
2024/03/04 07:04:00 - INFO - root -   Epoch: [154/300][0/200], lr: 0.00000048 	 loss = 0.5264(0.5264)
2024/03/04 07:04:31 - INFO - root -   Epoch: [154/300][20/200], lr: 0.00000048 	 loss = 0.0487(0.4093)
2024/03/04 07:04:52 - INFO - root -   Epoch: [154/300][40/200], lr: 0.00000048 	 loss = 0.9967(0.3476)
2024/03/04 07:05:04 - INFO - root -   Epoch: [154/300][60/200], lr: 0.00000048 	 loss = 0.2756(0.3883)
2024/03/04 07:05:23 - INFO - root -   Epoch: [154/300][80/200], lr: 0.00000048 	 loss = 0.6902(0.3898)
2024/03/04 07:05:31 - INFO - root -   Epoch: [154/300][100/200], lr: 0.00000048 	 loss = 0.1002(0.3813)
2024/03/04 07:05:39 - INFO - root -   Epoch: [154/300][120/200], lr: 0.00000048 	 loss = 1.3559(0.3555)
2024/03/04 07:06:01 - INFO - root -   Epoch: [154/300][140/200], lr: 0.00000048 	 loss = 3.0499(0.3776)
2024/03/04 07:06:19 - INFO - root -   Epoch: [154/300][160/200], lr: 0.00000048 	 loss = 0.1691(0.3758)
2024/03/04 07:06:32 - INFO - root -   Epoch: [154/300][180/200], lr: 0.00000048 	 loss = 0.0206(0.3746)
2024/03/04 07:06:40 - INFO - root -   Epoch: [154/300] 	 loss = 0.3728
2024/03/04 07:06:44 - INFO - root -   precision = 0.7111
2024/03/04 07:06:44 - INFO - root -   eval_loss = 1.7234
2024/03/04 07:06:44 - INFO - root -   eval_acc = 0.7111
2024/03/04 07:06:45 - INFO - root -   train_accuracy = 0.8650
2024/03/04 07:06:47 - INFO - root -   Epoch: [155/300][0/200], lr: 0.00000048 	 loss = 0.3122(0.3122)
2024/03/04 07:07:16 - INFO - root -   Epoch: [155/300][20/200], lr: 0.00000048 	 loss = 0.0869(0.5479)
2024/03/04 07:07:39 - INFO - root -   Epoch: [155/300][40/200], lr: 0.00000048 	 loss = 0.0162(0.4223)
2024/03/04 07:07:50 - INFO - root -   Epoch: [155/300][60/200], lr: 0.00000048 	 loss = 0.2691(0.4029)
2024/03/04 07:08:08 - INFO - root -   Epoch: [155/300][80/200], lr: 0.00000048 	 loss = 0.3598(0.3717)
2024/03/04 07:08:23 - INFO - root -   Epoch: [155/300][100/200], lr: 0.00000048 	 loss = 0.0052(0.3458)
2024/03/04 07:08:36 - INFO - root -   Epoch: [155/300][120/200], lr: 0.00000048 	 loss = 1.8496(0.3431)
2024/03/04 07:08:43 - INFO - root -   Epoch: [155/300][140/200], lr: 0.00000048 	 loss = 0.9709(0.3341)
2024/03/04 07:09:04 - INFO - root -   Epoch: [155/300][160/200], lr: 0.00000048 	 loss = 0.2733(0.3250)
2024/03/04 07:09:15 - INFO - root -   Epoch: [155/300][180/200], lr: 0.00000048 	 loss = 0.0573(0.3251)
2024/03/04 07:09:23 - INFO - root -   Epoch: [155/300] 	 loss = 0.3299
2024/03/04 07:09:23 - INFO - root -   train_accuracy = 0.8800
2024/03/04 07:09:24 - INFO - root -   Epoch: [156/300][0/200], lr: 0.00000049 	 loss = 0.5586(0.5586)
2024/03/04 07:09:57 - INFO - root -   Epoch: [156/300][20/200], lr: 0.00000049 	 loss = 0.1805(0.3968)
2024/03/04 07:10:05 - INFO - root -   Epoch: [156/300][40/200], lr: 0.00000049 	 loss = 0.0216(0.3498)
2024/03/04 07:10:29 - INFO - root -   Epoch: [156/300][60/200], lr: 0.00000049 	 loss = 0.1243(0.3391)
2024/03/04 07:10:37 - INFO - root -   Epoch: [156/300][80/200], lr: 0.00000049 	 loss = 0.2644(0.3199)
2024/03/04 07:10:45 - INFO - root -   Epoch: [156/300][100/200], lr: 0.00000049 	 loss = 0.0030(0.2950)
2024/03/04 07:11:07 - INFO - root -   Epoch: [156/300][120/200], lr: 0.00000049 	 loss = 1.2918(0.2928)
2024/03/04 07:11:24 - INFO - root -   Epoch: [156/300][140/200], lr: 0.00000049 	 loss = 0.1691(0.2904)
2024/03/04 07:11:35 - INFO - root -   Epoch: [156/300][160/200], lr: 0.00000049 	 loss = 0.0262(0.2992)
2024/03/04 07:11:55 - INFO - root -   Epoch: [156/300][180/200], lr: 0.00000049 	 loss = 0.0098(0.2912)
2024/03/04 07:12:03 - INFO - root -   Epoch: [156/300] 	 loss = 0.2957
2024/03/04 07:12:03 - INFO - root -   train_accuracy = 0.8875
2024/03/04 07:12:15 - INFO - root -   Epoch: [157/300][0/200], lr: 0.00000049 	 loss = 0.3537(0.3537)
2024/03/04 07:12:32 - INFO - root -   Epoch: [157/300][20/200], lr: 0.00000049 	 loss = 0.0054(0.3708)
2024/03/04 07:12:48 - INFO - root -   Epoch: [157/300][40/200], lr: 0.00000049 	 loss = 0.1238(0.3510)
2024/03/04 07:13:01 - INFO - root -   Epoch: [157/300][60/200], lr: 0.00000049 	 loss = 0.1066(0.3173)
2024/03/04 07:13:13 - INFO - root -   Epoch: [157/300][80/200], lr: 0.00000049 	 loss = 0.5467(0.3303)
2024/03/04 07:13:32 - INFO - root -   Epoch: [157/300][100/200], lr: 0.00000049 	 loss = 0.0128(0.3263)
2024/03/04 07:13:58 - INFO - root -   Epoch: [157/300][120/200], lr: 0.00000049 	 loss = 3.5370(0.3427)
2024/03/04 07:14:15 - INFO - root -   Epoch: [157/300][140/200], lr: 0.00000049 	 loss = 0.8407(0.3373)
2024/03/04 07:14:33 - INFO - root -   Epoch: [157/300][160/200], lr: 0.00000049 	 loss = 0.0657(0.3306)
2024/03/04 07:14:45 - INFO - root -   Epoch: [157/300][180/200], lr: 0.00000049 	 loss = 0.1510(0.3390)
2024/03/04 07:14:54 - INFO - root -   Epoch: [157/300] 	 loss = 0.3315
2024/03/04 07:14:54 - INFO - root -   train_accuracy = 0.8825
2024/03/04 07:14:55 - INFO - root -   Epoch: [158/300][0/200], lr: 0.00000049 	 loss = 0.5764(0.5764)
2024/03/04 07:15:24 - INFO - root -   Epoch: [158/300][20/200], lr: 0.00000049 	 loss = 0.0383(0.4418)
2024/03/04 07:15:45 - INFO - root -   Epoch: [158/300][40/200], lr: 0.00000049 	 loss = 0.1452(0.3211)
2024/03/04 07:16:07 - INFO - root -   Epoch: [158/300][60/200], lr: 0.00000049 	 loss = 0.2819(0.3606)
2024/03/04 07:16:15 - INFO - root -   Epoch: [158/300][80/200], lr: 0.00000049 	 loss = 0.2744(0.3806)
2024/03/04 07:16:34 - INFO - root -   Epoch: [158/300][100/200], lr: 0.00000049 	 loss = 0.0002(0.3485)
2024/03/04 07:16:59 - INFO - root -   Epoch: [158/300][120/200], lr: 0.00000049 	 loss = 2.0254(0.3488)
2024/03/04 07:17:06 - INFO - root -   Epoch: [158/300][140/200], lr: 0.00000049 	 loss = 0.3894(0.3523)
2024/03/04 07:17:24 - INFO - root -   Epoch: [158/300][160/200], lr: 0.00000049 	 loss = 0.7216(0.3565)
2024/03/04 07:17:39 - INFO - root -   Epoch: [158/300][180/200], lr: 0.00000049 	 loss = 0.5791(0.3712)
2024/03/04 07:17:50 - INFO - root -   Epoch: [158/300] 	 loss = 0.3933
2024/03/04 07:17:50 - INFO - root -   train_accuracy = 0.8450
2024/03/04 07:17:52 - INFO - root -   Epoch: [159/300][0/200], lr: 0.00000049 	 loss = 0.1463(0.1463)
2024/03/04 07:18:26 - INFO - root -   Epoch: [159/300][20/200], lr: 0.00000049 	 loss = 0.1874(0.4647)
2024/03/04 07:18:42 - INFO - root -   Epoch: [159/300][40/200], lr: 0.00000049 	 loss = 0.0052(0.3574)
2024/03/04 07:18:50 - INFO - root -   Epoch: [159/300][60/200], lr: 0.00000049 	 loss = 0.0038(0.3201)
2024/03/04 07:19:13 - INFO - root -   Epoch: [159/300][80/200], lr: 0.00000049 	 loss = 0.8278(0.3557)
2024/03/04 07:19:21 - INFO - root -   Epoch: [159/300][100/200], lr: 0.00000049 	 loss = 0.0105(0.3189)
2024/03/04 07:19:34 - INFO - root -   Epoch: [159/300][120/200], lr: 0.00000049 	 loss = 1.2360(0.3041)
2024/03/04 07:19:59 - INFO - root -   Epoch: [159/300][140/200], lr: 0.00000049 	 loss = 0.1280(0.3141)
2024/03/04 07:20:10 - INFO - root -   Epoch: [159/300][160/200], lr: 0.00000049 	 loss = 0.0504(0.3241)
2024/03/04 07:20:23 - INFO - root -   Epoch: [159/300][180/200], lr: 0.00000049 	 loss = 0.6702(0.3279)
2024/03/04 07:20:31 - INFO - root -   Epoch: [159/300] 	 loss = 0.3260
2024/03/04 07:20:35 - INFO - root -   precision = 0.7111
2024/03/04 07:20:35 - INFO - root -   eval_loss = 1.8688
2024/03/04 07:20:35 - INFO - root -   eval_acc = 0.7111
2024/03/04 07:20:36 - INFO - root -   train_accuracy = 0.8750
2024/03/04 07:20:54 - INFO - root -   Epoch: [160/300][0/200], lr: 0.00000050 	 loss = 1.3567(1.3567)
2024/03/04 07:21:02 - INFO - root -   Epoch: [160/300][20/200], lr: 0.00000050 	 loss = 0.0017(0.4128)
2024/03/04 07:21:14 - INFO - root -   Epoch: [160/300][40/200], lr: 0.00000050 	 loss = 0.0237(0.3107)
2024/03/04 07:21:24 - INFO - root -   Epoch: [160/300][60/200], lr: 0.00000050 	 loss = 0.0668(0.3415)
2024/03/04 07:21:42 - INFO - root -   Epoch: [160/300][80/200], lr: 0.00000050 	 loss = 0.6399(0.3388)
2024/03/04 07:21:57 - INFO - root -   Epoch: [160/300][100/200], lr: 0.00000050 	 loss = 0.0667(0.3176)
2024/03/04 07:22:17 - INFO - root -   Epoch: [160/300][120/200], lr: 0.00000050 	 loss = 2.0847(0.3124)
2024/03/04 07:22:25 - INFO - root -   Epoch: [160/300][140/200], lr: 0.00000050 	 loss = 0.4042(0.3147)
2024/03/04 07:22:44 - INFO - root -   Epoch: [160/300][160/200], lr: 0.00000050 	 loss = 0.0456(0.3274)
2024/03/04 07:22:57 - INFO - root -   Epoch: [160/300][180/200], lr: 0.00000050 	 loss = 0.0082(0.3246)
2024/03/04 07:23:05 - INFO - root -   Epoch: [160/300] 	 loss = 0.3456
2024/03/04 07:23:05 - INFO - root -   train_accuracy = 0.8700
2024/03/04 07:23:19 - INFO - root -   Epoch: [161/300][0/200], lr: 0.00000050 	 loss = 0.1250(0.1250)
2024/03/04 07:23:30 - INFO - root -   Epoch: [161/300][20/200], lr: 0.00000050 	 loss = 0.0064(0.4499)
2024/03/04 07:23:37 - INFO - root -   Epoch: [161/300][40/200], lr: 0.00000050 	 loss = 0.1310(0.3542)
2024/03/04 07:23:46 - INFO - root -   Epoch: [161/300][60/200], lr: 0.00000050 	 loss = 0.0030(0.2908)
2024/03/04 07:24:00 - INFO - root -   Epoch: [161/300][80/200], lr: 0.00000050 	 loss = 0.1908(0.2744)
2024/03/04 07:24:19 - INFO - root -   Epoch: [161/300][100/200], lr: 0.00000050 	 loss = 0.2228(0.2812)
2024/03/04 07:24:27 - INFO - root -   Epoch: [161/300][120/200], lr: 0.00000050 	 loss = 1.4450(0.2918)
2024/03/04 07:24:50 - INFO - root -   Epoch: [161/300][140/200], lr: 0.00000050 	 loss = 2.1014(0.3005)
2024/03/04 07:24:58 - INFO - root -   Epoch: [161/300][160/200], lr: 0.00000050 	 loss = 0.0624(0.2998)
2024/03/04 07:25:19 - INFO - root -   Epoch: [161/300][180/200], lr: 0.00000050 	 loss = 0.2141(0.3153)
2024/03/04 07:25:27 - INFO - root -   Epoch: [161/300] 	 loss = 0.3100
2024/03/04 07:25:27 - INFO - root -   train_accuracy = 0.8925
2024/03/04 07:25:40 - INFO - root -   Epoch: [162/300][0/200], lr: 0.00000050 	 loss = 0.3949(0.3949)
2024/03/04 07:25:54 - INFO - root -   Epoch: [162/300][20/200], lr: 0.00000050 	 loss = 0.0704(0.3639)
2024/03/04 07:26:13 - INFO - root -   Epoch: [162/300][40/200], lr: 0.00000050 	 loss = 0.0769(0.3514)
2024/03/04 07:26:24 - INFO - root -   Epoch: [162/300][60/200], lr: 0.00000050 	 loss = 0.0014(0.3384)
2024/03/04 07:26:40 - INFO - root -   Epoch: [162/300][80/200], lr: 0.00000050 	 loss = 0.4496(0.3383)
2024/03/04 07:26:52 - INFO - root -   Epoch: [162/300][100/200], lr: 0.00000050 	 loss = 0.0594(0.3272)
2024/03/04 07:27:08 - INFO - root -   Epoch: [162/300][120/200], lr: 0.00000050 	 loss = 1.7162(0.3168)
2024/03/04 07:27:28 - INFO - root -   Epoch: [162/300][140/200], lr: 0.00000050 	 loss = 0.2429(0.3036)
2024/03/04 07:27:36 - INFO - root -   Epoch: [162/300][160/200], lr: 0.00000050 	 loss = 0.0304(0.3115)
2024/03/04 07:27:47 - INFO - root -   Epoch: [162/300][180/200], lr: 0.00000050 	 loss = 0.1093(0.3253)
2024/03/04 07:27:55 - INFO - root -   Epoch: [162/300] 	 loss = 0.3278
2024/03/04 07:27:55 - INFO - root -   train_accuracy = 0.8800
2024/03/04 07:27:58 - INFO - root -   Epoch: [163/300][0/200], lr: 0.00000050 	 loss = 0.5546(0.5546)
2024/03/04 07:28:30 - INFO - root -   Epoch: [163/300][20/200], lr: 0.00000050 	 loss = 0.0049(0.3680)
2024/03/04 07:28:38 - INFO - root -   Epoch: [163/300][40/200], lr: 0.00000050 	 loss = 0.0125(0.2941)
2024/03/04 07:28:56 - INFO - root -   Epoch: [163/300][60/200], lr: 0.00000050 	 loss = 0.1447(0.3287)
2024/03/04 07:29:08 - INFO - root -   Epoch: [163/300][80/200], lr: 0.00000050 	 loss = 1.1398(0.3299)
2024/03/04 07:29:26 - INFO - root -   Epoch: [163/300][100/200], lr: 0.00000050 	 loss = 0.0465(0.2928)
2024/03/04 07:29:52 - INFO - root -   Epoch: [163/300][120/200], lr: 0.00000050 	 loss = 1.5707(0.2991)
2024/03/04 07:30:10 - INFO - root -   Epoch: [163/300][140/200], lr: 0.00000050 	 loss = 1.1083(0.3305)
2024/03/04 07:30:24 - INFO - root -   Epoch: [163/300][160/200], lr: 0.00000050 	 loss = 0.0829(0.3416)
2024/03/04 07:30:41 - INFO - root -   Epoch: [163/300][180/200], lr: 0.00000050 	 loss = 0.4375(0.3457)
2024/03/04 07:30:49 - INFO - root -   Epoch: [163/300] 	 loss = 0.3483
2024/03/04 07:30:49 - INFO - root -   train_accuracy = 0.8700
2024/03/04 07:31:05 - INFO - root -   Epoch: [164/300][0/200], lr: 0.00000051 	 loss = 0.8357(0.8357)
2024/03/04 07:31:30 - INFO - root -   Epoch: [164/300][20/200], lr: 0.00000051 	 loss = 0.0201(0.5735)
2024/03/04 07:31:44 - INFO - root -   Epoch: [164/300][40/200], lr: 0.00000051 	 loss = 0.0127(0.3729)
2024/03/04 07:31:53 - INFO - root -   Epoch: [164/300][60/200], lr: 0.00000051 	 loss = 0.0812(0.3468)
2024/03/04 07:32:15 - INFO - root -   Epoch: [164/300][80/200], lr: 0.00000051 	 loss = 1.4243(0.3372)
2024/03/04 07:32:23 - INFO - root -   Epoch: [164/300][100/200], lr: 0.00000051 	 loss = 0.0167(0.3578)
2024/03/04 07:32:31 - INFO - root -   Epoch: [164/300][120/200], lr: 0.00000051 	 loss = 0.5162(0.3482)
2024/03/04 07:32:43 - INFO - root -   Epoch: [164/300][140/200], lr: 0.00000051 	 loss = 0.3464(0.3540)
2024/03/04 07:33:01 - INFO - root -   Epoch: [164/300][160/200], lr: 0.00000051 	 loss = 0.0315(0.3541)
2024/03/04 07:33:12 - INFO - root -   Epoch: [164/300][180/200], lr: 0.00000051 	 loss = 0.0064(0.3689)
2024/03/04 07:33:20 - INFO - root -   Epoch: [164/300] 	 loss = 0.3619
2024/03/04 07:33:24 - INFO - root -   precision = 0.6889
2024/03/04 07:33:24 - INFO - root -   eval_loss = 1.7652
2024/03/04 07:33:24 - INFO - root -   eval_acc = 0.6889
2024/03/04 07:33:24 - INFO - root -   train_accuracy = 0.8650
2024/03/04 07:33:26 - INFO - root -   Epoch: [165/300][0/200], lr: 0.00000051 	 loss = 0.1718(0.1718)
2024/03/04 07:33:55 - INFO - root -   Epoch: [165/300][20/200], lr: 0.00000051 	 loss = 0.0587(0.3753)
2024/03/04 07:34:24 - INFO - root -   Epoch: [165/300][40/200], lr: 0.00000051 	 loss = 0.0865(0.3066)
2024/03/04 07:34:32 - INFO - root -   Epoch: [165/300][60/200], lr: 0.00000051 	 loss = 0.0017(0.2908)
2024/03/04 07:34:40 - INFO - root -   Epoch: [165/300][80/200], lr: 0.00000051 	 loss = 1.2217(0.2986)
2024/03/04 07:35:02 - INFO - root -   Epoch: [165/300][100/200], lr: 0.00000051 	 loss = 0.0142(0.2867)
2024/03/04 07:35:10 - INFO - root -   Epoch: [165/300][120/200], lr: 0.00000051 	 loss = 0.6668(0.2756)
2024/03/04 07:35:20 - INFO - root -   Epoch: [165/300][140/200], lr: 0.00000051 	 loss = 0.3287(0.2602)
2024/03/04 07:35:28 - INFO - root -   Epoch: [165/300][160/200], lr: 0.00000051 	 loss = 0.0875(0.2687)
2024/03/04 07:35:48 - INFO - root -   Epoch: [165/300][180/200], lr: 0.00000051 	 loss = 0.0034(0.2859)
2024/03/04 07:35:55 - INFO - root -   Epoch: [165/300] 	 loss = 0.2794
2024/03/04 07:35:55 - INFO - root -   train_accuracy = 0.8875
2024/03/04 07:36:18 - INFO - root -   Epoch: [166/300][0/200], lr: 0.00000051 	 loss = 0.4035(0.4035)
2024/03/04 07:36:26 - INFO - root -   Epoch: [166/300][20/200], lr: 0.00000051 	 loss = 0.0887(0.4099)
2024/03/04 07:36:43 - INFO - root -   Epoch: [166/300][40/200], lr: 0.00000051 	 loss = 0.0135(0.2904)
2024/03/04 07:36:59 - INFO - root -   Epoch: [166/300][60/200], lr: 0.00000051 	 loss = 0.0030(0.3030)
2024/03/04 07:37:19 - INFO - root -   Epoch: [166/300][80/200], lr: 0.00000051 	 loss = 0.6514(0.3340)
2024/03/04 07:37:35 - INFO - root -   Epoch: [166/300][100/200], lr: 0.00000051 	 loss = 0.0829(0.3298)
2024/03/04 07:37:43 - INFO - root -   Epoch: [166/300][120/200], lr: 0.00000051 	 loss = 2.1248(0.3269)
2024/03/04 07:37:51 - INFO - root -   Epoch: [166/300][140/200], lr: 0.00000051 	 loss = 1.4195(0.3278)
2024/03/04 07:38:03 - INFO - root -   Epoch: [166/300][160/200], lr: 0.00000051 	 loss = 0.0282(0.3417)
2024/03/04 07:38:17 - INFO - root -   Epoch: [166/300][180/200], lr: 0.00000051 	 loss = 0.3087(0.3425)
2024/03/04 07:38:27 - INFO - root -   Epoch: [166/300] 	 loss = 0.3452
2024/03/04 07:38:27 - INFO - root -   train_accuracy = 0.8700
2024/03/04 07:38:29 - INFO - root -   Epoch: [167/300][0/200], lr: 0.00000051 	 loss = 0.0958(0.0958)
2024/03/04 07:38:51 - INFO - root -   Epoch: [167/300][20/200], lr: 0.00000051 	 loss = 0.0078(0.5204)
2024/03/04 07:39:03 - INFO - root -   Epoch: [167/300][40/200], lr: 0.00000051 	 loss = 0.0209(0.3762)
2024/03/04 07:39:12 - INFO - root -   Epoch: [167/300][60/200], lr: 0.00000051 	 loss = 0.0865(0.3452)
2024/03/04 07:39:33 - INFO - root -   Epoch: [167/300][80/200], lr: 0.00000051 	 loss = 0.3127(0.3607)
2024/03/04 07:39:45 - INFO - root -   Epoch: [167/300][100/200], lr: 0.00000051 	 loss = 0.0840(0.3618)
2024/03/04 07:40:04 - INFO - root -   Epoch: [167/300][120/200], lr: 0.00000051 	 loss = 0.6917(0.3521)
2024/03/04 07:40:12 - INFO - root -   Epoch: [167/300][140/200], lr: 0.00000051 	 loss = 1.7504(0.3544)
2024/03/04 07:40:23 - INFO - root -   Epoch: [167/300][160/200], lr: 0.00000051 	 loss = 0.1861(0.3517)
2024/03/04 07:40:36 - INFO - root -   Epoch: [167/300][180/200], lr: 0.00000051 	 loss = 0.0315(0.3601)
2024/03/04 07:40:43 - INFO - root -   Epoch: [167/300] 	 loss = 0.3480
2024/03/04 07:40:43 - INFO - root -   train_accuracy = 0.8700
2024/03/04 07:40:44 - INFO - root -   Epoch: [168/300][0/200], lr: 0.00000052 	 loss = 1.7924(1.7924)
2024/03/04 07:41:19 - INFO - root -   Epoch: [168/300][20/200], lr: 0.00000052 	 loss = 0.2596(0.6722)
2024/03/04 07:41:29 - INFO - root -   Epoch: [168/300][40/200], lr: 0.00000052 	 loss = 0.8545(0.5100)
2024/03/04 07:41:44 - INFO - root -   Epoch: [168/300][60/200], lr: 0.00000052 	 loss = 0.0064(0.4658)
2024/03/04 07:42:05 - INFO - root -   Epoch: [168/300][80/200], lr: 0.00000052 	 loss = 0.8752(0.4010)
2024/03/04 07:42:18 - INFO - root -   Epoch: [168/300][100/200], lr: 0.00000052 	 loss = 0.0774(0.3606)
2024/03/04 07:42:33 - INFO - root -   Epoch: [168/300][120/200], lr: 0.00000052 	 loss = 0.6288(0.3377)
2024/03/04 07:42:49 - INFO - root -   Epoch: [168/300][140/200], lr: 0.00000052 	 loss = 1.2938(0.3379)
2024/03/04 07:43:11 - INFO - root -   Epoch: [168/300][160/200], lr: 0.00000052 	 loss = 0.0845(0.3520)
2024/03/04 07:43:23 - INFO - root -   Epoch: [168/300][180/200], lr: 0.00000052 	 loss = 0.0939(0.3709)
2024/03/04 07:43:33 - INFO - root -   Epoch: [168/300] 	 loss = 0.3744
2024/03/04 07:43:33 - INFO - root -   train_accuracy = 0.8675
2024/03/04 07:43:49 - INFO - root -   Epoch: [169/300][0/200], lr: 0.00000052 	 loss = 1.2086(1.2086)
2024/03/04 07:44:06 - INFO - root -   Epoch: [169/300][20/200], lr: 0.00000052 	 loss = 0.1759(0.4705)
2024/03/04 07:44:26 - INFO - root -   Epoch: [169/300][40/200], lr: 0.00000052 	 loss = 0.1572(0.3715)
2024/03/04 07:44:39 - INFO - root -   Epoch: [169/300][60/200], lr: 0.00000052 	 loss = 0.0937(0.3596)
2024/03/04 07:45:02 - INFO - root -   Epoch: [169/300][80/200], lr: 0.00000052 	 loss = 1.8266(0.3831)
2024/03/04 07:45:19 - INFO - root -   Epoch: [169/300][100/200], lr: 0.00000052 	 loss = 0.0012(0.3982)
2024/03/04 07:45:33 - INFO - root -   Epoch: [169/300][120/200], lr: 0.00000052 	 loss = 0.7068(0.3680)
2024/03/04 07:45:49 - INFO - root -   Epoch: [169/300][140/200], lr: 0.00000052 	 loss = 0.9015(0.3594)
2024/03/04 07:46:03 - INFO - root -   Epoch: [169/300][160/200], lr: 0.00000052 	 loss = 0.5783(0.3494)
2024/03/04 07:46:22 - INFO - root -   Epoch: [169/300][180/200], lr: 0.00000052 	 loss = 0.2337(0.3520)
2024/03/04 07:46:29 - INFO - root -   Epoch: [169/300] 	 loss = 0.3583
2024/03/04 07:46:33 - INFO - root -   precision = 0.7111
2024/03/04 07:46:33 - INFO - root -   eval_loss = 1.7559
2024/03/04 07:46:33 - INFO - root -   eval_acc = 0.7111
2024/03/04 07:46:34 - INFO - root -   train_accuracy = 0.8600
2024/03/04 07:46:48 - INFO - root -   Epoch: [170/300][0/200], lr: 0.00000052 	 loss = 0.6341(0.6341)
2024/03/04 07:47:03 - INFO - root -   Epoch: [170/300][20/200], lr: 0.00000052 	 loss = 0.2426(0.4383)
2024/03/04 07:47:18 - INFO - root -   Epoch: [170/300][40/200], lr: 0.00000052 	 loss = 0.2712(0.3248)
2024/03/04 07:47:40 - INFO - root -   Epoch: [170/300][60/200], lr: 0.00000052 	 loss = 0.0576(0.3266)
2024/03/04 07:47:56 - INFO - root -   Epoch: [170/300][80/200], lr: 0.00000052 	 loss = 0.8309(0.3422)
2024/03/04 07:48:04 - INFO - root -   Epoch: [170/300][100/200], lr: 0.00000052 	 loss = 0.0040(0.3175)
2024/03/04 07:48:29 - INFO - root -   Epoch: [170/300][120/200], lr: 0.00000052 	 loss = 1.2254(0.3168)
2024/03/04 07:48:46 - INFO - root -   Epoch: [170/300][140/200], lr: 0.00000052 	 loss = 2.5332(0.3377)
2024/03/04 07:48:55 - INFO - root -   Epoch: [170/300][160/200], lr: 0.00000052 	 loss = 0.0357(0.3398)
2024/03/04 07:49:10 - INFO - root -   Epoch: [170/300][180/200], lr: 0.00000052 	 loss = 0.6877(0.3520)
2024/03/04 07:49:18 - INFO - root -   Epoch: [170/300] 	 loss = 0.3476
2024/03/04 07:49:18 - INFO - root -   train_accuracy = 0.8550
2024/03/04 07:49:20 - INFO - root -   Epoch: [171/300][0/200], lr: 0.00000052 	 loss = 0.1234(0.1234)
2024/03/04 07:49:48 - INFO - root -   Epoch: [171/300][20/200], lr: 0.00000052 	 loss = 0.0050(0.3734)
2024/03/04 07:49:56 - INFO - root -   Epoch: [171/300][40/200], lr: 0.00000052 	 loss = 0.0184(0.3176)
2024/03/04 07:50:14 - INFO - root -   Epoch: [171/300][60/200], lr: 0.00000052 	 loss = 0.0114(0.3132)
2024/03/04 07:50:26 - INFO - root -   Epoch: [171/300][80/200], lr: 0.00000052 	 loss = 0.3331(0.3284)
2024/03/04 07:50:44 - INFO - root -   Epoch: [171/300][100/200], lr: 0.00000052 	 loss = 0.0028(0.2918)
2024/03/04 07:50:55 - INFO - root -   Epoch: [171/300][120/200], lr: 0.00000052 	 loss = 1.0865(0.2826)
2024/03/04 07:51:15 - INFO - root -   Epoch: [171/300][140/200], lr: 0.00000052 	 loss = 0.3262(0.3009)
2024/03/04 07:51:29 - INFO - root -   Epoch: [171/300][160/200], lr: 0.00000052 	 loss = 0.1200(0.3194)
2024/03/04 07:51:49 - INFO - root -   Epoch: [171/300][180/200], lr: 0.00000052 	 loss = 0.8299(0.3209)
2024/03/04 07:51:57 - INFO - root -   Epoch: [171/300] 	 loss = 0.3201
2024/03/04 07:51:57 - INFO - root -   train_accuracy = 0.8725
2024/03/04 07:52:16 - INFO - root -   Epoch: [172/300][0/200], lr: 0.00000053 	 loss = 0.7157(0.7157)
2024/03/04 07:52:24 - INFO - root -   Epoch: [172/300][20/200], lr: 0.00000053 	 loss = 0.0036(0.3627)
2024/03/04 07:52:32 - INFO - root -   Epoch: [172/300][40/200], lr: 0.00000053 	 loss = 0.1369(0.2989)
2024/03/04 07:52:49 - INFO - root -   Epoch: [172/300][60/200], lr: 0.00000053 	 loss = 0.0111(0.2856)
2024/03/04 07:53:00 - INFO - root -   Epoch: [172/300][80/200], lr: 0.00000053 	 loss = 0.3691(0.2990)
2024/03/04 07:53:17 - INFO - root -   Epoch: [172/300][100/200], lr: 0.00000053 	 loss = 0.0051(0.2843)
2024/03/04 07:53:28 - INFO - root -   Epoch: [172/300][120/200], lr: 0.00000053 	 loss = 0.9804(0.2913)
2024/03/04 07:53:45 - INFO - root -   Epoch: [172/300][140/200], lr: 0.00000053 	 loss = 0.6522(0.3004)
2024/03/04 07:53:55 - INFO - root -   Epoch: [172/300][160/200], lr: 0.00000053 	 loss = 0.5413(0.3038)
2024/03/04 07:54:03 - INFO - root -   Epoch: [172/300][180/200], lr: 0.00000053 	 loss = 0.2964(0.3087)
2024/03/04 07:54:10 - INFO - root -   Epoch: [172/300] 	 loss = 0.3032
2024/03/04 07:54:10 - INFO - root -   train_accuracy = 0.8875
2024/03/04 07:54:12 - INFO - root -   Epoch: [173/300][0/200], lr: 0.00000053 	 loss = 0.7219(0.7219)
2024/03/04 07:54:40 - INFO - root -   Epoch: [173/300][20/200], lr: 0.00000053 	 loss = 0.0138(0.4097)
2024/03/04 07:54:56 - INFO - root -   Epoch: [173/300][40/200], lr: 0.00000053 	 loss = 0.1767(0.3443)
2024/03/04 07:55:19 - INFO - root -   Epoch: [173/300][60/200], lr: 0.00000053 	 loss = 0.1748(0.3578)
2024/03/04 07:55:35 - INFO - root -   Epoch: [173/300][80/200], lr: 0.00000053 	 loss = 0.2987(0.3482)
2024/03/04 07:55:43 - INFO - root -   Epoch: [173/300][100/200], lr: 0.00000053 	 loss = 0.0802(0.3426)
2024/03/04 07:55:50 - INFO - root -   Epoch: [173/300][120/200], lr: 0.00000053 	 loss = 0.9986(0.3415)
2024/03/04 07:56:17 - INFO - root -   Epoch: [173/300][140/200], lr: 0.00000053 	 loss = 0.6337(0.3359)
2024/03/04 07:56:25 - INFO - root -   Epoch: [173/300][160/200], lr: 0.00000053 	 loss = 0.0266(0.3293)
2024/03/04 07:56:36 - INFO - root -   Epoch: [173/300][180/200], lr: 0.00000053 	 loss = 0.0084(0.3224)
2024/03/04 07:56:44 - INFO - root -   Epoch: [173/300] 	 loss = 0.3192
2024/03/04 07:56:44 - INFO - root -   train_accuracy = 0.8850
2024/03/04 07:56:45 - INFO - root -   Epoch: [174/300][0/200], lr: 0.00000053 	 loss = 0.1780(0.1780)
2024/03/04 07:57:13 - INFO - root -   Epoch: [174/300][20/200], lr: 0.00000053 	 loss = 0.1355(0.3250)
2024/03/04 07:57:41 - INFO - root -   Epoch: [174/300][40/200], lr: 0.00000053 	 loss = 0.1338(0.2891)
2024/03/04 07:57:49 - INFO - root -   Epoch: [174/300][60/200], lr: 0.00000053 	 loss = 0.0063(0.3272)
2024/03/04 07:58:21 - INFO - root -   Epoch: [174/300][80/200], lr: 0.00000053 	 loss = 0.4918(0.3689)
2024/03/04 07:58:35 - INFO - root -   Epoch: [174/300][100/200], lr: 0.00000053 	 loss = 0.0010(0.3697)
2024/03/04 07:58:43 - INFO - root -   Epoch: [174/300][120/200], lr: 0.00000053 	 loss = 0.6356(0.3384)
2024/03/04 07:58:51 - INFO - root -   Epoch: [174/300][140/200], lr: 0.00000053 	 loss = 1.4872(0.3632)
2024/03/04 07:59:09 - INFO - root -   Epoch: [174/300][160/200], lr: 0.00000053 	 loss = 0.2237(0.3536)
2024/03/04 07:59:17 - INFO - root -   Epoch: [174/300][180/200], lr: 0.00000053 	 loss = 1.9507(0.3452)
2024/03/04 07:59:26 - INFO - root -   Epoch: [174/300] 	 loss = 0.3406
2024/03/04 07:59:30 - INFO - root -   precision = 0.7111
2024/03/04 07:59:30 - INFO - root -   eval_loss = 1.7658
2024/03/04 07:59:30 - INFO - root -   eval_acc = 0.7111
2024/03/04 07:59:31 - INFO - root -   train_accuracy = 0.8900
2024/03/04 07:59:32 - INFO - root -   Epoch: [175/300][0/200], lr: 0.00000053 	 loss = 0.2211(0.2211)
2024/03/04 08:00:00 - INFO - root -   Epoch: [175/300][20/200], lr: 0.00000053 	 loss = 0.0311(0.4667)
2024/03/04 08:00:25 - INFO - root -   Epoch: [175/300][40/200], lr: 0.00000053 	 loss = 0.0078(0.3426)
2024/03/04 08:00:33 - INFO - root -   Epoch: [175/300][60/200], lr: 0.00000053 	 loss = 0.0913(0.3219)
2024/03/04 08:00:53 - INFO - root -   Epoch: [175/300][80/200], lr: 0.00000053 	 loss = 0.1711(0.3467)
2024/03/04 08:01:01 - INFO - root -   Epoch: [175/300][100/200], lr: 0.00000053 	 loss = 0.0006(0.3221)
2024/03/04 08:01:09 - INFO - root -   Epoch: [175/300][120/200], lr: 0.00000053 	 loss = 0.6219(0.2902)
2024/03/04 08:01:29 - INFO - root -   Epoch: [175/300][140/200], lr: 0.00000053 	 loss = 0.6020(0.2815)
2024/03/04 08:01:41 - INFO - root -   Epoch: [175/300][160/200], lr: 0.00000053 	 loss = 0.1958(0.2851)
2024/03/04 08:01:57 - INFO - root -   Epoch: [175/300][180/200], lr: 0.00000053 	 loss = 0.0060(0.2940)
2024/03/04 08:02:10 - INFO - root -   Epoch: [175/300] 	 loss = 0.3107
2024/03/04 08:02:10 - INFO - root -   train_accuracy = 0.8875
2024/03/04 08:02:23 - INFO - root -   Epoch: [176/300][0/200], lr: 0.00000054 	 loss = 1.1925(1.1925)
2024/03/04 08:02:45 - INFO - root -   Epoch: [176/300][20/200], lr: 0.00000054 	 loss = 0.0100(0.3889)
2024/03/04 08:02:53 - INFO - root -   Epoch: [176/300][40/200], lr: 0.00000054 	 loss = 0.1541(0.3496)
2024/03/04 08:03:11 - INFO - root -   Epoch: [176/300][60/200], lr: 0.00000054 	 loss = 0.0484(0.3161)
2024/03/04 08:03:31 - INFO - root -   Epoch: [176/300][80/200], lr: 0.00000054 	 loss = 0.5318(0.3257)
2024/03/04 08:03:39 - INFO - root -   Epoch: [176/300][100/200], lr: 0.00000054 	 loss = 0.0030(0.2951)
2024/03/04 08:03:55 - INFO - root -   Epoch: [176/300][120/200], lr: 0.00000054 	 loss = 2.7578(0.2932)
2024/03/04 08:04:11 - INFO - root -   Epoch: [176/300][140/200], lr: 0.00000054 	 loss = 0.3741(0.3064)
2024/03/04 08:04:27 - INFO - root -   Epoch: [176/300][160/200], lr: 0.00000054 	 loss = 0.2164(0.3132)
2024/03/04 08:04:35 - INFO - root -   Epoch: [176/300][180/200], lr: 0.00000054 	 loss = 0.0088(0.3067)
2024/03/04 08:04:42 - INFO - root -   Epoch: [176/300] 	 loss = 0.3054
2024/03/04 08:04:42 - INFO - root -   train_accuracy = 0.8950
2024/03/04 08:05:06 - INFO - root -   Epoch: [177/300][0/200], lr: 0.00000054 	 loss = 1.1747(1.1747)
2024/03/04 08:05:14 - INFO - root -   Epoch: [177/300][20/200], lr: 0.00000054 	 loss = 0.0157(0.3818)
2024/03/04 08:05:26 - INFO - root -   Epoch: [177/300][40/200], lr: 0.00000054 	 loss = 0.4013(0.3184)
2024/03/04 08:05:44 - INFO - root -   Epoch: [177/300][60/200], lr: 0.00000054 	 loss = 0.1643(0.2904)
2024/03/04 08:05:57 - INFO - root -   Epoch: [177/300][80/200], lr: 0.00000054 	 loss = 0.3399(0.3167)
2024/03/04 08:06:15 - INFO - root -   Epoch: [177/300][100/200], lr: 0.00000054 	 loss = 0.1736(0.3037)
2024/03/04 08:06:30 - INFO - root -   Epoch: [177/300][120/200], lr: 0.00000054 	 loss = 1.1183(0.2904)
2024/03/04 08:06:55 - INFO - root -   Epoch: [177/300][140/200], lr: 0.00000054 	 loss = 0.2084(0.3075)
2024/03/04 08:07:15 - INFO - root -   Epoch: [177/300][160/200], lr: 0.00000054 	 loss = 0.0568(0.3243)
2024/03/04 08:07:24 - INFO - root -   Epoch: [177/300][180/200], lr: 0.00000054 	 loss = 0.9570(0.3381)
2024/03/04 08:07:32 - INFO - root -   Epoch: [177/300] 	 loss = 0.3411
2024/03/04 08:07:32 - INFO - root -   train_accuracy = 0.8725
2024/03/04 08:07:54 - INFO - root -   Epoch: [178/300][0/200], lr: 0.00000054 	 loss = 0.8037(0.8037)
2024/03/04 08:08:02 - INFO - root -   Epoch: [178/300][20/200], lr: 0.00000054 	 loss = 0.0585(0.3934)
2024/03/04 08:08:11 - INFO - root -   Epoch: [178/300][40/200], lr: 0.00000054 	 loss = 0.5908(0.2908)
2024/03/04 08:08:23 - INFO - root -   Epoch: [178/300][60/200], lr: 0.00000054 	 loss = 0.0088(0.2831)
2024/03/04 08:08:39 - INFO - root -   Epoch: [178/300][80/200], lr: 0.00000054 	 loss = 0.7908(0.2838)
2024/03/04 08:08:50 - INFO - root -   Epoch: [178/300][100/200], lr: 0.00000054 	 loss = 0.0018(0.2663)
2024/03/04 08:09:07 - INFO - root -   Epoch: [178/300][120/200], lr: 0.00000054 	 loss = 0.6528(0.2571)
2024/03/04 08:09:22 - INFO - root -   Epoch: [178/300][140/200], lr: 0.00000054 	 loss = 0.7225(0.2561)
2024/03/04 08:09:42 - INFO - root -   Epoch: [178/300][160/200], lr: 0.00000054 	 loss = 0.0594(0.2571)
2024/03/04 08:09:57 - INFO - root -   Epoch: [178/300][180/200], lr: 0.00000054 	 loss = 0.0345(0.2576)
2024/03/04 08:10:04 - INFO - root -   Epoch: [178/300] 	 loss = 0.2608
2024/03/04 08:10:04 - INFO - root -   train_accuracy = 0.8975
2024/03/04 08:10:18 - INFO - root -   Epoch: [179/300][0/200], lr: 0.00000054 	 loss = 1.9025(1.9025)
2024/03/04 08:10:35 - INFO - root -   Epoch: [179/300][20/200], lr: 0.00000054 	 loss = 0.0506(0.6652)
2024/03/04 08:10:43 - INFO - root -   Epoch: [179/300][40/200], lr: 0.00000054 	 loss = 0.0134(0.4582)
2024/03/04 08:11:00 - INFO - root -   Epoch: [179/300][60/200], lr: 0.00000054 	 loss = 0.1222(0.4110)
2024/03/04 08:11:18 - INFO - root -   Epoch: [179/300][80/200], lr: 0.00000054 	 loss = 1.9012(0.3921)
2024/03/04 08:11:35 - INFO - root -   Epoch: [179/300][100/200], lr: 0.00000054 	 loss = 0.3060(0.3814)
2024/03/04 08:11:59 - INFO - root -   Epoch: [179/300][120/200], lr: 0.00000054 	 loss = 0.9003(0.3572)
2024/03/04 08:12:20 - INFO - root -   Epoch: [179/300][140/200], lr: 0.00000054 	 loss = 0.8087(0.3663)
2024/03/04 08:12:28 - INFO - root -   Epoch: [179/300][160/200], lr: 0.00000054 	 loss = 0.2313(0.3834)
2024/03/04 08:12:36 - INFO - root -   Epoch: [179/300][180/200], lr: 0.00000054 	 loss = 0.6795(0.3776)
2024/03/04 08:12:47 - INFO - root -   Epoch: [179/300] 	 loss = 0.3765
2024/03/04 08:12:51 - INFO - root -   precision = 0.6889
2024/03/04 08:12:51 - INFO - root -   eval_loss = 1.7720
2024/03/04 08:12:51 - INFO - root -   eval_acc = 0.6889
2024/03/04 08:12:52 - INFO - root -   train_accuracy = 0.8500
2024/03/04 08:13:14 - INFO - root -   Epoch: [180/300][0/200], lr: 0.00000055 	 loss = 0.8004(0.8004)
2024/03/04 08:13:22 - INFO - root -   Epoch: [180/300][20/200], lr: 0.00000055 	 loss = 0.0057(0.4114)
2024/03/04 08:13:39 - INFO - root -   Epoch: [180/300][40/200], lr: 0.00000055 	 loss = 0.5066(0.3395)
2024/03/04 08:13:53 - INFO - root -   Epoch: [180/300][60/200], lr: 0.00000055 	 loss = 0.0250(0.3151)
2024/03/04 08:14:01 - INFO - root -   Epoch: [180/300][80/200], lr: 0.00000055 	 loss = 0.8741(0.3123)
2024/03/04 08:14:09 - INFO - root -   Epoch: [180/300][100/200], lr: 0.00000055 	 loss = 0.0670(0.2918)
2024/03/04 08:14:36 - INFO - root -   Epoch: [180/300][120/200], lr: 0.00000055 	 loss = 0.5737(0.2862)
2024/03/04 08:14:45 - INFO - root -   Epoch: [180/300][140/200], lr: 0.00000055 	 loss = 0.1123(0.2975)
2024/03/04 08:15:13 - INFO - root -   Epoch: [180/300][160/200], lr: 0.00000055 	 loss = 0.3085(0.2941)
2024/03/04 08:15:21 - INFO - root -   Epoch: [180/300][180/200], lr: 0.00000055 	 loss = 0.0526(0.3133)
2024/03/04 08:15:29 - INFO - root -   Epoch: [180/300] 	 loss = 0.3087
2024/03/04 08:15:29 - INFO - root -   train_accuracy = 0.8850
2024/03/04 08:15:31 - INFO - root -   Epoch: [181/300][0/200], lr: 0.00000055 	 loss = 1.8170(1.8170)
2024/03/04 08:16:05 - INFO - root -   Epoch: [181/300][20/200], lr: 0.00000055 	 loss = 0.0014(0.5026)
2024/03/04 08:16:17 - INFO - root -   Epoch: [181/300][40/200], lr: 0.00000055 	 loss = 0.1386(0.4083)
2024/03/04 08:16:26 - INFO - root -   Epoch: [181/300][60/200], lr: 0.00000055 	 loss = 0.0035(0.3701)
2024/03/04 08:16:44 - INFO - root -   Epoch: [181/300][80/200], lr: 0.00000055 	 loss = 0.3091(0.3460)
2024/03/04 08:17:07 - INFO - root -   Epoch: [181/300][100/200], lr: 0.00000055 	 loss = 0.3437(0.3349)
2024/03/04 08:17:24 - INFO - root -   Epoch: [181/300][120/200], lr: 0.00000055 	 loss = 2.0014(0.3224)
2024/03/04 08:17:39 - INFO - root -   Epoch: [181/300][140/200], lr: 0.00000055 	 loss = 0.8206(0.3175)
2024/03/04 08:18:04 - INFO - root -   Epoch: [181/300][160/200], lr: 0.00000055 	 loss = 0.1704(0.3246)
2024/03/04 08:18:12 - INFO - root -   Epoch: [181/300][180/200], lr: 0.00000055 	 loss = 0.8596(0.3312)
2024/03/04 08:18:19 - INFO - root -   Epoch: [181/300] 	 loss = 0.3222
2024/03/04 08:18:19 - INFO - root -   train_accuracy = 0.8800
2024/03/04 08:18:21 - INFO - root -   Epoch: [182/300][0/200], lr: 0.00000055 	 loss = 0.3629(0.3629)
2024/03/04 08:18:43 - INFO - root -   Epoch: [182/300][20/200], lr: 0.00000055 	 loss = 0.1368(0.3074)
2024/03/04 08:18:57 - INFO - root -   Epoch: [182/300][40/200], lr: 0.00000055 	 loss = 0.0914(0.3048)
2024/03/04 08:19:08 - INFO - root -   Epoch: [182/300][60/200], lr: 0.00000055 	 loss = 0.0105(0.3192)
2024/03/04 08:19:31 - INFO - root -   Epoch: [182/300][80/200], lr: 0.00000055 	 loss = 1.2503(0.3204)
2024/03/04 08:19:39 - INFO - root -   Epoch: [182/300][100/200], lr: 0.00000055 	 loss = 0.0017(0.3082)
2024/03/04 08:20:00 - INFO - root -   Epoch: [182/300][120/200], lr: 0.00000055 	 loss = 0.9147(0.3040)
2024/03/04 08:20:13 - INFO - root -   Epoch: [182/300][140/200], lr: 0.00000055 	 loss = 0.2964(0.3267)
2024/03/04 08:20:32 - INFO - root -   Epoch: [182/300][160/200], lr: 0.00000055 	 loss = 0.0300(0.3375)
2024/03/04 08:20:44 - INFO - root -   Epoch: [182/300][180/200], lr: 0.00000055 	 loss = 0.4395(0.3390)
2024/03/04 08:20:56 - INFO - root -   Epoch: [182/300] 	 loss = 0.3407
2024/03/04 08:20:56 - INFO - root -   train_accuracy = 0.8925
2024/03/04 08:21:11 - INFO - root -   Epoch: [183/300][0/200], lr: 0.00000055 	 loss = 0.7283(0.7283)
2024/03/04 08:21:28 - INFO - root -   Epoch: [183/300][20/200], lr: 0.00000055 	 loss = 0.3121(0.3903)
2024/03/04 08:21:45 - INFO - root -   Epoch: [183/300][40/200], lr: 0.00000055 	 loss = 0.0238(0.3544)
2024/03/04 08:22:04 - INFO - root -   Epoch: [183/300][60/200], lr: 0.00000055 	 loss = 0.1055(0.3513)
2024/03/04 08:22:18 - INFO - root -   Epoch: [183/300][80/200], lr: 0.00000055 	 loss = 0.7444(0.3613)
2024/03/04 08:22:29 - INFO - root -   Epoch: [183/300][100/200], lr: 0.00000055 	 loss = 0.2534(0.3541)
2024/03/04 08:22:52 - INFO - root -   Epoch: [183/300][120/200], lr: 0.00000055 	 loss = 0.9526(0.3524)
2024/03/04 08:23:02 - INFO - root -   Epoch: [183/300][140/200], lr: 0.00000055 	 loss = 0.2830(0.3406)
2024/03/04 08:23:20 - INFO - root -   Epoch: [183/300][160/200], lr: 0.00000055 	 loss = 0.0666(0.3318)
2024/03/04 08:23:36 - INFO - root -   Epoch: [183/300][180/200], lr: 0.00000055 	 loss = 0.2123(0.3442)
2024/03/04 08:23:44 - INFO - root -   Epoch: [183/300] 	 loss = 0.3380
2024/03/04 08:23:44 - INFO - root -   train_accuracy = 0.8775
2024/03/04 08:23:45 - INFO - root -   Epoch: [184/300][0/200], lr: 0.00000056 	 loss = 0.1762(0.1762)
2024/03/04 08:24:10 - INFO - root -   Epoch: [184/300][20/200], lr: 0.00000056 	 loss = 0.0069(0.4207)
2024/03/04 08:24:31 - INFO - root -   Epoch: [184/300][40/200], lr: 0.00000056 	 loss = 0.1919(0.3238)
2024/03/04 08:24:40 - INFO - root -   Epoch: [184/300][60/200], lr: 0.00000056 	 loss = 0.1628(0.3389)
2024/03/04 08:25:03 - INFO - root -   Epoch: [184/300][80/200], lr: 0.00000056 	 loss = 0.3487(0.3251)
2024/03/04 08:25:12 - INFO - root -   Epoch: [184/300][100/200], lr: 0.00000056 	 loss = 0.0071(0.3190)
2024/03/04 08:25:23 - INFO - root -   Epoch: [184/300][120/200], lr: 0.00000056 	 loss = 1.3816(0.3205)
2024/03/04 08:25:48 - INFO - root -   Epoch: [184/300][140/200], lr: 0.00000056 	 loss = 0.4532(0.3565)
2024/03/04 08:26:04 - INFO - root -   Epoch: [184/300][160/200], lr: 0.00000056 	 loss = 0.1038(0.3540)
2024/03/04 08:26:12 - INFO - root -   Epoch: [184/300][180/200], lr: 0.00000056 	 loss = 0.3524(0.3518)
2024/03/04 08:26:20 - INFO - root -   Epoch: [184/300] 	 loss = 0.3420
2024/03/04 08:26:24 - INFO - root -   precision = 0.6889
2024/03/04 08:26:24 - INFO - root -   eval_loss = 1.8164
2024/03/04 08:26:24 - INFO - root -   eval_acc = 0.6889
2024/03/04 08:26:25 - INFO - root -   train_accuracy = 0.8750
2024/03/04 08:26:41 - INFO - root -   Epoch: [185/300][0/200], lr: 0.00000056 	 loss = 0.4715(0.4715)
2024/03/04 08:27:01 - INFO - root -   Epoch: [185/300][20/200], lr: 0.00000056 	 loss = 0.0212(0.5016)
2024/03/04 08:27:10 - INFO - root -   Epoch: [185/300][40/200], lr: 0.00000056 	 loss = 0.1604(0.3725)
2024/03/04 08:27:22 - INFO - root -   Epoch: [185/300][60/200], lr: 0.00000056 	 loss = 0.0356(0.3199)
2024/03/04 08:27:34 - INFO - root -   Epoch: [185/300][80/200], lr: 0.00000056 	 loss = 1.2067(0.3456)
2024/03/04 08:27:44 - INFO - root -   Epoch: [185/300][100/200], lr: 0.00000056 	 loss = 0.3107(0.3478)
2024/03/04 08:28:00 - INFO - root -   Epoch: [185/300][120/200], lr: 0.00000056 	 loss = 2.6531(0.3359)
2024/03/04 08:28:13 - INFO - root -   Epoch: [185/300][140/200], lr: 0.00000056 	 loss = 2.3681(0.3420)
2024/03/04 08:28:21 - INFO - root -   Epoch: [185/300][160/200], lr: 0.00000056 	 loss = 0.1186(0.3275)
2024/03/04 08:28:40 - INFO - root -   Epoch: [185/300][180/200], lr: 0.00000056 	 loss = 0.2180(0.3292)
2024/03/04 08:28:48 - INFO - root -   Epoch: [185/300] 	 loss = 0.3179
2024/03/04 08:28:48 - INFO - root -   train_accuracy = 0.8850
2024/03/04 08:29:02 - INFO - root -   Epoch: [186/300][0/200], lr: 0.00000056 	 loss = 0.3842(0.3842)
2024/03/04 08:29:18 - INFO - root -   Epoch: [186/300][20/200], lr: 0.00000056 	 loss = 0.1191(0.4110)
2024/03/04 08:29:26 - INFO - root -   Epoch: [186/300][40/200], lr: 0.00000056 	 loss = 0.0100(0.2617)
2024/03/04 08:29:55 - INFO - root -   Epoch: [186/300][60/200], lr: 0.00000056 	 loss = 0.0035(0.2939)
2024/03/04 08:30:13 - INFO - root -   Epoch: [186/300][80/200], lr: 0.00000056 	 loss = 0.9399(0.3153)
2024/03/04 08:30:25 - INFO - root -   Epoch: [186/300][100/200], lr: 0.00000056 	 loss = 0.0530(0.3033)
2024/03/04 08:30:33 - INFO - root -   Epoch: [186/300][120/200], lr: 0.00000056 	 loss = 0.9823(0.2925)
2024/03/04 08:30:47 - INFO - root -   Epoch: [186/300][140/200], lr: 0.00000056 	 loss = 1.7375(0.3033)
2024/03/04 08:30:58 - INFO - root -   Epoch: [186/300][160/200], lr: 0.00000056 	 loss = 0.0230(0.3162)
2024/03/04 08:31:16 - INFO - root -   Epoch: [186/300][180/200], lr: 0.00000056 	 loss = 0.2573(0.3236)
2024/03/04 08:31:24 - INFO - root -   Epoch: [186/300] 	 loss = 0.3187
2024/03/04 08:31:24 - INFO - root -   train_accuracy = 0.8775
2024/03/04 08:31:25 - INFO - root -   Epoch: [187/300][0/200], lr: 0.00000056 	 loss = 0.1140(0.1140)
2024/03/04 08:31:47 - INFO - root -   Epoch: [187/300][20/200], lr: 0.00000056 	 loss = 0.1932(0.3257)
2024/03/04 08:32:01 - INFO - root -   Epoch: [187/300][40/200], lr: 0.00000056 	 loss = 0.0108(0.2835)
2024/03/04 08:32:09 - INFO - root -   Epoch: [187/300][60/200], lr: 0.00000056 	 loss = 0.0584(0.2781)
2024/03/04 08:32:32 - INFO - root -   Epoch: [187/300][80/200], lr: 0.00000056 	 loss = 0.8093(0.2834)
2024/03/04 08:32:48 - INFO - root -   Epoch: [187/300][100/200], lr: 0.00000056 	 loss = 0.0458(0.2839)
2024/03/04 08:33:08 - INFO - root -   Epoch: [187/300][120/200], lr: 0.00000056 	 loss = 1.6247(0.2802)
2024/03/04 08:33:26 - INFO - root -   Epoch: [187/300][140/200], lr: 0.00000056 	 loss = 0.5993(0.2898)
2024/03/04 08:33:35 - INFO - root -   Epoch: [187/300][160/200], lr: 0.00000056 	 loss = 0.0242(0.3013)
2024/03/04 08:33:50 - INFO - root -   Epoch: [187/300][180/200], lr: 0.00000056 	 loss = 1.2069(0.3101)
2024/03/04 08:33:57 - INFO - root -   Epoch: [187/300] 	 loss = 0.3058
2024/03/04 08:33:57 - INFO - root -   train_accuracy = 0.8800
2024/03/04 08:33:59 - INFO - root -   Epoch: [188/300][0/200], lr: 0.00000057 	 loss = 0.3244(0.3244)
2024/03/04 08:34:45 - INFO - root -   Epoch: [188/300][20/200], lr: 0.00000057 	 loss = 0.0092(0.4109)
2024/03/04 08:34:53 - INFO - root -   Epoch: [188/300][40/200], lr: 0.00000057 	 loss = 0.0023(0.3089)
2024/03/04 08:35:01 - INFO - root -   Epoch: [188/300][60/200], lr: 0.00000057 	 loss = 0.0844(0.2992)
2024/03/04 08:35:21 - INFO - root -   Epoch: [188/300][80/200], lr: 0.00000057 	 loss = 1.0068(0.3229)
2024/03/04 08:35:43 - INFO - root -   Epoch: [188/300][100/200], lr: 0.00000057 	 loss = 0.0651(0.3220)
2024/03/04 08:35:51 - INFO - root -   Epoch: [188/300][120/200], lr: 0.00000057 	 loss = 0.9513(0.3047)
2024/03/04 08:36:14 - INFO - root -   Epoch: [188/300][140/200], lr: 0.00000057 	 loss = 0.8633(0.3070)
2024/03/04 08:36:24 - INFO - root -   Epoch: [188/300][160/200], lr: 0.00000057 	 loss = 0.2394(0.3252)
2024/03/04 08:36:41 - INFO - root -   Epoch: [188/300][180/200], lr: 0.00000057 	 loss = 1.0157(0.3231)
2024/03/04 08:36:49 - INFO - root -   Epoch: [188/300] 	 loss = 0.3176
2024/03/04 08:36:49 - INFO - root -   train_accuracy = 0.8750
2024/03/04 08:37:02 - INFO - root -   Epoch: [189/300][0/200], lr: 0.00000057 	 loss = 0.7767(0.7767)
2024/03/04 08:37:24 - INFO - root -   Epoch: [189/300][20/200], lr: 0.00000057 	 loss = 0.0017(0.3663)
2024/03/04 08:37:41 - INFO - root -   Epoch: [189/300][40/200], lr: 0.00000057 	 loss = 0.0469(0.3678)
2024/03/04 08:37:49 - INFO - root -   Epoch: [189/300][60/200], lr: 0.00000057 	 loss = 0.1153(0.3748)
2024/03/04 08:38:04 - INFO - root -   Epoch: [189/300][80/200], lr: 0.00000057 	 loss = 0.1780(0.3610)
2024/03/04 08:38:21 - INFO - root -   Epoch: [189/300][100/200], lr: 0.00000057 	 loss = 0.0013(0.3476)
2024/03/04 08:38:31 - INFO - root -   Epoch: [189/300][120/200], lr: 0.00000057 	 loss = 1.3514(0.3602)
2024/03/04 08:38:44 - INFO - root -   Epoch: [189/300][140/200], lr: 0.00000057 	 loss = 2.1747(0.3628)
2024/03/04 08:39:12 - INFO - root -   Epoch: [189/300][160/200], lr: 0.00000057 	 loss = 0.6324(0.3770)
2024/03/04 08:39:26 - INFO - root -   Epoch: [189/300][180/200], lr: 0.00000057 	 loss = 0.0048(0.3712)
2024/03/04 08:39:34 - INFO - root -   Epoch: [189/300] 	 loss = 0.3706
2024/03/04 08:39:37 - INFO - root -   precision = 0.7111
2024/03/04 08:39:37 - INFO - root -   eval_loss = 1.7210
2024/03/04 08:39:37 - INFO - root -   eval_acc = 0.7111
2024/03/04 08:39:38 - INFO - root -   train_accuracy = 0.8625
2024/03/04 08:39:39 - INFO - root -   Epoch: [190/300][0/200], lr: 0.00000057 	 loss = 0.6375(0.6375)
2024/03/04 08:40:12 - INFO - root -   Epoch: [190/300][20/200], lr: 0.00000057 	 loss = 0.0621(0.3166)
2024/03/04 08:40:20 - INFO - root -   Epoch: [190/300][40/200], lr: 0.00000057 	 loss = 0.2301(0.2763)
2024/03/04 08:40:38 - INFO - root -   Epoch: [190/300][60/200], lr: 0.00000057 	 loss = 0.0571(0.2373)
2024/03/04 08:40:47 - INFO - root -   Epoch: [190/300][80/200], lr: 0.00000057 	 loss = 0.3240(0.2520)
2024/03/04 08:41:09 - INFO - root -   Epoch: [190/300][100/200], lr: 0.00000057 	 loss = 0.0004(0.2425)
2024/03/04 08:41:25 - INFO - root -   Epoch: [190/300][120/200], lr: 0.00000057 	 loss = 0.6810(0.2446)
2024/03/04 08:41:34 - INFO - root -   Epoch: [190/300][140/200], lr: 0.00000057 	 loss = 0.1042(0.2538)
2024/03/04 08:41:51 - INFO - root -   Epoch: [190/300][160/200], lr: 0.00000057 	 loss = 0.0153(0.2537)
2024/03/04 08:42:02 - INFO - root -   Epoch: [190/300][180/200], lr: 0.00000057 	 loss = 0.0062(0.2696)
2024/03/04 08:42:10 - INFO - root -   Epoch: [190/300] 	 loss = 0.2847
2024/03/04 08:42:10 - INFO - root -   train_accuracy = 0.9000
2024/03/04 08:42:11 - INFO - root -   Epoch: [191/300][0/200], lr: 0.00000057 	 loss = 0.4498(0.4498)
2024/03/04 08:42:46 - INFO - root -   Epoch: [191/300][20/200], lr: 0.00000057 	 loss = 0.0101(0.3777)
2024/03/04 08:42:58 - INFO - root -   Epoch: [191/300][40/200], lr: 0.00000057 	 loss = 0.0158(0.3131)
2024/03/04 08:43:07 - INFO - root -   Epoch: [191/300][60/200], lr: 0.00000057 	 loss = 0.0026(0.3227)
2024/03/04 08:43:21 - INFO - root -   Epoch: [191/300][80/200], lr: 0.00000057 	 loss = 0.1119(0.3403)
2024/03/04 08:43:48 - INFO - root -   Epoch: [191/300][100/200], lr: 0.00000057 	 loss = 0.0009(0.3325)
2024/03/04 08:44:00 - INFO - root -   Epoch: [191/300][120/200], lr: 0.00000057 	 loss = 1.0878(0.3184)
2024/03/04 08:44:08 - INFO - root -   Epoch: [191/300][140/200], lr: 0.00000057 	 loss = 0.0915(0.3073)
2024/03/04 08:44:29 - INFO - root -   Epoch: [191/300][160/200], lr: 0.00000057 	 loss = 0.0904(0.3149)
2024/03/04 08:44:45 - INFO - root -   Epoch: [191/300][180/200], lr: 0.00000057 	 loss = 0.2440(0.3198)
2024/03/04 08:44:52 - INFO - root -   Epoch: [191/300] 	 loss = 0.3351
2024/03/04 08:44:52 - INFO - root -   train_accuracy = 0.8700
2024/03/04 08:45:04 - INFO - root -   Epoch: [192/300][0/200], lr: 0.00000058 	 loss = 0.3789(0.3789)
2024/03/04 08:45:29 - INFO - root -   Epoch: [192/300][20/200], lr: 0.00000058 	 loss = 0.4667(0.3875)
2024/03/04 08:45:37 - INFO - root -   Epoch: [192/300][40/200], lr: 0.00000058 	 loss = 0.2270(0.3323)
2024/03/04 08:45:56 - INFO - root -   Epoch: [192/300][60/200], lr: 0.00000058 	 loss = 0.1430(0.3646)
2024/03/04 08:46:05 - INFO - root -   Epoch: [192/300][80/200], lr: 0.00000058 	 loss = 1.7171(0.3445)
2024/03/04 08:46:15 - INFO - root -   Epoch: [192/300][100/200], lr: 0.00000058 	 loss = 0.0026(0.3236)
2024/03/04 08:46:25 - INFO - root -   Epoch: [192/300][120/200], lr: 0.00000058 	 loss = 0.8837(0.3040)
2024/03/04 08:46:40 - INFO - root -   Epoch: [192/300][140/200], lr: 0.00000058 	 loss = 0.2220(0.3071)
2024/03/04 08:46:53 - INFO - root -   Epoch: [192/300][160/200], lr: 0.00000058 	 loss = 0.0265(0.3184)
2024/03/04 08:47:00 - INFO - root -   Epoch: [192/300][180/200], lr: 0.00000058 	 loss = 0.0041(0.3104)
2024/03/04 08:47:08 - INFO - root -   Epoch: [192/300] 	 loss = 0.3051
2024/03/04 08:47:08 - INFO - root -   train_accuracy = 0.8800
2024/03/04 08:47:24 - INFO - root -   Epoch: [193/300][0/200], lr: 0.00000058 	 loss = 0.1457(0.1457)
2024/03/04 08:47:44 - INFO - root -   Epoch: [193/300][20/200], lr: 0.00000058 	 loss = 0.0010(0.3975)
2024/03/04 08:47:55 - INFO - root -   Epoch: [193/300][40/200], lr: 0.00000058 	 loss = 0.0442(0.3365)
2024/03/04 08:48:07 - INFO - root -   Epoch: [193/300][60/200], lr: 0.00000058 	 loss = 0.0494(0.3046)
2024/03/04 08:48:28 - INFO - root -   Epoch: [193/300][80/200], lr: 0.00000058 	 loss = 1.8078(0.3217)
2024/03/04 08:48:44 - INFO - root -   Epoch: [193/300][100/200], lr: 0.00000058 	 loss = 0.0682(0.2979)
2024/03/04 08:49:00 - INFO - root -   Epoch: [193/300][120/200], lr: 0.00000058 	 loss = 0.9852(0.3106)
2024/03/04 08:49:19 - INFO - root -   Epoch: [193/300][140/200], lr: 0.00000058 	 loss = 0.6668(0.3297)
2024/03/04 08:49:37 - INFO - root -   Epoch: [193/300][160/200], lr: 0.00000058 	 loss = 0.0237(0.3154)
2024/03/04 08:49:52 - INFO - root -   Epoch: [193/300][180/200], lr: 0.00000058 	 loss = 0.0769(0.3299)
2024/03/04 08:50:00 - INFO - root -   Epoch: [193/300] 	 loss = 0.3243
2024/03/04 08:50:00 - INFO - root -   train_accuracy = 0.8825
2024/03/04 08:50:01 - INFO - root -   Epoch: [194/300][0/200], lr: 0.00000058 	 loss = 0.2132(0.2132)
2024/03/04 08:50:29 - INFO - root -   Epoch: [194/300][20/200], lr: 0.00000058 	 loss = 0.1688(0.4832)
2024/03/04 08:50:49 - INFO - root -   Epoch: [194/300][40/200], lr: 0.00000058 	 loss = 0.0651(0.3865)
2024/03/04 08:51:00 - INFO - root -   Epoch: [194/300][60/200], lr: 0.00000058 	 loss = 0.1675(0.3618)
2024/03/04 08:51:21 - INFO - root -   Epoch: [194/300][80/200], lr: 0.00000058 	 loss = 1.1015(0.3486)
2024/03/04 08:51:40 - INFO - root -   Epoch: [194/300][100/200], lr: 0.00000058 	 loss = 0.1587(0.3380)
2024/03/04 08:51:57 - INFO - root -   Epoch: [194/300][120/200], lr: 0.00000058 	 loss = 1.2764(0.3284)
2024/03/04 08:52:07 - INFO - root -   Epoch: [194/300][140/200], lr: 0.00000058 	 loss = 0.4627(0.3312)
2024/03/04 08:52:27 - INFO - root -   Epoch: [194/300][160/200], lr: 0.00000058 	 loss = 0.1902(0.3305)
2024/03/04 08:52:41 - INFO - root -   Epoch: [194/300][180/200], lr: 0.00000058 	 loss = 0.1180(0.3499)
2024/03/04 08:52:49 - INFO - root -   Epoch: [194/300] 	 loss = 0.3458
2024/03/04 08:52:52 - INFO - root -   precision = 0.6889
2024/03/04 08:52:52 - INFO - root -   eval_loss = 1.8963
2024/03/04 08:52:52 - INFO - root -   eval_acc = 0.6889
2024/03/04 08:52:53 - INFO - root -   train_accuracy = 0.8675
2024/03/04 08:53:15 - INFO - root -   Epoch: [195/300][0/200], lr: 0.00000058 	 loss = 1.3481(1.3481)
2024/03/04 08:53:29 - INFO - root -   Epoch: [195/300][20/200], lr: 0.00000058 	 loss = 0.0042(0.4537)
2024/03/04 08:53:37 - INFO - root -   Epoch: [195/300][40/200], lr: 0.00000058 	 loss = 0.0165(0.3214)
2024/03/04 08:53:59 - INFO - root -   Epoch: [195/300][60/200], lr: 0.00000058 	 loss = 0.0024(0.2925)
2024/03/04 08:54:07 - INFO - root -   Epoch: [195/300][80/200], lr: 0.00000058 	 loss = 1.5443(0.3106)
2024/03/04 08:54:27 - INFO - root -   Epoch: [195/300][100/200], lr: 0.00000058 	 loss = 0.0042(0.2955)
2024/03/04 08:54:44 - INFO - root -   Epoch: [195/300][120/200], lr: 0.00000058 	 loss = 0.8390(0.2781)
2024/03/04 08:54:54 - INFO - root -   Epoch: [195/300][140/200], lr: 0.00000058 	 loss = 1.2355(0.2861)
2024/03/04 08:55:18 - INFO - root -   Epoch: [195/300][160/200], lr: 0.00000058 	 loss = 0.5393(0.2867)
2024/03/04 08:55:27 - INFO - root -   Epoch: [195/300][180/200], lr: 0.00000058 	 loss = 0.0294(0.2865)
2024/03/04 08:55:34 - INFO - root -   Epoch: [195/300] 	 loss = 0.2887
2024/03/04 08:55:34 - INFO - root -   train_accuracy = 0.8900
2024/03/04 08:55:53 - INFO - root -   Epoch: [196/300][0/200], lr: 0.00000059 	 loss = 0.8990(0.8990)
2024/03/04 08:56:08 - INFO - root -   Epoch: [196/300][20/200], lr: 0.00000059 	 loss = 0.0010(0.4980)
2024/03/04 08:56:25 - INFO - root -   Epoch: [196/300][40/200], lr: 0.00000059 	 loss = 0.2616(0.3736)
2024/03/04 08:56:38 - INFO - root -   Epoch: [196/300][60/200], lr: 0.00000059 	 loss = 0.1599(0.3339)
2024/03/04 08:56:55 - INFO - root -   Epoch: [196/300][80/200], lr: 0.00000059 	 loss = 1.0413(0.3523)
2024/03/04 08:57:09 - INFO - root -   Epoch: [196/300][100/200], lr: 0.00000059 	 loss = 0.0016(0.3224)
2024/03/04 08:57:19 - INFO - root -   Epoch: [196/300][120/200], lr: 0.00000059 	 loss = 1.6408(0.3073)
2024/03/04 08:57:48 - INFO - root -   Epoch: [196/300][140/200], lr: 0.00000059 	 loss = 0.1508(0.3079)
2024/03/04 08:58:09 - INFO - root -   Epoch: [196/300][160/200], lr: 0.00000059 	 loss = 0.1677(0.3142)
2024/03/04 08:58:20 - INFO - root -   Epoch: [196/300][180/200], lr: 0.00000059 	 loss = 0.0590(0.3182)
2024/03/04 08:58:30 - INFO - root -   Epoch: [196/300] 	 loss = 0.3408
2024/03/04 08:58:30 - INFO - root -   train_accuracy = 0.8775
2024/03/04 08:58:54 - INFO - root -   Epoch: [197/300][0/200], lr: 0.00000059 	 loss = 0.9364(0.9364)
2024/03/04 08:59:02 - INFO - root -   Epoch: [197/300][20/200], lr: 0.00000059 	 loss = 0.2725(0.4247)
2024/03/04 08:59:16 - INFO - root -   Epoch: [197/300][40/200], lr: 0.00000059 	 loss = 0.0817(0.2888)
2024/03/04 08:59:40 - INFO - root -   Epoch: [197/300][60/200], lr: 0.00000059 	 loss = 0.0013(0.3150)
2024/03/04 09:00:03 - INFO - root -   Epoch: [197/300][80/200], lr: 0.00000059 	 loss = 1.1424(0.3581)
2024/03/04 09:00:11 - INFO - root -   Epoch: [197/300][100/200], lr: 0.00000059 	 loss = 0.1538(0.3585)
2024/03/04 09:00:42 - INFO - root -   Epoch: [197/300][120/200], lr: 0.00000059 	 loss = 1.4945(0.3338)
2024/03/04 09:00:54 - INFO - root -   Epoch: [197/300][140/200], lr: 0.00000059 	 loss = 0.9891(0.3350)
2024/03/04 09:01:22 - INFO - root -   Epoch: [197/300][160/200], lr: 0.00000059 	 loss = 0.1520(0.3369)
2024/03/04 09:01:30 - INFO - root -   Epoch: [197/300][180/200], lr: 0.00000059 	 loss = 0.1338(0.3432)
2024/03/04 09:01:38 - INFO - root -   Epoch: [197/300] 	 loss = 0.3482
2024/03/04 09:01:38 - INFO - root -   train_accuracy = 0.8800
2024/03/04 09:01:51 - INFO - root -   Epoch: [198/300][0/200], lr: 0.00000059 	 loss = 0.6320(0.6320)
2024/03/04 09:02:19 - INFO - root -   Epoch: [198/300][20/200], lr: 0.00000059 	 loss = 0.0758(0.5217)
2024/03/04 09:02:36 - INFO - root -   Epoch: [198/300][40/200], lr: 0.00000059 	 loss = 0.0041(0.3868)
2024/03/04 09:02:44 - INFO - root -   Epoch: [198/300][60/200], lr: 0.00000059 	 loss = 0.2496(0.3634)
2024/03/04 09:03:01 - INFO - root -   Epoch: [198/300][80/200], lr: 0.00000059 	 loss = 0.2118(0.3167)
2024/03/04 09:03:11 - INFO - root -   Epoch: [198/300][100/200], lr: 0.00000059 	 loss = 0.0028(0.2929)
2024/03/04 09:03:29 - INFO - root -   Epoch: [198/300][120/200], lr: 0.00000059 	 loss = 0.8841(0.2899)
2024/03/04 09:03:44 - INFO - root -   Epoch: [198/300][140/200], lr: 0.00000059 	 loss = 1.6216(0.3272)
2024/03/04 09:03:54 - INFO - root -   Epoch: [198/300][160/200], lr: 0.00000059 	 loss = 0.0523(0.3112)
2024/03/04 09:04:02 - INFO - root -   Epoch: [198/300][180/200], lr: 0.00000059 	 loss = 0.0730(0.3119)
2024/03/04 09:04:10 - INFO - root -   Epoch: [198/300] 	 loss = 0.3060
2024/03/04 09:04:10 - INFO - root -   train_accuracy = 0.8950
2024/03/04 09:04:12 - INFO - root -   Epoch: [199/300][0/200], lr: 0.00000059 	 loss = 0.3225(0.3225)
2024/03/04 09:04:42 - INFO - root -   Epoch: [199/300][20/200], lr: 0.00000059 	 loss = 0.0764(0.5638)
2024/03/04 09:04:50 - INFO - root -   Epoch: [199/300][40/200], lr: 0.00000059 	 loss = 0.8731(0.4063)
2024/03/04 09:05:18 - INFO - root -   Epoch: [199/300][60/200], lr: 0.00000059 	 loss = 0.0025(0.4178)
2024/03/04 09:05:30 - INFO - root -   Epoch: [199/300][80/200], lr: 0.00000059 	 loss = 0.1180(0.3845)
2024/03/04 09:05:58 - INFO - root -   Epoch: [199/300][100/200], lr: 0.00000059 	 loss = 0.0245(0.3718)
2024/03/04 09:06:12 - INFO - root -   Epoch: [199/300][120/200], lr: 0.00000059 	 loss = 2.5394(0.3506)
2024/03/04 09:06:28 - INFO - root -   Epoch: [199/300][140/200], lr: 0.00000059 	 loss = 0.6053(0.3489)
2024/03/04 09:06:40 - INFO - root -   Epoch: [199/300][160/200], lr: 0.00000059 	 loss = 0.0049(0.3538)
2024/03/04 09:07:07 - INFO - root -   Epoch: [199/300][180/200], lr: 0.00000059 	 loss = 0.0036(0.3559)
2024/03/04 09:07:14 - INFO - root -   Epoch: [199/300] 	 loss = 0.3583
2024/03/04 09:07:18 - INFO - root -   precision = 0.6889
2024/03/04 09:07:18 - INFO - root -   eval_loss = 1.8928
2024/03/04 09:07:18 - INFO - root -   eval_acc = 0.6889
2024/03/04 09:07:19 - INFO - root -   train_accuracy = 0.8700
2024/03/04 09:07:35 - INFO - root -   Epoch: [200/300][0/200], lr: 0.00000060 	 loss = 0.2183(0.2183)
2024/03/04 09:07:57 - INFO - root -   Epoch: [200/300][20/200], lr: 0.00000060 	 loss = 0.1287(0.3567)
2024/03/04 09:08:11 - INFO - root -   Epoch: [200/300][40/200], lr: 0.00000060 	 loss = 0.3024(0.2448)
2024/03/04 09:08:31 - INFO - root -   Epoch: [200/300][60/200], lr: 0.00000060 	 loss = 0.0016(0.2383)
2024/03/04 09:08:49 - INFO - root -   Epoch: [200/300][80/200], lr: 0.00000060 	 loss = 0.4853(0.2582)
2024/03/04 09:08:59 - INFO - root -   Epoch: [200/300][100/200], lr: 0.00000060 	 loss = 0.0327(0.2418)
2024/03/04 09:09:08 - INFO - root -   Epoch: [200/300][120/200], lr: 0.00000060 	 loss = 1.0253(0.2271)
2024/03/04 09:09:28 - INFO - root -   Epoch: [200/300][140/200], lr: 0.00000060 	 loss = 2.3401(0.2527)
2024/03/04 09:09:39 - INFO - root -   Epoch: [200/300][160/200], lr: 0.00000060 	 loss = 0.0186(0.2458)
2024/03/04 09:09:53 - INFO - root -   Epoch: [200/300][180/200], lr: 0.00000060 	 loss = 0.0030(0.2619)
2024/03/04 09:10:01 - INFO - root -   Epoch: [200/300] 	 loss = 0.2619
2024/03/04 09:10:01 - INFO - root -   train_accuracy = 0.8825
2024/03/04 09:10:03 - INFO - root -   Epoch: [201/300][0/200], lr: 0.00000060 	 loss = 0.6503(0.6503)
2024/03/04 09:10:31 - INFO - root -   Epoch: [201/300][20/200], lr: 0.00000060 	 loss = 0.0029(0.4330)
2024/03/04 09:10:47 - INFO - root -   Epoch: [201/300][40/200], lr: 0.00000060 	 loss = 0.0067(0.3244)
2024/03/04 09:11:08 - INFO - root -   Epoch: [201/300][60/200], lr: 0.00000060 	 loss = 0.0322(0.3275)
2024/03/04 09:11:26 - INFO - root -   Epoch: [201/300][80/200], lr: 0.00000060 	 loss = 0.3008(0.3395)
2024/03/04 09:11:38 - INFO - root -   Epoch: [201/300][100/200], lr: 0.00000060 	 loss = 0.0706(0.3634)
2024/03/04 09:12:00 - INFO - root -   Epoch: [201/300][120/200], lr: 0.00000060 	 loss = 2.2476(0.3731)
2024/03/04 09:12:20 - INFO - root -   Epoch: [201/300][140/200], lr: 0.00000060 	 loss = 1.3498(0.3844)
2024/03/04 09:12:28 - INFO - root -   Epoch: [201/300][160/200], lr: 0.00000060 	 loss = 0.2664(0.3715)
2024/03/04 09:12:45 - INFO - root -   Epoch: [201/300][180/200], lr: 0.00000060 	 loss = 0.3893(0.3614)
2024/03/04 09:12:53 - INFO - root -   Epoch: [201/300] 	 loss = 0.3547
2024/03/04 09:12:53 - INFO - root -   train_accuracy = 0.8775
2024/03/04 09:13:07 - INFO - root -   Epoch: [202/300][0/200], lr: 0.00000060 	 loss = 0.9130(0.9130)
2024/03/04 09:13:26 - INFO - root -   Epoch: [202/300][20/200], lr: 0.00000060 	 loss = 0.6866(0.4783)
2024/03/04 09:13:38 - INFO - root -   Epoch: [202/300][40/200], lr: 0.00000060 	 loss = 0.0870(0.3390)
2024/03/04 09:13:50 - INFO - root -   Epoch: [202/300][60/200], lr: 0.00000060 	 loss = 0.0032(0.3387)
2024/03/04 09:14:02 - INFO - root -   Epoch: [202/300][80/200], lr: 0.00000060 	 loss = 0.3089(0.3548)
2024/03/04 09:14:18 - INFO - root -   Epoch: [202/300][100/200], lr: 0.00000060 	 loss = 0.1012(0.3318)
2024/03/04 09:14:30 - INFO - root -   Epoch: [202/300][120/200], lr: 0.00000060 	 loss = 0.9616(0.3082)
2024/03/04 09:14:51 - INFO - root -   Epoch: [202/300][140/200], lr: 0.00000060 	 loss = 1.9261(0.3046)
2024/03/04 09:15:05 - INFO - root -   Epoch: [202/300][160/200], lr: 0.00000060 	 loss = 0.0225(0.3029)
2024/03/04 09:15:21 - INFO - root -   Epoch: [202/300][180/200], lr: 0.00000060 	 loss = 0.0258(0.2998)
2024/03/04 09:15:29 - INFO - root -   Epoch: [202/300] 	 loss = 0.3032
2024/03/04 09:15:29 - INFO - root -   train_accuracy = 0.8950
2024/03/04 09:15:41 - INFO - root -   Epoch: [203/300][0/200], lr: 0.00000060 	 loss = 0.2313(0.2313)
2024/03/04 09:15:56 - INFO - root -   Epoch: [203/300][20/200], lr: 0.00000060 	 loss = 0.1478(0.4005)
2024/03/04 09:16:09 - INFO - root -   Epoch: [203/300][40/200], lr: 0.00000060 	 loss = 0.0112(0.3341)
2024/03/04 09:16:33 - INFO - root -   Epoch: [203/300][60/200], lr: 0.00000060 	 loss = 0.0644(0.2984)
2024/03/04 09:16:51 - INFO - root -   Epoch: [203/300][80/200], lr: 0.00000060 	 loss = 0.9183(0.3085)
2024/03/04 09:17:14 - INFO - root -   Epoch: [203/300][100/200], lr: 0.00000060 	 loss = 0.0039(0.3040)
2024/03/04 09:17:24 - INFO - root -   Epoch: [203/300][120/200], lr: 0.00000060 	 loss = 2.2805(0.2877)
2024/03/04 09:17:38 - INFO - root -   Epoch: [203/300][140/200], lr: 0.00000060 	 loss = 1.7001(0.2978)
2024/03/04 09:17:52 - INFO - root -   Epoch: [203/300][160/200], lr: 0.00000060 	 loss = 0.3780(0.2923)
2024/03/04 09:18:05 - INFO - root -   Epoch: [203/300][180/200], lr: 0.00000060 	 loss = 0.0928(0.2952)
2024/03/04 09:18:12 - INFO - root -   Epoch: [203/300] 	 loss = 0.2904
2024/03/04 09:18:12 - INFO - root -   train_accuracy = 0.8800
2024/03/04 09:18:14 - INFO - root -   Epoch: [204/300][0/200], lr: 0.00000060 	 loss = 0.4018(0.4018)
2024/03/04 09:18:45 - INFO - root -   Epoch: [204/300][20/200], lr: 0.00000060 	 loss = 0.0856(0.2870)
2024/03/04 09:19:00 - INFO - root -   Epoch: [204/300][40/200], lr: 0.00000060 	 loss = 0.0113(0.2782)
2024/03/04 09:19:17 - INFO - root -   Epoch: [204/300][60/200], lr: 0.00000060 	 loss = 0.0152(0.2916)
2024/03/04 09:19:39 - INFO - root -   Epoch: [204/300][80/200], lr: 0.00000060 	 loss = 0.8470(0.3523)
2024/03/04 09:19:55 - INFO - root -   Epoch: [204/300][100/200], lr: 0.00000060 	 loss = 0.0015(0.3177)
2024/03/04 09:20:03 - INFO - root -   Epoch: [204/300][120/200], lr: 0.00000060 	 loss = 1.7709(0.3180)
2024/03/04 09:20:24 - INFO - root -   Epoch: [204/300][140/200], lr: 0.00000060 	 loss = 0.5520(0.3233)
2024/03/04 09:20:38 - INFO - root -   Epoch: [204/300][160/200], lr: 0.00000060 	 loss = 0.0742(0.3407)
2024/03/04 09:20:46 - INFO - root -   Epoch: [204/300][180/200], lr: 0.00000060 	 loss = 0.8655(0.3416)
2024/03/04 09:20:54 - INFO - root -   Epoch: [204/300] 	 loss = 0.3307
2024/03/04 09:20:57 - INFO - root -   precision = 0.6889
2024/03/04 09:20:57 - INFO - root -   eval_loss = 2.0568
2024/03/04 09:20:57 - INFO - root -   eval_acc = 0.6889
2024/03/04 09:20:58 - INFO - root -   train_accuracy = 0.8750
2024/03/04 09:21:01 - INFO - root -   Epoch: [205/300][0/200], lr: 0.00000061 	 loss = 0.2110(0.2110)
2024/03/04 09:21:37 - INFO - root -   Epoch: [205/300][20/200], lr: 0.00000061 	 loss = 0.0046(0.4287)
2024/03/04 09:21:57 - INFO - root -   Epoch: [205/300][40/200], lr: 0.00000061 	 loss = 0.0025(0.3284)
2024/03/04 09:22:06 - INFO - root -   Epoch: [205/300][60/200], lr: 0.00000061 	 loss = 0.2500(0.3282)
2024/03/04 09:22:27 - INFO - root -   Epoch: [205/300][80/200], lr: 0.00000061 	 loss = 1.1772(0.3281)
2024/03/04 09:22:35 - INFO - root -   Epoch: [205/300][100/200], lr: 0.00000061 	 loss = 0.1004(0.3292)
2024/03/04 09:22:59 - INFO - root -   Epoch: [205/300][120/200], lr: 0.00000061 	 loss = 0.8115(0.3004)
2024/03/04 09:23:07 - INFO - root -   Epoch: [205/300][140/200], lr: 0.00000061 	 loss = 0.7362(0.3145)
2024/03/04 09:23:15 - INFO - root -   Epoch: [205/300][160/200], lr: 0.00000061 	 loss = 0.0398(0.3025)
2024/03/04 09:23:41 - INFO - root -   Epoch: [205/300][180/200], lr: 0.00000061 	 loss = 0.2961(0.3062)
2024/03/04 09:23:48 - INFO - root -   Epoch: [205/300] 	 loss = 0.3096
2024/03/04 09:23:48 - INFO - root -   train_accuracy = 0.8725
2024/03/04 09:24:12 - INFO - root -   Epoch: [206/300][0/200], lr: 0.00000061 	 loss = 1.2274(1.2274)
2024/03/04 09:24:25 - INFO - root -   Epoch: [206/300][20/200], lr: 0.00000061 	 loss = 0.0011(0.3009)
2024/03/04 09:24:45 - INFO - root -   Epoch: [206/300][40/200], lr: 0.00000061 	 loss = 0.0829(0.2453)
2024/03/04 09:25:01 - INFO - root -   Epoch: [206/300][60/200], lr: 0.00000061 	 loss = 0.0040(0.2809)
2024/03/04 09:25:17 - INFO - root -   Epoch: [206/300][80/200], lr: 0.00000061 	 loss = 1.2190(0.2818)
2024/03/04 09:25:45 - INFO - root -   Epoch: [206/300][100/200], lr: 0.00000061 	 loss = 0.1024(0.2985)
2024/03/04 09:25:59 - INFO - root -   Epoch: [206/300][120/200], lr: 0.00000061 	 loss = 0.6817(0.3008)
2024/03/04 09:26:09 - INFO - root -   Epoch: [206/300][140/200], lr: 0.00000061 	 loss = 0.2003(0.3116)
2024/03/04 09:26:21 - INFO - root -   Epoch: [206/300][160/200], lr: 0.00000061 	 loss = 0.1382(0.3103)
2024/03/04 09:26:41 - INFO - root -   Epoch: [206/300][180/200], lr: 0.00000061 	 loss = 0.2384(0.3082)
2024/03/04 09:26:48 - INFO - root -   Epoch: [206/300] 	 loss = 0.3276
2024/03/04 09:26:48 - INFO - root -   train_accuracy = 0.8825
2024/03/04 09:26:50 - INFO - root -   Epoch: [207/300][0/200], lr: 0.00000061 	 loss = 0.2251(0.2251)
2024/03/04 09:27:16 - INFO - root -   Epoch: [207/300][20/200], lr: 0.00000061 	 loss = 0.7386(0.3842)
2024/03/04 09:27:31 - INFO - root -   Epoch: [207/300][40/200], lr: 0.00000061 	 loss = 0.5787(0.3770)
2024/03/04 09:27:50 - INFO - root -   Epoch: [207/300][60/200], lr: 0.00000061 	 loss = 0.0238(0.4242)
2024/03/04 09:28:01 - INFO - root -   Epoch: [207/300][80/200], lr: 0.00000061 	 loss = 0.9294(0.4077)
2024/03/04 09:28:12 - INFO - root -   Epoch: [207/300][100/200], lr: 0.00000061 	 loss = 0.0062(0.4157)
2024/03/04 09:28:26 - INFO - root -   Epoch: [207/300][120/200], lr: 0.00000061 	 loss = 2.3292(0.3964)
2024/03/04 09:28:41 - INFO - root -   Epoch: [207/300][140/200], lr: 0.00000061 	 loss = 0.9397(0.3880)
2024/03/04 09:28:57 - INFO - root -   Epoch: [207/300][160/200], lr: 0.00000061 	 loss = 0.9094(0.3878)
2024/03/04 09:29:11 - INFO - root -   Epoch: [207/300][180/200], lr: 0.00000061 	 loss = 0.1678(0.3812)
2024/03/04 09:29:19 - INFO - root -   Epoch: [207/300] 	 loss = 0.3699
2024/03/04 09:29:19 - INFO - root -   train_accuracy = 0.8550
2024/03/04 09:29:21 - INFO - root -   Epoch: [208/300][0/200], lr: 0.00000061 	 loss = 0.1363(0.1363)
2024/03/04 09:29:39 - INFO - root -   Epoch: [208/300][20/200], lr: 0.00000061 	 loss = 0.0049(0.4088)
2024/03/04 09:29:53 - INFO - root -   Epoch: [208/300][40/200], lr: 0.00000061 	 loss = 0.4486(0.3080)
2024/03/04 09:30:13 - INFO - root -   Epoch: [208/300][60/200], lr: 0.00000061 	 loss = 0.0880(0.2722)
2024/03/04 09:30:32 - INFO - root -   Epoch: [208/300][80/200], lr: 0.00000061 	 loss = 1.3596(0.3283)
2024/03/04 09:30:45 - INFO - root -   Epoch: [208/300][100/200], lr: 0.00000061 	 loss = 0.1533(0.3166)
2024/03/04 09:30:56 - INFO - root -   Epoch: [208/300][120/200], lr: 0.00000061 	 loss = 1.8168(0.3183)
2024/03/04 09:31:21 - INFO - root -   Epoch: [208/300][140/200], lr: 0.00000061 	 loss = 0.8799(0.3184)
2024/03/04 09:31:29 - INFO - root -   Epoch: [208/300][160/200], lr: 0.00000061 	 loss = 0.2029(0.3139)
2024/03/04 09:31:37 - INFO - root -   Epoch: [208/300][180/200], lr: 0.00000061 	 loss = 0.1103(0.3103)
2024/03/04 09:31:49 - INFO - root -   Epoch: [208/300] 	 loss = 0.3082
2024/03/04 09:31:49 - INFO - root -   train_accuracy = 0.8900
2024/03/04 09:32:05 - INFO - root -   Epoch: [209/300][0/200], lr: 0.00000062 	 loss = 0.2819(0.2819)
2024/03/04 09:32:24 - INFO - root -   Epoch: [209/300][20/200], lr: 0.00000062 	 loss = 0.0118(0.4606)
2024/03/04 09:32:37 - INFO - root -   Epoch: [209/300][40/200], lr: 0.00000062 	 loss = 0.1725(0.4105)
2024/03/04 09:32:53 - INFO - root -   Epoch: [209/300][60/200], lr: 0.00000062 	 loss = 0.1910(0.3805)
2024/03/04 09:33:07 - INFO - root -   Epoch: [209/300][80/200], lr: 0.00000062 	 loss = 0.7208(0.3707)
2024/03/04 09:33:26 - INFO - root -   Epoch: [209/300][100/200], lr: 0.00000062 	 loss = 0.0009(0.3351)
2024/03/04 09:33:45 - INFO - root -   Epoch: [209/300][120/200], lr: 0.00000062 	 loss = 1.3024(0.3359)
2024/03/04 09:34:01 - INFO - root -   Epoch: [209/300][140/200], lr: 0.00000062 	 loss = 1.2467(0.3498)
2024/03/04 09:34:15 - INFO - root -   Epoch: [209/300][160/200], lr: 0.00000062 	 loss = 0.2168(0.3630)
2024/03/04 09:34:31 - INFO - root -   Epoch: [209/300][180/200], lr: 0.00000062 	 loss = 0.1302(0.3527)
2024/03/04 09:34:39 - INFO - root -   Epoch: [209/300] 	 loss = 0.3422
2024/03/04 09:34:42 - INFO - root -   precision = 0.6889
2024/03/04 09:34:42 - INFO - root -   eval_loss = 1.8559
2024/03/04 09:34:42 - INFO - root -   eval_acc = 0.6889
2024/03/04 09:34:43 - INFO - root -   train_accuracy = 0.8800
2024/03/04 09:34:45 - INFO - root -   Epoch: [210/300][0/200], lr: 0.00000062 	 loss = 0.2166(0.2166)
2024/03/04 09:35:18 - INFO - root -   Epoch: [210/300][20/200], lr: 0.00000062 	 loss = 0.0156(0.4250)
2024/03/04 09:35:26 - INFO - root -   Epoch: [210/300][40/200], lr: 0.00000062 	 loss = 0.5156(0.3078)
2024/03/04 09:35:40 - INFO - root -   Epoch: [210/300][60/200], lr: 0.00000062 	 loss = 0.0022(0.3030)
2024/03/04 09:36:10 - INFO - root -   Epoch: [210/300][80/200], lr: 0.00000062 	 loss = 1.3340(0.3696)
2024/03/04 09:36:24 - INFO - root -   Epoch: [210/300][100/200], lr: 0.00000062 	 loss = 0.0004(0.3396)
2024/03/04 09:36:32 - INFO - root -   Epoch: [210/300][120/200], lr: 0.00000062 	 loss = 1.0400(0.3363)
2024/03/04 09:36:53 - INFO - root -   Epoch: [210/300][140/200], lr: 0.00000062 	 loss = 0.3698(0.3349)
2024/03/04 09:37:01 - INFO - root -   Epoch: [210/300][160/200], lr: 0.00000062 	 loss = 0.1756(0.3333)
2024/03/04 09:37:20 - INFO - root -   Epoch: [210/300][180/200], lr: 0.00000062 	 loss = 0.3027(0.3299)
2024/03/04 09:37:28 - INFO - root -   Epoch: [210/300] 	 loss = 0.3429
2024/03/04 09:37:28 - INFO - root -   train_accuracy = 0.8875
2024/03/04 09:37:44 - INFO - root -   Epoch: [211/300][0/200], lr: 0.00000062 	 loss = 0.5333(0.5333)
2024/03/04 09:38:06 - INFO - root -   Epoch: [211/300][20/200], lr: 0.00000062 	 loss = 0.1496(0.4721)
2024/03/04 09:38:26 - INFO - root -   Epoch: [211/300][40/200], lr: 0.00000062 	 loss = 0.3322(0.4092)
2024/03/04 09:38:34 - INFO - root -   Epoch: [211/300][60/200], lr: 0.00000062 	 loss = 0.1894(0.3581)
2024/03/04 09:39:03 - INFO - root -   Epoch: [211/300][80/200], lr: 0.00000062 	 loss = 0.4264(0.3495)
2024/03/04 09:39:11 - INFO - root -   Epoch: [211/300][100/200], lr: 0.00000062 	 loss = 0.0008(0.3267)
2024/03/04 09:39:19 - INFO - root -   Epoch: [211/300][120/200], lr: 0.00000062 	 loss = 0.7445(0.3199)
2024/03/04 09:39:38 - INFO - root -   Epoch: [211/300][140/200], lr: 0.00000062 	 loss = 0.8480(0.3170)
2024/03/04 09:39:57 - INFO - root -   Epoch: [211/300][160/200], lr: 0.00000062 	 loss = 0.1333(0.3236)
2024/03/04 09:40:08 - INFO - root -   Epoch: [211/300][180/200], lr: 0.00000062 	 loss = 0.0183(0.3233)
2024/03/04 09:40:15 - INFO - root -   Epoch: [211/300] 	 loss = 0.3169
2024/03/04 09:40:15 - INFO - root -   train_accuracy = 0.8800
2024/03/04 09:40:28 - INFO - root -   Epoch: [212/300][0/200], lr: 0.00000062 	 loss = 0.7132(0.7132)
2024/03/04 09:40:46 - INFO - root -   Epoch: [212/300][20/200], lr: 0.00000062 	 loss = 0.1286(0.3534)
2024/03/04 09:40:54 - INFO - root -   Epoch: [212/300][40/200], lr: 0.00000062 	 loss = 0.0944(0.2530)
2024/03/04 09:41:13 - INFO - root -   Epoch: [212/300][60/200], lr: 0.00000062 	 loss = 0.1288(0.3398)
2024/03/04 09:41:26 - INFO - root -   Epoch: [212/300][80/200], lr: 0.00000062 	 loss = 0.4882(0.3397)
2024/03/04 09:41:39 - INFO - root -   Epoch: [212/300][100/200], lr: 0.00000062 	 loss = 0.0196(0.3185)
2024/03/04 09:42:03 - INFO - root -   Epoch: [212/300][120/200], lr: 0.00000062 	 loss = 1.4755(0.3170)
2024/03/04 09:42:27 - INFO - root -   Epoch: [212/300][140/200], lr: 0.00000062 	 loss = 0.4577(0.3366)
2024/03/04 09:42:44 - INFO - root -   Epoch: [212/300][160/200], lr: 0.00000062 	 loss = 0.0190(0.3400)
2024/03/04 09:42:52 - INFO - root -   Epoch: [212/300][180/200], lr: 0.00000062 	 loss = 0.2158(0.3432)
2024/03/04 09:43:00 - INFO - root -   Epoch: [212/300] 	 loss = 0.3338
2024/03/04 09:43:00 - INFO - root -   train_accuracy = 0.8700
2024/03/04 09:43:23 - INFO - root -   Epoch: [213/300][0/200], lr: 0.00000063 	 loss = 0.4661(0.4661)
2024/03/04 09:43:32 - INFO - root -   Epoch: [213/300][20/200], lr: 0.00000063 	 loss = 0.2024(0.5433)
2024/03/04 09:43:47 - INFO - root -   Epoch: [213/300][40/200], lr: 0.00000063 	 loss = 0.0048(0.3504)
2024/03/04 09:44:06 - INFO - root -   Epoch: [213/300][60/200], lr: 0.00000063 	 loss = 0.1648(0.3078)
2024/03/04 09:44:22 - INFO - root -   Epoch: [213/300][80/200], lr: 0.00000063 	 loss = 1.0621(0.3293)
2024/03/04 09:44:38 - INFO - root -   Epoch: [213/300][100/200], lr: 0.00000063 	 loss = 0.2954(0.3215)
2024/03/04 09:44:48 - INFO - root -   Epoch: [213/300][120/200], lr: 0.00000063 	 loss = 0.6843(0.3133)
2024/03/04 09:45:12 - INFO - root -   Epoch: [213/300][140/200], lr: 0.00000063 	 loss = 1.7012(0.3083)
2024/03/04 09:45:20 - INFO - root -   Epoch: [213/300][160/200], lr: 0.00000063 	 loss = 0.0034(0.3147)
2024/03/04 09:45:37 - INFO - root -   Epoch: [213/300][180/200], lr: 0.00000063 	 loss = 0.7612(0.3212)
2024/03/04 09:45:48 - INFO - root -   Epoch: [213/300] 	 loss = 0.3195
2024/03/04 09:45:48 - INFO - root -   train_accuracy = 0.8825
2024/03/04 09:45:49 - INFO - root -   Epoch: [214/300][0/200], lr: 0.00000063 	 loss = 0.3589(0.3589)
2024/03/04 09:46:13 - INFO - root -   Epoch: [214/300][20/200], lr: 0.00000063 	 loss = 0.0753(0.3962)
2024/03/04 09:46:24 - INFO - root -   Epoch: [214/300][40/200], lr: 0.00000063 	 loss = 0.0946(0.2814)
2024/03/04 09:46:43 - INFO - root -   Epoch: [214/300][60/200], lr: 0.00000063 	 loss = 0.0071(0.2785)
2024/03/04 09:46:57 - INFO - root -   Epoch: [214/300][80/200], lr: 0.00000063 	 loss = 0.1776(0.2947)
2024/03/04 09:47:19 - INFO - root -   Epoch: [214/300][100/200], lr: 0.00000063 	 loss = 0.0078(0.2779)
2024/03/04 09:47:26 - INFO - root -   Epoch: [214/300][120/200], lr: 0.00000063 	 loss = 0.8249(0.2632)
2024/03/04 09:47:42 - INFO - root -   Epoch: [214/300][140/200], lr: 0.00000063 	 loss = 0.3717(0.2649)
2024/03/04 09:48:06 - INFO - root -   Epoch: [214/300][160/200], lr: 0.00000063 	 loss = 0.1121(0.2777)
2024/03/04 09:48:23 - INFO - root -   Epoch: [214/300][180/200], lr: 0.00000063 	 loss = 0.0060(0.2849)
2024/03/04 09:48:30 - INFO - root -   Epoch: [214/300] 	 loss = 0.2913
2024/03/04 09:48:34 - INFO - root -   precision = 0.6667
2024/03/04 09:48:34 - INFO - root -   eval_loss = 2.1790
2024/03/04 09:48:34 - INFO - root -   eval_acc = 0.6667
2024/03/04 09:48:35 - INFO - root -   train_accuracy = 0.9025
2024/03/04 09:48:37 - INFO - root -   Epoch: [215/300][0/200], lr: 0.00000063 	 loss = 0.1957(0.1957)
2024/03/04 09:49:05 - INFO - root -   Epoch: [215/300][20/200], lr: 0.00000063 	 loss = 0.0035(0.5137)
2024/03/04 09:49:20 - INFO - root -   Epoch: [215/300][40/200], lr: 0.00000063 	 loss = 0.0005(0.3741)
2024/03/04 09:49:28 - INFO - root -   Epoch: [215/300][60/200], lr: 0.00000063 	 loss = 0.0160(0.3223)
2024/03/04 09:49:49 - INFO - root -   Epoch: [215/300][80/200], lr: 0.00000063 	 loss = 1.1682(0.3013)
2024/03/04 09:50:06 - INFO - root -   Epoch: [215/300][100/200], lr: 0.00000063 	 loss = 0.0505(0.2764)
2024/03/04 09:50:26 - INFO - root -   Epoch: [215/300][120/200], lr: 0.00000063 	 loss = 1.5387(0.2800)
2024/03/04 09:50:44 - INFO - root -   Epoch: [215/300][140/200], lr: 0.00000063 	 loss = 1.9527(0.2901)
2024/03/04 09:50:52 - INFO - root -   Epoch: [215/300][160/200], lr: 0.00000063 	 loss = 0.0162(0.2990)
2024/03/04 09:51:04 - INFO - root -   Epoch: [215/300][180/200], lr: 0.00000063 	 loss = 0.0903(0.3006)
2024/03/04 09:51:11 - INFO - root -   Epoch: [215/300] 	 loss = 0.2879
2024/03/04 09:51:11 - INFO - root -   train_accuracy = 0.8800
2024/03/04 09:51:25 - INFO - root -   Epoch: [216/300][0/200], lr: 0.00000063 	 loss = 1.7563(1.7563)
2024/03/04 09:51:45 - INFO - root -   Epoch: [216/300][20/200], lr: 0.00000063 	 loss = 0.2700(0.5051)
2024/03/04 09:51:53 - INFO - root -   Epoch: [216/300][40/200], lr: 0.00000063 	 loss = 0.0107(0.3427)
2024/03/04 09:52:07 - INFO - root -   Epoch: [216/300][60/200], lr: 0.00000063 	 loss = 0.0013(0.3132)
2024/03/04 09:52:21 - INFO - root -   Epoch: [216/300][80/200], lr: 0.00000063 	 loss = 1.1359(0.3229)
2024/03/04 09:52:51 - INFO - root -   Epoch: [216/300][100/200], lr: 0.00000063 	 loss = 0.0858(0.3262)
2024/03/04 09:53:11 - INFO - root -   Epoch: [216/300][120/200], lr: 0.00000063 	 loss = 1.2620(0.3571)
2024/03/04 09:53:24 - INFO - root -   Epoch: [216/300][140/200], lr: 0.00000063 	 loss = 1.4150(0.3795)
2024/03/04 09:53:41 - INFO - root -   Epoch: [216/300][160/200], lr: 0.00000063 	 loss = 0.1465(0.3788)
2024/03/04 09:53:49 - INFO - root -   Epoch: [216/300][180/200], lr: 0.00000063 	 loss = 0.0082(0.3628)
2024/03/04 09:53:57 - INFO - root -   Epoch: [216/300] 	 loss = 0.3537
2024/03/04 09:53:57 - INFO - root -   train_accuracy = 0.8775
2024/03/04 09:53:58 - INFO - root -   Epoch: [217/300][0/200], lr: 0.00000064 	 loss = 0.0926(0.0926)
2024/03/04 09:54:20 - INFO - root -   Epoch: [217/300][20/200], lr: 0.00000064 	 loss = 0.0015(0.5733)
2024/03/04 09:54:34 - INFO - root -   Epoch: [217/300][40/200], lr: 0.00000064 	 loss = 0.1105(0.4063)
2024/03/04 09:54:45 - INFO - root -   Epoch: [217/300][60/200], lr: 0.00000064 	 loss = 0.1825(0.3703)
2024/03/04 09:54:58 - INFO - root -   Epoch: [217/300][80/200], lr: 0.00000064 	 loss = 0.4286(0.3438)
2024/03/04 09:55:19 - INFO - root -   Epoch: [217/300][100/200], lr: 0.00000064 	 loss = 0.0793(0.3147)
2024/03/04 09:55:27 - INFO - root -   Epoch: [217/300][120/200], lr: 0.00000064 	 loss = 1.8854(0.2887)
2024/03/04 09:55:36 - INFO - root -   Epoch: [217/300][140/200], lr: 0.00000064 	 loss = 0.2219(0.3029)
2024/03/04 09:55:58 - INFO - root -   Epoch: [217/300][160/200], lr: 0.00000064 	 loss = 0.0129(0.2948)
2024/03/04 09:56:11 - INFO - root -   Epoch: [217/300][180/200], lr: 0.00000064 	 loss = 0.0079(0.3139)
2024/03/04 09:56:19 - INFO - root -   Epoch: [217/300] 	 loss = 0.3009
2024/03/04 09:56:19 - INFO - root -   train_accuracy = 0.8925
2024/03/04 09:56:21 - INFO - root -   Epoch: [218/300][0/200], lr: 0.00000064 	 loss = 0.6047(0.6047)
2024/03/04 09:56:54 - INFO - root -   Epoch: [218/300][20/200], lr: 0.00000064 	 loss = 0.0104(0.4825)
2024/03/04 09:57:04 - INFO - root -   Epoch: [218/300][40/200], lr: 0.00000064 	 loss = 0.0032(0.3575)
2024/03/04 09:57:21 - INFO - root -   Epoch: [218/300][60/200], lr: 0.00000064 	 loss = 0.1701(0.3441)
2024/03/04 09:57:39 - INFO - root -   Epoch: [218/300][80/200], lr: 0.00000064 	 loss = 0.5521(0.3223)
2024/03/04 09:57:58 - INFO - root -   Epoch: [218/300][100/200], lr: 0.00000064 	 loss = 0.0451(0.2989)
2024/03/04 09:58:06 - INFO - root -   Epoch: [218/300][120/200], lr: 0.00000064 	 loss = 1.2363(0.2774)
2024/03/04 09:58:33 - INFO - root -   Epoch: [218/300][140/200], lr: 0.00000064 	 loss = 0.6229(0.2958)
2024/03/04 09:58:43 - INFO - root -   Epoch: [218/300][160/200], lr: 0.00000064 	 loss = 0.0089(0.3113)
2024/03/04 09:59:00 - INFO - root -   Epoch: [218/300][180/200], lr: 0.00000064 	 loss = 0.0027(0.2995)
2024/03/04 09:59:08 - INFO - root -   Epoch: [218/300] 	 loss = 0.3102
2024/03/04 09:59:08 - INFO - root -   train_accuracy = 0.8750
2024/03/04 09:59:22 - INFO - root -   Epoch: [219/300][0/200], lr: 0.00000064 	 loss = 0.4201(0.4201)
2024/03/04 09:59:42 - INFO - root -   Epoch: [219/300][20/200], lr: 0.00000064 	 loss = 0.5347(0.3375)
2024/03/04 09:59:59 - INFO - root -   Epoch: [219/300][40/200], lr: 0.00000064 	 loss = 0.1533(0.2969)
2024/03/04 10:00:21 - INFO - root -   Epoch: [219/300][60/200], lr: 0.00000064 	 loss = 0.0154(0.3067)
2024/03/04 10:00:33 - INFO - root -   Epoch: [219/300][80/200], lr: 0.00000064 	 loss = 0.7287(0.3554)
2024/03/04 10:00:56 - INFO - root -   Epoch: [219/300][100/200], lr: 0.00000064 	 loss = 0.0001(0.3452)
2024/03/04 10:01:08 - INFO - root -   Epoch: [219/300][120/200], lr: 0.00000064 	 loss = 0.9011(0.3424)
2024/03/04 10:01:23 - INFO - root -   Epoch: [219/300][140/200], lr: 0.00000064 	 loss = 0.3311(0.3271)
2024/03/04 10:01:41 - INFO - root -   Epoch: [219/300][160/200], lr: 0.00000064 	 loss = 0.0231(0.3244)
2024/03/04 10:01:49 - INFO - root -   Epoch: [219/300][180/200], lr: 0.00000064 	 loss = 0.0184(0.3171)
2024/03/04 10:02:03 - INFO - root -   Epoch: [219/300] 	 loss = 0.3211
2024/03/04 10:02:06 - INFO - root -   precision = 0.6667
2024/03/04 10:02:06 - INFO - root -   eval_loss = 2.1537
2024/03/04 10:02:06 - INFO - root -   eval_acc = 0.6667
2024/03/04 10:02:07 - INFO - root -   train_accuracy = 0.8900
2024/03/04 10:02:10 - INFO - root -   Epoch: [220/300][0/200], lr: 0.00000064 	 loss = 0.0601(0.0601)
2024/03/04 10:02:27 - INFO - root -   Epoch: [220/300][20/200], lr: 0.00000064 	 loss = 0.0269(0.4032)
2024/03/04 10:02:38 - INFO - root -   Epoch: [220/300][40/200], lr: 0.00000064 	 loss = 0.0070(0.2467)
2024/03/04 10:03:01 - INFO - root -   Epoch: [220/300][60/200], lr: 0.00000064 	 loss = 0.0043(0.2575)
2024/03/04 10:03:09 - INFO - root -   Epoch: [220/300][80/200], lr: 0.00000064 	 loss = 0.1951(0.3033)
2024/03/04 10:03:21 - INFO - root -   Epoch: [220/300][100/200], lr: 0.00000064 	 loss = 0.0005(0.2973)
2024/03/04 10:03:29 - INFO - root -   Epoch: [220/300][120/200], lr: 0.00000064 	 loss = 1.2773(0.2938)
2024/03/04 10:03:50 - INFO - root -   Epoch: [220/300][140/200], lr: 0.00000064 	 loss = 1.9218(0.3043)
2024/03/04 10:03:58 - INFO - root -   Epoch: [220/300][160/200], lr: 0.00000064 	 loss = 0.0698(0.2904)
2024/03/04 10:04:17 - INFO - root -   Epoch: [220/300][180/200], lr: 0.00000064 	 loss = 0.3243(0.2913)
2024/03/04 10:04:25 - INFO - root -   Epoch: [220/300] 	 loss = 0.2940
2024/03/04 10:04:25 - INFO - root -   train_accuracy = 0.8950
2024/03/04 10:04:38 - INFO - root -   Epoch: [221/300][0/200], lr: 0.00000065 	 loss = 0.1965(0.1965)
2024/03/04 10:04:52 - INFO - root -   Epoch: [221/300][20/200], lr: 0.00000065 	 loss = 0.1923(0.5297)
2024/03/04 10:05:00 - INFO - root -   Epoch: [221/300][40/200], lr: 0.00000065 	 loss = 0.0247(0.3514)
2024/03/04 10:05:21 - INFO - root -   Epoch: [221/300][60/200], lr: 0.00000065 	 loss = 0.0234(0.3674)
2024/03/04 10:05:33 - INFO - root -   Epoch: [221/300][80/200], lr: 0.00000065 	 loss = 0.6919(0.4062)
2024/03/04 10:05:49 - INFO - root -   Epoch: [221/300][100/200], lr: 0.00000065 	 loss = 0.0044(0.3793)
2024/03/04 10:06:03 - INFO - root -   Epoch: [221/300][120/200], lr: 0.00000065 	 loss = 0.9248(0.3490)
2024/03/04 10:06:22 - INFO - root -   Epoch: [221/300][140/200], lr: 0.00000065 	 loss = 0.1126(0.3475)
2024/03/04 10:06:38 - INFO - root -   Epoch: [221/300][160/200], lr: 0.00000065 	 loss = 0.0380(0.3403)
2024/03/04 10:06:46 - INFO - root -   Epoch: [221/300][180/200], lr: 0.00000065 	 loss = 0.0117(0.3348)
2024/03/04 10:06:54 - INFO - root -   Epoch: [221/300] 	 loss = 0.3278
2024/03/04 10:06:54 - INFO - root -   train_accuracy = 0.8675
2024/03/04 10:07:07 - INFO - root -   Epoch: [222/300][0/200], lr: 0.00000065 	 loss = 0.0701(0.0701)
2024/03/04 10:07:33 - INFO - root -   Epoch: [222/300][20/200], lr: 0.00000065 	 loss = 0.2681(0.4752)
2024/03/04 10:07:41 - INFO - root -   Epoch: [222/300][40/200], lr: 0.00000065 	 loss = 0.0106(0.3344)
2024/03/04 10:07:55 - INFO - root -   Epoch: [222/300][60/200], lr: 0.00000065 	 loss = 0.0006(0.3242)
2024/03/04 10:08:03 - INFO - root -   Epoch: [222/300][80/200], lr: 0.00000065 	 loss = 1.4278(0.3198)
2024/03/04 10:08:21 - INFO - root -   Epoch: [222/300][100/200], lr: 0.00000065 	 loss = 0.0030(0.2968)
2024/03/04 10:08:39 - INFO - root -   Epoch: [222/300][120/200], lr: 0.00000065 	 loss = 1.3423(0.2802)
2024/03/04 10:08:47 - INFO - root -   Epoch: [222/300][140/200], lr: 0.00000065 	 loss = 1.7222(0.2970)
2024/03/04 10:09:13 - INFO - root -   Epoch: [222/300][160/200], lr: 0.00000065 	 loss = 0.1719(0.3100)
2024/03/04 10:09:26 - INFO - root -   Epoch: [222/300][180/200], lr: 0.00000065 	 loss = 0.0091(0.3194)
2024/03/04 10:09:34 - INFO - root -   Epoch: [222/300] 	 loss = 0.3092
2024/03/04 10:09:34 - INFO - root -   train_accuracy = 0.8800
2024/03/04 10:09:35 - INFO - root -   Epoch: [223/300][0/200], lr: 0.00000065 	 loss = 0.0526(0.0526)
2024/03/04 10:10:05 - INFO - root -   Epoch: [223/300][20/200], lr: 0.00000065 	 loss = 0.0008(0.1747)
2024/03/04 10:10:21 - INFO - root -   Epoch: [223/300][40/200], lr: 0.00000065 	 loss = 0.0364(0.1550)
2024/03/04 10:10:29 - INFO - root -   Epoch: [223/300][60/200], lr: 0.00000065 	 loss = 0.0017(0.1921)
2024/03/04 10:10:46 - INFO - root -   Epoch: [223/300][80/200], lr: 0.00000065 	 loss = 0.3083(0.2768)
2024/03/04 10:10:58 - INFO - root -   Epoch: [223/300][100/200], lr: 0.00000065 	 loss = 0.0466(0.2625)
2024/03/04 10:11:15 - INFO - root -   Epoch: [223/300][120/200], lr: 0.00000065 	 loss = 0.5781(0.2392)
2024/03/04 10:11:28 - INFO - root -   Epoch: [223/300][140/200], lr: 0.00000065 	 loss = 0.1737(0.2329)
2024/03/04 10:11:49 - INFO - root -   Epoch: [223/300][160/200], lr: 0.00000065 	 loss = 0.0050(0.2800)
2024/03/04 10:11:58 - INFO - root -   Epoch: [223/300][180/200], lr: 0.00000065 	 loss = 0.0073(0.2809)
2024/03/04 10:12:05 - INFO - root -   Epoch: [223/300] 	 loss = 0.2862
2024/03/04 10:12:05 - INFO - root -   train_accuracy = 0.9050
2024/03/04 10:12:08 - INFO - root -   Epoch: [224/300][0/200], lr: 0.00000065 	 loss = 0.1403(0.1403)
2024/03/04 10:12:36 - INFO - root -   Epoch: [224/300][20/200], lr: 0.00000065 	 loss = 0.3281(0.3771)
2024/03/04 10:12:55 - INFO - root -   Epoch: [224/300][40/200], lr: 0.00000065 	 loss = 0.0946(0.2824)
2024/03/04 10:13:03 - INFO - root -   Epoch: [224/300][60/200], lr: 0.00000065 	 loss = 0.0779(0.2751)
2024/03/04 10:13:33 - INFO - root -   Epoch: [224/300][80/200], lr: 0.00000065 	 loss = 0.6781(0.3152)
2024/03/04 10:13:52 - INFO - root -   Epoch: [224/300][100/200], lr: 0.00000065 	 loss = 0.1322(0.2857)
2024/03/04 10:14:08 - INFO - root -   Epoch: [224/300][120/200], lr: 0.00000065 	 loss = 0.9889(0.2675)
2024/03/04 10:14:27 - INFO - root -   Epoch: [224/300][140/200], lr: 0.00000065 	 loss = 0.3081(0.2740)
2024/03/04 10:14:36 - INFO - root -   Epoch: [224/300][160/200], lr: 0.00000065 	 loss = 0.1750(0.2676)
2024/03/04 10:14:50 - INFO - root -   Epoch: [224/300][180/200], lr: 0.00000065 	 loss = 1.2768(0.2695)
2024/03/04 10:14:58 - INFO - root -   Epoch: [224/300] 	 loss = 0.2727
2024/03/04 10:15:02 - INFO - root -   precision = 0.6667
2024/03/04 10:15:02 - INFO - root -   eval_loss = 2.1215
2024/03/04 10:15:02 - INFO - root -   eval_acc = 0.6667
2024/03/04 10:15:02 - INFO - root -   train_accuracy = 0.9050
2024/03/04 10:15:05 - INFO - root -   Epoch: [225/300][0/200], lr: 0.00000066 	 loss = 0.1511(0.1511)
2024/03/04 10:15:31 - INFO - root -   Epoch: [225/300][20/200], lr: 0.00000066 	 loss = 0.0008(0.2611)
2024/03/04 10:15:48 - INFO - root -   Epoch: [225/300][40/200], lr: 0.00000066 	 loss = 0.0079(0.2439)
2024/03/04 10:16:07 - INFO - root -   Epoch: [225/300][60/200], lr: 0.00000066 	 loss = 0.0886(0.2569)
2024/03/04 10:16:21 - INFO - root -   Epoch: [225/300][80/200], lr: 0.00000066 	 loss = 2.2959(0.2752)
2024/03/04 10:16:29 - INFO - root -   Epoch: [225/300][100/200], lr: 0.00000066 	 loss = 0.0004(0.2968)
2024/03/04 10:16:42 - INFO - root -   Epoch: [225/300][120/200], lr: 0.00000066 	 loss = 1.4578(0.2920)
2024/03/04 10:16:56 - INFO - root -   Epoch: [225/300][140/200], lr: 0.00000066 	 loss = 0.3072(0.2909)
2024/03/04 10:17:17 - INFO - root -   Epoch: [225/300][160/200], lr: 0.00000066 	 loss = 0.0985(0.2981)
2024/03/04 10:17:25 - INFO - root -   Epoch: [225/300][180/200], lr: 0.00000066 	 loss = 0.0869(0.2931)
2024/03/04 10:17:34 - INFO - root -   Epoch: [225/300] 	 loss = 0.2956
2024/03/04 10:17:34 - INFO - root -   train_accuracy = 0.8750
2024/03/04 10:17:50 - INFO - root -   Epoch: [226/300][0/200], lr: 0.00000066 	 loss = 0.2281(0.2281)
2024/03/04 10:18:04 - INFO - root -   Epoch: [226/300][20/200], lr: 0.00000066 	 loss = 0.0685(0.3048)
2024/03/04 10:18:16 - INFO - root -   Epoch: [226/300][40/200], lr: 0.00000066 	 loss = 0.2636(0.2700)
2024/03/04 10:18:32 - INFO - root -   Epoch: [226/300][60/200], lr: 0.00000066 	 loss = 0.0089(0.3054)
2024/03/04 10:18:55 - INFO - root -   Epoch: [226/300][80/200], lr: 0.00000066 	 loss = 0.5134(0.3106)
2024/03/04 10:19:02 - INFO - root -   Epoch: [226/300][100/200], lr: 0.00000066 	 loss = 0.0003(0.3010)
2024/03/04 10:19:24 - INFO - root -   Epoch: [226/300][120/200], lr: 0.00000066 	 loss = 0.4257(0.2903)
2024/03/04 10:19:39 - INFO - root -   Epoch: [226/300][140/200], lr: 0.00000066 	 loss = 0.8295(0.3118)
2024/03/04 10:19:49 - INFO - root -   Epoch: [226/300][160/200], lr: 0.00000066 	 loss = 0.1936(0.3141)
2024/03/04 10:20:05 - INFO - root -   Epoch: [226/300][180/200], lr: 0.00000066 	 loss = 0.0065(0.3103)
2024/03/04 10:20:13 - INFO - root -   Epoch: [226/300] 	 loss = 0.3107
2024/03/04 10:20:13 - INFO - root -   train_accuracy = 0.8900
2024/03/04 10:20:14 - INFO - root -   Epoch: [227/300][0/200], lr: 0.00000066 	 loss = 0.1329(0.1329)
2024/03/04 10:20:39 - INFO - root -   Epoch: [227/300][20/200], lr: 0.00000066 	 loss = 0.1587(0.2242)
2024/03/04 10:20:58 - INFO - root -   Epoch: [227/300][40/200], lr: 0.00000066 	 loss = 0.0007(0.2499)
2024/03/04 10:21:07 - INFO - root -   Epoch: [227/300][60/200], lr: 0.00000066 	 loss = 0.0043(0.2686)
2024/03/04 10:21:35 - INFO - root -   Epoch: [227/300][80/200], lr: 0.00000066 	 loss = 1.3088(0.2625)
2024/03/04 10:21:44 - INFO - root -   Epoch: [227/300][100/200], lr: 0.00000066 	 loss = 0.2010(0.2571)
2024/03/04 10:21:54 - INFO - root -   Epoch: [227/300][120/200], lr: 0.00000066 	 loss = 1.0710(0.2407)
2024/03/04 10:22:08 - INFO - root -   Epoch: [227/300][140/200], lr: 0.00000066 	 loss = 3.2299(0.2651)
2024/03/04 10:22:26 - INFO - root -   Epoch: [227/300][160/200], lr: 0.00000066 	 loss = 0.2973(0.2538)
2024/03/04 10:22:34 - INFO - root -   Epoch: [227/300][180/200], lr: 0.00000066 	 loss = 0.8749(0.2542)
2024/03/04 10:22:42 - INFO - root -   Epoch: [227/300] 	 loss = 0.2654
2024/03/04 10:22:42 - INFO - root -   train_accuracy = 0.8975
2024/03/04 10:23:03 - INFO - root -   Epoch: [228/300][0/200], lr: 0.00000066 	 loss = 1.7113(1.7113)
2024/03/04 10:23:16 - INFO - root -   Epoch: [228/300][20/200], lr: 0.00000066 	 loss = 0.0054(0.3799)
2024/03/04 10:23:33 - INFO - root -   Epoch: [228/300][40/200], lr: 0.00000066 	 loss = 0.0195(0.2787)
2024/03/04 10:23:44 - INFO - root -   Epoch: [228/300][60/200], lr: 0.00000066 	 loss = 0.0093(0.2889)
2024/03/04 10:24:09 - INFO - root -   Epoch: [228/300][80/200], lr: 0.00000066 	 loss = 1.3073(0.3384)
2024/03/04 10:24:28 - INFO - root -   Epoch: [228/300][100/200], lr: 0.00000066 	 loss = 0.0006(0.3247)
2024/03/04 10:24:47 - INFO - root -   Epoch: [228/300][120/200], lr: 0.00000066 	 loss = 0.8929(0.3195)
2024/03/04 10:24:56 - INFO - root -   Epoch: [228/300][140/200], lr: 0.00000066 	 loss = 1.0290(0.3380)
2024/03/04 10:25:11 - INFO - root -   Epoch: [228/300][160/200], lr: 0.00000066 	 loss = 0.1767(0.3221)
2024/03/04 10:25:24 - INFO - root -   Epoch: [228/300][180/200], lr: 0.00000066 	 loss = 0.0061(0.3224)
2024/03/04 10:25:32 - INFO - root -   Epoch: [228/300] 	 loss = 0.3150
2024/03/04 10:25:32 - INFO - root -   train_accuracy = 0.8875
2024/03/04 10:25:47 - INFO - root -   Epoch: [229/300][0/200], lr: 0.00000067 	 loss = 0.1561(0.1561)
2024/03/04 10:26:04 - INFO - root -   Epoch: [229/300][20/200], lr: 0.00000067 	 loss = 0.0021(0.2461)
2024/03/04 10:26:22 - INFO - root -   Epoch: [229/300][40/200], lr: 0.00000067 	 loss = 0.4196(0.2509)
2024/03/04 10:26:42 - INFO - root -   Epoch: [229/300][60/200], lr: 0.00000067 	 loss = 0.0399(0.2593)
2024/03/04 10:26:53 - INFO - root -   Epoch: [229/300][80/200], lr: 0.00000067 	 loss = 0.4305(0.3039)
2024/03/04 10:27:05 - INFO - root -   Epoch: [229/300][100/200], lr: 0.00000067 	 loss = 0.0005(0.2782)
2024/03/04 10:27:28 - INFO - root -   Epoch: [229/300][120/200], lr: 0.00000067 	 loss = 2.3338(0.2873)
2024/03/04 10:27:43 - INFO - root -   Epoch: [229/300][140/200], lr: 0.00000067 	 loss = 2.1410(0.3167)
2024/03/04 10:28:07 - INFO - root -   Epoch: [229/300][160/200], lr: 0.00000067 	 loss = 0.1703(0.3336)
2024/03/04 10:28:17 - INFO - root -   Epoch: [229/300][180/200], lr: 0.00000067 	 loss = 0.0061(0.3410)
2024/03/04 10:28:25 - INFO - root -   Epoch: [229/300] 	 loss = 0.3392
2024/03/04 10:28:28 - INFO - root -   precision = 0.6889
2024/03/04 10:28:28 - INFO - root -   eval_loss = 2.0038
2024/03/04 10:28:28 - INFO - root -   eval_acc = 0.6889
2024/03/04 10:28:29 - INFO - root -   train_accuracy = 0.8700
2024/03/04 10:28:43 - INFO - root -   Epoch: [230/300][0/200], lr: 0.00000067 	 loss = 0.3116(0.3116)
2024/03/04 10:29:10 - INFO - root -   Epoch: [230/300][20/200], lr: 0.00000067 	 loss = 0.5415(0.4421)
2024/03/04 10:29:22 - INFO - root -   Epoch: [230/300][40/200], lr: 0.00000067 	 loss = 0.2804(0.3035)
2024/03/04 10:29:42 - INFO - root -   Epoch: [230/300][60/200], lr: 0.00000067 	 loss = 0.1253(0.2668)
2024/03/04 10:29:53 - INFO - root -   Epoch: [230/300][80/200], lr: 0.00000067 	 loss = 1.1815(0.3055)
2024/03/04 10:30:09 - INFO - root -   Epoch: [230/300][100/200], lr: 0.00000067 	 loss = 0.0013(0.2994)
2024/03/04 10:30:21 - INFO - root -   Epoch: [230/300][120/200], lr: 0.00000067 	 loss = 1.4668(0.2789)
2024/03/04 10:30:33 - INFO - root -   Epoch: [230/300][140/200], lr: 0.00000067 	 loss = 2.3307(0.2824)
2024/03/04 10:30:50 - INFO - root -   Epoch: [230/300][160/200], lr: 0.00000067 	 loss = 0.1406(0.2804)
2024/03/04 10:31:03 - INFO - root -   Epoch: [230/300][180/200], lr: 0.00000067 	 loss = 0.7813(0.3100)
2024/03/04 10:31:15 - INFO - root -   Epoch: [230/300] 	 loss = 0.3140
2024/03/04 10:31:15 - INFO - root -   train_accuracy = 0.8900
2024/03/04 10:31:32 - INFO - root -   Epoch: [231/300][0/200], lr: 0.00000067 	 loss = 0.8703(0.8703)
2024/03/04 10:31:40 - INFO - root -   Epoch: [231/300][20/200], lr: 0.00000067 	 loss = 0.0055(0.5178)
2024/03/04 10:31:49 - INFO - root -   Epoch: [231/300][40/200], lr: 0.00000067 	 loss = 0.0025(0.3917)
2024/03/04 10:32:05 - INFO - root -   Epoch: [231/300][60/200], lr: 0.00000067 	 loss = 0.0620(0.3458)
2024/03/04 10:32:20 - INFO - root -   Epoch: [231/300][80/200], lr: 0.00000067 	 loss = 1.5237(0.3563)
2024/03/04 10:32:30 - INFO - root -   Epoch: [231/300][100/200], lr: 0.00000067 	 loss = 0.0004(0.3468)
2024/03/04 10:32:38 - INFO - root -   Epoch: [231/300][120/200], lr: 0.00000067 	 loss = 2.0435(0.3194)
2024/03/04 10:32:56 - INFO - root -   Epoch: [231/300][140/200], lr: 0.00000067 	 loss = 0.3827(0.3128)
2024/03/04 10:33:27 - INFO - root -   Epoch: [231/300][160/200], lr: 0.00000067 	 loss = 0.0573(0.3127)
2024/03/04 10:33:35 - INFO - root -   Epoch: [231/300][180/200], lr: 0.00000067 	 loss = 0.3370(0.3325)
2024/03/04 10:33:42 - INFO - root -   Epoch: [231/300] 	 loss = 0.3412
2024/03/04 10:33:42 - INFO - root -   train_accuracy = 0.8775
2024/03/04 10:33:58 - INFO - root -   Epoch: [232/300][0/200], lr: 0.00000067 	 loss = 0.1869(0.1869)
2024/03/04 10:34:15 - INFO - root -   Epoch: [232/300][20/200], lr: 0.00000067 	 loss = 0.1792(0.2838)
2024/03/04 10:34:27 - INFO - root -   Epoch: [232/300][40/200], lr: 0.00000067 	 loss = 0.2632(0.2495)
2024/03/04 10:34:39 - INFO - root -   Epoch: [232/300][60/200], lr: 0.00000067 	 loss = 0.0026(0.2340)
2024/03/04 10:34:56 - INFO - root -   Epoch: [232/300][80/200], lr: 0.00000067 	 loss = 0.1939(0.2481)
2024/03/04 10:35:19 - INFO - root -   Epoch: [232/300][100/200], lr: 0.00000067 	 loss = 0.0330(0.2309)
2024/03/04 10:35:27 - INFO - root -   Epoch: [232/300][120/200], lr: 0.00000067 	 loss = 1.0314(0.2340)
2024/03/04 10:35:39 - INFO - root -   Epoch: [232/300][140/200], lr: 0.00000067 	 loss = 1.8722(0.2529)
2024/03/04 10:35:57 - INFO - root -   Epoch: [232/300][160/200], lr: 0.00000067 	 loss = 0.0903(0.2409)
2024/03/04 10:36:13 - INFO - root -   Epoch: [232/300][180/200], lr: 0.00000067 	 loss = 0.1661(0.2468)
2024/03/04 10:36:21 - INFO - root -   Epoch: [232/300] 	 loss = 0.2533
2024/03/04 10:36:21 - INFO - root -   train_accuracy = 0.9050
2024/03/04 10:36:22 - INFO - root -   Epoch: [233/300][0/200], lr: 0.00000068 	 loss = 0.1436(0.1436)
2024/03/04 10:36:49 - INFO - root -   Epoch: [233/300][20/200], lr: 0.00000068 	 loss = 0.0343(0.3531)
2024/03/04 10:37:10 - INFO - root -   Epoch: [233/300][40/200], lr: 0.00000068 	 loss = 0.0923(0.2977)
2024/03/04 10:37:18 - INFO - root -   Epoch: [233/300][60/200], lr: 0.00000068 	 loss = 0.0103(0.2982)
2024/03/04 10:37:32 - INFO - root -   Epoch: [233/300][80/200], lr: 0.00000068 	 loss = 0.3838(0.3404)
2024/03/04 10:37:48 - INFO - root -   Epoch: [233/300][100/200], lr: 0.00000068 	 loss = 0.1232(0.3238)
2024/03/04 10:37:56 - INFO - root -   Epoch: [233/300][120/200], lr: 0.00000068 	 loss = 1.0258(0.2969)
2024/03/04 10:38:09 - INFO - root -   Epoch: [233/300][140/200], lr: 0.00000068 	 loss = 0.9591(0.2938)
2024/03/04 10:38:20 - INFO - root -   Epoch: [233/300][160/200], lr: 0.00000068 	 loss = 0.5162(0.2882)
2024/03/04 10:38:32 - INFO - root -   Epoch: [233/300][180/200], lr: 0.00000068 	 loss = 0.0052(0.2854)
2024/03/04 10:38:42 - INFO - root -   Epoch: [233/300] 	 loss = 0.2811
2024/03/04 10:38:42 - INFO - root -   train_accuracy = 0.8900
2024/03/04 10:39:05 - INFO - root -   Epoch: [234/300][0/200], lr: 0.00000068 	 loss = 1.3372(1.3372)
2024/03/04 10:39:13 - INFO - root -   Epoch: [234/300][20/200], lr: 0.00000068 	 loss = 0.0070(0.5297)
2024/03/04 10:39:29 - INFO - root -   Epoch: [234/300][40/200], lr: 0.00000068 	 loss = 0.3528(0.3269)
2024/03/04 10:39:51 - INFO - root -   Epoch: [234/300][60/200], lr: 0.00000068 	 loss = 0.1931(0.3289)
2024/03/04 10:40:09 - INFO - root -   Epoch: [234/300][80/200], lr: 0.00000068 	 loss = 0.3260(0.3637)
2024/03/04 10:40:35 - INFO - root -   Epoch: [234/300][100/200], lr: 0.00000068 	 loss = 0.0695(0.3777)
2024/03/04 10:40:44 - INFO - root -   Epoch: [234/300][120/200], lr: 0.00000068 	 loss = 0.5977(0.3564)
2024/03/04 10:40:54 - INFO - root -   Epoch: [234/300][140/200], lr: 0.00000068 	 loss = 0.1995(0.3562)
2024/03/04 10:41:02 - INFO - root -   Epoch: [234/300][160/200], lr: 0.00000068 	 loss = 0.0659(0.3579)
2024/03/04 10:41:24 - INFO - root -   Epoch: [234/300][180/200], lr: 0.00000068 	 loss = 0.0061(0.3593)
2024/03/04 10:41:32 - INFO - root -   Epoch: [234/300] 	 loss = 0.3678
2024/03/04 10:41:35 - INFO - root -   precision = 0.6667
2024/03/04 10:41:35 - INFO - root -   eval_loss = 2.0964
2024/03/04 10:41:35 - INFO - root -   eval_acc = 0.6667
2024/03/04 10:41:36 - INFO - root -   train_accuracy = 0.8525
2024/03/04 10:41:37 - INFO - root -   Epoch: [235/300][0/200], lr: 0.00000068 	 loss = 0.0841(0.0841)
2024/03/04 10:42:16 - INFO - root -   Epoch: [235/300][20/200], lr: 0.00000068 	 loss = 0.1040(0.3975)
2024/03/04 10:42:29 - INFO - root -   Epoch: [235/300][40/200], lr: 0.00000068 	 loss = 0.0541(0.3354)
2024/03/04 10:42:37 - INFO - root -   Epoch: [235/300][60/200], lr: 0.00000068 	 loss = 0.0019(0.3266)
2024/03/04 10:42:55 - INFO - root -   Epoch: [235/300][80/200], lr: 0.00000068 	 loss = 1.1395(0.3259)
2024/03/04 10:43:10 - INFO - root -   Epoch: [235/300][100/200], lr: 0.00000068 	 loss = 0.0074(0.3119)
2024/03/04 10:43:20 - INFO - root -   Epoch: [235/300][120/200], lr: 0.00000068 	 loss = 0.5117(0.2920)
2024/03/04 10:43:44 - INFO - root -   Epoch: [235/300][140/200], lr: 0.00000068 	 loss = 0.3109(0.2778)
2024/03/04 10:44:01 - INFO - root -   Epoch: [235/300][160/200], lr: 0.00000068 	 loss = 0.0051(0.2803)
2024/03/04 10:44:08 - INFO - root -   Epoch: [235/300][180/200], lr: 0.00000068 	 loss = 0.0694(0.2806)
2024/03/04 10:44:16 - INFO - root -   Epoch: [235/300] 	 loss = 0.2862
2024/03/04 10:44:16 - INFO - root -   train_accuracy = 0.9050
2024/03/04 10:44:18 - INFO - root -   Epoch: [236/300][0/200], lr: 0.00000068 	 loss = 0.0428(0.0428)
2024/03/04 10:44:47 - INFO - root -   Epoch: [236/300][20/200], lr: 0.00000068 	 loss = 0.0048(0.2996)
2024/03/04 10:44:55 - INFO - root -   Epoch: [236/300][40/200], lr: 0.00000068 	 loss = 0.0096(0.2793)
2024/03/04 10:45:10 - INFO - root -   Epoch: [236/300][60/200], lr: 0.00000068 	 loss = 0.0542(0.2412)
2024/03/04 10:45:21 - INFO - root -   Epoch: [236/300][80/200], lr: 0.00000068 	 loss = 0.1572(0.2464)
2024/03/04 10:45:41 - INFO - root -   Epoch: [236/300][100/200], lr: 0.00000068 	 loss = 0.0031(0.2358)
2024/03/04 10:45:49 - INFO - root -   Epoch: [236/300][120/200], lr: 0.00000068 	 loss = 0.9817(0.2293)
2024/03/04 10:46:04 - INFO - root -   Epoch: [236/300][140/200], lr: 0.00000068 	 loss = 2.2865(0.2475)
2024/03/04 10:46:21 - INFO - root -   Epoch: [236/300][160/200], lr: 0.00000068 	 loss = 0.2989(0.2505)
2024/03/04 10:46:35 - INFO - root -   Epoch: [236/300][180/200], lr: 0.00000068 	 loss = 0.0053(0.2537)
2024/03/04 10:46:43 - INFO - root -   Epoch: [236/300] 	 loss = 0.2673
2024/03/04 10:46:43 - INFO - root -   train_accuracy = 0.9000
2024/03/04 10:46:44 - INFO - root -   Epoch: [237/300][0/200], lr: 0.00000069 	 loss = 0.0518(0.0518)
2024/03/04 10:47:14 - INFO - root -   Epoch: [237/300][20/200], lr: 0.00000069 	 loss = 0.1358(0.4527)
2024/03/04 10:47:27 - INFO - root -   Epoch: [237/300][40/200], lr: 0.00000069 	 loss = 0.3598(0.3689)
2024/03/04 10:47:35 - INFO - root -   Epoch: [237/300][60/200], lr: 0.00000069 	 loss = 0.0010(0.3094)
2024/03/04 10:47:52 - INFO - root -   Epoch: [237/300][80/200], lr: 0.00000069 	 loss = 0.7612(0.2967)
2024/03/04 10:48:06 - INFO - root -   Epoch: [237/300][100/200], lr: 0.00000069 	 loss = 0.0011(0.2718)
2024/03/04 10:48:17 - INFO - root -   Epoch: [237/300][120/200], lr: 0.00000069 	 loss = 1.2134(0.2563)
2024/03/04 10:48:25 - INFO - root -   Epoch: [237/300][140/200], lr: 0.00000069 	 loss = 2.6028(0.2656)
2024/03/04 10:48:46 - INFO - root -   Epoch: [237/300][160/200], lr: 0.00000069 	 loss = 0.2773(0.2820)
2024/03/04 10:48:59 - INFO - root -   Epoch: [237/300][180/200], lr: 0.00000069 	 loss = 0.9263(0.2894)
2024/03/04 10:49:07 - INFO - root -   Epoch: [237/300] 	 loss = 0.3062
2024/03/04 10:49:07 - INFO - root -   train_accuracy = 0.8800
2024/03/04 10:49:34 - INFO - root -   Epoch: [238/300][0/200], lr: 0.00000069 	 loss = 0.8692(0.8692)
2024/03/04 10:49:52 - INFO - root -   Epoch: [238/300][20/200], lr: 0.00000069 	 loss = 0.1176(0.6511)
2024/03/04 10:50:11 - INFO - root -   Epoch: [238/300][40/200], lr: 0.00000069 	 loss = 0.1473(0.5451)
2024/03/04 10:50:19 - INFO - root -   Epoch: [238/300][60/200], lr: 0.00000069 	 loss = 0.0294(0.4276)
2024/03/04 10:50:33 - INFO - root -   Epoch: [238/300][80/200], lr: 0.00000069 	 loss = 0.7997(0.4373)
2024/03/04 10:50:44 - INFO - root -   Epoch: [238/300][100/200], lr: 0.00000069 	 loss = 0.0003(0.3992)
2024/03/04 10:51:02 - INFO - root -   Epoch: [238/300][120/200], lr: 0.00000069 	 loss = 1.9481(0.3894)
2024/03/04 10:51:19 - INFO - root -   Epoch: [238/300][140/200], lr: 0.00000069 	 loss = 1.9051(0.3936)
2024/03/04 10:51:31 - INFO - root -   Epoch: [238/300][160/200], lr: 0.00000069 	 loss = 0.0215(0.3819)
2024/03/04 10:51:54 - INFO - root -   Epoch: [238/300][180/200], lr: 0.00000069 	 loss = 0.0037(0.3677)
2024/03/04 10:52:02 - INFO - root -   Epoch: [238/300] 	 loss = 0.3620
2024/03/04 10:52:02 - INFO - root -   train_accuracy = 0.8725
2024/03/04 10:52:24 - INFO - root -   Epoch: [239/300][0/200], lr: 0.00000069 	 loss = 1.1943(1.1943)
2024/03/04 10:52:32 - INFO - root -   Epoch: [239/300][20/200], lr: 0.00000069 	 loss = 0.0017(0.3655)
2024/03/04 10:52:40 - INFO - root -   Epoch: [239/300][40/200], lr: 0.00000069 	 loss = 0.0558(0.2505)
2024/03/04 10:53:03 - INFO - root -   Epoch: [239/300][60/200], lr: 0.00000069 	 loss = 0.2370(0.3032)
2024/03/04 10:53:23 - INFO - root -   Epoch: [239/300][80/200], lr: 0.00000069 	 loss = 0.3693(0.3266)
2024/03/04 10:53:42 - INFO - root -   Epoch: [239/300][100/200], lr: 0.00000069 	 loss = 0.1427(0.3054)
2024/03/04 10:53:50 - INFO - root -   Epoch: [239/300][120/200], lr: 0.00000069 	 loss = 0.6572(0.2818)
2024/03/04 10:54:03 - INFO - root -   Epoch: [239/300][140/200], lr: 0.00000069 	 loss = 0.8573(0.2958)
2024/03/04 10:54:11 - INFO - root -   Epoch: [239/300][160/200], lr: 0.00000069 	 loss = 0.0608(0.3038)
2024/03/04 10:54:23 - INFO - root -   Epoch: [239/300][180/200], lr: 0.00000069 	 loss = 0.0572(0.3148)
2024/03/04 10:54:31 - INFO - root -   Epoch: [239/300] 	 loss = 0.3123
2024/03/04 10:54:34 - INFO - root -   precision = 0.6667
2024/03/04 10:54:34 - INFO - root -   eval_loss = 1.9897
2024/03/04 10:54:34 - INFO - root -   eval_acc = 0.6667
2024/03/04 10:54:35 - INFO - root -   train_accuracy = 0.8750
2024/03/04 10:54:37 - INFO - root -   Epoch: [240/300][0/200], lr: 0.00000069 	 loss = 0.4488(0.4488)
2024/03/04 10:55:13 - INFO - root -   Epoch: [240/300][20/200], lr: 0.00000069 	 loss = 0.0101(0.4144)
2024/03/04 10:55:21 - INFO - root -   Epoch: [240/300][40/200], lr: 0.00000069 	 loss = 0.0173(0.3858)
2024/03/04 10:55:42 - INFO - root -   Epoch: [240/300][60/200], lr: 0.00000069 	 loss = 0.0103(0.3370)
2024/03/04 10:55:51 - INFO - root -   Epoch: [240/300][80/200], lr: 0.00000069 	 loss = 0.7702(0.3448)
2024/03/04 10:56:00 - INFO - root -   Epoch: [240/300][100/200], lr: 0.00000069 	 loss = 0.0894(0.3140)
2024/03/04 10:56:09 - INFO - root -   Epoch: [240/300][120/200], lr: 0.00000069 	 loss = 0.7355(0.2846)
2024/03/04 10:56:27 - INFO - root -   Epoch: [240/300][140/200], lr: 0.00000069 	 loss = 0.1398(0.2875)
2024/03/04 10:56:39 - INFO - root -   Epoch: [240/300][160/200], lr: 0.00000069 	 loss = 0.1080(0.2910)
2024/03/04 10:56:53 - INFO - root -   Epoch: [240/300][180/200], lr: 0.00000069 	 loss = 1.0541(0.2932)
2024/03/04 10:57:00 - INFO - root -   Epoch: [240/300] 	 loss = 0.2974
2024/03/04 10:57:00 - INFO - root -   train_accuracy = 0.8875
2024/03/04 10:57:01 - INFO - root -   Epoch: [241/300][0/200], lr: 0.00000070 	 loss = 0.4962(0.4962)
2024/03/04 10:57:28 - INFO - root -   Epoch: [241/300][20/200], lr: 0.00000070 	 loss = 0.0930(0.2759)
2024/03/04 10:57:39 - INFO - root -   Epoch: [241/300][40/200], lr: 0.00000070 	 loss = 0.0701(0.2683)
2024/03/04 10:57:56 - INFO - root -   Epoch: [241/300][60/200], lr: 0.00000070 	 loss = 0.0064(0.2794)
2024/03/04 10:58:09 - INFO - root -   Epoch: [241/300][80/200], lr: 0.00000070 	 loss = 0.7754(0.2985)
2024/03/04 10:58:19 - INFO - root -   Epoch: [241/300][100/200], lr: 0.00000070 	 loss = 0.0347(0.2745)
2024/03/04 10:58:52 - INFO - root -   Epoch: [241/300][120/200], lr: 0.00000070 	 loss = 2.1467(0.2725)
2024/03/04 10:59:06 - INFO - root -   Epoch: [241/300][140/200], lr: 0.00000070 	 loss = 1.3747(0.2945)
2024/03/04 10:59:14 - INFO - root -   Epoch: [241/300][160/200], lr: 0.00000070 	 loss = 0.0356(0.2817)
2024/03/04 10:59:32 - INFO - root -   Epoch: [241/300][180/200], lr: 0.00000070 	 loss = 0.2139(0.2906)
2024/03/04 10:59:40 - INFO - root -   Epoch: [241/300] 	 loss = 0.3054
2024/03/04 10:59:40 - INFO - root -   train_accuracy = 0.8900
2024/03/04 10:59:54 - INFO - root -   Epoch: [242/300][0/200], lr: 0.00000070 	 loss = 0.1034(0.1034)
2024/03/04 11:00:10 - INFO - root -   Epoch: [242/300][20/200], lr: 0.00000070 	 loss = 0.0008(0.3860)
2024/03/04 11:00:18 - INFO - root -   Epoch: [242/300][40/200], lr: 0.00000070 	 loss = 0.0489(0.3039)
2024/03/04 11:00:26 - INFO - root -   Epoch: [242/300][60/200], lr: 0.00000070 	 loss = 0.0031(0.2674)
2024/03/04 11:00:45 - INFO - root -   Epoch: [242/300][80/200], lr: 0.00000070 	 loss = 0.6365(0.2880)
2024/03/04 11:01:06 - INFO - root -   Epoch: [242/300][100/200], lr: 0.00000070 	 loss = 0.2071(0.2776)
2024/03/04 11:01:14 - INFO - root -   Epoch: [242/300][120/200], lr: 0.00000070 	 loss = 1.0976(0.2687)
2024/03/04 11:01:42 - INFO - root -   Epoch: [242/300][140/200], lr: 0.00000070 	 loss = 0.2874(0.2865)
2024/03/04 11:01:50 - INFO - root -   Epoch: [242/300][160/200], lr: 0.00000070 	 loss = 0.0354(0.3064)
2024/03/04 11:02:06 - INFO - root -   Epoch: [242/300][180/200], lr: 0.00000070 	 loss = 0.0070(0.2983)
2024/03/04 11:02:14 - INFO - root -   Epoch: [242/300] 	 loss = 0.3019
2024/03/04 11:02:14 - INFO - root -   train_accuracy = 0.8925
2024/03/04 11:02:25 - INFO - root -   Epoch: [243/300][0/200], lr: 0.00000070 	 loss = 0.4446(0.4446)
2024/03/04 11:02:37 - INFO - root -   Epoch: [243/300][20/200], lr: 0.00000070 	 loss = 0.2048(0.2970)
2024/03/04 11:02:45 - INFO - root -   Epoch: [243/300][40/200], lr: 0.00000070 	 loss = 0.0029(0.2376)
2024/03/04 11:02:55 - INFO - root -   Epoch: [243/300][60/200], lr: 0.00000070 	 loss = 0.0306(0.2591)
2024/03/04 11:03:14 - INFO - root -   Epoch: [243/300][80/200], lr: 0.00000070 	 loss = 0.1077(0.2639)
2024/03/04 11:03:22 - INFO - root -   Epoch: [243/300][100/200], lr: 0.00000070 	 loss = 0.0012(0.2469)
2024/03/04 11:03:42 - INFO - root -   Epoch: [243/300][120/200], lr: 0.00000070 	 loss = 1.9892(0.2559)
2024/03/04 11:03:50 - INFO - root -   Epoch: [243/300][140/200], lr: 0.00000070 	 loss = 0.1758(0.2680)
2024/03/04 11:04:05 - INFO - root -   Epoch: [243/300][160/200], lr: 0.00000070 	 loss = 0.0250(0.2735)
2024/03/04 11:04:26 - INFO - root -   Epoch: [243/300][180/200], lr: 0.00000070 	 loss = 0.0019(0.2775)
2024/03/04 11:04:33 - INFO - root -   Epoch: [243/300] 	 loss = 0.2868
2024/03/04 11:04:33 - INFO - root -   train_accuracy = 0.8900
2024/03/04 11:04:50 - INFO - root -   Epoch: [244/300][0/200], lr: 0.00000070 	 loss = 3.1779(3.1779)
2024/03/04 11:05:04 - INFO - root -   Epoch: [244/300][20/200], lr: 0.00000070 	 loss = 0.0005(0.3663)
2024/03/04 11:05:33 - INFO - root -   Epoch: [244/300][40/200], lr: 0.00000070 	 loss = 0.0705(0.2894)
2024/03/04 11:05:44 - INFO - root -   Epoch: [244/300][60/200], lr: 0.00000070 	 loss = 0.0020(0.2960)
2024/03/04 11:05:52 - INFO - root -   Epoch: [244/300][80/200], lr: 0.00000070 	 loss = 0.1635(0.2890)
2024/03/04 11:06:00 - INFO - root -   Epoch: [244/300][100/200], lr: 0.00000070 	 loss = 0.0001(0.2830)
2024/03/04 11:06:11 - INFO - root -   Epoch: [244/300][120/200], lr: 0.00000070 	 loss = 1.4654(0.2887)
2024/03/04 11:06:22 - INFO - root -   Epoch: [244/300][140/200], lr: 0.00000070 	 loss = 1.0445(0.2941)
2024/03/04 11:06:32 - INFO - root -   Epoch: [244/300][160/200], lr: 0.00000070 	 loss = 0.0825(0.2930)
2024/03/04 11:06:55 - INFO - root -   Epoch: [244/300][180/200], lr: 0.00000070 	 loss = 0.0890(0.2851)
2024/03/04 11:07:02 - INFO - root -   Epoch: [244/300] 	 loss = 0.2974
2024/03/04 11:07:06 - INFO - root -   precision = 0.6667
2024/03/04 11:07:06 - INFO - root -   eval_loss = 2.0791
2024/03/04 11:07:06 - INFO - root -   eval_acc = 0.6667
2024/03/04 11:07:07 - INFO - root -   train_accuracy = 0.8975
2024/03/04 11:07:20 - INFO - root -   Epoch: [245/300][0/200], lr: 0.00000071 	 loss = 0.8360(0.8360)
2024/03/04 11:07:36 - INFO - root -   Epoch: [245/300][20/200], lr: 0.00000071 	 loss = 0.0044(0.3527)
2024/03/04 11:07:50 - INFO - root -   Epoch: [245/300][40/200], lr: 0.00000071 	 loss = 0.0060(0.3004)
2024/03/04 11:08:09 - INFO - root -   Epoch: [245/300][60/200], lr: 0.00000071 	 loss = 0.0013(0.3194)
2024/03/04 11:08:17 - INFO - root -   Epoch: [245/300][80/200], lr: 0.00000071 	 loss = 0.0828(0.3057)
2024/03/04 11:08:32 - INFO - root -   Epoch: [245/300][100/200], lr: 0.00000071 	 loss = 0.0005(0.2759)
2024/03/04 11:08:53 - INFO - root -   Epoch: [245/300][120/200], lr: 0.00000071 	 loss = 1.5168(0.2673)
2024/03/04 11:09:04 - INFO - root -   Epoch: [245/300][140/200], lr: 0.00000071 	 loss = 2.5253(0.2910)
2024/03/04 11:09:24 - INFO - root -   Epoch: [245/300][160/200], lr: 0.00000071 	 loss = 0.7940(0.2975)
2024/03/04 11:09:34 - INFO - root -   Epoch: [245/300][180/200], lr: 0.00000071 	 loss = 0.0145(0.3038)
2024/03/04 11:09:42 - INFO - root -   Epoch: [245/300] 	 loss = 0.3019
2024/03/04 11:09:42 - INFO - root -   train_accuracy = 0.8950
2024/03/04 11:09:54 - INFO - root -   Epoch: [246/300][0/200], lr: 0.00000071 	 loss = 0.1196(0.1196)
2024/03/04 11:10:15 - INFO - root -   Epoch: [246/300][20/200], lr: 0.00000071 	 loss = 0.0589(0.2636)
2024/03/04 11:10:23 - INFO - root -   Epoch: [246/300][40/200], lr: 0.00000071 	 loss = 0.0779(0.2040)
2024/03/04 11:10:44 - INFO - root -   Epoch: [246/300][60/200], lr: 0.00000071 	 loss = 0.0073(0.2105)
2024/03/04 11:10:56 - INFO - root -   Epoch: [246/300][80/200], lr: 0.00000071 	 loss = 1.4653(0.2533)
2024/03/04 11:11:05 - INFO - root -   Epoch: [246/300][100/200], lr: 0.00000071 	 loss = 0.0034(0.2567)
2024/03/04 11:11:29 - INFO - root -   Epoch: [246/300][120/200], lr: 0.00000071 	 loss = 0.7261(0.2379)
2024/03/04 11:11:43 - INFO - root -   Epoch: [246/300][140/200], lr: 0.00000071 	 loss = 0.5016(0.2562)
2024/03/04 11:11:56 - INFO - root -   Epoch: [246/300][160/200], lr: 0.00000071 	 loss = 0.0247(0.2573)
2024/03/04 11:12:19 - INFO - root -   Epoch: [246/300][180/200], lr: 0.00000071 	 loss = 0.0639(0.2691)
2024/03/04 11:12:27 - INFO - root -   Epoch: [246/300] 	 loss = 0.2744
2024/03/04 11:12:27 - INFO - root -   train_accuracy = 0.9025
2024/03/04 11:12:29 - INFO - root -   Epoch: [247/300][0/200], lr: 0.00000071 	 loss = 0.0809(0.0809)
2024/03/04 11:12:58 - INFO - root -   Epoch: [247/300][20/200], lr: 0.00000071 	 loss = 0.0519(0.3501)
2024/03/04 11:13:19 - INFO - root -   Epoch: [247/300][40/200], lr: 0.00000071 	 loss = 0.2213(0.2577)
2024/03/04 11:13:27 - INFO - root -   Epoch: [247/300][60/200], lr: 0.00000071 	 loss = 0.1891(0.2827)
2024/03/04 11:13:52 - INFO - root -   Epoch: [247/300][80/200], lr: 0.00000071 	 loss = 1.3130(0.2995)
2024/03/04 11:14:00 - INFO - root -   Epoch: [247/300][100/200], lr: 0.00000071 	 loss = 0.0002(0.2765)
2024/03/04 11:14:17 - INFO - root -   Epoch: [247/300][120/200], lr: 0.00000071 	 loss = 0.7123(0.2537)
2024/03/04 11:14:26 - INFO - root -   Epoch: [247/300][140/200], lr: 0.00000071 	 loss = 0.9782(0.2796)
2024/03/04 11:14:43 - INFO - root -   Epoch: [247/300][160/200], lr: 0.00000071 	 loss = 1.3654(0.2836)
2024/03/04 11:14:51 - INFO - root -   Epoch: [247/300][180/200], lr: 0.00000071 	 loss = 0.1296(0.2922)
2024/03/04 11:14:59 - INFO - root -   Epoch: [247/300] 	 loss = 0.2831
2024/03/04 11:14:59 - INFO - root -   train_accuracy = 0.8900
2024/03/04 11:15:14 - INFO - root -   Epoch: [248/300][0/200], lr: 0.00000071 	 loss = 0.0697(0.0697)
2024/03/04 11:15:27 - INFO - root -   Epoch: [248/300][20/200], lr: 0.00000071 	 loss = 0.0018(0.2957)
2024/03/04 11:15:35 - INFO - root -   Epoch: [248/300][40/200], lr: 0.00000071 	 loss = 0.0053(0.2994)
2024/03/04 11:15:46 - INFO - root -   Epoch: [248/300][60/200], lr: 0.00000071 	 loss = 0.0281(0.2910)
2024/03/04 11:16:07 - INFO - root -   Epoch: [248/300][80/200], lr: 0.00000071 	 loss = 0.9018(0.3074)
2024/03/04 11:16:15 - INFO - root -   Epoch: [248/300][100/200], lr: 0.00000071 	 loss = 0.0003(0.2947)
2024/03/04 11:16:43 - INFO - root -   Epoch: [248/300][120/200], lr: 0.00000071 	 loss = 1.1151(0.2780)
2024/03/04 11:16:51 - INFO - root -   Epoch: [248/300][140/200], lr: 0.00000071 	 loss = 1.2054(0.2774)
2024/03/04 11:16:59 - INFO - root -   Epoch: [248/300][160/200], lr: 0.00000071 	 loss = 0.1001(0.3002)
2024/03/04 11:17:23 - INFO - root -   Epoch: [248/300][180/200], lr: 0.00000071 	 loss = 0.0726(0.3102)
2024/03/04 11:17:31 - INFO - root -   Epoch: [248/300] 	 loss = 0.3123
2024/03/04 11:17:31 - INFO - root -   train_accuracy = 0.8850
2024/03/04 11:17:33 - INFO - root -   Epoch: [249/300][0/200], lr: 0.00000072 	 loss = 1.0824(1.0824)
2024/03/04 11:18:01 - INFO - root -   Epoch: [249/300][20/200], lr: 0.00000072 	 loss = 0.0031(0.3413)
2024/03/04 11:18:09 - INFO - root -   Epoch: [249/300][40/200], lr: 0.00000072 	 loss = 0.1620(0.2239)
2024/03/04 11:18:20 - INFO - root -   Epoch: [249/300][60/200], lr: 0.00000072 	 loss = 0.1536(0.2681)
2024/03/04 11:18:35 - INFO - root -   Epoch: [249/300][80/200], lr: 0.00000072 	 loss = 0.3697(0.2601)
2024/03/04 11:18:51 - INFO - root -   Epoch: [249/300][100/200], lr: 0.00000072 	 loss = 0.0034(0.2476)
2024/03/04 11:19:04 - INFO - root -   Epoch: [249/300][120/200], lr: 0.00000072 	 loss = 1.1596(0.2296)
2024/03/04 11:19:27 - INFO - root -   Epoch: [249/300][140/200], lr: 0.00000072 	 loss = 0.3556(0.2311)
2024/03/04 11:19:40 - INFO - root -   Epoch: [249/300][160/200], lr: 0.00000072 	 loss = 0.0953(0.2474)
2024/03/04 11:20:02 - INFO - root -   Epoch: [249/300][180/200], lr: 0.00000072 	 loss = 0.0202(0.2531)
2024/03/04 11:20:10 - INFO - root -   Epoch: [249/300] 	 loss = 0.2704
2024/03/04 11:20:14 - INFO - root -   precision = 0.6667
2024/03/04 11:20:14 - INFO - root -   eval_loss = 2.1812
2024/03/04 11:20:14 - INFO - root -   eval_acc = 0.6667
2024/03/04 11:20:15 - INFO - root -   train_accuracy = 0.9000
2024/03/04 11:20:16 - INFO - root -   Epoch: [250/300][0/200], lr: 0.00000072 	 loss = 0.3138(0.3138)
2024/03/04 11:20:43 - INFO - root -   Epoch: [250/300][20/200], lr: 0.00000072 	 loss = 0.1110(0.4332)
2024/03/04 11:20:58 - INFO - root -   Epoch: [250/300][40/200], lr: 0.00000072 	 loss = 0.0022(0.3468)
2024/03/04 11:21:08 - INFO - root -   Epoch: [250/300][60/200], lr: 0.00000072 	 loss = 0.0628(0.3187)
2024/03/04 11:21:20 - INFO - root -   Epoch: [250/300][80/200], lr: 0.00000072 	 loss = 1.4903(0.3205)
2024/03/04 11:21:28 - INFO - root -   Epoch: [250/300][100/200], lr: 0.00000072 	 loss = 0.0031(0.2925)
2024/03/04 11:21:56 - INFO - root -   Epoch: [250/300][120/200], lr: 0.00000072 	 loss = 2.6417(0.3196)
2024/03/04 11:22:08 - INFO - root -   Epoch: [250/300][140/200], lr: 0.00000072 	 loss = 0.4687(0.3104)
2024/03/04 11:22:25 - INFO - root -   Epoch: [250/300][160/200], lr: 0.00000072 	 loss = 0.0516(0.2944)
2024/03/04 11:22:33 - INFO - root -   Epoch: [250/300][180/200], lr: 0.00000072 	 loss = 0.0038(0.2892)
2024/03/04 11:22:41 - INFO - root -   Epoch: [250/300] 	 loss = 0.2927
2024/03/04 11:22:41 - INFO - root -   train_accuracy = 0.8950
2024/03/04 11:22:42 - INFO - root -   Epoch: [251/300][0/200], lr: 0.00000072 	 loss = 0.0598(0.0598)
2024/03/04 11:23:05 - INFO - root -   Epoch: [251/300][20/200], lr: 0.00000072 	 loss = 0.0006(0.2816)
2024/03/04 11:23:29 - INFO - root -   Epoch: [251/300][40/200], lr: 0.00000072 	 loss = 0.1577(0.2289)
2024/03/04 11:23:40 - INFO - root -   Epoch: [251/300][60/200], lr: 0.00000072 	 loss = 0.0050(0.2158)
2024/03/04 11:23:52 - INFO - root -   Epoch: [251/300][80/200], lr: 0.00000072 	 loss = 0.1399(0.2223)
2024/03/04 11:24:09 - INFO - root -   Epoch: [251/300][100/200], lr: 0.00000072 	 loss = 0.0712(0.2155)
2024/03/04 11:24:22 - INFO - root -   Epoch: [251/300][120/200], lr: 0.00000072 	 loss = 0.8795(0.2176)
2024/03/04 11:24:35 - INFO - root -   Epoch: [251/300][140/200], lr: 0.00000072 	 loss = 1.6993(0.2237)
2024/03/04 11:24:53 - INFO - root -   Epoch: [251/300][160/200], lr: 0.00000072 	 loss = 0.2773(0.2248)
2024/03/04 11:25:05 - INFO - root -   Epoch: [251/300][180/200], lr: 0.00000072 	 loss = 0.0005(0.2318)
2024/03/04 11:25:13 - INFO - root -   Epoch: [251/300] 	 loss = 0.2373
2024/03/04 11:25:13 - INFO - root -   train_accuracy = 0.9125
2024/03/04 11:25:14 - INFO - root -   Epoch: [252/300][0/200], lr: 0.00000072 	 loss = 0.0879(0.0879)
2024/03/04 11:25:45 - INFO - root -   Epoch: [252/300][20/200], lr: 0.00000072 	 loss = 0.0073(0.3455)
2024/03/04 11:26:07 - INFO - root -   Epoch: [252/300][40/200], lr: 0.00000072 	 loss = 0.2222(0.2747)
2024/03/04 11:26:22 - INFO - root -   Epoch: [252/300][60/200], lr: 0.00000072 	 loss = 0.0460(0.2960)
2024/03/04 11:26:30 - INFO - root -   Epoch: [252/300][80/200], lr: 0.00000072 	 loss = 1.6881(0.3213)
2024/03/04 11:26:38 - INFO - root -   Epoch: [252/300][100/200], lr: 0.00000072 	 loss = 0.0274(0.2845)
2024/03/04 11:26:55 - INFO - root -   Epoch: [252/300][120/200], lr: 0.00000072 	 loss = 0.3831(0.2742)
2024/03/04 11:27:27 - INFO - root -   Epoch: [252/300][140/200], lr: 0.00000072 	 loss = 0.3521(0.2693)
2024/03/04 11:27:35 - INFO - root -   Epoch: [252/300][160/200], lr: 0.00000072 	 loss = 0.0048(0.2786)
2024/03/04 11:27:47 - INFO - root -   Epoch: [252/300][180/200], lr: 0.00000072 	 loss = 0.0211(0.2839)
2024/03/04 11:27:57 - INFO - root -   Epoch: [252/300] 	 loss = 0.2929
2024/03/04 11:27:57 - INFO - root -   train_accuracy = 0.8975
2024/03/04 11:28:17 - INFO - root -   Epoch: [253/300][0/200], lr: 0.00000073 	 loss = 0.2777(0.2777)
2024/03/04 11:28:25 - INFO - root -   Epoch: [253/300][20/200], lr: 0.00000073 	 loss = 0.0077(0.3890)
2024/03/04 11:28:34 - INFO - root -   Epoch: [253/300][40/200], lr: 0.00000073 	 loss = 0.0025(0.2611)
2024/03/04 11:28:55 - INFO - root -   Epoch: [253/300][60/200], lr: 0.00000073 	 loss = 0.0095(0.2869)
2024/03/04 11:29:03 - INFO - root -   Epoch: [253/300][80/200], lr: 0.00000073 	 loss = 0.2002(0.2483)
2024/03/04 11:29:15 - INFO - root -   Epoch: [253/300][100/200], lr: 0.00000073 	 loss = 0.0098(0.2273)
2024/03/04 11:29:30 - INFO - root -   Epoch: [253/300][120/200], lr: 0.00000073 	 loss = 1.2120(0.2220)
2024/03/04 11:29:48 - INFO - root -   Epoch: [253/300][140/200], lr: 0.00000073 	 loss = 0.0499(0.2457)
2024/03/04 11:30:12 - INFO - root -   Epoch: [253/300][160/200], lr: 0.00000073 	 loss = 0.1411(0.2569)
2024/03/04 11:30:20 - INFO - root -   Epoch: [253/300][180/200], lr: 0.00000073 	 loss = 0.1370(0.2695)
2024/03/04 11:30:27 - INFO - root -   Epoch: [253/300] 	 loss = 0.2899
2024/03/04 11:30:27 - INFO - root -   train_accuracy = 0.9000
2024/03/04 11:30:43 - INFO - root -   Epoch: [254/300][0/200], lr: 0.00000073 	 loss = 0.0999(0.0999)
2024/03/04 11:30:57 - INFO - root -   Epoch: [254/300][20/200], lr: 0.00000073 	 loss = 0.2649(0.3639)
2024/03/04 11:31:22 - INFO - root -   Epoch: [254/300][40/200], lr: 0.00000073 	 loss = 0.0078(0.2968)
2024/03/04 11:31:30 - INFO - root -   Epoch: [254/300][60/200], lr: 0.00000073 	 loss = 0.0073(0.2851)
2024/03/04 11:31:38 - INFO - root -   Epoch: [254/300][80/200], lr: 0.00000073 	 loss = 1.6119(0.2944)
2024/03/04 11:31:55 - INFO - root -   Epoch: [254/300][100/200], lr: 0.00000073 	 loss = 0.1299(0.2650)
2024/03/04 11:32:06 - INFO - root -   Epoch: [254/300][120/200], lr: 0.00000073 	 loss = 1.2675(0.2471)
2024/03/04 11:32:33 - INFO - root -   Epoch: [254/300][140/200], lr: 0.00000073 	 loss = 1.1733(0.2707)
2024/03/04 11:32:41 - INFO - root -   Epoch: [254/300][160/200], lr: 0.00000073 	 loss = 0.1599(0.2539)
2024/03/04 11:32:54 - INFO - root -   Epoch: [254/300][180/200], lr: 0.00000073 	 loss = 0.1177(0.2564)
2024/03/04 11:33:03 - INFO - root -   Epoch: [254/300] 	 loss = 0.2618
2024/03/04 11:33:07 - INFO - root -   precision = 0.6667
2024/03/04 11:33:07 - INFO - root -   eval_loss = 2.2980
2024/03/04 11:33:07 - INFO - root -   eval_acc = 0.6667
2024/03/04 11:33:08 - INFO - root -   train_accuracy = 0.9175
2024/03/04 11:33:23 - INFO - root -   Epoch: [255/300][0/200], lr: 0.00000073 	 loss = 0.0576(0.0576)
2024/03/04 11:33:39 - INFO - root -   Epoch: [255/300][20/200], lr: 0.00000073 	 loss = 0.0078(0.2644)
2024/03/04 11:33:47 - INFO - root -   Epoch: [255/300][40/200], lr: 0.00000073 	 loss = 0.0020(0.2300)
2024/03/04 11:33:58 - INFO - root -   Epoch: [255/300][60/200], lr: 0.00000073 	 loss = 0.0290(0.2610)
2024/03/04 11:34:17 - INFO - root -   Epoch: [255/300][80/200], lr: 0.00000073 	 loss = 0.3900(0.2574)
2024/03/04 11:34:34 - INFO - root -   Epoch: [255/300][100/200], lr: 0.00000073 	 loss = 0.0002(0.2512)
2024/03/04 11:34:52 - INFO - root -   Epoch: [255/300][120/200], lr: 0.00000073 	 loss = 0.8311(0.2498)
2024/03/04 11:35:00 - INFO - root -   Epoch: [255/300][140/200], lr: 0.00000073 	 loss = 0.8962(0.2423)
2024/03/04 11:35:22 - INFO - root -   Epoch: [255/300][160/200], lr: 0.00000073 	 loss = 0.1594(0.2338)
2024/03/04 11:35:38 - INFO - root -   Epoch: [255/300][180/200], lr: 0.00000073 	 loss = 0.0098(0.2604)
2024/03/04 11:35:45 - INFO - root -   Epoch: [255/300] 	 loss = 0.2644
2024/03/04 11:35:45 - INFO - root -   train_accuracy = 0.9100
2024/03/04 11:35:46 - INFO - root -   Epoch: [256/300][0/200], lr: 0.00000073 	 loss = 0.0427(0.0427)
2024/03/04 11:36:12 - INFO - root -   Epoch: [256/300][20/200], lr: 0.00000073 	 loss = 0.0127(0.2893)
2024/03/04 11:36:30 - INFO - root -   Epoch: [256/300][40/200], lr: 0.00000073 	 loss = 0.0019(0.3133)
2024/03/04 11:36:38 - INFO - root -   Epoch: [256/300][60/200], lr: 0.00000073 	 loss = 0.0033(0.3408)
2024/03/04 11:36:57 - INFO - root -   Epoch: [256/300][80/200], lr: 0.00000073 	 loss = 0.4416(0.3433)
2024/03/04 11:37:24 - INFO - root -   Epoch: [256/300][100/200], lr: 0.00000073 	 loss = 0.0013(0.3129)
2024/03/04 11:37:31 - INFO - root -   Epoch: [256/300][120/200], lr: 0.00000073 	 loss = 0.7549(0.2899)
2024/03/04 11:37:39 - INFO - root -   Epoch: [256/300][140/200], lr: 0.00000073 	 loss = 0.1836(0.2974)
2024/03/04 11:38:00 - INFO - root -   Epoch: [256/300][160/200], lr: 0.00000073 	 loss = 0.1651(0.3015)
2024/03/04 11:38:13 - INFO - root -   Epoch: [256/300][180/200], lr: 0.00000073 	 loss = 0.3886(0.2898)
2024/03/04 11:38:21 - INFO - root -   Epoch: [256/300] 	 loss = 0.3032
2024/03/04 11:38:21 - INFO - root -   train_accuracy = 0.8975
2024/03/04 11:38:22 - INFO - root -   Epoch: [257/300][0/200], lr: 0.00000074 	 loss = 0.0833(0.0833)
2024/03/04 11:38:48 - INFO - root -   Epoch: [257/300][20/200], lr: 0.00000074 	 loss = 0.1224(0.3928)
2024/03/04 11:39:10 - INFO - root -   Epoch: [257/300][40/200], lr: 0.00000074 	 loss = 0.1349(0.3824)
2024/03/04 11:39:24 - INFO - root -   Epoch: [257/300][60/200], lr: 0.00000074 	 loss = 0.1324(0.3782)
2024/03/04 11:39:35 - INFO - root -   Epoch: [257/300][80/200], lr: 0.00000074 	 loss = 0.0753(0.3445)
2024/03/04 11:39:49 - INFO - root -   Epoch: [257/300][100/200], lr: 0.00000074 	 loss = 0.1081(0.3206)
2024/03/04 11:40:06 - INFO - root -   Epoch: [257/300][120/200], lr: 0.00000074 	 loss = 1.3096(0.3056)
2024/03/04 11:40:14 - INFO - root -   Epoch: [257/300][140/200], lr: 0.00000074 	 loss = 0.6433(0.2916)
2024/03/04 11:40:22 - INFO - root -   Epoch: [257/300][160/200], lr: 0.00000074 	 loss = 0.0862(0.2919)
2024/03/04 11:40:36 - INFO - root -   Epoch: [257/300][180/200], lr: 0.00000074 	 loss = 0.0189(0.2873)
2024/03/04 11:40:52 - INFO - root -   Epoch: [257/300] 	 loss = 0.2768
2024/03/04 11:40:52 - INFO - root -   train_accuracy = 0.9000
2024/03/04 11:40:55 - INFO - root -   Epoch: [258/300][0/200], lr: 0.00000074 	 loss = 0.6075(0.6075)
2024/03/04 11:41:26 - INFO - root -   Epoch: [258/300][20/200], lr: 0.00000074 	 loss = 0.0082(0.4162)
2024/03/04 11:41:41 - INFO - root -   Epoch: [258/300][40/200], lr: 0.00000074 	 loss = 0.0686(0.2834)
2024/03/04 11:41:49 - INFO - root -   Epoch: [258/300][60/200], lr: 0.00000074 	 loss = 0.0452(0.3299)
2024/03/04 11:42:05 - INFO - root -   Epoch: [258/300][80/200], lr: 0.00000074 	 loss = 0.1100(0.3181)
2024/03/04 11:42:22 - INFO - root -   Epoch: [258/300][100/200], lr: 0.00000074 	 loss = 0.0778(0.2812)
2024/03/04 11:42:43 - INFO - root -   Epoch: [258/300][120/200], lr: 0.00000074 	 loss = 0.8758(0.2712)
2024/03/04 11:42:59 - INFO - root -   Epoch: [258/300][140/200], lr: 0.00000074 	 loss = 0.4348(0.2828)
2024/03/04 11:43:17 - INFO - root -   Epoch: [258/300][160/200], lr: 0.00000074 	 loss = 0.1400(0.3025)
2024/03/04 11:43:27 - INFO - root -   Epoch: [258/300][180/200], lr: 0.00000074 	 loss = 0.1709(0.2953)
2024/03/04 11:43:35 - INFO - root -   Epoch: [258/300] 	 loss = 0.2886
2024/03/04 11:43:35 - INFO - root -   train_accuracy = 0.8950
2024/03/04 11:43:36 - INFO - root -   Epoch: [259/300][0/200], lr: 0.00000074 	 loss = 0.0770(0.0770)
2024/03/04 11:44:04 - INFO - root -   Epoch: [259/300][20/200], lr: 0.00000074 	 loss = 0.0767(0.3391)
2024/03/04 11:44:18 - INFO - root -   Epoch: [259/300][40/200], lr: 0.00000074 	 loss = 0.2752(0.2204)
2024/03/04 11:44:33 - INFO - root -   Epoch: [259/300][60/200], lr: 0.00000074 	 loss = 0.0294(0.2303)
2024/03/04 11:44:45 - INFO - root -   Epoch: [259/300][80/200], lr: 0.00000074 	 loss = 0.5703(0.2816)
2024/03/04 11:45:03 - INFO - root -   Epoch: [259/300][100/200], lr: 0.00000074 	 loss = 0.0003(0.2659)
2024/03/04 11:45:21 - INFO - root -   Epoch: [259/300][120/200], lr: 0.00000074 	 loss = 0.6861(0.2447)
2024/03/04 11:45:42 - INFO - root -   Epoch: [259/300][140/200], lr: 0.00000074 	 loss = 1.2090(0.2650)
2024/03/04 11:45:50 - INFO - root -   Epoch: [259/300][160/200], lr: 0.00000074 	 loss = 0.0356(0.2665)
2024/03/04 11:46:09 - INFO - root -   Epoch: [259/300][180/200], lr: 0.00000074 	 loss = 0.0510(0.2767)
2024/03/04 11:46:17 - INFO - root -   Epoch: [259/300] 	 loss = 0.2889
2024/03/04 11:46:20 - INFO - root -   precision = 0.6667
2024/03/04 11:46:20 - INFO - root -   eval_loss = 2.3639
2024/03/04 11:46:20 - INFO - root -   eval_acc = 0.6667
2024/03/04 11:46:21 - INFO - root -   train_accuracy = 0.8900
2024/03/04 11:46:37 - INFO - root -   Epoch: [260/300][0/200], lr: 0.00000074 	 loss = 0.6592(0.6592)
2024/03/04 11:46:57 - INFO - root -   Epoch: [260/300][20/200], lr: 0.00000074 	 loss = 0.1407(0.4252)
2024/03/04 11:47:12 - INFO - root -   Epoch: [260/300][40/200], lr: 0.00000074 	 loss = 0.0702(0.3030)
2024/03/04 11:47:33 - INFO - root -   Epoch: [260/300][60/200], lr: 0.00000074 	 loss = 0.0004(0.3020)
2024/03/04 11:47:40 - INFO - root -   Epoch: [260/300][80/200], lr: 0.00000074 	 loss = 0.7269(0.2950)
2024/03/04 11:48:02 - INFO - root -   Epoch: [260/300][100/200], lr: 0.00000074 	 loss = 0.0015(0.2663)
2024/03/04 11:48:18 - INFO - root -   Epoch: [260/300][120/200], lr: 0.00000074 	 loss = 1.4848(0.2544)
2024/03/04 11:48:26 - INFO - root -   Epoch: [260/300][140/200], lr: 0.00000074 	 loss = 0.3107(0.2752)
2024/03/04 11:48:41 - INFO - root -   Epoch: [260/300][160/200], lr: 0.00000074 	 loss = 0.0144(0.2613)
2024/03/04 11:49:04 - INFO - root -   Epoch: [260/300][180/200], lr: 0.00000074 	 loss = 0.5968(0.2691)
2024/03/04 11:49:11 - INFO - root -   Epoch: [260/300] 	 loss = 0.2735
2024/03/04 11:49:11 - INFO - root -   train_accuracy = 0.9125
2024/03/04 11:49:12 - INFO - root -   Epoch: [261/300][0/200], lr: 0.00000075 	 loss = 0.0784(0.0784)
2024/03/04 11:49:39 - INFO - root -   Epoch: [261/300][20/200], lr: 0.00000075 	 loss = 0.0024(0.2151)
2024/03/04 11:49:47 - INFO - root -   Epoch: [261/300][40/200], lr: 0.00000075 	 loss = 0.1149(0.1795)
2024/03/04 11:50:10 - INFO - root -   Epoch: [261/300][60/200], lr: 0.00000075 	 loss = 0.0773(0.2429)
2024/03/04 11:50:20 - INFO - root -   Epoch: [261/300][80/200], lr: 0.00000075 	 loss = 0.1079(0.2609)
2024/03/04 11:50:37 - INFO - root -   Epoch: [261/300][100/200], lr: 0.00000075 	 loss = 0.0001(0.2517)
2024/03/04 11:50:48 - INFO - root -   Epoch: [261/300][120/200], lr: 0.00000075 	 loss = 0.6622(0.2394)
2024/03/04 11:50:59 - INFO - root -   Epoch: [261/300][140/200], lr: 0.00000075 	 loss = 1.2848(0.2647)
2024/03/04 11:51:11 - INFO - root -   Epoch: [261/300][160/200], lr: 0.00000075 	 loss = 0.0811(0.2561)
2024/03/04 11:51:28 - INFO - root -   Epoch: [261/300][180/200], lr: 0.00000075 	 loss = 0.0129(0.2595)
2024/03/04 11:51:35 - INFO - root -   Epoch: [261/300] 	 loss = 0.2632
2024/03/04 11:51:35 - INFO - root -   train_accuracy = 0.9100
2024/03/04 11:51:52 - INFO - root -   Epoch: [262/300][0/200], lr: 0.00000075 	 loss = 0.3568(0.3568)
2024/03/04 11:52:02 - INFO - root -   Epoch: [262/300][20/200], lr: 0.00000075 	 loss = 0.2419(0.5030)
2024/03/04 11:52:12 - INFO - root -   Epoch: [262/300][40/200], lr: 0.00000075 	 loss = 0.0011(0.4113)
2024/03/04 11:52:34 - INFO - root -   Epoch: [262/300][60/200], lr: 0.00000075 	 loss = 0.0359(0.3830)
2024/03/04 11:52:42 - INFO - root -   Epoch: [262/300][80/200], lr: 0.00000075 	 loss = 0.1821(0.3511)
2024/03/04 11:52:50 - INFO - root -   Epoch: [262/300][100/200], lr: 0.00000075 	 loss = 0.0033(0.3156)
2024/03/04 11:53:14 - INFO - root -   Epoch: [262/300][120/200], lr: 0.00000075 	 loss = 0.7512(0.3046)
2024/03/04 11:53:22 - INFO - root -   Epoch: [262/300][140/200], lr: 0.00000075 	 loss = 0.0617(0.3225)
2024/03/04 11:53:48 - INFO - root -   Epoch: [262/300][160/200], lr: 0.00000075 	 loss = 0.1264(0.3165)
2024/03/04 11:53:56 - INFO - root -   Epoch: [262/300][180/200], lr: 0.00000075 	 loss = 0.0365(0.3159)
2024/03/04 11:54:09 - INFO - root -   Epoch: [262/300] 	 loss = 0.3198
2024/03/04 11:54:09 - INFO - root -   train_accuracy = 0.8800
2024/03/04 11:54:11 - INFO - root -   Epoch: [263/300][0/200], lr: 0.00000075 	 loss = 0.2207(0.2207)
2024/03/04 11:54:35 - INFO - root -   Epoch: [263/300][20/200], lr: 0.00000075 	 loss = 0.1318(0.2926)
2024/03/04 11:54:50 - INFO - root -   Epoch: [263/300][40/200], lr: 0.00000075 	 loss = 0.0038(0.3141)
2024/03/04 11:54:58 - INFO - root -   Epoch: [263/300][60/200], lr: 0.00000075 	 loss = 0.1949(0.2945)
2024/03/04 11:55:06 - INFO - root -   Epoch: [263/300][80/200], lr: 0.00000075 	 loss = 0.2950(0.2977)
2024/03/04 11:55:23 - INFO - root -   Epoch: [263/300][100/200], lr: 0.00000075 	 loss = 0.1097(0.2792)
2024/03/04 11:55:39 - INFO - root -   Epoch: [263/300][120/200], lr: 0.00000075 	 loss = 1.8993(0.2902)
2024/03/04 11:56:04 - INFO - root -   Epoch: [263/300][140/200], lr: 0.00000075 	 loss = 0.2436(0.2856)
2024/03/04 11:56:12 - INFO - root -   Epoch: [263/300][160/200], lr: 0.00000075 	 loss = 0.0011(0.2639)
2024/03/04 11:56:24 - INFO - root -   Epoch: [263/300][180/200], lr: 0.00000075 	 loss = 0.1489(0.2686)
2024/03/04 11:56:35 - INFO - root -   Epoch: [263/300] 	 loss = 0.2802
2024/03/04 11:56:35 - INFO - root -   train_accuracy = 0.9025
2024/03/04 11:56:49 - INFO - root -   Epoch: [264/300][0/200], lr: 0.00000075 	 loss = 1.1254(1.1254)
2024/03/04 11:57:11 - INFO - root -   Epoch: [264/300][20/200], lr: 0.00000075 	 loss = 0.0783(0.3627)
2024/03/04 11:57:25 - INFO - root -   Epoch: [264/300][40/200], lr: 0.00000075 	 loss = 0.0038(0.3065)
2024/03/04 11:57:48 - INFO - root -   Epoch: [264/300][60/200], lr: 0.00000075 	 loss = 0.3297(0.3392)
2024/03/04 11:57:56 - INFO - root -   Epoch: [264/300][80/200], lr: 0.00000075 	 loss = 0.3291(0.3297)
2024/03/04 11:58:20 - INFO - root -   Epoch: [264/300][100/200], lr: 0.00000075 	 loss = 0.0001(0.3168)
2024/03/04 11:58:28 - INFO - root -   Epoch: [264/300][120/200], lr: 0.00000075 	 loss = 0.6775(0.3044)
2024/03/04 11:58:50 - INFO - root -   Epoch: [264/300][140/200], lr: 0.00000075 	 loss = 0.3719(0.2857)
2024/03/04 11:58:58 - INFO - root -   Epoch: [264/300][160/200], lr: 0.00000075 	 loss = 0.0533(0.2883)
2024/03/04 11:59:24 - INFO - root -   Epoch: [264/300][180/200], lr: 0.00000075 	 loss = 0.0135(0.3046)
2024/03/04 11:59:32 - INFO - root -   Epoch: [264/300] 	 loss = 0.3125
2024/03/04 11:59:35 - INFO - root -   precision = 0.6667
2024/03/04 11:59:35 - INFO - root -   eval_loss = 2.2612
2024/03/04 11:59:35 - INFO - root -   eval_acc = 0.6667
2024/03/04 11:59:36 - INFO - root -   train_accuracy = 0.9000
2024/03/04 11:59:38 - INFO - root -   Epoch: [265/300][0/200], lr: 0.00000076 	 loss = 0.1371(0.1371)
2024/03/04 12:00:06 - INFO - root -   Epoch: [265/300][20/200], lr: 0.00000076 	 loss = 0.0011(0.4423)
2024/03/04 12:00:25 - INFO - root -   Epoch: [265/300][40/200], lr: 0.00000076 	 loss = 0.2160(0.3155)
2024/03/04 12:00:41 - INFO - root -   Epoch: [265/300][60/200], lr: 0.00000076 	 loss = 0.1662(0.3125)
2024/03/04 12:01:04 - INFO - root -   Epoch: [265/300][80/200], lr: 0.00000076 	 loss = 1.1190(0.3146)
2024/03/04 12:01:12 - INFO - root -   Epoch: [265/300][100/200], lr: 0.00000076 	 loss = 0.0003(0.2796)
2024/03/04 12:01:28 - INFO - root -   Epoch: [265/300][120/200], lr: 0.00000076 	 loss = 1.2581(0.2804)
2024/03/04 12:01:36 - INFO - root -   Epoch: [265/300][140/200], lr: 0.00000076 	 loss = 0.2613(0.2805)
2024/03/04 12:01:50 - INFO - root -   Epoch: [265/300][160/200], lr: 0.00000076 	 loss = 0.0055(0.2718)
2024/03/04 12:02:09 - INFO - root -   Epoch: [265/300][180/200], lr: 0.00000076 	 loss = 0.1457(0.2863)
2024/03/04 12:02:17 - INFO - root -   Epoch: [265/300] 	 loss = 0.2843
2024/03/04 12:02:17 - INFO - root -   train_accuracy = 0.9000
2024/03/04 12:02:32 - INFO - root -   Epoch: [266/300][0/200], lr: 0.00000076 	 loss = 0.7660(0.7660)
2024/03/04 12:02:47 - INFO - root -   Epoch: [266/300][20/200], lr: 0.00000076 	 loss = 0.0049(0.4205)
2024/03/04 12:03:05 - INFO - root -   Epoch: [266/300][40/200], lr: 0.00000076 	 loss = 0.2771(0.3480)
2024/03/04 12:03:17 - INFO - root -   Epoch: [266/300][60/200], lr: 0.00000076 	 loss = 0.0017(0.3611)
2024/03/04 12:03:33 - INFO - root -   Epoch: [266/300][80/200], lr: 0.00000076 	 loss = 0.7756(0.3460)
2024/03/04 12:03:52 - INFO - root -   Epoch: [266/300][100/200], lr: 0.00000076 	 loss = 0.3594(0.3600)
2024/03/04 12:04:07 - INFO - root -   Epoch: [266/300][120/200], lr: 0.00000076 	 loss = 1.1375(0.3408)
2024/03/04 12:04:15 - INFO - root -   Epoch: [266/300][140/200], lr: 0.00000076 	 loss = 0.1714(0.3230)
2024/03/04 12:04:36 - INFO - root -   Epoch: [266/300][160/200], lr: 0.00000076 	 loss = 0.0391(0.3171)
2024/03/04 12:04:44 - INFO - root -   Epoch: [266/300][180/200], lr: 0.00000076 	 loss = 0.0224(0.3179)
2024/03/04 12:04:52 - INFO - root -   Epoch: [266/300] 	 loss = 0.3172
2024/03/04 12:04:52 - INFO - root -   train_accuracy = 0.8800
2024/03/04 12:04:54 - INFO - root -   Epoch: [267/300][0/200], lr: 0.00000076 	 loss = 0.0612(0.0612)
2024/03/04 12:05:28 - INFO - root -   Epoch: [267/300][20/200], lr: 0.00000076 	 loss = 0.1228(0.3403)
2024/03/04 12:05:39 - INFO - root -   Epoch: [267/300][40/200], lr: 0.00000076 	 loss = 0.0121(0.2716)
2024/03/04 12:05:55 - INFO - root -   Epoch: [267/300][60/200], lr: 0.00000076 	 loss = 0.3646(0.2497)
2024/03/04 12:06:10 - INFO - root -   Epoch: [267/300][80/200], lr: 0.00000076 	 loss = 1.1643(0.2637)
2024/03/04 12:06:32 - INFO - root -   Epoch: [267/300][100/200], lr: 0.00000076 	 loss = 0.1050(0.2573)
2024/03/04 12:06:41 - INFO - root -   Epoch: [267/300][120/200], lr: 0.00000076 	 loss = 2.5643(0.2821)
2024/03/04 12:07:02 - INFO - root -   Epoch: [267/300][140/200], lr: 0.00000076 	 loss = 0.2687(0.2827)
2024/03/04 12:07:10 - INFO - root -   Epoch: [267/300][160/200], lr: 0.00000076 	 loss = 0.0659(0.2873)
2024/03/04 12:07:27 - INFO - root -   Epoch: [267/300][180/200], lr: 0.00000076 	 loss = 0.0419(0.2744)
2024/03/04 12:07:35 - INFO - root -   Epoch: [267/300] 	 loss = 0.2799
2024/03/04 12:07:35 - INFO - root -   train_accuracy = 0.8900
2024/03/04 12:07:57 - INFO - root -   Epoch: [268/300][0/200], lr: 0.00000076 	 loss = 0.4866(0.4866)
2024/03/04 12:08:05 - INFO - root -   Epoch: [268/300][20/200], lr: 0.00000076 	 loss = 0.0003(0.5228)
2024/03/04 12:08:13 - INFO - root -   Epoch: [268/300][40/200], lr: 0.00000076 	 loss = 0.0102(0.3481)
2024/03/04 12:08:44 - INFO - root -   Epoch: [268/300][60/200], lr: 0.00000076 	 loss = 0.0062(0.3397)
2024/03/04 12:08:56 - INFO - root -   Epoch: [268/300][80/200], lr: 0.00000076 	 loss = 0.9113(0.3639)
2024/03/04 12:09:09 - INFO - root -   Epoch: [268/300][100/200], lr: 0.00000076 	 loss = 0.0001(0.3675)
2024/03/04 12:09:24 - INFO - root -   Epoch: [268/300][120/200], lr: 0.00000076 	 loss = 1.6436(0.3400)
2024/03/04 12:09:37 - INFO - root -   Epoch: [268/300][140/200], lr: 0.00000076 	 loss = 0.0747(0.3291)
2024/03/04 12:09:53 - INFO - root -   Epoch: [268/300][160/200], lr: 0.00000076 	 loss = 0.0482(0.3213)
2024/03/04 12:10:11 - INFO - root -   Epoch: [268/300][180/200], lr: 0.00000076 	 loss = 0.0017(0.3044)
2024/03/04 12:10:19 - INFO - root -   Epoch: [268/300] 	 loss = 0.2967
2024/03/04 12:10:19 - INFO - root -   train_accuracy = 0.8825
2024/03/04 12:10:30 - INFO - root -   Epoch: [269/300][0/200], lr: 0.00000077 	 loss = 1.7289(1.7289)
2024/03/04 12:10:46 - INFO - root -   Epoch: [269/300][20/200], lr: 0.00000077 	 loss = 0.0660(0.3697)
2024/03/04 12:10:57 - INFO - root -   Epoch: [269/300][40/200], lr: 0.00000077 	 loss = 0.0036(0.2402)
2024/03/04 12:11:24 - INFO - root -   Epoch: [269/300][60/200], lr: 0.00000077 	 loss = 0.1660(0.2515)
2024/03/04 12:11:32 - INFO - root -   Epoch: [269/300][80/200], lr: 0.00000077 	 loss = 1.0429(0.2625)
2024/03/04 12:11:48 - INFO - root -   Epoch: [269/300][100/200], lr: 0.00000077 	 loss = 0.0001(0.2502)
2024/03/04 12:12:16 - INFO - root -   Epoch: [269/300][120/200], lr: 0.00000077 	 loss = 1.1513(0.2524)
2024/03/04 12:12:26 - INFO - root -   Epoch: [269/300][140/200], lr: 0.00000077 	 loss = 0.4458(0.2688)
2024/03/04 12:12:36 - INFO - root -   Epoch: [269/300][160/200], lr: 0.00000077 	 loss = 0.0103(0.2634)
2024/03/04 12:12:52 - INFO - root -   Epoch: [269/300][180/200], lr: 0.00000077 	 loss = 0.0141(0.2775)
2024/03/04 12:13:00 - INFO - root -   Epoch: [269/300] 	 loss = 0.2700
2024/03/04 12:13:03 - INFO - root -   precision = 0.6667
2024/03/04 12:13:03 - INFO - root -   eval_loss = 2.4096
2024/03/04 12:13:03 - INFO - root -   eval_acc = 0.6667
2024/03/04 12:13:04 - INFO - root -   train_accuracy = 0.9000
2024/03/04 12:13:05 - INFO - root -   Epoch: [270/300][0/200], lr: 0.00000077 	 loss = 0.0838(0.0838)
2024/03/04 12:13:27 - INFO - root -   Epoch: [270/300][20/200], lr: 0.00000077 	 loss = 0.1106(0.4404)
2024/03/04 12:13:49 - INFO - root -   Epoch: [270/300][40/200], lr: 0.00000077 	 loss = 0.0010(0.3492)
2024/03/04 12:14:08 - INFO - root -   Epoch: [270/300][60/200], lr: 0.00000077 	 loss = 0.1778(0.3341)
2024/03/04 12:14:25 - INFO - root -   Epoch: [270/300][80/200], lr: 0.00000077 	 loss = 1.7081(0.3726)
2024/03/04 12:14:50 - INFO - root -   Epoch: [270/300][100/200], lr: 0.00000077 	 loss = 0.1453(0.3469)
2024/03/04 12:15:02 - INFO - root -   Epoch: [270/300][120/200], lr: 0.00000077 	 loss = 1.7454(0.3283)
2024/03/04 12:15:27 - INFO - root -   Epoch: [270/300][140/200], lr: 0.00000077 	 loss = 0.0605(0.3586)
2024/03/04 12:15:45 - INFO - root -   Epoch: [270/300][160/200], lr: 0.00000077 	 loss = 0.0124(0.3500)
2024/03/04 12:15:53 - INFO - root -   Epoch: [270/300][180/200], lr: 0.00000077 	 loss = 0.0214(0.3544)
2024/03/04 12:16:00 - INFO - root -   Epoch: [270/300] 	 loss = 0.3429
2024/03/04 12:16:00 - INFO - root -   train_accuracy = 0.8700
2024/03/04 12:16:01 - INFO - root -   Epoch: [271/300][0/200], lr: 0.00000077 	 loss = 0.2358(0.2358)
2024/03/04 12:16:35 - INFO - root -   Epoch: [271/300][20/200], lr: 0.00000077 	 loss = 0.0866(0.3294)
2024/03/04 12:16:50 - INFO - root -   Epoch: [271/300][40/200], lr: 0.00000077 	 loss = 0.1330(0.2386)
2024/03/04 12:17:04 - INFO - root -   Epoch: [271/300][60/200], lr: 0.00000077 	 loss = 0.0195(0.3003)
2024/03/04 12:17:19 - INFO - root -   Epoch: [271/300][80/200], lr: 0.00000077 	 loss = 1.9343(0.3189)
2024/03/04 12:17:27 - INFO - root -   Epoch: [271/300][100/200], lr: 0.00000077 	 loss = 0.0015(0.3012)
2024/03/04 12:17:43 - INFO - root -   Epoch: [271/300][120/200], lr: 0.00000077 	 loss = 1.1403(0.2925)
2024/03/04 12:17:54 - INFO - root -   Epoch: [271/300][140/200], lr: 0.00000077 	 loss = 0.2406(0.2933)
2024/03/04 12:18:15 - INFO - root -   Epoch: [271/300][160/200], lr: 0.00000077 	 loss = 0.1725(0.2992)
2024/03/04 12:18:31 - INFO - root -   Epoch: [271/300][180/200], lr: 0.00000077 	 loss = 0.9411(0.3053)
2024/03/04 12:18:38 - INFO - root -   Epoch: [271/300] 	 loss = 0.2975
2024/03/04 12:18:38 - INFO - root -   train_accuracy = 0.8850
2024/03/04 12:18:54 - INFO - root -   Epoch: [272/300][0/200], lr: 0.00000077 	 loss = 0.2427(0.2427)
2024/03/04 12:19:06 - INFO - root -   Epoch: [272/300][20/200], lr: 0.00000077 	 loss = 0.1259(0.3120)
2024/03/04 12:19:32 - INFO - root -   Epoch: [272/300][40/200], lr: 0.00000077 	 loss = 0.1260(0.2720)
2024/03/04 12:19:40 - INFO - root -   Epoch: [272/300][60/200], lr: 0.00000077 	 loss = 0.0056(0.2710)
2024/03/04 12:19:52 - INFO - root -   Epoch: [272/300][80/200], lr: 0.00000077 	 loss = 0.9340(0.2865)
2024/03/04 12:20:08 - INFO - root -   Epoch: [272/300][100/200], lr: 0.00000077 	 loss = 0.1242(0.2702)
2024/03/04 12:20:22 - INFO - root -   Epoch: [272/300][120/200], lr: 0.00000077 	 loss = 2.0021(0.2607)
2024/03/04 12:20:45 - INFO - root -   Epoch: [272/300][140/200], lr: 0.00000077 	 loss = 2.1467(0.2787)
2024/03/04 12:20:56 - INFO - root -   Epoch: [272/300][160/200], lr: 0.00000077 	 loss = 0.0427(0.2681)
2024/03/04 12:21:08 - INFO - root -   Epoch: [272/300][180/200], lr: 0.00000077 	 loss = 0.0254(0.2712)
2024/03/04 12:21:16 - INFO - root -   Epoch: [272/300] 	 loss = 0.2741
2024/03/04 12:21:16 - INFO - root -   train_accuracy = 0.8925
2024/03/04 12:21:17 - INFO - root -   Epoch: [273/300][0/200], lr: 0.00000078 	 loss = 0.1703(0.1703)
2024/03/04 12:21:46 - INFO - root -   Epoch: [273/300][20/200], lr: 0.00000078 	 loss = 0.0015(0.3055)
2024/03/04 12:21:58 - INFO - root -   Epoch: [273/300][40/200], lr: 0.00000078 	 loss = 0.1483(0.2202)
2024/03/04 12:22:14 - INFO - root -   Epoch: [273/300][60/200], lr: 0.00000078 	 loss = 0.0031(0.2792)
2024/03/04 12:22:22 - INFO - root -   Epoch: [273/300][80/200], lr: 0.00000078 	 loss = 0.2876(0.2719)
2024/03/04 12:22:44 - INFO - root -   Epoch: [273/300][100/200], lr: 0.00000078 	 loss = 0.0474(0.2686)
2024/03/04 12:23:03 - INFO - root -   Epoch: [273/300][120/200], lr: 0.00000078 	 loss = 1.5273(0.2617)
2024/03/04 12:23:21 - INFO - root -   Epoch: [273/300][140/200], lr: 0.00000078 	 loss = 0.1403(0.2551)
2024/03/04 12:23:29 - INFO - root -   Epoch: [273/300][160/200], lr: 0.00000078 	 loss = 0.0127(0.2804)
2024/03/04 12:23:45 - INFO - root -   Epoch: [273/300][180/200], lr: 0.00000078 	 loss = 0.0011(0.2743)
2024/03/04 12:23:53 - INFO - root -   Epoch: [273/300] 	 loss = 0.2839
2024/03/04 12:23:53 - INFO - root -   train_accuracy = 0.9025
2024/03/04 12:23:54 - INFO - root -   Epoch: [274/300][0/200], lr: 0.00000078 	 loss = 0.1018(0.1018)
2024/03/04 12:24:20 - INFO - root -   Epoch: [274/300][20/200], lr: 0.00000078 	 loss = 0.2053(0.4737)
2024/03/04 12:24:30 - INFO - root -   Epoch: [274/300][40/200], lr: 0.00000078 	 loss = 0.4567(0.2972)
2024/03/04 12:24:49 - INFO - root -   Epoch: [274/300][60/200], lr: 0.00000078 	 loss = 0.1171(0.3247)
2024/03/04 12:25:00 - INFO - root -   Epoch: [274/300][80/200], lr: 0.00000078 	 loss = 0.7880(0.3268)
2024/03/04 12:25:08 - INFO - root -   Epoch: [274/300][100/200], lr: 0.00000078 	 loss = 0.0003(0.3117)
2024/03/04 12:25:29 - INFO - root -   Epoch: [274/300][120/200], lr: 0.00000078 	 loss = 1.2348(0.3177)
2024/03/04 12:25:37 - INFO - root -   Epoch: [274/300][140/200], lr: 0.00000078 	 loss = 0.5223(0.3103)
2024/03/04 12:25:54 - INFO - root -   Epoch: [274/300][160/200], lr: 0.00000078 	 loss = 0.0282(0.3269)
2024/03/04 12:26:11 - INFO - root -   Epoch: [274/300][180/200], lr: 0.00000078 	 loss = 0.2673(0.3158)
2024/03/04 12:26:19 - INFO - root -   Epoch: [274/300] 	 loss = 0.3250
2024/03/04 12:26:22 - INFO - root -   precision = 0.6889
2024/03/04 12:26:22 - INFO - root -   eval_loss = 1.9848
2024/03/04 12:26:22 - INFO - root -   eval_acc = 0.6889
2024/03/04 12:26:23 - INFO - root -   train_accuracy = 0.8825
2024/03/04 12:26:24 - INFO - root -   Epoch: [275/300][0/200], lr: 0.00000078 	 loss = 0.2519(0.2519)
2024/03/04 12:26:53 - INFO - root -   Epoch: [275/300][20/200], lr: 0.00000078 	 loss = 0.0017(0.3274)
2024/03/04 12:27:11 - INFO - root -   Epoch: [275/300][40/200], lr: 0.00000078 	 loss = 0.2756(0.2979)
2024/03/04 12:27:19 - INFO - root -   Epoch: [275/300][60/200], lr: 0.00000078 	 loss = 0.1565(0.2819)
2024/03/04 12:27:43 - INFO - root -   Epoch: [275/300][80/200], lr: 0.00000078 	 loss = 0.1105(0.3012)
2024/03/04 12:27:52 - INFO - root -   Epoch: [275/300][100/200], lr: 0.00000078 	 loss = 0.0788(0.2778)
2024/03/04 12:28:12 - INFO - root -   Epoch: [275/300][120/200], lr: 0.00000078 	 loss = 3.4378(0.2906)
2024/03/04 12:28:25 - INFO - root -   Epoch: [275/300][140/200], lr: 0.00000078 	 loss = 0.5816(0.2941)
2024/03/04 12:28:50 - INFO - root -   Epoch: [275/300][160/200], lr: 0.00000078 	 loss = 0.0790(0.2980)
2024/03/04 12:29:00 - INFO - root -   Epoch: [275/300][180/200], lr: 0.00000078 	 loss = 0.2251(0.2975)
2024/03/04 12:29:08 - INFO - root -   Epoch: [275/300] 	 loss = 0.2985
2024/03/04 12:29:08 - INFO - root -   train_accuracy = 0.9050
2024/03/04 12:29:09 - INFO - root -   Epoch: [276/300][0/200], lr: 0.00000078 	 loss = 0.4147(0.4147)
2024/03/04 12:29:42 - INFO - root -   Epoch: [276/300][20/200], lr: 0.00000078 	 loss = 0.0074(0.4142)
2024/03/04 12:29:50 - INFO - root -   Epoch: [276/300][40/200], lr: 0.00000078 	 loss = 0.4673(0.3195)
2024/03/04 12:30:11 - INFO - root -   Epoch: [276/300][60/200], lr: 0.00000078 	 loss = 0.0029(0.2959)
2024/03/04 12:30:27 - INFO - root -   Epoch: [276/300][80/200], lr: 0.00000078 	 loss = 1.6056(0.3189)
2024/03/04 12:30:35 - INFO - root -   Epoch: [276/300][100/200], lr: 0.00000078 	 loss = 0.0002(0.3040)
2024/03/04 12:30:43 - INFO - root -   Epoch: [276/300][120/200], lr: 0.00000078 	 loss = 1.1528(0.2885)
2024/03/04 12:31:00 - INFO - root -   Epoch: [276/300][140/200], lr: 0.00000078 	 loss = 0.0677(0.2877)
2024/03/04 12:31:22 - INFO - root -   Epoch: [276/300][160/200], lr: 0.00000078 	 loss = 0.0078(0.2834)
2024/03/04 12:31:41 - INFO - root -   Epoch: [276/300][180/200], lr: 0.00000078 	 loss = 0.0557(0.2877)
2024/03/04 12:31:49 - INFO - root -   Epoch: [276/300] 	 loss = 0.2926
2024/03/04 12:31:49 - INFO - root -   train_accuracy = 0.8900
2024/03/04 12:31:51 - INFO - root -   Epoch: [277/300][0/200], lr: 0.00000079 	 loss = 0.5978(0.5978)
2024/03/04 12:32:23 - INFO - root -   Epoch: [277/300][20/200], lr: 0.00000079 	 loss = 0.0056(0.4203)
2024/03/04 12:32:37 - INFO - root -   Epoch: [277/300][40/200], lr: 0.00000079 	 loss = 0.0939(0.3185)
2024/03/04 12:32:45 - INFO - root -   Epoch: [277/300][60/200], lr: 0.00000079 	 loss = 0.0061(0.2685)
2024/03/04 12:33:06 - INFO - root -   Epoch: [277/300][80/200], lr: 0.00000079 	 loss = 0.5414(0.3053)
2024/03/04 12:33:20 - INFO - root -   Epoch: [277/300][100/200], lr: 0.00000079 	 loss = 0.0002(0.2968)
2024/03/04 12:33:41 - INFO - root -   Epoch: [277/300][120/200], lr: 0.00000079 	 loss = 1.7659(0.2918)
2024/03/04 12:33:57 - INFO - root -   Epoch: [277/300][140/200], lr: 0.00000079 	 loss = 1.2614(0.2897)
2024/03/04 12:34:05 - INFO - root -   Epoch: [277/300][160/200], lr: 0.00000079 	 loss = 0.0653(0.2860)
2024/03/04 12:34:13 - INFO - root -   Epoch: [277/300][180/200], lr: 0.00000079 	 loss = 0.1491(0.2972)
2024/03/04 12:34:21 - INFO - root -   Epoch: [277/300] 	 loss = 0.2803
2024/03/04 12:34:21 - INFO - root -   train_accuracy = 0.9025
2024/03/04 12:34:22 - INFO - root -   Epoch: [278/300][0/200], lr: 0.00000079 	 loss = 0.0560(0.0560)
2024/03/04 12:34:52 - INFO - root -   Epoch: [278/300][20/200], lr: 0.00000079 	 loss = 0.0349(0.3583)
2024/03/04 12:35:10 - INFO - root -   Epoch: [278/300][40/200], lr: 0.00000079 	 loss = 0.1351(0.2994)
2024/03/04 12:35:28 - INFO - root -   Epoch: [278/300][60/200], lr: 0.00000079 	 loss = 0.0111(0.2985)
2024/03/04 12:35:41 - INFO - root -   Epoch: [278/300][80/200], lr: 0.00000079 	 loss = 0.0474(0.2979)
2024/03/04 12:35:51 - INFO - root -   Epoch: [278/300][100/200], lr: 0.00000079 	 loss = 0.0072(0.2785)
2024/03/04 12:36:23 - INFO - root -   Epoch: [278/300][120/200], lr: 0.00000079 	 loss = 1.0102(0.2913)
2024/03/04 12:36:31 - INFO - root -   Epoch: [278/300][140/200], lr: 0.00000079 	 loss = 1.1664(0.3067)
2024/03/04 12:36:48 - INFO - root -   Epoch: [278/300][160/200], lr: 0.00000079 	 loss = 0.1479(0.3022)
2024/03/04 12:37:03 - INFO - root -   Epoch: [278/300][180/200], lr: 0.00000079 	 loss = 1.5902(0.3030)
2024/03/04 12:37:10 - INFO - root -   Epoch: [278/300] 	 loss = 0.2930
2024/03/04 12:37:10 - INFO - root -   train_accuracy = 0.9050
2024/03/04 12:37:36 - INFO - root -   Epoch: [279/300][0/200], lr: 0.00000079 	 loss = 0.5737(0.5737)
2024/03/04 12:37:47 - INFO - root -   Epoch: [279/300][20/200], lr: 0.00000079 	 loss = 0.3221(0.4322)
2024/03/04 12:37:58 - INFO - root -   Epoch: [279/300][40/200], lr: 0.00000079 	 loss = 0.0027(0.3137)
2024/03/04 12:38:16 - INFO - root -   Epoch: [279/300][60/200], lr: 0.00000079 	 loss = 0.2547(0.2856)
2024/03/04 12:38:24 - INFO - root -   Epoch: [279/300][80/200], lr: 0.00000079 	 loss = 1.2454(0.2716)
2024/03/04 12:38:43 - INFO - root -   Epoch: [279/300][100/200], lr: 0.00000079 	 loss = 0.0001(0.2436)
2024/03/04 12:38:51 - INFO - root -   Epoch: [279/300][120/200], lr: 0.00000079 	 loss = 1.6838(0.2459)
2024/03/04 12:39:12 - INFO - root -   Epoch: [279/300][140/200], lr: 0.00000079 	 loss = 0.5930(0.2525)
2024/03/04 12:39:21 - INFO - root -   Epoch: [279/300][160/200], lr: 0.00000079 	 loss = 0.0848(0.2647)
2024/03/04 12:39:38 - INFO - root -   Epoch: [279/300][180/200], lr: 0.00000079 	 loss = 0.0056(0.2687)
2024/03/04 12:39:46 - INFO - root -   Epoch: [279/300] 	 loss = 0.2653
2024/03/04 12:39:50 - INFO - root -   precision = 0.6667
2024/03/04 12:39:50 - INFO - root -   eval_loss = 2.2411
2024/03/04 12:39:50 - INFO - root -   eval_acc = 0.6667
2024/03/04 12:39:51 - INFO - root -   train_accuracy = 0.9050
2024/03/04 12:40:02 - INFO - root -   Epoch: [280/300][0/200], lr: 0.00000079 	 loss = 1.0677(1.0677)
2024/03/04 12:40:10 - INFO - root -   Epoch: [280/300][20/200], lr: 0.00000079 	 loss = 0.0006(0.2283)
2024/03/04 12:40:30 - INFO - root -   Epoch: [280/300][40/200], lr: 0.00000079 	 loss = 0.0032(0.2051)
2024/03/04 12:40:45 - INFO - root -   Epoch: [280/300][60/200], lr: 0.00000079 	 loss = 0.0493(0.2593)
2024/03/04 12:40:59 - INFO - root -   Epoch: [280/300][80/200], lr: 0.00000079 	 loss = 0.0795(0.2514)
2024/03/04 12:41:07 - INFO - root -   Epoch: [280/300][100/200], lr: 0.00000079 	 loss = 0.0677(0.2446)
2024/03/04 12:41:30 - INFO - root -   Epoch: [280/300][120/200], lr: 0.00000079 	 loss = 1.3177(0.2463)
2024/03/04 12:41:38 - INFO - root -   Epoch: [280/300][140/200], lr: 0.00000079 	 loss = 0.8575(0.2442)
2024/03/04 12:41:51 - INFO - root -   Epoch: [280/300][160/200], lr: 0.00000079 	 loss = 0.0065(0.2496)
2024/03/04 12:42:02 - INFO - root -   Epoch: [280/300][180/200], lr: 0.00000079 	 loss = 0.0045(0.2635)
2024/03/04 12:42:10 - INFO - root -   Epoch: [280/300] 	 loss = 0.2544
2024/03/04 12:42:10 - INFO - root -   train_accuracy = 0.9000
2024/03/04 12:42:12 - INFO - root -   Epoch: [281/300][0/200], lr: 0.00000080 	 loss = 0.0323(0.0323)
2024/03/04 12:42:45 - INFO - root -   Epoch: [281/300][20/200], lr: 0.00000080 	 loss = 0.0015(0.6158)
2024/03/04 12:42:54 - INFO - root -   Epoch: [281/300][40/200], lr: 0.00000080 	 loss = 0.0104(0.4048)
2024/03/04 12:43:08 - INFO - root -   Epoch: [281/300][60/200], lr: 0.00000080 	 loss = 0.0072(0.3851)
2024/03/04 12:43:26 - INFO - root -   Epoch: [281/300][80/200], lr: 0.00000080 	 loss = 1.1799(0.3706)
2024/03/04 12:43:34 - INFO - root -   Epoch: [281/300][100/200], lr: 0.00000080 	 loss = 0.1486(0.3318)
2024/03/04 12:43:57 - INFO - root -   Epoch: [281/300][120/200], lr: 0.00000080 	 loss = 0.9251(0.3039)
2024/03/04 12:44:20 - INFO - root -   Epoch: [281/300][140/200], lr: 0.00000080 	 loss = 0.2646(0.2913)
2024/03/04 12:44:36 - INFO - root -   Epoch: [281/300][160/200], lr: 0.00000080 	 loss = 0.2488(0.2975)
2024/03/04 12:44:47 - INFO - root -   Epoch: [281/300][180/200], lr: 0.00000080 	 loss = 0.1103(0.2913)
2024/03/04 12:44:55 - INFO - root -   Epoch: [281/300] 	 loss = 0.2827
2024/03/04 12:44:55 - INFO - root -   train_accuracy = 0.8900
2024/03/04 12:44:56 - INFO - root -   Epoch: [282/300][0/200], lr: 0.00000080 	 loss = 0.1122(0.1122)
2024/03/04 12:45:21 - INFO - root -   Epoch: [282/300][20/200], lr: 0.00000080 	 loss = 0.0001(0.3149)
2024/03/04 12:45:36 - INFO - root -   Epoch: [282/300][40/200], lr: 0.00000080 	 loss = 0.0021(0.2366)
2024/03/04 12:45:54 - INFO - root -   Epoch: [282/300][60/200], lr: 0.00000080 	 loss = 0.0108(0.2200)
2024/03/04 12:46:02 - INFO - root -   Epoch: [282/300][80/200], lr: 0.00000080 	 loss = 0.1197(0.1931)
2024/03/04 12:46:31 - INFO - root -   Epoch: [282/300][100/200], lr: 0.00000080 	 loss = 0.0018(0.1787)
2024/03/04 12:46:38 - INFO - root -   Epoch: [282/300][120/200], lr: 0.00000080 	 loss = 1.7692(0.1836)
2024/03/04 12:47:03 - INFO - root -   Epoch: [282/300][140/200], lr: 0.00000080 	 loss = 1.2360(0.2157)
2024/03/04 12:47:15 - INFO - root -   Epoch: [282/300][160/200], lr: 0.00000080 	 loss = 0.1944(0.2229)
2024/03/04 12:47:26 - INFO - root -   Epoch: [282/300][180/200], lr: 0.00000080 	 loss = 0.0047(0.2354)
2024/03/04 12:47:39 - INFO - root -   Epoch: [282/300] 	 loss = 0.2331
2024/03/04 12:47:39 - INFO - root -   train_accuracy = 0.9150
2024/03/04 12:47:52 - INFO - root -   Epoch: [283/300][0/200], lr: 0.00000080 	 loss = 0.9465(0.9465)
2024/03/04 12:48:12 - INFO - root -   Epoch: [283/300][20/200], lr: 0.00000080 	 loss = 0.0012(0.4632)
2024/03/04 12:48:23 - INFO - root -   Epoch: [283/300][40/200], lr: 0.00000080 	 loss = 0.0010(0.3522)
2024/03/04 12:48:46 - INFO - root -   Epoch: [283/300][60/200], lr: 0.00000080 	 loss = 0.0019(0.3673)
2024/03/04 12:49:02 - INFO - root -   Epoch: [283/300][80/200], lr: 0.00000080 	 loss = 0.2279(0.3867)
2024/03/04 12:49:15 - INFO - root -   Epoch: [283/300][100/200], lr: 0.00000080 	 loss = 0.0002(0.3315)
2024/03/04 12:49:25 - INFO - root -   Epoch: [283/300][120/200], lr: 0.00000080 	 loss = 0.2678(0.2937)
2024/03/04 12:49:45 - INFO - root -   Epoch: [283/300][140/200], lr: 0.00000080 	 loss = 1.0394(0.3049)
2024/03/04 12:49:58 - INFO - root -   Epoch: [283/300][160/200], lr: 0.00000080 	 loss = 0.0609(0.2920)
2024/03/04 12:50:12 - INFO - root -   Epoch: [283/300][180/200], lr: 0.00000080 	 loss = 0.0518(0.2878)
2024/03/04 12:50:23 - INFO - root -   Epoch: [283/300] 	 loss = 0.2897
2024/03/04 12:50:23 - INFO - root -   train_accuracy = 0.8975
2024/03/04 12:50:24 - INFO - root -   Epoch: [284/300][0/200], lr: 0.00000080 	 loss = 0.5110(0.5110)
2024/03/04 12:51:00 - INFO - root -   Epoch: [284/300][20/200], lr: 0.00000080 	 loss = 0.0067(0.3105)
2024/03/04 12:51:07 - INFO - root -   Epoch: [284/300][40/200], lr: 0.00000080 	 loss = 0.0062(0.2817)
2024/03/04 12:51:25 - INFO - root -   Epoch: [284/300][60/200], lr: 0.00000080 	 loss = 0.0019(0.2652)
2024/03/04 12:51:38 - INFO - root -   Epoch: [284/300][80/200], lr: 0.00000080 	 loss = 0.4236(0.2819)
2024/03/04 12:52:00 - INFO - root -   Epoch: [284/300][100/200], lr: 0.00000080 	 loss = 0.0271(0.2746)
2024/03/04 12:52:17 - INFO - root -   Epoch: [284/300][120/200], lr: 0.00000080 	 loss = 1.4855(0.2683)
2024/03/04 12:52:37 - INFO - root -   Epoch: [284/300][140/200], lr: 0.00000080 	 loss = 0.1873(0.2640)
2024/03/04 12:52:50 - INFO - root -   Epoch: [284/300][160/200], lr: 0.00000080 	 loss = 0.0859(0.2799)
2024/03/04 12:52:58 - INFO - root -   Epoch: [284/300][180/200], lr: 0.00000080 	 loss = 0.0184(0.2810)
2024/03/04 12:53:06 - INFO - root -   Epoch: [284/300] 	 loss = 0.2805
2024/03/04 12:53:10 - INFO - root -   precision = 0.6889
2024/03/04 12:53:10 - INFO - root -   eval_loss = 2.3988
2024/03/04 12:53:10 - INFO - root -   eval_acc = 0.6889
2024/03/04 12:53:11 - INFO - root -   train_accuracy = 0.9000
2024/03/04 12:53:13 - INFO - root -   Epoch: [285/300][0/200], lr: 0.00000081 	 loss = 0.0960(0.0960)
2024/03/04 12:53:43 - INFO - root -   Epoch: [285/300][20/200], lr: 0.00000081 	 loss = 0.0026(0.3181)
2024/03/04 12:53:56 - INFO - root -   Epoch: [285/300][40/200], lr: 0.00000081 	 loss = 0.0018(0.2572)
2024/03/04 12:54:09 - INFO - root -   Epoch: [285/300][60/200], lr: 0.00000081 	 loss = 0.0031(0.2439)
2024/03/04 12:54:28 - INFO - root -   Epoch: [285/300][80/200], lr: 0.00000081 	 loss = 0.2319(0.2432)
2024/03/04 12:54:44 - INFO - root -   Epoch: [285/300][100/200], lr: 0.00000081 	 loss = 0.0566(0.2262)
2024/03/04 12:54:59 - INFO - root -   Epoch: [285/300][120/200], lr: 0.00000081 	 loss = 0.7747(0.2356)
2024/03/04 12:55:07 - INFO - root -   Epoch: [285/300][140/200], lr: 0.00000081 	 loss = 0.1389(0.2487)
2024/03/04 12:55:18 - INFO - root -   Epoch: [285/300][160/200], lr: 0.00000081 	 loss = 0.0053(0.2463)
2024/03/04 12:55:38 - INFO - root -   Epoch: [285/300][180/200], lr: 0.00000081 	 loss = 0.0909(0.2358)
2024/03/04 12:55:46 - INFO - root -   Epoch: [285/300] 	 loss = 0.2448
2024/03/04 12:55:46 - INFO - root -   train_accuracy = 0.9125
2024/03/04 12:55:49 - INFO - root -   Epoch: [286/300][0/200], lr: 0.00000081 	 loss = 0.1165(0.1165)
2024/03/04 12:56:21 - INFO - root -   Epoch: [286/300][20/200], lr: 0.00000081 	 loss = 0.1551(0.4181)
2024/03/04 12:56:36 - INFO - root -   Epoch: [286/300][40/200], lr: 0.00000081 	 loss = 0.0011(0.2472)
2024/03/04 12:56:57 - INFO - root -   Epoch: [286/300][60/200], lr: 0.00000081 	 loss = 0.0060(0.2602)
2024/03/04 12:57:05 - INFO - root -   Epoch: [286/300][80/200], lr: 0.00000081 	 loss = 0.0971(0.2701)
2024/03/04 12:57:24 - INFO - root -   Epoch: [286/300][100/200], lr: 0.00000081 	 loss = 0.0001(0.2517)
2024/03/04 12:57:37 - INFO - root -   Epoch: [286/300][120/200], lr: 0.00000081 	 loss = 1.4079(0.2367)
2024/03/04 12:57:52 - INFO - root -   Epoch: [286/300][140/200], lr: 0.00000081 	 loss = 0.0556(0.2428)
2024/03/04 12:58:05 - INFO - root -   Epoch: [286/300][160/200], lr: 0.00000081 	 loss = 0.0166(0.2498)
2024/03/04 12:58:22 - INFO - root -   Epoch: [286/300][180/200], lr: 0.00000081 	 loss = 0.0052(0.2521)
2024/03/04 12:58:30 - INFO - root -   Epoch: [286/300] 	 loss = 0.2501
2024/03/04 12:58:30 - INFO - root -   train_accuracy = 0.9075
2024/03/04 12:58:53 - INFO - root -   Epoch: [287/300][0/200], lr: 0.00000081 	 loss = 1.1957(1.1957)
2024/03/04 12:59:04 - INFO - root -   Epoch: [287/300][20/200], lr: 0.00000081 	 loss = 0.1303(0.5596)
2024/03/04 12:59:12 - INFO - root -   Epoch: [287/300][40/200], lr: 0.00000081 	 loss = 0.2915(0.3852)
2024/03/04 12:59:29 - INFO - root -   Epoch: [287/300][60/200], lr: 0.00000081 	 loss = 0.0011(0.3636)
2024/03/04 12:59:50 - INFO - root -   Epoch: [287/300][80/200], lr: 0.00000081 	 loss = 0.1106(0.3468)
2024/03/04 13:00:05 - INFO - root -   Epoch: [287/300][100/200], lr: 0.00000081 	 loss = 0.2224(0.3295)
2024/03/04 13:00:23 - INFO - root -   Epoch: [287/300][120/200], lr: 0.00000081 	 loss = 0.1811(0.2919)
2024/03/04 13:00:31 - INFO - root -   Epoch: [287/300][140/200], lr: 0.00000081 	 loss = 0.2705(0.2889)
2024/03/04 13:00:48 - INFO - root -   Epoch: [287/300][160/200], lr: 0.00000081 	 loss = 0.0113(0.2939)
2024/03/04 13:00:57 - INFO - root -   Epoch: [287/300][180/200], lr: 0.00000081 	 loss = 0.0065(0.2984)
2024/03/04 13:01:05 - INFO - root -   Epoch: [287/300] 	 loss = 0.2931
2024/03/04 13:01:05 - INFO - root -   train_accuracy = 0.8950
2024/03/04 13:01:06 - INFO - root -   Epoch: [288/300][0/200], lr: 0.00000081 	 loss = 0.0818(0.0818)
2024/03/04 13:01:34 - INFO - root -   Epoch: [288/300][20/200], lr: 0.00000081 	 loss = 0.0587(0.3977)
2024/03/04 13:02:03 - INFO - root -   Epoch: [288/300][40/200], lr: 0.00000081 	 loss = 0.0072(0.2866)
2024/03/04 13:02:11 - INFO - root -   Epoch: [288/300][60/200], lr: 0.00000081 	 loss = 0.0841(0.3195)
2024/03/04 13:02:20 - INFO - root -   Epoch: [288/300][80/200], lr: 0.00000081 	 loss = 0.9979(0.3012)
2024/03/04 13:02:31 - INFO - root -   Epoch: [288/300][100/200], lr: 0.00000081 	 loss = 0.0002(0.2732)
2024/03/04 13:02:47 - INFO - root -   Epoch: [288/300][120/200], lr: 0.00000081 	 loss = 1.0579(0.2547)
2024/03/04 13:03:06 - INFO - root -   Epoch: [288/300][140/200], lr: 0.00000081 	 loss = 1.3622(0.2627)
2024/03/04 13:03:14 - INFO - root -   Epoch: [288/300][160/200], lr: 0.00000081 	 loss = 0.0043(0.2919)
2024/03/04 13:03:22 - INFO - root -   Epoch: [288/300][180/200], lr: 0.00000081 	 loss = 0.0023(0.2865)
2024/03/04 13:03:36 - INFO - root -   Epoch: [288/300] 	 loss = 0.2914
2024/03/04 13:03:36 - INFO - root -   train_accuracy = 0.9050
2024/03/04 13:03:53 - INFO - root -   Epoch: [289/300][0/200], lr: 0.00000082 	 loss = 0.0456(0.0456)
2024/03/04 13:04:16 - INFO - root -   Epoch: [289/300][20/200], lr: 0.00000082 	 loss = 0.0232(0.2436)
2024/03/04 13:04:33 - INFO - root -   Epoch: [289/300][40/200], lr: 0.00000082 	 loss = 0.1565(0.2301)
2024/03/04 13:04:41 - INFO - root -   Epoch: [289/300][60/200], lr: 0.00000082 	 loss = 0.4424(0.2506)
2024/03/04 13:04:56 - INFO - root -   Epoch: [289/300][80/200], lr: 0.00000082 	 loss = 0.2726(0.2628)
2024/03/04 13:05:11 - INFO - root -   Epoch: [289/300][100/200], lr: 0.00000082 	 loss = 0.0001(0.2551)
2024/03/04 13:05:25 - INFO - root -   Epoch: [289/300][120/200], lr: 0.00000082 	 loss = 1.4630(0.2453)
2024/03/04 13:05:35 - INFO - root -   Epoch: [289/300][140/200], lr: 0.00000082 	 loss = 0.2477(0.2301)
2024/03/04 13:05:56 - INFO - root -   Epoch: [289/300][160/200], lr: 0.00000082 	 loss = 0.0010(0.2201)
2024/03/04 13:06:04 - INFO - root -   Epoch: [289/300][180/200], lr: 0.00000082 	 loss = 0.0230(0.2324)
2024/03/04 13:06:12 - INFO - root -   Epoch: [289/300] 	 loss = 0.2430
2024/03/04 13:06:15 - INFO - root -   precision = 0.6667
2024/03/04 13:06:15 - INFO - root -   eval_loss = 2.4541
2024/03/04 13:06:15 - INFO - root -   eval_acc = 0.6667
2024/03/04 13:06:16 - INFO - root -   train_accuracy = 0.9150
2024/03/04 13:06:29 - INFO - root -   Epoch: [290/300][0/200], lr: 0.00000082 	 loss = 0.8927(0.8927)
2024/03/04 13:06:49 - INFO - root -   Epoch: [290/300][20/200], lr: 0.00000082 	 loss = 0.0033(0.3472)
2024/03/04 13:07:10 - INFO - root -   Epoch: [290/300][40/200], lr: 0.00000082 	 loss = 0.0037(0.2523)
2024/03/04 13:07:27 - INFO - root -   Epoch: [290/300][60/200], lr: 0.00000082 	 loss = 0.0815(0.2652)
2024/03/04 13:07:43 - INFO - root -   Epoch: [290/300][80/200], lr: 0.00000082 	 loss = 0.9188(0.2442)
2024/03/04 13:07:51 - INFO - root -   Epoch: [290/300][100/200], lr: 0.00000082 	 loss = 0.0004(0.2420)
2024/03/04 13:08:13 - INFO - root -   Epoch: [290/300][120/200], lr: 0.00000082 	 loss = 1.6350(0.2362)
2024/03/04 13:08:32 - INFO - root -   Epoch: [290/300][140/200], lr: 0.00000082 	 loss = 1.0856(0.2695)
2024/03/04 13:08:43 - INFO - root -   Epoch: [290/300][160/200], lr: 0.00000082 	 loss = 0.0034(0.2776)
2024/03/04 13:08:58 - INFO - root -   Epoch: [290/300][180/200], lr: 0.00000082 	 loss = 0.3079(0.2870)
2024/03/04 13:09:05 - INFO - root -   Epoch: [290/300] 	 loss = 0.2923
2024/03/04 13:09:05 - INFO - root -   train_accuracy = 0.8925
2024/03/04 13:09:20 - INFO - root -   Epoch: [291/300][0/200], lr: 0.00000082 	 loss = 0.2114(0.2114)
2024/03/04 13:09:36 - INFO - root -   Epoch: [291/300][20/200], lr: 0.00000082 	 loss = 0.0395(0.3989)
2024/03/04 13:09:46 - INFO - root -   Epoch: [291/300][40/200], lr: 0.00000082 	 loss = 0.0037(0.2680)
2024/03/04 13:10:03 - INFO - root -   Epoch: [291/300][60/200], lr: 0.00000082 	 loss = 0.0081(0.2421)
2024/03/04 13:10:17 - INFO - root -   Epoch: [291/300][80/200], lr: 0.00000082 	 loss = 0.2007(0.2600)
2024/03/04 13:10:41 - INFO - root -   Epoch: [291/300][100/200], lr: 0.00000082 	 loss = 0.0604(0.2299)
2024/03/04 13:10:52 - INFO - root -   Epoch: [291/300][120/200], lr: 0.00000082 	 loss = 0.7519(0.2493)
2024/03/04 13:11:17 - INFO - root -   Epoch: [291/300][140/200], lr: 0.00000082 	 loss = 0.2514(0.2560)
2024/03/04 13:11:25 - INFO - root -   Epoch: [291/300][160/200], lr: 0.00000082 	 loss = 0.0231(0.2631)
2024/03/04 13:11:40 - INFO - root -   Epoch: [291/300][180/200], lr: 0.00000082 	 loss = 0.0047(0.2841)
2024/03/04 13:11:47 - INFO - root -   Epoch: [291/300] 	 loss = 0.2774
2024/03/04 13:11:47 - INFO - root -   train_accuracy = 0.9050
2024/03/04 13:11:50 - INFO - root -   Epoch: [292/300][0/200], lr: 0.00000082 	 loss = 0.0155(0.0155)
2024/03/04 13:12:20 - INFO - root -   Epoch: [292/300][20/200], lr: 0.00000082 	 loss = 0.0015(0.4050)
2024/03/04 13:12:31 - INFO - root -   Epoch: [292/300][40/200], lr: 0.00000082 	 loss = 0.1306(0.2774)
2024/03/04 13:12:42 - INFO - root -   Epoch: [292/300][60/200], lr: 0.00000082 	 loss = 0.0888(0.3072)
2024/03/04 13:13:09 - INFO - root -   Epoch: [292/300][80/200], lr: 0.00000082 	 loss = 0.1672(0.2860)
2024/03/04 13:13:17 - INFO - root -   Epoch: [292/300][100/200], lr: 0.00000082 	 loss = 0.0003(0.2834)
2024/03/04 13:13:34 - INFO - root -   Epoch: [292/300][120/200], lr: 0.00000082 	 loss = 0.4067(0.2673)
2024/03/04 13:13:45 - INFO - root -   Epoch: [292/300][140/200], lr: 0.00000082 	 loss = 1.5796(0.2843)
2024/03/04 13:14:06 - INFO - root -   Epoch: [292/300][160/200], lr: 0.00000082 	 loss = 0.5197(0.2899)
2024/03/04 13:14:16 - INFO - root -   Epoch: [292/300][180/200], lr: 0.00000082 	 loss = 0.0050(0.2930)
2024/03/04 13:14:23 - INFO - root -   Epoch: [292/300] 	 loss = 0.2916
2024/03/04 13:14:23 - INFO - root -   train_accuracy = 0.8925
2024/03/04 13:14:43 - INFO - root -   Epoch: [293/300][0/200], lr: 0.00000083 	 loss = 0.4721(0.4721)
2024/03/04 13:14:51 - INFO - root -   Epoch: [293/300][20/200], lr: 0.00000083 	 loss = 0.0002(0.2023)
2024/03/04 13:15:11 - INFO - root -   Epoch: [293/300][40/200], lr: 0.00000083 	 loss = 0.6682(0.2236)
2024/03/04 13:15:19 - INFO - root -   Epoch: [293/300][60/200], lr: 0.00000083 	 loss = 0.1312(0.3089)
2024/03/04 13:15:31 - INFO - root -   Epoch: [293/300][80/200], lr: 0.00000083 	 loss = 0.0533(0.2708)
2024/03/04 13:15:46 - INFO - root -   Epoch: [293/300][100/200], lr: 0.00000083 	 loss = 0.0000(0.2490)
2024/03/04 13:15:54 - INFO - root -   Epoch: [293/300][120/200], lr: 0.00000083 	 loss = 1.7106(0.2546)
2024/03/04 13:16:24 - INFO - root -   Epoch: [293/300][140/200], lr: 0.00000083 	 loss = 0.3804(0.2601)
2024/03/04 13:16:37 - INFO - root -   Epoch: [293/300][160/200], lr: 0.00000083 	 loss = 0.0093(0.2661)
2024/03/04 13:16:55 - INFO - root -   Epoch: [293/300][180/200], lr: 0.00000083 	 loss = 0.0967(0.2715)
2024/03/04 13:17:05 - INFO - root -   Epoch: [293/300] 	 loss = 0.2786
2024/03/04 13:17:05 - INFO - root -   train_accuracy = 0.9125
2024/03/04 13:17:06 - INFO - root -   Epoch: [294/300][0/200], lr: 0.00000083 	 loss = 0.0610(0.0610)
2024/03/04 13:17:35 - INFO - root -   Epoch: [294/300][20/200], lr: 0.00000083 	 loss = 0.0663(0.4416)
2024/03/04 13:17:57 - INFO - root -   Epoch: [294/300][40/200], lr: 0.00000083 	 loss = 0.2690(0.3320)
2024/03/04 13:18:05 - INFO - root -   Epoch: [294/300][60/200], lr: 0.00000083 	 loss = 0.0033(0.2715)
2024/03/04 13:18:13 - INFO - root -   Epoch: [294/300][80/200], lr: 0.00000083 	 loss = 0.1076(0.2481)
2024/03/04 13:18:29 - INFO - root -   Epoch: [294/300][100/200], lr: 0.00000083 	 loss = 0.1386(0.2432)
2024/03/04 13:18:48 - INFO - root -   Epoch: [294/300][120/200], lr: 0.00000083 	 loss = 1.1240(0.2439)
2024/03/04 13:19:04 - INFO - root -   Epoch: [294/300][140/200], lr: 0.00000083 	 loss = 0.5162(0.2611)
2024/03/04 13:19:16 - INFO - root -   Epoch: [294/300][160/200], lr: 0.00000083 	 loss = 0.0728(0.2898)
2024/03/04 13:19:38 - INFO - root -   Epoch: [294/300][180/200], lr: 0.00000083 	 loss = 0.0192(0.2791)
2024/03/04 13:19:46 - INFO - root -   Epoch: [294/300] 	 loss = 0.2898
2024/03/04 13:19:49 - INFO - root -   precision = 0.6889
2024/03/04 13:19:49 - INFO - root -   eval_loss = 2.2586
2024/03/04 13:19:49 - INFO - root -   eval_acc = 0.6889
2024/03/04 13:19:50 - INFO - root -   train_accuracy = 0.9025
2024/03/04 13:20:14 - INFO - root -   Epoch: [295/300][0/200], lr: 0.00000083 	 loss = 1.1213(1.1213)
2024/03/04 13:20:22 - INFO - root -   Epoch: [295/300][20/200], lr: 0.00000083 	 loss = 0.1575(0.2960)
2024/03/04 13:20:40 - INFO - root -   Epoch: [295/300][40/200], lr: 0.00000083 	 loss = 0.0058(0.2384)
2024/03/04 13:20:48 - INFO - root -   Epoch: [295/300][60/200], lr: 0.00000083 	 loss = 0.0004(0.3033)
2024/03/04 13:21:08 - INFO - root -   Epoch: [295/300][80/200], lr: 0.00000083 	 loss = 0.1387(0.2859)
2024/03/04 13:21:16 - INFO - root -   Epoch: [295/300][100/200], lr: 0.00000083 	 loss = 0.0001(0.2796)
2024/03/04 13:21:28 - INFO - root -   Epoch: [295/300][120/200], lr: 0.00000083 	 loss = 2.4972(0.2701)
2024/03/04 13:21:39 - INFO - root -   Epoch: [295/300][140/200], lr: 0.00000083 	 loss = 0.5598(0.2665)
2024/03/04 13:22:07 - INFO - root -   Epoch: [295/300][160/200], lr: 0.00000083 	 loss = 0.5315(0.2822)
2024/03/04 13:22:15 - INFO - root -   Epoch: [295/300][180/200], lr: 0.00000083 	 loss = 0.0075(0.3042)
2024/03/04 13:22:24 - INFO - root -   Epoch: [295/300] 	 loss = 0.2992
2024/03/04 13:22:24 - INFO - root -   train_accuracy = 0.9000
2024/03/04 13:22:25 - INFO - root -   Epoch: [296/300][0/200], lr: 0.00000083 	 loss = 0.2200(0.2200)
2024/03/04 13:23:04 - INFO - root -   Epoch: [296/300][20/200], lr: 0.00000083 	 loss = 0.0007(0.2760)
2024/03/04 13:23:12 - INFO - root -   Epoch: [296/300][40/200], lr: 0.00000083 	 loss = 0.0618(0.2617)
2024/03/04 13:23:42 - INFO - root -   Epoch: [296/300][60/200], lr: 0.00000083 	 loss = 0.0535(0.2520)
2024/03/04 13:23:56 - INFO - root -   Epoch: [296/300][80/200], lr: 0.00000083 	 loss = 0.1717(0.2494)
2024/03/04 13:24:04 - INFO - root -   Epoch: [296/300][100/200], lr: 0.00000083 	 loss = 0.0292(0.2357)
2024/03/04 13:24:20 - INFO - root -   Epoch: [296/300][120/200], lr: 0.00000083 	 loss = 1.3582(0.2427)
2024/03/04 13:24:38 - INFO - root -   Epoch: [296/300][140/200], lr: 0.00000083 	 loss = 1.0587(0.2535)
2024/03/04 13:24:47 - INFO - root -   Epoch: [296/300][160/200], lr: 0.00000083 	 loss = 0.0047(0.2500)
2024/03/04 13:25:04 - INFO - root -   Epoch: [296/300][180/200], lr: 0.00000083 	 loss = 0.0791(0.2414)
2024/03/04 13:25:12 - INFO - root -   Epoch: [296/300] 	 loss = 0.2456
2024/03/04 13:25:12 - INFO - root -   train_accuracy = 0.9150
2024/03/04 13:25:37 - INFO - root -   Epoch: [297/300][0/200], lr: 0.00000084 	 loss = 1.2542(1.2542)
2024/03/04 13:25:54 - INFO - root -   Epoch: [297/300][20/200], lr: 0.00000084 	 loss = 0.0016(0.4039)
2024/03/04 13:26:10 - INFO - root -   Epoch: [297/300][40/200], lr: 0.00000084 	 loss = 0.0081(0.2665)
2024/03/04 13:26:25 - INFO - root -   Epoch: [297/300][60/200], lr: 0.00000084 	 loss = 0.0003(0.2490)
2024/03/04 13:26:42 - INFO - root -   Epoch: [297/300][80/200], lr: 0.00000084 	 loss = 1.3246(0.2731)
2024/03/04 13:27:02 - INFO - root -   Epoch: [297/300][100/200], lr: 0.00000084 	 loss = 0.0006(0.2558)
2024/03/04 13:27:15 - INFO - root -   Epoch: [297/300][120/200], lr: 0.00000084 	 loss = 2.9029(0.2709)
2024/03/04 13:27:22 - INFO - root -   Epoch: [297/300][140/200], lr: 0.00000084 	 loss = 0.3309(0.2605)
2024/03/04 13:27:37 - INFO - root -   Epoch: [297/300][160/200], lr: 0.00000084 	 loss = 0.0620(0.2568)
2024/03/04 13:27:54 - INFO - root -   Epoch: [297/300][180/200], lr: 0.00000084 	 loss = 0.0999(0.2716)
2024/03/04 13:28:02 - INFO - root -   Epoch: [297/300] 	 loss = 0.2829
2024/03/04 13:28:02 - INFO - root -   train_accuracy = 0.9000
2024/03/04 13:28:15 - INFO - root -   Epoch: [298/300][0/200], lr: 0.00000084 	 loss = 0.9992(0.9992)
2024/03/04 13:28:22 - INFO - root -   Epoch: [298/300][20/200], lr: 0.00000084 	 loss = 0.0001(0.4923)
2024/03/04 13:28:38 - INFO - root -   Epoch: [298/300][40/200], lr: 0.00000084 	 loss = 0.2815(0.3390)
2024/03/04 13:29:02 - INFO - root -   Epoch: [298/300][60/200], lr: 0.00000084 	 loss = 0.0019(0.3429)
2024/03/04 13:29:17 - INFO - root -   Epoch: [298/300][80/200], lr: 0.00000084 	 loss = 1.7389(0.3546)
2024/03/04 13:29:25 - INFO - root -   Epoch: [298/300][100/200], lr: 0.00000084 	 loss = 0.2064(0.3447)
2024/03/04 13:29:43 - INFO - root -   Epoch: [298/300][120/200], lr: 0.00000084 	 loss = 0.8858(0.3148)
2024/03/04 13:29:55 - INFO - root -   Epoch: [298/300][140/200], lr: 0.00000084 	 loss = 0.0698(0.3036)
2024/03/04 13:30:03 - INFO - root -   Epoch: [298/300][160/200], lr: 0.00000084 	 loss = 0.0657(0.2910)
2024/03/04 13:30:16 - INFO - root -   Epoch: [298/300][180/200], lr: 0.00000084 	 loss = 0.8969(0.2961)
2024/03/04 13:30:27 - INFO - root -   Epoch: [298/300] 	 loss = 0.3010
2024/03/04 13:30:27 - INFO - root -   train_accuracy = 0.8975
2024/03/04 13:30:47 - INFO - root -   Epoch: [299/300][0/200], lr: 0.00000084 	 loss = 0.6380(0.6380)
2024/03/04 13:30:55 - INFO - root -   Epoch: [299/300][20/200], lr: 0.00000084 	 loss = 0.0004(0.3495)
2024/03/04 13:31:13 - INFO - root -   Epoch: [299/300][40/200], lr: 0.00000084 	 loss = 0.0053(0.2723)
2024/03/04 13:31:33 - INFO - root -   Epoch: [299/300][60/200], lr: 0.00000084 	 loss = 0.0144(0.2819)
2024/03/04 13:31:41 - INFO - root -   Epoch: [299/300][80/200], lr: 0.00000084 	 loss = 0.1956(0.2490)
2024/03/04 13:31:56 - INFO - root -   Epoch: [299/300][100/200], lr: 0.00000084 	 loss = 0.0001(0.2435)
2024/03/04 13:32:16 - INFO - root -   Epoch: [299/300][120/200], lr: 0.00000084 	 loss = 0.3964(0.2164)
2024/03/04 13:32:24 - INFO - root -   Epoch: [299/300][140/200], lr: 0.00000084 	 loss = 1.8890(0.2220)
2024/03/04 13:32:46 - INFO - root -   Epoch: [299/300][160/200], lr: 0.00000084 	 loss = 0.0186(0.2338)
2024/03/04 13:32:54 - INFO - root -   Epoch: [299/300][180/200], lr: 0.00000084 	 loss = 0.0087(0.2491)
2024/03/04 13:33:02 - INFO - root -   Epoch: [299/300] 	 loss = 0.2493
2024/03/04 13:33:06 - INFO - root -   precision = 0.6889
2024/03/04 13:33:06 - INFO - root -   eval_loss = 2.2703
2024/03/04 13:33:06 - INFO - root -   eval_acc = 0.6889
2024/03/04 13:33:07 - INFO - root -   train_accuracy = 0.9075
2024/03/05 00:06:09 - INFO - root -   Num train examples = 400
2024/03/05 00:06:09 - INFO - root -   Num val examples = 45
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.0181818176060915
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.036363635212183
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.05454545468091965
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.072727270424366
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.09090908616781235
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.10909091681241989
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.12727272510528564
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.1454545557498932
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.16363637149333954
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.1818181872367859
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.20000000298023224
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Use checkpoint: False
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Checkpoint number: [0]
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.13333334028720856
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.2666666507720947
2024/03/05 00:06:09 - INFO - models.uniformerv2_model -   Drop path rate: 0.4000000059604645
2024/03/05 00:06:09 - INFO - root -   backend = nccl
2024/03/05 00:06:09 - INFO - root -   batch_size = 2
2024/03/05 00:06:09 - INFO - root -   dropout = 0.5
2024/03/05 00:06:09 - INFO - root -   epochs = 300
2024/03/05 00:06:09 - INFO - root -   eval_freq = 5
2024/03/05 00:06:09 - INFO - root -   focal_loss = False
2024/03/05 00:06:09 - INFO - root -   input_size = 128
2024/03/05 00:06:09 - INFO - root -   is_pretrained = False
2024/03/05 00:06:09 - INFO - root -   label_smooth = False
2024/03/05 00:06:09 - INFO - root -   local_rank = -1
2024/03/05 00:06:09 - INFO - root -   lr = 1e-05
2024/03/05 00:06:09 - INFO - root -   lr_decay_rate = 0.1
2024/03/05 00:06:09 - INFO - root -   lr_steps = [50, 100]
2024/03/05 00:06:09 - INFO - root -   lr_type = cosine
2024/03/05 00:06:09 - INFO - root -   model_depth = 34
2024/03/05 00:06:09 - INFO - root -   model_name = resnet50
2024/03/05 00:06:09 - INFO - root -   momentum = 0.9
2024/03/05 00:06:09 - INFO - root -   num_classes = 3
2024/03/05 00:06:09 - INFO - root -   output = ./ucsf_roi_3grade_outputs
2024/03/05 00:06:09 - INFO - root -   print_freq = 20
2024/03/05 00:06:09 - INFO - root -   resume = 
2024/03/05 00:06:09 - INFO - root -   start_epoch = 0
2024/03/05 00:06:09 - INFO - root -   test_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_test_patients.txt
2024/03/05 00:06:09 - INFO - root -   train_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_train_patients.txt
2024/03/05 00:06:09 - INFO - root -   tune_from = 
2024/03/05 00:06:09 - INFO - root -   val_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_val_patients.txt
2024/03/05 00:06:09 - INFO - root -   warmup_epoch = 20
2024/03/05 00:06:09 - INFO - root -   warmup_multiplier = 100
2024/03/05 00:06:09 - INFO - root -   weight_decay = 0.0005
2024/03/05 00:06:09 - INFO - root -   workers = 16
2024/03/05 00:06:41 - INFO - root -   Epoch: [0/300][0/200], lr: 0.00000010 	 loss = 1.6564(1.6564)
2024/03/05 00:07:27 - INFO - root -   Epoch: [0/300][20/200], lr: 0.00000010 	 loss = 1.1857(1.1228)
2024/03/05 00:08:10 - INFO - root -   Epoch: [0/300][40/200], lr: 0.00000010 	 loss = 0.4843(1.0284)
2024/03/05 00:08:52 - INFO - root -   Epoch: [0/300][60/200], lr: 0.00000010 	 loss = 0.8292(1.0014)
2024/03/05 00:09:35 - INFO - root -   Epoch: [0/300][80/200], lr: 0.00000010 	 loss = 1.9509(1.0010)
2024/03/05 00:10:26 - INFO - root -   Epoch: [0/300][100/200], lr: 0.00000010 	 loss = 0.5318(0.9277)
2024/03/05 00:11:05 - INFO - root -   Epoch: [0/300][120/200], lr: 0.00000010 	 loss = 2.0593(0.8909)
2024/03/05 00:11:41 - INFO - root -   Epoch: [0/300][140/200], lr: 0.00000010 	 loss = 1.5053(0.8808)
2024/03/05 00:12:15 - INFO - root -   Epoch: [0/300][160/200], lr: 0.00000010 	 loss = 0.2994(0.8584)
2024/03/05 00:12:56 - INFO - root -   Epoch: [0/300][180/200], lr: 0.00000010 	 loss = 0.2837(0.8488)
2024/03/05 00:13:12 - INFO - root -   Epoch: [0/300] 	 loss = 0.8365
2024/03/05 00:13:12 - INFO - root -   train_accuracy = 0.6575
2024/03/05 00:13:51 - INFO - root -   Epoch: [1/300][0/200], lr: 0.00000010 	 loss = 1.0838(1.0838)
2024/03/05 00:14:35 - INFO - root -   Epoch: [1/300][20/200], lr: 0.00000010 	 loss = 0.6349(0.8911)
2024/03/05 00:15:14 - INFO - root -   Epoch: [1/300][40/200], lr: 0.00000010 	 loss = 0.2719(0.6897)
2024/03/05 00:15:40 - INFO - root -   Epoch: [1/300][60/200], lr: 0.00000010 	 loss = 0.4071(0.6839)
2024/03/05 00:16:20 - INFO - root -   Epoch: [1/300][80/200], lr: 0.00000010 	 loss = 1.0872(0.6801)
2024/03/05 00:16:56 - INFO - root -   Epoch: [1/300][100/200], lr: 0.00000010 	 loss = 0.2315(0.6547)
2024/03/05 00:17:45 - INFO - root -   Epoch: [1/300][120/200], lr: 0.00000010 	 loss = 2.0252(0.6232)
2024/03/05 00:18:37 - INFO - root -   Epoch: [1/300][140/200], lr: 0.00000010 	 loss = 1.3009(0.6493)
2024/03/05 00:18:57 - INFO - root -   Epoch: [1/300][160/200], lr: 0.00000010 	 loss = 0.1223(0.6417)
2024/03/05 00:19:30 - INFO - root -   Epoch: [1/300][180/200], lr: 0.00000010 	 loss = 0.2577(0.6557)
2024/03/05 00:19:56 - INFO - root -   Epoch: [1/300] 	 loss = 0.6635
2024/03/05 00:19:56 - INFO - root -   train_accuracy = 0.7975
2024/03/05 00:20:16 - INFO - root -   Epoch: [2/300][0/200], lr: 0.00000010 	 loss = 2.0115(2.0115)
2024/03/05 00:21:16 - INFO - root -   Epoch: [2/300][20/200], lr: 0.00000010 	 loss = 0.2741(0.9162)
2024/03/05 00:21:56 - INFO - root -   Epoch: [2/300][40/200], lr: 0.00000010 	 loss = 0.1459(0.7284)
2024/03/05 00:22:27 - INFO - root -   Epoch: [2/300][60/200], lr: 0.00000010 	 loss = 0.2380(0.7491)
2024/03/05 00:23:06 - INFO - root -   Epoch: [2/300][80/200], lr: 0.00000010 	 loss = 1.5701(0.7415)
2024/03/05 00:24:07 - INFO - root -   Epoch: [2/300][100/200], lr: 0.00000010 	 loss = 0.1249(0.7105)
2024/03/05 00:24:42 - INFO - root -   Epoch: [2/300][120/200], lr: 0.00000010 	 loss = 3.0179(0.6869)
2024/03/05 00:25:19 - INFO - root -   Epoch: [2/300][140/200], lr: 0.00000010 	 loss = 1.4851(0.6955)
2024/03/05 00:25:48 - INFO - root -   Epoch: [2/300][160/200], lr: 0.00000010 	 loss = 0.0819(0.6912)
2024/03/05 00:26:37 - INFO - root -   Epoch: [2/300][180/200], lr: 0.00000010 	 loss = 0.1896(0.6989)
2024/03/05 00:26:49 - INFO - root -   Epoch: [2/300] 	 loss = 0.7038
2024/03/05 00:26:49 - INFO - root -   train_accuracy = 0.8000
2024/03/05 00:27:33 - INFO - root -   Epoch: [3/300][0/200], lr: 0.00000011 	 loss = 1.5426(1.5426)
2024/03/05 00:28:11 - INFO - root -   Epoch: [3/300][20/200], lr: 0.00000011 	 loss = 0.6609(0.8888)
2024/03/05 00:28:45 - INFO - root -   Epoch: [3/300][40/200], lr: 0.00000011 	 loss = 0.1698(0.7112)
2024/03/05 00:29:24 - INFO - root -   Epoch: [3/300][60/200], lr: 0.00000011 	 loss = 0.2706(0.7227)
2024/03/05 00:30:06 - INFO - root -   Epoch: [3/300][80/200], lr: 0.00000011 	 loss = 1.1120(0.7256)
2024/03/05 00:30:48 - INFO - root -   Epoch: [3/300][100/200], lr: 0.00000011 	 loss = 0.1370(0.6943)
2024/03/05 00:31:24 - INFO - root -   Epoch: [3/300][120/200], lr: 0.00000011 	 loss = 2.8069(0.6734)
2024/03/05 00:32:05 - INFO - root -   Epoch: [3/300][140/200], lr: 0.00000011 	 loss = 1.0859(0.6688)
2024/03/05 00:32:46 - INFO - root -   Epoch: [3/300][160/200], lr: 0.00000011 	 loss = 0.3139(0.6659)
2024/03/05 00:33:23 - INFO - root -   Epoch: [3/300][180/200], lr: 0.00000011 	 loss = 0.2293(0.6817)
2024/03/05 00:33:38 - INFO - root -   Epoch: [3/300] 	 loss = 0.6811
2024/03/05 00:33:38 - INFO - root -   train_accuracy = 0.7850
2024/03/05 00:33:58 - INFO - root -   Epoch: [4/300][0/200], lr: 0.00000011 	 loss = 0.8037(0.8037)
2024/03/05 00:34:58 - INFO - root -   Epoch: [4/300][20/200], lr: 0.00000011 	 loss = 0.3403(0.7999)
2024/03/05 00:35:35 - INFO - root -   Epoch: [4/300][40/200], lr: 0.00000011 	 loss = 0.2236(0.6592)
2024/03/05 00:36:16 - INFO - root -   Epoch: [4/300][60/200], lr: 0.00000011 	 loss = 0.2516(0.6715)
2024/03/05 00:36:56 - INFO - root -   Epoch: [4/300][80/200], lr: 0.00000011 	 loss = 1.3288(0.6844)
2024/03/05 00:37:41 - INFO - root -   Epoch: [4/300][100/200], lr: 0.00000011 	 loss = 0.1550(0.6636)
2024/03/05 00:38:34 - INFO - root -   Epoch: [4/300][120/200], lr: 0.00000011 	 loss = 3.0602(0.6375)
2024/03/05 00:39:12 - INFO - root -   Epoch: [4/300][140/200], lr: 0.00000011 	 loss = 1.5282(0.6572)
2024/03/05 00:39:36 - INFO - root -   Epoch: [4/300][160/200], lr: 0.00000011 	 loss = 0.2503(0.6648)
2024/03/05 00:40:04 - INFO - root -   Epoch: [4/300][180/200], lr: 0.00000011 	 loss = 0.2263(0.6804)
2024/03/05 00:40:16 - INFO - root -   Epoch: [4/300] 	 loss = 0.6739
2024/03/05 00:40:20 - INFO - root -   precision = 0.8222
2024/03/05 00:40:20 - INFO - root -   eval_loss = 0.5856
2024/03/05 00:40:20 - INFO - root -   eval_acc = 0.8222
2024/03/05 00:40:21 - INFO - root -   train_accuracy = 0.7975
2024/03/05 00:40:53 - INFO - root -   Epoch: [5/300][0/200], lr: 0.00000011 	 loss = 1.3875(1.3875)
2024/03/05 00:41:39 - INFO - root -   Epoch: [5/300][20/200], lr: 0.00000011 	 loss = 0.4184(0.9410)
2024/03/05 00:42:14 - INFO - root -   Epoch: [5/300][40/200], lr: 0.00000011 	 loss = 0.1439(0.7238)
2024/03/05 00:42:56 - INFO - root -   Epoch: [5/300][60/200], lr: 0.00000011 	 loss = 0.1683(0.6770)
2024/03/05 00:43:43 - INFO - root -   Epoch: [5/300][80/200], lr: 0.00000011 	 loss = 1.5907(0.6910)
2024/03/05 00:44:15 - INFO - root -   Epoch: [5/300][100/200], lr: 0.00000011 	 loss = 0.2099(0.6510)
2024/03/05 00:44:47 - INFO - root -   Epoch: [5/300][120/200], lr: 0.00000011 	 loss = 1.9010(0.6231)
2024/03/05 00:45:28 - INFO - root -   Epoch: [5/300][140/200], lr: 0.00000011 	 loss = 1.2188(0.6339)
2024/03/05 00:46:15 - INFO - root -   Epoch: [5/300][160/200], lr: 0.00000011 	 loss = 0.2578(0.6321)
2024/03/05 00:46:46 - INFO - root -   Epoch: [5/300][180/200], lr: 0.00000011 	 loss = 0.6397(0.6646)
2024/03/05 00:47:01 - INFO - root -   Epoch: [5/300] 	 loss = 0.6628
2024/03/05 00:47:01 - INFO - root -   train_accuracy = 0.8000
2024/03/05 00:47:35 - INFO - root -   Epoch: [6/300][0/200], lr: 0.00000011 	 loss = 1.6903(1.6903)
2024/03/05 00:48:24 - INFO - root -   Epoch: [6/300][20/200], lr: 0.00000011 	 loss = 0.1541(0.8172)
2024/03/05 00:49:02 - INFO - root -   Epoch: [6/300][40/200], lr: 0.00000011 	 loss = 0.1601(0.6151)
2024/03/05 00:49:28 - INFO - root -   Epoch: [6/300][60/200], lr: 0.00000011 	 loss = 0.1064(0.6040)
2024/03/05 00:50:13 - INFO - root -   Epoch: [6/300][80/200], lr: 0.00000011 	 loss = 1.1793(0.6290)
2024/03/05 00:50:49 - INFO - root -   Epoch: [6/300][100/200], lr: 0.00000011 	 loss = 0.0566(0.6078)
2024/03/05 00:51:28 - INFO - root -   Epoch: [6/300][120/200], lr: 0.00000011 	 loss = 2.3186(0.6016)
2024/03/05 00:52:25 - INFO - root -   Epoch: [6/300][140/200], lr: 0.00000011 	 loss = 1.2124(0.6158)
2024/03/05 00:52:57 - INFO - root -   Epoch: [6/300][160/200], lr: 0.00000011 	 loss = 0.1282(0.6225)
2024/03/05 00:53:41 - INFO - root -   Epoch: [6/300][180/200], lr: 0.00000011 	 loss = 0.5835(0.6444)
2024/03/05 00:53:48 - INFO - root -   Epoch: [6/300] 	 loss = 0.6403
2024/03/05 00:53:48 - INFO - root -   train_accuracy = 0.8050
2024/03/05 00:54:28 - INFO - root -   Epoch: [7/300][0/200], lr: 0.00000012 	 loss = 0.9274(0.9274)
2024/03/05 00:55:14 - INFO - root -   Epoch: [7/300][20/200], lr: 0.00000012 	 loss = 0.1735(0.7018)
2024/03/05 00:55:48 - INFO - root -   Epoch: [7/300][40/200], lr: 0.00000012 	 loss = 0.2508(0.5567)
2024/03/05 00:56:26 - INFO - root -   Epoch: [7/300][60/200], lr: 0.00000012 	 loss = 0.1608(0.6088)
2024/03/05 00:57:02 - INFO - root -   Epoch: [7/300][80/200], lr: 0.00000012 	 loss = 1.8733(0.6002)
2024/03/05 00:58:05 - INFO - root -   Epoch: [7/300][100/200], lr: 0.00000012 	 loss = 0.2872(0.6074)
2024/03/05 00:58:34 - INFO - root -   Epoch: [7/300][120/200], lr: 0.00000012 	 loss = 2.8520(0.5869)
2024/03/05 00:59:08 - INFO - root -   Epoch: [7/300][140/200], lr: 0.00000012 	 loss = 1.7885(0.5992)
2024/03/05 00:59:40 - INFO - root -   Epoch: [7/300][160/200], lr: 0.00000012 	 loss = 0.0966(0.6146)
2024/03/05 01:00:13 - INFO - root -   Epoch: [7/300][180/200], lr: 0.00000012 	 loss = 0.2134(0.6174)
2024/03/05 01:00:26 - INFO - root -   Epoch: [7/300] 	 loss = 0.6156
2024/03/05 01:00:26 - INFO - root -   train_accuracy = 0.7975
2024/03/05 01:01:00 - INFO - root -   Epoch: [8/300][0/200], lr: 0.00000012 	 loss = 1.4870(1.4870)
2024/03/05 01:01:49 - INFO - root -   Epoch: [8/300][20/200], lr: 0.00000012 	 loss = 0.2809(0.8102)
2024/03/05 01:02:27 - INFO - root -   Epoch: [8/300][40/200], lr: 0.00000012 	 loss = 0.2143(0.6558)
2024/03/05 01:03:04 - INFO - root -   Epoch: [8/300][60/200], lr: 0.00000012 	 loss = 0.3200(0.6595)
2024/03/05 01:03:34 - INFO - root -   Epoch: [8/300][80/200], lr: 0.00000012 	 loss = 0.8753(0.6762)
2024/03/05 01:04:22 - INFO - root -   Epoch: [8/300][100/200], lr: 0.00000012 	 loss = 0.1940(0.6707)
2024/03/05 01:05:13 - INFO - root -   Epoch: [8/300][120/200], lr: 0.00000012 	 loss = 2.7505(0.6505)
2024/03/05 01:05:49 - INFO - root -   Epoch: [8/300][140/200], lr: 0.00000012 	 loss = 1.4674(0.6668)
2024/03/05 01:06:24 - INFO - root -   Epoch: [8/300][160/200], lr: 0.00000012 	 loss = 0.1974(0.6654)
2024/03/05 01:07:05 - INFO - root -   Epoch: [8/300][180/200], lr: 0.00000012 	 loss = 0.2890(0.6704)
2024/03/05 01:07:21 - INFO - root -   Epoch: [8/300] 	 loss = 0.6716
2024/03/05 01:07:21 - INFO - root -   train_accuracy = 0.7925
2024/03/05 01:07:55 - INFO - root -   Epoch: [9/300][0/200], lr: 0.00000012 	 loss = 1.5014(1.5014)
2024/03/05 01:08:36 - INFO - root -   Epoch: [9/300][20/200], lr: 0.00000012 	 loss = 0.5132(0.7902)
2024/03/05 01:09:13 - INFO - root -   Epoch: [9/300][40/200], lr: 0.00000012 	 loss = 0.1344(0.6083)
2024/03/05 01:09:49 - INFO - root -   Epoch: [9/300][60/200], lr: 0.00000012 	 loss = 0.1915(0.6304)
2024/03/05 01:10:51 - INFO - root -   Epoch: [9/300][80/200], lr: 0.00000012 	 loss = 1.4463(0.6439)
2024/03/05 01:11:21 - INFO - root -   Epoch: [9/300][100/200], lr: 0.00000012 	 loss = 0.2571(0.6232)
2024/03/05 01:11:40 - INFO - root -   Epoch: [9/300][120/200], lr: 0.00000012 	 loss = 2.2577(0.6056)
2024/03/05 01:12:20 - INFO - root -   Epoch: [9/300][140/200], lr: 0.00000012 	 loss = 1.3468(0.6159)
2024/03/05 01:13:19 - INFO - root -   Epoch: [9/300][160/200], lr: 0.00000012 	 loss = 0.1153(0.6211)
2024/03/05 01:13:41 - INFO - root -   Epoch: [9/300][180/200], lr: 0.00000012 	 loss = 0.0526(0.6346)
2024/03/05 01:13:48 - INFO - root -   Epoch: [9/300] 	 loss = 0.6438
2024/03/05 01:13:52 - INFO - root -   precision = 0.8222
2024/03/05 01:13:52 - INFO - root -   eval_loss = 0.6078
2024/03/05 01:13:52 - INFO - root -   eval_acc = 0.8222
2024/03/05 01:13:53 - INFO - root -   train_accuracy = 0.7975
2024/03/05 01:14:18 - INFO - root -   Epoch: [10/300][0/200], lr: 0.00000012 	 loss = 1.2583(1.2583)
2024/03/05 01:15:08 - INFO - root -   Epoch: [10/300][20/200], lr: 0.00000012 	 loss = 0.3254(0.8488)
2024/03/05 01:15:48 - INFO - root -   Epoch: [10/300][40/200], lr: 0.00000012 	 loss = 0.2189(0.6386)
2024/03/05 01:16:28 - INFO - root -   Epoch: [10/300][60/200], lr: 0.00000012 	 loss = 0.0894(0.6322)
2024/03/05 01:17:08 - INFO - root -   Epoch: [10/300][80/200], lr: 0.00000012 	 loss = 2.1801(0.6453)
2024/03/05 01:17:41 - INFO - root -   Epoch: [10/300][100/200], lr: 0.00000012 	 loss = 0.2371(0.6296)
2024/03/05 01:18:04 - INFO - root -   Epoch: [10/300][120/200], lr: 0.00000012 	 loss = 2.3684(0.6010)
2024/03/05 01:18:54 - INFO - root -   Epoch: [10/300][140/200], lr: 0.00000012 	 loss = 1.5919(0.6117)
2024/03/05 01:19:41 - INFO - root -   Epoch: [10/300][160/200], lr: 0.00000012 	 loss = 0.0618(0.6063)
2024/03/05 01:20:16 - INFO - root -   Epoch: [10/300][180/200], lr: 0.00000012 	 loss = 0.1834(0.6263)
2024/03/05 01:20:36 - INFO - root -   Epoch: [10/300] 	 loss = 0.6189
2024/03/05 01:20:36 - INFO - root -   train_accuracy = 0.8000
2024/03/05 01:21:15 - INFO - root -   Epoch: [11/300][0/200], lr: 0.00000013 	 loss = 1.6544(1.6544)
2024/03/05 01:21:57 - INFO - root -   Epoch: [11/300][20/200], lr: 0.00000013 	 loss = 0.6092(0.7316)
2024/03/05 01:22:32 - INFO - root -   Epoch: [11/300][40/200], lr: 0.00000013 	 loss = 0.9639(0.6391)
2024/03/05 01:23:10 - INFO - root -   Epoch: [11/300][60/200], lr: 0.00000013 	 loss = 0.2322(0.6163)
2024/03/05 01:24:15 - INFO - root -   Epoch: [11/300][80/200], lr: 0.00000013 	 loss = 1.8768(0.6196)
2024/03/05 01:24:54 - INFO - root -   Epoch: [11/300][100/200], lr: 0.00000013 	 loss = 0.0477(0.6165)
2024/03/05 01:25:24 - INFO - root -   Epoch: [11/300][120/200], lr: 0.00000013 	 loss = 3.5022(0.6008)
2024/03/05 01:26:05 - INFO - root -   Epoch: [11/300][140/200], lr: 0.00000013 	 loss = 2.0473(0.6252)
2024/03/05 01:26:40 - INFO - root -   Epoch: [11/300][160/200], lr: 0.00000013 	 loss = 0.2405(0.6204)
2024/03/05 01:27:25 - INFO - root -   Epoch: [11/300][180/200], lr: 0.00000013 	 loss = 0.1434(0.6350)
2024/03/05 01:27:35 - INFO - root -   Epoch: [11/300] 	 loss = 0.6305
2024/03/05 01:27:35 - INFO - root -   train_accuracy = 0.7950
2024/03/05 01:28:16 - INFO - root -   Epoch: [12/300][0/200], lr: 0.00000013 	 loss = 1.2211(1.2211)
2024/03/05 01:28:56 - INFO - root -   Epoch: [12/300][20/200], lr: 0.00000013 	 loss = 0.2256(0.8337)
2024/03/05 01:29:32 - INFO - root -   Epoch: [12/300][40/200], lr: 0.00000013 	 loss = 0.1281(0.6325)
2024/03/05 01:30:10 - INFO - root -   Epoch: [12/300][60/200], lr: 0.00000013 	 loss = 0.0475(0.5989)
2024/03/05 01:31:01 - INFO - root -   Epoch: [12/300][80/200], lr: 0.00000013 	 loss = 2.2253(0.6343)
2024/03/05 01:31:47 - INFO - root -   Epoch: [12/300][100/200], lr: 0.00000013 	 loss = 0.1330(0.6243)
2024/03/05 01:32:19 - INFO - root -   Epoch: [12/300][120/200], lr: 0.00000013 	 loss = 3.0187(0.6140)
2024/03/05 01:33:00 - INFO - root -   Epoch: [12/300][140/200], lr: 0.00000013 	 loss = 1.5909(0.6229)
2024/03/05 01:33:25 - INFO - root -   Epoch: [12/300][160/200], lr: 0.00000013 	 loss = 0.0585(0.6285)
2024/03/05 01:34:12 - INFO - root -   Epoch: [12/300][180/200], lr: 0.00000013 	 loss = 0.2339(0.6525)
2024/03/05 01:34:22 - INFO - root -   Epoch: [12/300] 	 loss = 0.6543
2024/03/05 01:34:22 - INFO - root -   train_accuracy = 0.7975
2024/03/05 01:35:01 - INFO - root -   Epoch: [13/300][0/200], lr: 0.00000013 	 loss = 1.7476(1.7476)
2024/03/05 01:35:41 - INFO - root -   Epoch: [13/300][20/200], lr: 0.00000013 	 loss = 0.3543(0.6909)
2024/03/05 01:36:18 - INFO - root -   Epoch: [13/300][40/200], lr: 0.00000013 	 loss = 0.1479(0.5428)
2024/03/05 01:36:54 - INFO - root -   Epoch: [13/300][60/200], lr: 0.00000013 	 loss = 0.4815(0.5668)
2024/03/05 01:37:31 - INFO - root -   Epoch: [13/300][80/200], lr: 0.00000013 	 loss = 1.8533(0.6106)
2024/03/05 01:38:29 - INFO - root -   Epoch: [13/300][100/200], lr: 0.00000013 	 loss = 0.2050(0.5853)
2024/03/05 01:39:07 - INFO - root -   Epoch: [13/300][120/200], lr: 0.00000013 	 loss = 2.6068(0.5775)
2024/03/05 01:39:43 - INFO - root -   Epoch: [13/300][140/200], lr: 0.00000013 	 loss = 1.4352(0.5839)
2024/03/05 01:40:25 - INFO - root -   Epoch: [13/300][160/200], lr: 0.00000013 	 loss = 0.2040(0.5891)
2024/03/05 01:41:03 - INFO - root -   Epoch: [13/300][180/200], lr: 0.00000013 	 loss = 0.1062(0.6168)
2024/03/05 01:41:12 - INFO - root -   Epoch: [13/300] 	 loss = 0.6193
2024/03/05 01:41:12 - INFO - root -   train_accuracy = 0.8075
2024/03/05 01:41:41 - INFO - root -   Epoch: [14/300][0/200], lr: 0.00000013 	 loss = 2.0899(2.0899)
2024/03/05 01:42:33 - INFO - root -   Epoch: [14/300][20/200], lr: 0.00000013 	 loss = 0.4426(0.8792)
2024/03/05 01:43:09 - INFO - root -   Epoch: [14/300][40/200], lr: 0.00000013 	 loss = 0.1342(0.6838)
2024/03/05 01:43:46 - INFO - root -   Epoch: [14/300][60/200], lr: 0.00000013 	 loss = 0.0636(0.6623)
2024/03/05 01:44:39 - INFO - root -   Epoch: [14/300][80/200], lr: 0.00000013 	 loss = 0.9971(0.6504)
2024/03/05 01:45:13 - INFO - root -   Epoch: [14/300][100/200], lr: 0.00000013 	 loss = 0.3248(0.6438)
2024/03/05 01:45:52 - INFO - root -   Epoch: [14/300][120/200], lr: 0.00000013 	 loss = 2.2294(0.6113)
2024/03/05 01:46:21 - INFO - root -   Epoch: [14/300][140/200], lr: 0.00000013 	 loss = 2.0186(0.6372)
2024/03/05 01:47:18 - INFO - root -   Epoch: [14/300][160/200], lr: 0.00000013 	 loss = 0.1394(0.6401)
2024/03/05 01:47:48 - INFO - root -   Epoch: [14/300][180/200], lr: 0.00000013 	 loss = 0.2715(0.6432)
2024/03/05 01:47:56 - INFO - root -   Epoch: [14/300] 	 loss = 0.6334
2024/03/05 01:48:00 - INFO - root -   precision = 0.8000
2024/03/05 01:48:00 - INFO - root -   eval_loss = 0.6279
2024/03/05 01:48:00 - INFO - root -   eval_acc = 0.8000
2024/03/05 01:48:01 - INFO - root -   train_accuracy = 0.8000
2024/03/05 01:48:30 - INFO - root -   Epoch: [15/300][0/200], lr: 0.00000014 	 loss = 1.9980(1.9980)
2024/03/05 01:49:13 - INFO - root -   Epoch: [15/300][20/200], lr: 0.00000014 	 loss = 0.4000(0.7232)
2024/03/05 01:50:03 - INFO - root -   Epoch: [15/300][40/200], lr: 0.00000014 	 loss = 0.2040(0.5746)
2024/03/05 01:50:37 - INFO - root -   Epoch: [15/300][60/200], lr: 0.00000014 	 loss = 0.0371(0.5679)
2024/03/05 01:51:16 - INFO - root -   Epoch: [15/300][80/200], lr: 0.00000014 	 loss = 1.4688(0.5648)
2024/03/05 01:52:01 - INFO - root -   Epoch: [15/300][100/200], lr: 0.00000014 	 loss = 0.0513(0.5578)
2024/03/05 01:52:47 - INFO - root -   Epoch: [15/300][120/200], lr: 0.00000014 	 loss = 3.0955(0.5502)
2024/03/05 01:53:20 - INFO - root -   Epoch: [15/300][140/200], lr: 0.00000014 	 loss = 1.5318(0.5765)
2024/03/05 01:53:49 - INFO - root -   Epoch: [15/300][160/200], lr: 0.00000014 	 loss = 0.4694(0.5927)
2024/03/05 01:54:42 - INFO - root -   Epoch: [15/300][180/200], lr: 0.00000014 	 loss = 0.3125(0.6112)
2024/03/05 01:54:49 - INFO - root -   Epoch: [15/300] 	 loss = 0.6062
2024/03/05 01:54:49 - INFO - root -   train_accuracy = 0.8125
2024/03/05 01:55:30 - INFO - root -   Epoch: [16/300][0/200], lr: 0.00000014 	 loss = 1.2926(1.2926)
2024/03/05 01:56:09 - INFO - root -   Epoch: [16/300][20/200], lr: 0.00000014 	 loss = 0.2562(0.7366)
2024/03/05 01:56:50 - INFO - root -   Epoch: [16/300][40/200], lr: 0.00000014 	 loss = 0.1704(0.5690)
2024/03/05 01:57:27 - INFO - root -   Epoch: [16/300][60/200], lr: 0.00000014 	 loss = 0.2030(0.6100)
2024/03/05 01:57:51 - INFO - root -   Epoch: [16/300][80/200], lr: 0.00000014 	 loss = 1.3373(0.6419)
2024/03/05 01:58:34 - INFO - root -   Epoch: [16/300][100/200], lr: 0.00000014 	 loss = 0.1045(0.6094)
2024/03/05 01:59:10 - INFO - root -   Epoch: [16/300][120/200], lr: 0.00000014 	 loss = 2.8148(0.5940)
2024/03/05 01:59:58 - INFO - root -   Epoch: [16/300][140/200], lr: 0.00000014 	 loss = 1.8886(0.6205)
2024/03/05 02:00:29 - INFO - root -   Epoch: [16/300][160/200], lr: 0.00000014 	 loss = 0.1145(0.6165)
2024/03/05 02:01:15 - INFO - root -   Epoch: [16/300][180/200], lr: 0.00000014 	 loss = 0.1886(0.6297)
2024/03/05 02:01:23 - INFO - root -   Epoch: [16/300] 	 loss = 0.6279
2024/03/05 02:01:23 - INFO - root -   train_accuracy = 0.7900
2024/03/05 02:02:00 - INFO - root -   Epoch: [17/300][0/200], lr: 0.00000014 	 loss = 1.0469(1.0469)
2024/03/05 02:02:50 - INFO - root -   Epoch: [17/300][20/200], lr: 0.00000014 	 loss = 0.0917(0.8082)
2024/03/05 02:03:14 - INFO - root -   Epoch: [17/300][40/200], lr: 0.00000014 	 loss = 0.3437(0.6618)
2024/03/05 02:04:02 - INFO - root -   Epoch: [17/300][60/200], lr: 0.00000014 	 loss = 0.1359(0.6201)
2024/03/05 02:04:44 - INFO - root -   Epoch: [17/300][80/200], lr: 0.00000014 	 loss = 2.2835(0.6449)
2024/03/05 02:05:25 - INFO - root -   Epoch: [17/300][100/200], lr: 0.00000014 	 loss = 0.1870(0.6277)
2024/03/05 02:05:55 - INFO - root -   Epoch: [17/300][120/200], lr: 0.00000014 	 loss = 2.6016(0.6094)
2024/03/05 02:06:35 - INFO - root -   Epoch: [17/300][140/200], lr: 0.00000014 	 loss = 1.5144(0.6289)
2024/03/05 02:07:11 - INFO - root -   Epoch: [17/300][160/200], lr: 0.00000014 	 loss = 0.2118(0.6231)
2024/03/05 02:08:04 - INFO - root -   Epoch: [17/300][180/200], lr: 0.00000014 	 loss = 0.1074(0.6374)
2024/03/05 02:08:11 - INFO - root -   Epoch: [17/300] 	 loss = 0.6233
2024/03/05 02:08:11 - INFO - root -   train_accuracy = 0.8000
2024/03/05 02:08:48 - INFO - root -   Epoch: [18/300][0/200], lr: 0.00000014 	 loss = 0.6449(0.6449)
2024/03/05 02:09:31 - INFO - root -   Epoch: [18/300][20/200], lr: 0.00000014 	 loss = 0.1742(0.7272)
2024/03/05 02:10:06 - INFO - root -   Epoch: [18/300][40/200], lr: 0.00000014 	 loss = 0.2659(0.5896)
2024/03/05 02:10:48 - INFO - root -   Epoch: [18/300][60/200], lr: 0.00000014 	 loss = 0.1841(0.5909)
2024/03/05 02:11:13 - INFO - root -   Epoch: [18/300][80/200], lr: 0.00000014 	 loss = 1.3762(0.6018)
2024/03/05 02:11:58 - INFO - root -   Epoch: [18/300][100/200], lr: 0.00000014 	 loss = 0.1893(0.5756)
2024/03/05 02:13:09 - INFO - root -   Epoch: [18/300][120/200], lr: 0.00000014 	 loss = 3.4764(0.5759)
2024/03/05 02:13:44 - INFO - root -   Epoch: [18/300][140/200], lr: 0.00000014 	 loss = 1.9390(0.5895)
2024/03/05 02:14:01 - INFO - root -   Epoch: [18/300][160/200], lr: 0.00000014 	 loss = 0.3064(0.5893)
2024/03/05 02:14:46 - INFO - root -   Epoch: [18/300][180/200], lr: 0.00000014 	 loss = 0.3222(0.6063)
2024/03/05 02:14:56 - INFO - root -   Epoch: [18/300] 	 loss = 0.6050
2024/03/05 02:14:56 - INFO - root -   train_accuracy = 0.8000
2024/03/05 02:15:31 - INFO - root -   Epoch: [19/300][0/200], lr: 0.00000015 	 loss = 0.8652(0.8652)
2024/03/05 02:16:09 - INFO - root -   Epoch: [19/300][20/200], lr: 0.00000015 	 loss = 0.2460(0.8230)
2024/03/05 02:16:52 - INFO - root -   Epoch: [19/300][40/200], lr: 0.00000015 	 loss = 0.1090(0.6511)
2024/03/05 02:17:34 - INFO - root -   Epoch: [19/300][60/200], lr: 0.00000015 	 loss = 0.0912(0.6333)
2024/03/05 02:18:12 - INFO - root -   Epoch: [19/300][80/200], lr: 0.00000015 	 loss = 1.3079(0.6103)
2024/03/05 02:18:52 - INFO - root -   Epoch: [19/300][100/200], lr: 0.00000015 	 loss = 0.1090(0.5761)
2024/03/05 02:19:38 - INFO - root -   Epoch: [19/300][120/200], lr: 0.00000015 	 loss = 3.4766(0.5647)
2024/03/05 02:20:20 - INFO - root -   Epoch: [19/300][140/200], lr: 0.00000015 	 loss = 1.5071(0.5861)
2024/03/05 02:21:20 - INFO - root -   Epoch: [19/300][160/200], lr: 0.00000015 	 loss = 0.0579(0.5910)
2024/03/05 02:21:44 - INFO - root -   Epoch: [19/300][180/200], lr: 0.00000015 	 loss = 0.6447(0.6071)
2024/03/05 02:21:53 - INFO - root -   Epoch: [19/300] 	 loss = 0.6054
2024/03/05 02:21:57 - INFO - root -   precision = 0.7778
2024/03/05 02:21:57 - INFO - root -   eval_loss = 0.6481
2024/03/05 02:21:57 - INFO - root -   eval_acc = 0.7778
2024/03/05 02:21:58 - INFO - root -   train_accuracy = 0.8200
2024/03/05 02:22:24 - INFO - root -   Epoch: [20/300][0/200], lr: 0.00000015 	 loss = 1.2122(1.2122)
2024/03/05 02:23:10 - INFO - root -   Epoch: [20/300][20/200], lr: 0.00000015 	 loss = 0.5056(0.7360)
2024/03/05 02:23:50 - INFO - root -   Epoch: [20/300][40/200], lr: 0.00000015 	 loss = 0.2420(0.5867)
2024/03/05 02:24:26 - INFO - root -   Epoch: [20/300][60/200], lr: 0.00000015 	 loss = 0.0876(0.5690)
2024/03/05 02:25:19 - INFO - root -   Epoch: [20/300][80/200], lr: 0.00000015 	 loss = 1.1729(0.5743)
2024/03/05 02:26:01 - INFO - root -   Epoch: [20/300][100/200], lr: 0.00000015 	 loss = 0.1684(0.5736)
2024/03/05 02:26:39 - INFO - root -   Epoch: [20/300][120/200], lr: 0.00000015 	 loss = 3.4032(0.5644)
2024/03/05 02:27:25 - INFO - root -   Epoch: [20/300][140/200], lr: 0.00000015 	 loss = 0.6409(0.5746)
2024/03/05 02:28:12 - INFO - root -   Epoch: [20/300][160/200], lr: 0.00000015 	 loss = 0.2661(0.5653)
2024/03/05 02:28:37 - INFO - root -   Epoch: [20/300][180/200], lr: 0.00000015 	 loss = 0.4574(0.5821)
2024/03/05 02:28:49 - INFO - root -   Epoch: [20/300] 	 loss = 0.5818
2024/03/05 02:28:49 - INFO - root -   train_accuracy = 0.7975
2024/03/05 02:29:08 - INFO - root -   Epoch: [21/300][0/200], lr: 0.00000015 	 loss = 1.4456(1.4456)
2024/03/05 02:30:09 - INFO - root -   Epoch: [21/300][20/200], lr: 0.00000015 	 loss = 0.4550(0.7989)
2024/03/05 02:30:46 - INFO - root -   Epoch: [21/300][40/200], lr: 0.00000015 	 loss = 0.2009(0.6497)
2024/03/05 02:31:17 - INFO - root -   Epoch: [21/300][60/200], lr: 0.00000015 	 loss = 0.1173(0.6145)
2024/03/05 02:32:01 - INFO - root -   Epoch: [21/300][80/200], lr: 0.00000015 	 loss = 0.8126(0.6172)
2024/03/05 02:32:49 - INFO - root -   Epoch: [21/300][100/200], lr: 0.00000015 	 loss = 0.2158(0.5895)
2024/03/05 02:33:28 - INFO - root -   Epoch: [21/300][120/200], lr: 0.00000015 	 loss = 3.1350(0.5776)
2024/03/05 02:34:02 - INFO - root -   Epoch: [21/300][140/200], lr: 0.00000015 	 loss = 1.8272(0.6050)
2024/03/05 02:34:38 - INFO - root -   Epoch: [21/300][160/200], lr: 0.00000015 	 loss = 0.1411(0.5975)
2024/03/05 02:35:22 - INFO - root -   Epoch: [21/300][180/200], lr: 0.00000015 	 loss = 0.2234(0.6065)
2024/03/05 02:35:30 - INFO - root -   Epoch: [21/300] 	 loss = 0.6039
2024/03/05 02:35:30 - INFO - root -   train_accuracy = 0.7900
2024/03/05 02:36:03 - INFO - root -   Epoch: [22/300][0/200], lr: 0.00000015 	 loss = 1.1150(1.1150)
2024/03/05 02:36:43 - INFO - root -   Epoch: [22/300][20/200], lr: 0.00000015 	 loss = 0.3753(0.7882)
2024/03/05 02:37:29 - INFO - root -   Epoch: [22/300][40/200], lr: 0.00000015 	 loss = 0.0391(0.6436)
2024/03/05 02:38:10 - INFO - root -   Epoch: [22/300][60/200], lr: 0.00000015 	 loss = 0.1307(0.6249)
2024/03/05 02:38:40 - INFO - root -   Epoch: [22/300][80/200], lr: 0.00000015 	 loss = 1.3305(0.6410)
2024/03/05 02:39:34 - INFO - root -   Epoch: [22/300][100/200], lr: 0.00000015 	 loss = 0.0709(0.5995)
2024/03/05 02:40:19 - INFO - root -   Epoch: [22/300][120/200], lr: 0.00000015 	 loss = 2.6397(0.5881)
2024/03/05 02:40:55 - INFO - root -   Epoch: [22/300][140/200], lr: 0.00000015 	 loss = 1.5772(0.6042)
2024/03/05 02:41:41 - INFO - root -   Epoch: [22/300][160/200], lr: 0.00000015 	 loss = 0.0570(0.6137)
2024/03/05 02:42:04 - INFO - root -   Epoch: [22/300][180/200], lr: 0.00000015 	 loss = 0.5278(0.6290)
2024/03/05 02:42:15 - INFO - root -   Epoch: [22/300] 	 loss = 0.6180
2024/03/05 02:42:15 - INFO - root -   train_accuracy = 0.7975
2024/03/05 02:42:49 - INFO - root -   Epoch: [23/300][0/200], lr: 0.00000016 	 loss = 1.8456(1.8456)
2024/03/05 02:43:18 - INFO - root -   Epoch: [23/300][20/200], lr: 0.00000016 	 loss = 0.1793(0.6733)
2024/03/05 02:44:11 - INFO - root -   Epoch: [23/300][40/200], lr: 0.00000016 	 loss = 0.1335(0.5231)
2024/03/05 02:44:40 - INFO - root -   Epoch: [23/300][60/200], lr: 0.00000016 	 loss = 0.1096(0.5351)
2024/03/05 02:45:26 - INFO - root -   Epoch: [23/300][80/200], lr: 0.00000016 	 loss = 1.0261(0.5762)
2024/03/05 02:45:53 - INFO - root -   Epoch: [23/300][100/200], lr: 0.00000016 	 loss = 0.2385(0.5688)
2024/03/05 02:46:50 - INFO - root -   Epoch: [23/300][120/200], lr: 0.00000016 	 loss = 3.0459(0.5586)
2024/03/05 02:47:30 - INFO - root -   Epoch: [23/300][140/200], lr: 0.00000016 	 loss = 2.4885(0.5867)
2024/03/05 02:48:01 - INFO - root -   Epoch: [23/300][160/200], lr: 0.00000016 	 loss = 0.1490(0.5933)
2024/03/05 02:48:46 - INFO - root -   Epoch: [23/300][180/200], lr: 0.00000016 	 loss = 0.3965(0.6130)
2024/03/05 02:48:54 - INFO - root -   Epoch: [23/300] 	 loss = 0.6077
2024/03/05 02:48:54 - INFO - root -   train_accuracy = 0.8050
2024/03/05 02:49:31 - INFO - root -   Epoch: [24/300][0/200], lr: 0.00000016 	 loss = 1.0217(1.0217)
2024/03/05 02:50:16 - INFO - root -   Epoch: [24/300][20/200], lr: 0.00000016 	 loss = 0.1644(0.7243)
2024/03/05 02:51:00 - INFO - root -   Epoch: [24/300][40/200], lr: 0.00000016 	 loss = 0.0846(0.5620)
2024/03/05 02:51:36 - INFO - root -   Epoch: [24/300][60/200], lr: 0.00000016 	 loss = 0.1435(0.5764)
2024/03/05 02:52:25 - INFO - root -   Epoch: [24/300][80/200], lr: 0.00000016 	 loss = 1.9732(0.6029)
2024/03/05 02:53:00 - INFO - root -   Epoch: [24/300][100/200], lr: 0.00000016 	 loss = 0.1359(0.5827)
2024/03/05 02:53:36 - INFO - root -   Epoch: [24/300][120/200], lr: 0.00000016 	 loss = 3.1577(0.5668)
2024/03/05 02:54:09 - INFO - root -   Epoch: [24/300][140/200], lr: 0.00000016 	 loss = 1.7267(0.5964)
2024/03/05 02:55:05 - INFO - root -   Epoch: [24/300][160/200], lr: 0.00000016 	 loss = 0.1716(0.6001)
2024/03/05 02:55:29 - INFO - root -   Epoch: [24/300][180/200], lr: 0.00000016 	 loss = 0.4076(0.6268)
2024/03/05 02:55:47 - INFO - root -   Epoch: [24/300] 	 loss = 0.6293
2024/03/05 02:55:51 - INFO - root -   precision = 0.7778
2024/03/05 02:55:51 - INFO - root -   eval_loss = 0.6536
2024/03/05 02:55:51 - INFO - root -   eval_acc = 0.7778
2024/03/05 02:55:52 - INFO - root -   train_accuracy = 0.7975
2024/03/05 02:56:20 - INFO - root -   Epoch: [25/300][0/200], lr: 0.00000016 	 loss = 1.5427(1.5427)
2024/03/05 02:57:10 - INFO - root -   Epoch: [25/300][20/200], lr: 0.00000016 	 loss = 0.3684(0.7977)
2024/03/05 02:57:49 - INFO - root -   Epoch: [25/300][40/200], lr: 0.00000016 	 loss = 0.1579(0.6490)
2024/03/05 02:58:24 - INFO - root -   Epoch: [25/300][60/200], lr: 0.00000016 	 loss = 0.0653(0.6077)
2024/03/05 02:58:53 - INFO - root -   Epoch: [25/300][80/200], lr: 0.00000016 	 loss = 0.9328(0.6141)
2024/03/05 02:59:45 - INFO - root -   Epoch: [25/300][100/200], lr: 0.00000016 	 loss = 0.2958(0.5955)
2024/03/05 03:00:25 - INFO - root -   Epoch: [25/300][120/200], lr: 0.00000016 	 loss = 2.7654(0.5930)
2024/03/05 03:01:16 - INFO - root -   Epoch: [25/300][140/200], lr: 0.00000016 	 loss = 1.6069(0.6112)
2024/03/05 03:01:46 - INFO - root -   Epoch: [25/300][160/200], lr: 0.00000016 	 loss = 0.0758(0.6106)
2024/03/05 03:02:23 - INFO - root -   Epoch: [25/300][180/200], lr: 0.00000016 	 loss = 0.3661(0.6269)
2024/03/05 03:02:40 - INFO - root -   Epoch: [25/300] 	 loss = 0.6283
2024/03/05 03:02:40 - INFO - root -   train_accuracy = 0.8125
2024/03/05 03:03:16 - INFO - root -   Epoch: [26/300][0/200], lr: 0.00000016 	 loss = 1.9077(1.9077)
2024/03/05 03:03:58 - INFO - root -   Epoch: [26/300][20/200], lr: 0.00000016 	 loss = 0.1657(0.6751)
2024/03/05 03:04:37 - INFO - root -   Epoch: [26/300][40/200], lr: 0.00000016 	 loss = 0.6969(0.5557)
2024/03/05 03:05:13 - INFO - root -   Epoch: [26/300][60/200], lr: 0.00000016 	 loss = 0.1323(0.5686)
2024/03/05 03:06:19 - INFO - root -   Epoch: [26/300][80/200], lr: 0.00000016 	 loss = 1.7148(0.5837)
2024/03/05 03:06:55 - INFO - root -   Epoch: [26/300][100/200], lr: 0.00000016 	 loss = 0.2231(0.5623)
2024/03/05 03:07:35 - INFO - root -   Epoch: [26/300][120/200], lr: 0.00000016 	 loss = 3.1134(0.5477)
2024/03/05 03:08:13 - INFO - root -   Epoch: [26/300][140/200], lr: 0.00000016 	 loss = 1.8920(0.5633)
2024/03/05 03:08:45 - INFO - root -   Epoch: [26/300][160/200], lr: 0.00000016 	 loss = 0.0380(0.5674)
2024/03/05 03:09:23 - INFO - root -   Epoch: [26/300][180/200], lr: 0.00000016 	 loss = 0.4014(0.5821)
2024/03/05 03:09:34 - INFO - root -   Epoch: [26/300] 	 loss = 0.5831
2024/03/05 03:09:34 - INFO - root -   train_accuracy = 0.8050
2024/03/05 03:10:13 - INFO - root -   Epoch: [27/300][0/200], lr: 0.00000017 	 loss = 1.1225(1.1225)
2024/03/05 03:10:55 - INFO - root -   Epoch: [27/300][20/200], lr: 0.00000017 	 loss = 0.1858(0.7684)
2024/03/05 03:11:36 - INFO - root -   Epoch: [27/300][40/200], lr: 0.00000017 	 loss = 0.1503(0.5987)
2024/03/05 03:12:05 - INFO - root -   Epoch: [27/300][60/200], lr: 0.00000017 	 loss = 0.1284(0.5783)
2024/03/05 03:12:54 - INFO - root -   Epoch: [27/300][80/200], lr: 0.00000017 	 loss = 1.8641(0.5923)
2024/03/05 03:13:29 - INFO - root -   Epoch: [27/300][100/200], lr: 0.00000017 	 loss = 0.2026(0.5904)
2024/03/05 03:14:21 - INFO - root -   Epoch: [27/300][120/200], lr: 0.00000017 	 loss = 3.3161(0.5856)
2024/03/05 03:14:54 - INFO - root -   Epoch: [27/300][140/200], lr: 0.00000017 	 loss = 1.8633(0.5942)
2024/03/05 03:15:26 - INFO - root -   Epoch: [27/300][160/200], lr: 0.00000017 	 loss = 0.1282(0.6101)
2024/03/05 03:16:09 - INFO - root -   Epoch: [27/300][180/200], lr: 0.00000017 	 loss = 0.7218(0.6307)
2024/03/05 03:16:21 - INFO - root -   Epoch: [27/300] 	 loss = 0.6184
2024/03/05 03:16:21 - INFO - root -   train_accuracy = 0.7925
2024/03/05 03:17:02 - INFO - root -   Epoch: [28/300][0/200], lr: 0.00000017 	 loss = 1.1476(1.1476)
2024/03/05 03:17:37 - INFO - root -   Epoch: [28/300][20/200], lr: 0.00000017 	 loss = 0.3233(0.7262)
2024/03/05 03:18:22 - INFO - root -   Epoch: [28/300][40/200], lr: 0.00000017 	 loss = 0.2197(0.5923)
2024/03/05 03:19:01 - INFO - root -   Epoch: [28/300][60/200], lr: 0.00000017 	 loss = 0.0665(0.5534)
2024/03/05 03:19:53 - INFO - root -   Epoch: [28/300][80/200], lr: 0.00000017 	 loss = 1.0553(0.5777)
2024/03/05 03:20:28 - INFO - root -   Epoch: [28/300][100/200], lr: 0.00000017 	 loss = 0.1002(0.5735)
2024/03/05 03:21:04 - INFO - root -   Epoch: [28/300][120/200], lr: 0.00000017 	 loss = 3.2301(0.5703)
2024/03/05 03:21:41 - INFO - root -   Epoch: [28/300][140/200], lr: 0.00000017 	 loss = 1.5122(0.5898)
2024/03/05 03:22:16 - INFO - root -   Epoch: [28/300][160/200], lr: 0.00000017 	 loss = 0.0630(0.5874)
2024/03/05 03:22:56 - INFO - root -   Epoch: [28/300][180/200], lr: 0.00000017 	 loss = 0.1460(0.6025)
2024/03/05 03:23:05 - INFO - root -   Epoch: [28/300] 	 loss = 0.6008
2024/03/05 03:23:05 - INFO - root -   train_accuracy = 0.8150
2024/03/05 03:23:48 - INFO - root -   Epoch: [29/300][0/200], lr: 0.00000017 	 loss = 1.1738(1.1738)
2024/03/05 03:24:30 - INFO - root -   Epoch: [29/300][20/200], lr: 0.00000017 	 loss = 0.1484(0.6806)
2024/03/05 03:24:52 - INFO - root -   Epoch: [29/300][40/200], lr: 0.00000017 	 loss = 0.2215(0.5676)
2024/03/05 03:25:23 - INFO - root -   Epoch: [29/300][60/200], lr: 0.00000017 	 loss = 0.1209(0.5466)
2024/03/05 03:26:23 - INFO - root -   Epoch: [29/300][80/200], lr: 0.00000017 	 loss = 0.8529(0.5682)
2024/03/05 03:27:04 - INFO - root -   Epoch: [29/300][100/200], lr: 0.00000017 	 loss = 0.1263(0.5494)
2024/03/05 03:27:43 - INFO - root -   Epoch: [29/300][120/200], lr: 0.00000017 	 loss = 3.0799(0.5417)
2024/03/05 03:28:20 - INFO - root -   Epoch: [29/300][140/200], lr: 0.00000017 	 loss = 1.7322(0.5619)
2024/03/05 03:29:26 - INFO - root -   Epoch: [29/300][160/200], lr: 0.00000017 	 loss = 0.2015(0.5657)
2024/03/05 03:29:48 - INFO - root -   Epoch: [29/300][180/200], lr: 0.00000017 	 loss = 0.4340(0.5920)
2024/03/05 03:29:56 - INFO - root -   Epoch: [29/300] 	 loss = 0.5838
2024/03/05 03:30:00 - INFO - root -   precision = 0.7778
2024/03/05 03:30:00 - INFO - root -   eval_loss = 0.6673
2024/03/05 03:30:00 - INFO - root -   eval_acc = 0.7778
2024/03/05 03:30:01 - INFO - root -   train_accuracy = 0.8175
2024/03/05 03:30:38 - INFO - root -   Epoch: [30/300][0/200], lr: 0.00000017 	 loss = 1.7098(1.7098)
2024/03/05 03:31:21 - INFO - root -   Epoch: [30/300][20/200], lr: 0.00000017 	 loss = 0.1270(0.7092)
2024/03/05 03:31:59 - INFO - root -   Epoch: [30/300][40/200], lr: 0.00000017 	 loss = 0.2030(0.5768)
2024/03/05 03:32:31 - INFO - root -   Epoch: [30/300][60/200], lr: 0.00000017 	 loss = 0.2459(0.5710)
2024/03/05 03:33:13 - INFO - root -   Epoch: [30/300][80/200], lr: 0.00000017 	 loss = 1.5053(0.5603)
2024/03/05 03:34:02 - INFO - root -   Epoch: [30/300][100/200], lr: 0.00000017 	 loss = 0.2230(0.5288)
2024/03/05 03:34:38 - INFO - root -   Epoch: [30/300][120/200], lr: 0.00000017 	 loss = 3.7879(0.5309)
2024/03/05 03:35:13 - INFO - root -   Epoch: [30/300][140/200], lr: 0.00000017 	 loss = 2.4408(0.5516)
2024/03/05 03:36:02 - INFO - root -   Epoch: [30/300][160/200], lr: 0.00000017 	 loss = 0.4576(0.5497)
2024/03/05 03:36:34 - INFO - root -   Epoch: [30/300][180/200], lr: 0.00000017 	 loss = 0.4773(0.5615)
2024/03/05 03:36:45 - INFO - root -   Epoch: [30/300] 	 loss = 0.5575
2024/03/05 03:36:45 - INFO - root -   train_accuracy = 0.8200
2024/03/05 03:37:27 - INFO - root -   Epoch: [31/300][0/200], lr: 0.00000018 	 loss = 0.9648(0.9648)
2024/03/05 03:38:06 - INFO - root -   Epoch: [31/300][20/200], lr: 0.00000018 	 loss = 0.6688(0.6915)
2024/03/05 03:38:54 - INFO - root -   Epoch: [31/300][40/200], lr: 0.00000018 	 loss = 0.1894(0.5696)
2024/03/05 03:39:17 - INFO - root -   Epoch: [31/300][60/200], lr: 0.00000018 	 loss = 0.1325(0.5843)
2024/03/05 03:40:13 - INFO - root -   Epoch: [31/300][80/200], lr: 0.00000018 	 loss = 1.0166(0.5936)
2024/03/05 03:40:59 - INFO - root -   Epoch: [31/300][100/200], lr: 0.00000018 	 loss = 0.5911(0.5653)
2024/03/05 03:41:37 - INFO - root -   Epoch: [31/300][120/200], lr: 0.00000018 	 loss = 1.9717(0.5476)
2024/03/05 03:42:11 - INFO - root -   Epoch: [31/300][140/200], lr: 0.00000018 	 loss = 1.4381(0.5586)
2024/03/05 03:42:50 - INFO - root -   Epoch: [31/300][160/200], lr: 0.00000018 	 loss = 0.0858(0.5623)
2024/03/05 03:43:28 - INFO - root -   Epoch: [31/300][180/200], lr: 0.00000018 	 loss = 0.7193(0.5856)
2024/03/05 03:43:39 - INFO - root -   Epoch: [31/300] 	 loss = 0.5914
2024/03/05 03:43:39 - INFO - root -   train_accuracy = 0.7800
2024/03/05 03:44:02 - INFO - root -   Epoch: [32/300][0/200], lr: 0.00000018 	 loss = 2.1152(2.1152)
2024/03/05 03:44:51 - INFO - root -   Epoch: [32/300][20/200], lr: 0.00000018 	 loss = 0.1352(0.6585)
2024/03/05 03:45:24 - INFO - root -   Epoch: [32/300][40/200], lr: 0.00000018 	 loss = 0.2546(0.5524)
2024/03/05 03:45:58 - INFO - root -   Epoch: [32/300][60/200], lr: 0.00000018 	 loss = 0.0793(0.5487)
2024/03/05 03:46:40 - INFO - root -   Epoch: [32/300][80/200], lr: 0.00000018 	 loss = 1.4776(0.5866)
2024/03/05 03:47:25 - INFO - root -   Epoch: [32/300][100/200], lr: 0.00000018 	 loss = 0.1102(0.5677)
2024/03/05 03:48:00 - INFO - root -   Epoch: [32/300][120/200], lr: 0.00000018 	 loss = 3.4867(0.5564)
2024/03/05 03:48:37 - INFO - root -   Epoch: [32/300][140/200], lr: 0.00000018 	 loss = 0.9909(0.5556)
2024/03/05 03:49:29 - INFO - root -   Epoch: [32/300][160/200], lr: 0.00000018 	 loss = 0.2027(0.5579)
2024/03/05 03:50:03 - INFO - root -   Epoch: [32/300][180/200], lr: 0.00000018 	 loss = 0.2923(0.5794)
2024/03/05 03:50:12 - INFO - root -   Epoch: [32/300] 	 loss = 0.5801
2024/03/05 03:50:12 - INFO - root -   train_accuracy = 0.8075
2024/03/05 03:50:48 - INFO - root -   Epoch: [33/300][0/200], lr: 0.00000018 	 loss = 1.5640(1.5640)
2024/03/05 03:51:30 - INFO - root -   Epoch: [33/300][20/200], lr: 0.00000018 	 loss = 0.1786(0.7001)
2024/03/05 03:52:11 - INFO - root -   Epoch: [33/300][40/200], lr: 0.00000018 	 loss = 0.2037(0.5581)
2024/03/05 03:52:54 - INFO - root -   Epoch: [33/300][60/200], lr: 0.00000018 	 loss = 0.1299(0.5550)
2024/03/05 03:53:41 - INFO - root -   Epoch: [33/300][80/200], lr: 0.00000018 	 loss = 1.5031(0.5640)
2024/03/05 03:54:20 - INFO - root -   Epoch: [33/300][100/200], lr: 0.00000018 	 loss = 0.0643(0.5446)
2024/03/05 03:54:55 - INFO - root -   Epoch: [33/300][120/200], lr: 0.00000018 	 loss = 3.5744(0.5554)
2024/03/05 03:55:36 - INFO - root -   Epoch: [33/300][140/200], lr: 0.00000018 	 loss = 1.6499(0.5692)
2024/03/05 03:56:04 - INFO - root -   Epoch: [33/300][160/200], lr: 0.00000018 	 loss = 0.1815(0.5707)
2024/03/05 03:56:48 - INFO - root -   Epoch: [33/300][180/200], lr: 0.00000018 	 loss = 0.2376(0.6010)
2024/03/05 03:57:01 - INFO - root -   Epoch: [33/300] 	 loss = 0.5899
2024/03/05 03:57:01 - INFO - root -   train_accuracy = 0.8150
2024/03/05 03:57:37 - INFO - root -   Epoch: [34/300][0/200], lr: 0.00000018 	 loss = 1.2747(1.2747)
2024/03/05 03:58:07 - INFO - root -   Epoch: [34/300][20/200], lr: 0.00000018 	 loss = 0.1009(0.7586)
2024/03/05 03:58:46 - INFO - root -   Epoch: [34/300][40/200], lr: 0.00000018 	 loss = 0.1260(0.5892)
2024/03/05 03:59:34 - INFO - root -   Epoch: [34/300][60/200], lr: 0.00000018 	 loss = 0.0689(0.5401)
2024/03/05 04:00:07 - INFO - root -   Epoch: [34/300][80/200], lr: 0.00000018 	 loss = 1.4823(0.5440)
2024/03/05 04:01:06 - INFO - root -   Epoch: [34/300][100/200], lr: 0.00000018 	 loss = 0.1296(0.5145)
2024/03/05 04:01:36 - INFO - root -   Epoch: [34/300][120/200], lr: 0.00000018 	 loss = 3.2534(0.5216)
2024/03/05 04:02:21 - INFO - root -   Epoch: [34/300][140/200], lr: 0.00000018 	 loss = 1.4465(0.5524)
2024/03/05 04:02:50 - INFO - root -   Epoch: [34/300][160/200], lr: 0.00000018 	 loss = 0.0970(0.5610)
2024/03/05 04:03:22 - INFO - root -   Epoch: [34/300][180/200], lr: 0.00000018 	 loss = 0.5539(0.5849)
2024/03/05 04:03:42 - INFO - root -   Epoch: [34/300] 	 loss = 0.5815
2024/03/05 04:03:46 - INFO - root -   precision = 0.7556
2024/03/05 04:03:46 - INFO - root -   eval_loss = 0.6777
2024/03/05 04:03:46 - INFO - root -   eval_acc = 0.7556
2024/03/05 04:03:47 - INFO - root -   train_accuracy = 0.7950
2024/03/05 04:03:54 - INFO - root -   Epoch: [35/300][0/200], lr: 0.00000019 	 loss = 1.4132(1.4132)
2024/03/05 04:04:58 - INFO - root -   Epoch: [35/300][20/200], lr: 0.00000019 	 loss = 0.0847(0.7004)
2024/03/05 04:05:46 - INFO - root -   Epoch: [35/300][40/200], lr: 0.00000019 	 loss = 0.1352(0.5805)
2024/03/05 04:06:15 - INFO - root -   Epoch: [35/300][60/200], lr: 0.00000019 	 loss = 0.1374(0.5654)
2024/03/05 04:06:46 - INFO - root -   Epoch: [35/300][80/200], lr: 0.00000019 	 loss = 1.5152(0.5826)
2024/03/05 04:07:46 - INFO - root -   Epoch: [35/300][100/200], lr: 0.00000019 	 loss = 0.1634(0.5648)
2024/03/05 04:08:12 - INFO - root -   Epoch: [35/300][120/200], lr: 0.00000019 	 loss = 4.2155(0.5749)
2024/03/05 04:08:47 - INFO - root -   Epoch: [35/300][140/200], lr: 0.00000019 	 loss = 2.1113(0.5843)
2024/03/05 04:09:32 - INFO - root -   Epoch: [35/300][160/200], lr: 0.00000019 	 loss = 0.1288(0.5767)
2024/03/05 04:10:17 - INFO - root -   Epoch: [35/300][180/200], lr: 0.00000019 	 loss = 0.1779(0.5822)
2024/03/05 04:10:24 - INFO - root -   Epoch: [35/300] 	 loss = 0.5859
2024/03/05 04:10:24 - INFO - root -   train_accuracy = 0.8100
2024/03/05 04:10:54 - INFO - root -   Epoch: [36/300][0/200], lr: 0.00000019 	 loss = 1.2537(1.2537)
2024/03/05 04:11:37 - INFO - root -   Epoch: [36/300][20/200], lr: 0.00000019 	 loss = 0.1620(0.7706)
2024/03/05 04:12:17 - INFO - root -   Epoch: [36/300][40/200], lr: 0.00000019 	 loss = 0.2309(0.5758)
2024/03/05 04:12:58 - INFO - root -   Epoch: [36/300][60/200], lr: 0.00000019 	 loss = 0.0679(0.5657)
2024/03/05 04:13:34 - INFO - root -   Epoch: [36/300][80/200], lr: 0.00000019 	 loss = 1.5857(0.5702)
2024/03/05 04:14:35 - INFO - root -   Epoch: [36/300][100/200], lr: 0.00000019 	 loss = 0.2632(0.5620)
2024/03/05 04:15:08 - INFO - root -   Epoch: [36/300][120/200], lr: 0.00000019 	 loss = 2.5550(0.5599)
2024/03/05 04:15:43 - INFO - root -   Epoch: [36/300][140/200], lr: 0.00000019 	 loss = 2.3645(0.5773)
2024/03/05 04:16:03 - INFO - root -   Epoch: [36/300][160/200], lr: 0.00000019 	 loss = 0.1733(0.5728)
2024/03/05 04:16:53 - INFO - root -   Epoch: [36/300][180/200], lr: 0.00000019 	 loss = 0.2522(0.5918)
2024/03/05 04:17:08 - INFO - root -   Epoch: [36/300] 	 loss = 0.5944
2024/03/05 04:17:08 - INFO - root -   train_accuracy = 0.8025
2024/03/05 04:17:41 - INFO - root -   Epoch: [37/300][0/200], lr: 0.00000019 	 loss = 1.5159(1.5159)
2024/03/05 04:18:34 - INFO - root -   Epoch: [37/300][20/200], lr: 0.00000019 	 loss = 0.2043(0.7583)
2024/03/05 04:19:12 - INFO - root -   Epoch: [37/300][40/200], lr: 0.00000019 	 loss = 0.2114(0.6147)
2024/03/05 04:19:40 - INFO - root -   Epoch: [37/300][60/200], lr: 0.00000019 	 loss = 0.0352(0.5756)
2024/03/05 04:20:26 - INFO - root -   Epoch: [37/300][80/200], lr: 0.00000019 	 loss = 1.3517(0.5824)
2024/03/05 04:21:33 - INFO - root -   Epoch: [37/300][100/200], lr: 0.00000019 	 loss = 0.1434(0.5813)
2024/03/05 04:22:09 - INFO - root -   Epoch: [37/300][120/200], lr: 0.00000019 	 loss = 3.4750(0.5850)
2024/03/05 04:22:47 - INFO - root -   Epoch: [37/300][140/200], lr: 0.00000019 	 loss = 1.3138(0.6087)
2024/03/05 04:23:19 - INFO - root -   Epoch: [37/300][160/200], lr: 0.00000019 	 loss = 0.0513(0.6114)
2024/03/05 04:24:01 - INFO - root -   Epoch: [37/300][180/200], lr: 0.00000019 	 loss = 0.1492(0.6117)
2024/03/05 04:24:08 - INFO - root -   Epoch: [37/300] 	 loss = 0.5947
2024/03/05 04:24:08 - INFO - root -   train_accuracy = 0.7900
2024/03/05 04:24:43 - INFO - root -   Epoch: [38/300][0/200], lr: 0.00000019 	 loss = 1.6612(1.6612)
2024/03/05 04:25:23 - INFO - root -   Epoch: [38/300][20/200], lr: 0.00000019 	 loss = 0.1663(0.6215)
2024/03/05 04:26:06 - INFO - root -   Epoch: [38/300][40/200], lr: 0.00000019 	 loss = 0.1804(0.5714)
2024/03/05 04:26:46 - INFO - root -   Epoch: [38/300][60/200], lr: 0.00000019 	 loss = 0.0591(0.5801)
2024/03/05 04:27:21 - INFO - root -   Epoch: [38/300][80/200], lr: 0.00000019 	 loss = 0.8503(0.5466)
2024/03/05 04:28:03 - INFO - root -   Epoch: [38/300][100/200], lr: 0.00000019 	 loss = 0.0578(0.5587)
2024/03/05 04:28:47 - INFO - root -   Epoch: [38/300][120/200], lr: 0.00000019 	 loss = 3.0706(0.5482)
2024/03/05 04:29:26 - INFO - root -   Epoch: [38/300][140/200], lr: 0.00000019 	 loss = 2.2881(0.5620)
2024/03/05 04:30:21 - INFO - root -   Epoch: [38/300][160/200], lr: 0.00000019 	 loss = 0.1919(0.5636)
2024/03/05 04:30:50 - INFO - root -   Epoch: [38/300][180/200], lr: 0.00000019 	 loss = 0.2724(0.5720)
2024/03/05 04:30:58 - INFO - root -   Epoch: [38/300] 	 loss = 0.5745
2024/03/05 04:30:58 - INFO - root -   train_accuracy = 0.8050
2024/03/05 04:31:36 - INFO - root -   Epoch: [39/300][0/200], lr: 0.00000020 	 loss = 1.1324(1.1324)
2024/03/05 04:32:13 - INFO - root -   Epoch: [39/300][20/200], lr: 0.00000020 	 loss = 0.2605(0.6336)
2024/03/05 04:32:47 - INFO - root -   Epoch: [39/300][40/200], lr: 0.00000020 	 loss = 0.3658(0.5533)
2024/03/05 04:33:24 - INFO - root -   Epoch: [39/300][60/200], lr: 0.00000020 	 loss = 0.1837(0.5505)
2024/03/05 04:34:03 - INFO - root -   Epoch: [39/300][80/200], lr: 0.00000020 	 loss = 1.3088(0.5506)
2024/03/05 04:34:59 - INFO - root -   Epoch: [39/300][100/200], lr: 0.00000020 	 loss = 0.1003(0.5222)
2024/03/05 04:35:44 - INFO - root -   Epoch: [39/300][120/200], lr: 0.00000020 	 loss = 4.0324(0.5195)
2024/03/05 04:36:16 - INFO - root -   Epoch: [39/300][140/200], lr: 0.00000020 	 loss = 1.9538(0.5403)
2024/03/05 04:36:52 - INFO - root -   Epoch: [39/300][160/200], lr: 0.00000020 	 loss = 0.2185(0.5517)
2024/03/05 04:37:30 - INFO - root -   Epoch: [39/300][180/200], lr: 0.00000020 	 loss = 0.4835(0.5741)
2024/03/05 04:37:44 - INFO - root -   Epoch: [39/300] 	 loss = 0.5776
2024/03/05 04:37:48 - INFO - root -   precision = 0.7778
2024/03/05 04:37:48 - INFO - root -   eval_loss = 0.6763
2024/03/05 04:37:48 - INFO - root -   eval_acc = 0.7778
2024/03/05 04:37:49 - INFO - root -   train_accuracy = 0.8225
2024/03/05 04:38:31 - INFO - root -   Epoch: [40/300][0/200], lr: 0.00000020 	 loss = 1.1128(1.1128)
2024/03/05 04:39:02 - INFO - root -   Epoch: [40/300][20/200], lr: 0.00000020 	 loss = 0.4790(0.7474)
2024/03/05 04:39:49 - INFO - root -   Epoch: [40/300][40/200], lr: 0.00000020 	 loss = 0.0874(0.5757)
2024/03/05 04:40:22 - INFO - root -   Epoch: [40/300][60/200], lr: 0.00000020 	 loss = 0.0642(0.5594)
2024/03/05 04:41:06 - INFO - root -   Epoch: [40/300][80/200], lr: 0.00000020 	 loss = 1.1147(0.5873)
2024/03/05 04:41:46 - INFO - root -   Epoch: [40/300][100/200], lr: 0.00000020 	 loss = 0.0905(0.5558)
2024/03/05 04:42:30 - INFO - root -   Epoch: [40/300][120/200], lr: 0.00000020 	 loss = 2.7423(0.5416)
2024/03/05 04:43:06 - INFO - root -   Epoch: [40/300][140/200], lr: 0.00000020 	 loss = 2.1002(0.5611)
2024/03/05 04:43:48 - INFO - root -   Epoch: [40/300][160/200], lr: 0.00000020 	 loss = 0.1747(0.5521)
2024/03/05 04:44:23 - INFO - root -   Epoch: [40/300][180/200], lr: 0.00000020 	 loss = 0.6358(0.5742)
2024/03/05 04:44:39 - INFO - root -   Epoch: [40/300] 	 loss = 0.5714
2024/03/05 04:44:39 - INFO - root -   train_accuracy = 0.8200
2024/03/05 04:45:16 - INFO - root -   Epoch: [41/300][0/200], lr: 0.00000020 	 loss = 1.5097(1.5097)
2024/03/05 04:46:04 - INFO - root -   Epoch: [41/300][20/200], lr: 0.00000020 	 loss = 0.6129(0.7186)
2024/03/05 04:46:30 - INFO - root -   Epoch: [41/300][40/200], lr: 0.00000020 	 loss = 0.1565(0.6543)
2024/03/05 04:47:25 - INFO - root -   Epoch: [41/300][60/200], lr: 0.00000020 	 loss = 0.4400(0.6145)
2024/03/05 04:48:05 - INFO - root -   Epoch: [41/300][80/200], lr: 0.00000020 	 loss = 1.6624(0.6186)
2024/03/05 04:49:00 - INFO - root -   Epoch: [41/300][100/200], lr: 0.00000020 	 loss = 0.0828(0.5927)
2024/03/05 04:49:35 - INFO - root -   Epoch: [41/300][120/200], lr: 0.00000020 	 loss = 3.0381(0.5776)
2024/03/05 04:50:09 - INFO - root -   Epoch: [41/300][140/200], lr: 0.00000020 	 loss = 1.2403(0.5846)
2024/03/05 04:50:46 - INFO - root -   Epoch: [41/300][160/200], lr: 0.00000020 	 loss = 0.1229(0.5889)
2024/03/05 04:51:32 - INFO - root -   Epoch: [41/300][180/200], lr: 0.00000020 	 loss = 0.5051(0.6055)
2024/03/05 04:51:39 - INFO - root -   Epoch: [41/300] 	 loss = 0.6060
2024/03/05 04:51:39 - INFO - root -   train_accuracy = 0.8100
2024/03/05 04:52:20 - INFO - root -   Epoch: [42/300][0/200], lr: 0.00000020 	 loss = 1.3967(1.3967)
2024/03/05 04:52:58 - INFO - root -   Epoch: [42/300][20/200], lr: 0.00000020 	 loss = 0.2639(0.7954)
2024/03/05 04:53:31 - INFO - root -   Epoch: [42/300][40/200], lr: 0.00000020 	 loss = 0.2751(0.6158)
2024/03/05 04:54:07 - INFO - root -   Epoch: [42/300][60/200], lr: 0.00000020 	 loss = 0.1863(0.5979)
2024/03/05 04:54:35 - INFO - root -   Epoch: [42/300][80/200], lr: 0.00000020 	 loss = 1.3937(0.5870)
2024/03/05 04:55:34 - INFO - root -   Epoch: [42/300][100/200], lr: 0.00000020 	 loss = 0.2044(0.5675)
2024/03/05 04:56:09 - INFO - root -   Epoch: [42/300][120/200], lr: 0.00000020 	 loss = 2.9092(0.5516)
2024/03/05 04:56:44 - INFO - root -   Epoch: [42/300][140/200], lr: 0.00000020 	 loss = 2.0244(0.5758)
2024/03/05 04:57:14 - INFO - root -   Epoch: [42/300][160/200], lr: 0.00000020 	 loss = 0.0526(0.5640)
2024/03/05 04:58:02 - INFO - root -   Epoch: [42/300][180/200], lr: 0.00000020 	 loss = 0.2013(0.5827)
2024/03/05 04:58:11 - INFO - root -   Epoch: [42/300] 	 loss = 0.5816
2024/03/05 04:58:11 - INFO - root -   train_accuracy = 0.8100
2024/03/05 04:58:54 - INFO - root -   Epoch: [43/300][0/200], lr: 0.00000021 	 loss = 1.1566(1.1566)
2024/03/05 04:59:32 - INFO - root -   Epoch: [43/300][20/200], lr: 0.00000021 	 loss = 0.2545(0.6335)
2024/03/05 05:00:04 - INFO - root -   Epoch: [43/300][40/200], lr: 0.00000021 	 loss = 0.1144(0.5770)
2024/03/05 05:00:49 - INFO - root -   Epoch: [43/300][60/200], lr: 0.00000021 	 loss = 0.1499(0.5716)
2024/03/05 05:01:34 - INFO - root -   Epoch: [43/300][80/200], lr: 0.00000021 	 loss = 1.5785(0.5918)
2024/03/05 05:02:21 - INFO - root -   Epoch: [43/300][100/200], lr: 0.00000021 	 loss = 0.1558(0.5839)
2024/03/05 05:02:59 - INFO - root -   Epoch: [43/300][120/200], lr: 0.00000021 	 loss = 2.8079(0.5692)
2024/03/05 05:03:36 - INFO - root -   Epoch: [43/300][140/200], lr: 0.00000021 	 loss = 1.7325(0.5714)
2024/03/05 05:04:19 - INFO - root -   Epoch: [43/300][160/200], lr: 0.00000021 	 loss = 0.1148(0.5689)
2024/03/05 05:04:44 - INFO - root -   Epoch: [43/300][180/200], lr: 0.00000021 	 loss = 0.1252(0.5786)
2024/03/05 05:04:53 - INFO - root -   Epoch: [43/300] 	 loss = 0.5755
2024/03/05 05:04:53 - INFO - root -   train_accuracy = 0.8200
2024/03/05 05:05:27 - INFO - root -   Epoch: [44/300][0/200], lr: 0.00000021 	 loss = 1.0171(1.0171)
2024/03/05 05:06:17 - INFO - root -   Epoch: [44/300][20/200], lr: 0.00000021 	 loss = 0.1666(0.6353)
2024/03/05 05:06:42 - INFO - root -   Epoch: [44/300][40/200], lr: 0.00000021 	 loss = 0.8102(0.5776)
2024/03/05 05:07:26 - INFO - root -   Epoch: [44/300][60/200], lr: 0.00000021 	 loss = 0.0927(0.5606)
2024/03/05 05:08:28 - INFO - root -   Epoch: [44/300][80/200], lr: 0.00000021 	 loss = 1.5319(0.5865)
2024/03/05 05:09:05 - INFO - root -   Epoch: [44/300][100/200], lr: 0.00000021 	 loss = 0.1303(0.5471)
2024/03/05 05:09:35 - INFO - root -   Epoch: [44/300][120/200], lr: 0.00000021 	 loss = 2.4244(0.5395)
2024/03/05 05:10:06 - INFO - root -   Epoch: [44/300][140/200], lr: 0.00000021 	 loss = 2.4952(0.5488)
2024/03/05 05:11:17 - INFO - root -   Epoch: [44/300][160/200], lr: 0.00000021 	 loss = 0.1306(0.5457)
2024/03/05 05:11:31 - INFO - root -   Epoch: [44/300][180/200], lr: 0.00000021 	 loss = 0.9713(0.5663)
2024/03/05 05:11:49 - INFO - root -   Epoch: [44/300] 	 loss = 0.5699
2024/03/05 05:11:53 - INFO - root -   precision = 0.7778
2024/03/05 05:11:53 - INFO - root -   eval_loss = 0.7002
2024/03/05 05:11:53 - INFO - root -   eval_acc = 0.7778
2024/03/05 05:11:54 - INFO - root -   train_accuracy = 0.8100
2024/03/05 05:12:28 - INFO - root -   Epoch: [45/300][0/200], lr: 0.00000021 	 loss = 1.5778(1.5778)
2024/03/05 05:13:16 - INFO - root -   Epoch: [45/300][20/200], lr: 0.00000021 	 loss = 0.3668(0.7526)
2024/03/05 05:14:01 - INFO - root -   Epoch: [45/300][40/200], lr: 0.00000021 	 loss = 0.2260(0.6067)
2024/03/05 05:14:41 - INFO - root -   Epoch: [45/300][60/200], lr: 0.00000021 	 loss = 0.2305(0.5662)
2024/03/05 05:15:15 - INFO - root -   Epoch: [45/300][80/200], lr: 0.00000021 	 loss = 1.5088(0.5536)
2024/03/05 05:16:23 - INFO - root -   Epoch: [45/300][100/200], lr: 0.00000021 	 loss = 0.0773(0.5455)
2024/03/05 05:16:52 - INFO - root -   Epoch: [45/300][120/200], lr: 0.00000021 	 loss = 3.0409(0.5471)
2024/03/05 05:17:15 - INFO - root -   Epoch: [45/300][140/200], lr: 0.00000021 	 loss = 1.7934(0.5624)
2024/03/05 05:17:47 - INFO - root -   Epoch: [45/300][160/200], lr: 0.00000021 	 loss = 0.4638(0.5668)
2024/03/05 05:18:31 - INFO - root -   Epoch: [45/300][180/200], lr: 0.00000021 	 loss = 0.1829(0.5885)
2024/03/05 05:18:47 - INFO - root -   Epoch: [45/300] 	 loss = 0.5746
2024/03/05 05:18:47 - INFO - root -   train_accuracy = 0.8125
2024/03/05 05:19:07 - INFO - root -   Epoch: [46/300][0/200], lr: 0.00000021 	 loss = 1.0741(1.0741)
2024/03/05 05:19:47 - INFO - root -   Epoch: [46/300][20/200], lr: 0.00000021 	 loss = 0.5803(0.5830)
2024/03/05 05:20:39 - INFO - root -   Epoch: [46/300][40/200], lr: 0.00000021 	 loss = 0.1595(0.5116)
2024/03/05 05:21:17 - INFO - root -   Epoch: [46/300][60/200], lr: 0.00000021 	 loss = 0.1001(0.4789)
2024/03/05 05:21:49 - INFO - root -   Epoch: [46/300][80/200], lr: 0.00000021 	 loss = 2.0963(0.5282)
2024/03/05 05:22:30 - INFO - root -   Epoch: [46/300][100/200], lr: 0.00000021 	 loss = 0.4330(0.5099)
2024/03/05 05:23:26 - INFO - root -   Epoch: [46/300][120/200], lr: 0.00000021 	 loss = 2.6855(0.5022)
2024/03/05 05:24:05 - INFO - root -   Epoch: [46/300][140/200], lr: 0.00000021 	 loss = 1.6184(0.5294)
2024/03/05 05:24:23 - INFO - root -   Epoch: [46/300][160/200], lr: 0.00000021 	 loss = 0.1107(0.5284)
2024/03/05 05:25:15 - INFO - root -   Epoch: [46/300][180/200], lr: 0.00000021 	 loss = 0.1696(0.5480)
2024/03/05 05:25:30 - INFO - root -   Epoch: [46/300] 	 loss = 0.5572
2024/03/05 05:25:30 - INFO - root -   train_accuracy = 0.8125
2024/03/05 05:26:01 - INFO - root -   Epoch: [47/300][0/200], lr: 0.00000022 	 loss = 1.9158(1.9158)
2024/03/05 05:26:41 - INFO - root -   Epoch: [47/300][20/200], lr: 0.00000022 	 loss = 0.3269(0.6758)
2024/03/05 05:27:26 - INFO - root -   Epoch: [47/300][40/200], lr: 0.00000022 	 loss = 0.2185(0.5921)
2024/03/05 05:28:04 - INFO - root -   Epoch: [47/300][60/200], lr: 0.00000022 	 loss = 0.0643(0.5670)
2024/03/05 05:28:42 - INFO - root -   Epoch: [47/300][80/200], lr: 0.00000022 	 loss = 1.6921(0.5891)
2024/03/05 05:29:23 - INFO - root -   Epoch: [47/300][100/200], lr: 0.00000022 	 loss = 0.3500(0.5507)
2024/03/05 05:30:22 - INFO - root -   Epoch: [47/300][120/200], lr: 0.00000022 	 loss = 2.8896(0.5417)
2024/03/05 05:31:02 - INFO - root -   Epoch: [47/300][140/200], lr: 0.00000022 	 loss = 2.3639(0.5690)
2024/03/05 05:31:22 - INFO - root -   Epoch: [47/300][160/200], lr: 0.00000022 	 loss = 0.2078(0.5537)
2024/03/05 05:32:06 - INFO - root -   Epoch: [47/300][180/200], lr: 0.00000022 	 loss = 0.2368(0.5705)
2024/03/05 05:32:19 - INFO - root -   Epoch: [47/300] 	 loss = 0.5602
2024/03/05 05:32:19 - INFO - root -   train_accuracy = 0.8200
2024/03/05 05:32:53 - INFO - root -   Epoch: [48/300][0/200], lr: 0.00000022 	 loss = 1.1383(1.1383)
2024/03/05 05:33:38 - INFO - root -   Epoch: [48/300][20/200], lr: 0.00000022 	 loss = 0.1509(0.7039)
2024/03/05 05:34:20 - INFO - root -   Epoch: [48/300][40/200], lr: 0.00000022 	 loss = 0.1725(0.5841)
2024/03/05 05:35:01 - INFO - root -   Epoch: [48/300][60/200], lr: 0.00000022 	 loss = 0.0583(0.5710)
2024/03/05 05:35:58 - INFO - root -   Epoch: [48/300][80/200], lr: 0.00000022 	 loss = 2.0812(0.6076)
2024/03/05 05:36:29 - INFO - root -   Epoch: [48/300][100/200], lr: 0.00000022 	 loss = 0.1713(0.5866)
2024/03/05 05:37:07 - INFO - root -   Epoch: [48/300][120/200], lr: 0.00000022 	 loss = 3.0330(0.5759)
2024/03/05 05:37:46 - INFO - root -   Epoch: [48/300][140/200], lr: 0.00000022 	 loss = 1.2595(0.5753)
2024/03/05 05:38:42 - INFO - root -   Epoch: [48/300][160/200], lr: 0.00000022 	 loss = 0.1218(0.5880)
2024/03/05 05:39:06 - INFO - root -   Epoch: [48/300][180/200], lr: 0.00000022 	 loss = 0.0888(0.5925)
2024/03/05 05:39:14 - INFO - root -   Epoch: [48/300] 	 loss = 0.5848
2024/03/05 05:39:14 - INFO - root -   train_accuracy = 0.8225
2024/03/05 05:39:49 - INFO - root -   Epoch: [49/300][0/200], lr: 0.00000022 	 loss = 0.9701(0.9701)
2024/03/05 05:40:27 - INFO - root -   Epoch: [49/300][20/200], lr: 0.00000022 	 loss = 0.2899(0.7435)
2024/03/05 05:41:07 - INFO - root -   Epoch: [49/300][40/200], lr: 0.00000022 	 loss = 0.2073(0.5856)
2024/03/05 05:41:37 - INFO - root -   Epoch: [49/300][60/200], lr: 0.00000022 	 loss = 0.0784(0.5554)
2024/03/05 05:42:11 - INFO - root -   Epoch: [49/300][80/200], lr: 0.00000022 	 loss = 2.3460(0.5722)
2024/03/05 05:43:05 - INFO - root -   Epoch: [49/300][100/200], lr: 0.00000022 	 loss = 0.1207(0.5519)
2024/03/05 05:43:45 - INFO - root -   Epoch: [49/300][120/200], lr: 0.00000022 	 loss = 2.3199(0.5391)
2024/03/05 05:44:21 - INFO - root -   Epoch: [49/300][140/200], lr: 0.00000022 	 loss = 1.3866(0.5635)
2024/03/05 05:45:00 - INFO - root -   Epoch: [49/300][160/200], lr: 0.00000022 	 loss = 0.1680(0.5627)
2024/03/05 05:45:44 - INFO - root -   Epoch: [49/300][180/200], lr: 0.00000022 	 loss = 0.1743(0.5707)
2024/03/05 05:45:53 - INFO - root -   Epoch: [49/300] 	 loss = 0.5761
2024/03/05 05:45:57 - INFO - root -   precision = 0.7778
2024/03/05 05:45:57 - INFO - root -   eval_loss = 0.7156
2024/03/05 05:45:57 - INFO - root -   eval_acc = 0.7778
2024/03/05 05:45:58 - INFO - root -   train_accuracy = 0.8200
2024/03/05 05:46:35 - INFO - root -   Epoch: [50/300][0/200], lr: 0.00000022 	 loss = 1.6255(1.6255)
2024/03/05 05:47:13 - INFO - root -   Epoch: [50/300][20/200], lr: 0.00000022 	 loss = 0.1418(0.6315)
2024/03/05 05:47:49 - INFO - root -   Epoch: [50/300][40/200], lr: 0.00000022 	 loss = 0.1161(0.5195)
2024/03/05 05:48:28 - INFO - root -   Epoch: [50/300][60/200], lr: 0.00000022 	 loss = 0.0630(0.5013)
2024/03/05 05:49:09 - INFO - root -   Epoch: [50/300][80/200], lr: 0.00000022 	 loss = 2.4472(0.5283)
2024/03/05 05:49:56 - INFO - root -   Epoch: [50/300][100/200], lr: 0.00000022 	 loss = 0.2069(0.5185)
2024/03/05 05:50:42 - INFO - root -   Epoch: [50/300][120/200], lr: 0.00000022 	 loss = 3.3264(0.5136)
2024/03/05 05:51:15 - INFO - root -   Epoch: [50/300][140/200], lr: 0.00000022 	 loss = 1.6995(0.5243)
2024/03/05 05:51:53 - INFO - root -   Epoch: [50/300][160/200], lr: 0.00000022 	 loss = 0.1164(0.5122)
2024/03/05 05:52:33 - INFO - root -   Epoch: [50/300][180/200], lr: 0.00000022 	 loss = 0.1194(0.5310)
2024/03/05 05:52:51 - INFO - root -   Epoch: [50/300] 	 loss = 0.5305
2024/03/05 05:52:51 - INFO - root -   train_accuracy = 0.8300
2024/03/05 05:53:33 - INFO - root -   Epoch: [51/300][0/200], lr: 0.00000023 	 loss = 1.7275(1.7275)
2024/03/05 05:54:12 - INFO - root -   Epoch: [51/300][20/200], lr: 0.00000023 	 loss = 0.1836(0.6778)
2024/03/05 05:54:43 - INFO - root -   Epoch: [51/300][40/200], lr: 0.00000023 	 loss = 0.6058(0.5558)
2024/03/05 05:55:18 - INFO - root -   Epoch: [51/300][60/200], lr: 0.00000023 	 loss = 0.1098(0.5220)
2024/03/05 05:55:58 - INFO - root -   Epoch: [51/300][80/200], lr: 0.00000023 	 loss = 0.8260(0.5298)
2024/03/05 05:56:54 - INFO - root -   Epoch: [51/300][100/200], lr: 0.00000023 	 loss = 0.3671(0.5252)
2024/03/05 05:57:25 - INFO - root -   Epoch: [51/300][120/200], lr: 0.00000023 	 loss = 3.7293(0.5292)
2024/03/05 05:58:10 - INFO - root -   Epoch: [51/300][140/200], lr: 0.00000023 	 loss = 2.1074(0.5538)
2024/03/05 05:58:43 - INFO - root -   Epoch: [51/300][160/200], lr: 0.00000023 	 loss = 0.1163(0.5709)
2024/03/05 05:59:28 - INFO - root -   Epoch: [51/300][180/200], lr: 0.00000023 	 loss = 0.5365(0.5749)
2024/03/05 05:59:36 - INFO - root -   Epoch: [51/300] 	 loss = 0.5703
2024/03/05 05:59:36 - INFO - root -   train_accuracy = 0.8300
2024/03/05 06:00:11 - INFO - root -   Epoch: [52/300][0/200], lr: 0.00000023 	 loss = 2.5240(2.5240)
2024/03/05 06:00:53 - INFO - root -   Epoch: [52/300][20/200], lr: 0.00000023 	 loss = 0.2661(0.8570)
2024/03/05 06:01:28 - INFO - root -   Epoch: [52/300][40/200], lr: 0.00000023 	 loss = 0.0843(0.6628)
2024/03/05 06:02:02 - INFO - root -   Epoch: [52/300][60/200], lr: 0.00000023 	 loss = 0.1170(0.6489)
2024/03/05 06:02:32 - INFO - root -   Epoch: [52/300][80/200], lr: 0.00000023 	 loss = 0.9312(0.6239)
2024/03/05 06:03:31 - INFO - root -   Epoch: [52/300][100/200], lr: 0.00000023 	 loss = 0.1146(0.5796)
2024/03/05 06:04:05 - INFO - root -   Epoch: [52/300][120/200], lr: 0.00000023 	 loss = 2.3755(0.5708)
2024/03/05 06:04:40 - INFO - root -   Epoch: [52/300][140/200], lr: 0.00000023 	 loss = 1.6101(0.5831)
2024/03/05 06:05:15 - INFO - root -   Epoch: [52/300][160/200], lr: 0.00000023 	 loss = 0.1754(0.5940)
2024/03/05 06:06:04 - INFO - root -   Epoch: [52/300][180/200], lr: 0.00000023 	 loss = 0.4178(0.5964)
2024/03/05 06:06:12 - INFO - root -   Epoch: [52/300] 	 loss = 0.5888
2024/03/05 06:06:12 - INFO - root -   train_accuracy = 0.8075
2024/03/05 06:06:36 - INFO - root -   Epoch: [53/300][0/200], lr: 0.00000023 	 loss = 1.5764(1.5764)
2024/03/05 06:07:30 - INFO - root -   Epoch: [53/300][20/200], lr: 0.00000023 	 loss = 0.1913(0.7977)
2024/03/05 06:08:08 - INFO - root -   Epoch: [53/300][40/200], lr: 0.00000023 	 loss = 0.1915(0.6287)
2024/03/05 06:08:46 - INFO - root -   Epoch: [53/300][60/200], lr: 0.00000023 	 loss = 0.0678(0.5856)
2024/03/05 06:09:22 - INFO - root -   Epoch: [53/300][80/200], lr: 0.00000023 	 loss = 1.8658(0.5767)
2024/03/05 06:10:16 - INFO - root -   Epoch: [53/300][100/200], lr: 0.00000023 	 loss = 0.0615(0.5623)
2024/03/05 06:11:02 - INFO - root -   Epoch: [53/300][120/200], lr: 0.00000023 	 loss = 2.9771(0.5587)
2024/03/05 06:11:34 - INFO - root -   Epoch: [53/300][140/200], lr: 0.00000023 	 loss = 1.4120(0.5548)
2024/03/05 06:12:15 - INFO - root -   Epoch: [53/300][160/200], lr: 0.00000023 	 loss = 0.1488(0.5479)
2024/03/05 06:12:47 - INFO - root -   Epoch: [53/300][180/200], lr: 0.00000023 	 loss = 0.2108(0.5739)
2024/03/05 06:13:03 - INFO - root -   Epoch: [53/300] 	 loss = 0.5714
2024/03/05 06:13:03 - INFO - root -   train_accuracy = 0.8075
2024/03/05 06:13:22 - INFO - root -   Epoch: [54/300][0/200], lr: 0.00000023 	 loss = 0.8689(0.8689)
2024/03/05 06:14:21 - INFO - root -   Epoch: [54/300][20/200], lr: 0.00000023 	 loss = 0.2337(0.6393)
2024/03/05 06:15:09 - INFO - root -   Epoch: [54/300][40/200], lr: 0.00000023 	 loss = 0.1526(0.5302)
2024/03/05 06:15:46 - INFO - root -   Epoch: [54/300][60/200], lr: 0.00000023 	 loss = 0.1064(0.5178)
2024/03/05 06:15:55 - INFO - root -   Epoch: [54/300][80/200], lr: 0.00000023 	 loss = 2.2057(0.5493)
2024/03/05 06:16:46 - INFO - root -   Epoch: [54/300][100/200], lr: 0.00000023 	 loss = 0.1078(0.5284)
2024/03/05 06:17:35 - INFO - root -   Epoch: [54/300][120/200], lr: 0.00000023 	 loss = 2.4326(0.5213)
2024/03/05 06:18:14 - INFO - root -   Epoch: [54/300][140/200], lr: 0.00000023 	 loss = 1.8157(0.5340)
2024/03/05 06:18:51 - INFO - root -   Epoch: [54/300][160/200], lr: 0.00000023 	 loss = 0.1189(0.5334)
2024/03/05 06:19:36 - INFO - root -   Epoch: [54/300][180/200], lr: 0.00000023 	 loss = 0.5699(0.5490)
2024/03/05 06:19:47 - INFO - root -   Epoch: [54/300] 	 loss = 0.5448
2024/03/05 06:19:51 - INFO - root -   precision = 0.7778
2024/03/05 06:19:51 - INFO - root -   eval_loss = 0.7007
2024/03/05 06:19:51 - INFO - root -   eval_acc = 0.7778
2024/03/05 06:19:52 - INFO - root -   train_accuracy = 0.8075
2024/03/05 06:20:10 - INFO - root -   Epoch: [55/300][0/200], lr: 0.00000024 	 loss = 1.4661(1.4661)
2024/03/05 06:21:07 - INFO - root -   Epoch: [55/300][20/200], lr: 0.00000024 	 loss = 0.4111(0.7350)
2024/03/05 06:21:45 - INFO - root -   Epoch: [55/300][40/200], lr: 0.00000024 	 loss = 0.1789(0.5783)
2024/03/05 06:22:32 - INFO - root -   Epoch: [55/300][60/200], lr: 0.00000024 	 loss = 0.0946(0.5664)
2024/03/05 06:23:05 - INFO - root -   Epoch: [55/300][80/200], lr: 0.00000024 	 loss = 1.0030(0.5977)
2024/03/05 06:24:06 - INFO - root -   Epoch: [55/300][100/200], lr: 0.00000024 	 loss = 0.2331(0.5784)
2024/03/05 06:24:26 - INFO - root -   Epoch: [55/300][120/200], lr: 0.00000024 	 loss = 3.2787(0.5631)
2024/03/05 06:25:08 - INFO - root -   Epoch: [55/300][140/200], lr: 0.00000024 	 loss = 1.6634(0.5730)
2024/03/05 06:25:59 - INFO - root -   Epoch: [55/300][160/200], lr: 0.00000024 	 loss = 0.0962(0.5678)
2024/03/05 06:26:35 - INFO - root -   Epoch: [55/300][180/200], lr: 0.00000024 	 loss = 0.3192(0.5689)
2024/03/05 06:26:45 - INFO - root -   Epoch: [55/300] 	 loss = 0.5858
2024/03/05 06:26:45 - INFO - root -   train_accuracy = 0.8075
2024/03/05 06:27:04 - INFO - root -   Epoch: [56/300][0/200], lr: 0.00000024 	 loss = 2.1642(2.1642)
2024/03/05 06:27:58 - INFO - root -   Epoch: [56/300][20/200], lr: 0.00000024 	 loss = 0.7363(0.6792)
2024/03/05 06:28:36 - INFO - root -   Epoch: [56/300][40/200], lr: 0.00000024 	 loss = 0.1083(0.5933)
2024/03/05 06:29:15 - INFO - root -   Epoch: [56/300][60/200], lr: 0.00000024 	 loss = 0.3054(0.5919)
2024/03/05 06:29:51 - INFO - root -   Epoch: [56/300][80/200], lr: 0.00000024 	 loss = 1.1426(0.5820)
2024/03/05 06:30:43 - INFO - root -   Epoch: [56/300][100/200], lr: 0.00000024 	 loss = 0.0901(0.5455)
2024/03/05 06:31:23 - INFO - root -   Epoch: [56/300][120/200], lr: 0.00000024 	 loss = 3.1501(0.5379)
2024/03/05 06:31:59 - INFO - root -   Epoch: [56/300][140/200], lr: 0.00000024 	 loss = 1.2902(0.5332)
2024/03/05 06:32:40 - INFO - root -   Epoch: [56/300][160/200], lr: 0.00000024 	 loss = 0.0766(0.5341)
2024/03/05 06:33:17 - INFO - root -   Epoch: [56/300][180/200], lr: 0.00000024 	 loss = 0.1780(0.5486)
2024/03/05 06:33:25 - INFO - root -   Epoch: [56/300] 	 loss = 0.5415
2024/03/05 06:33:25 - INFO - root -   train_accuracy = 0.8050
2024/03/05 06:34:03 - INFO - root -   Epoch: [57/300][0/200], lr: 0.00000024 	 loss = 1.3492(1.3492)
2024/03/05 06:34:45 - INFO - root -   Epoch: [57/300][20/200], lr: 0.00000024 	 loss = 0.3442(0.5758)
2024/03/05 06:35:19 - INFO - root -   Epoch: [57/300][40/200], lr: 0.00000024 	 loss = 0.1356(0.4564)
2024/03/05 06:35:50 - INFO - root -   Epoch: [57/300][60/200], lr: 0.00000024 	 loss = 0.1414(0.4570)
2024/03/05 06:36:59 - INFO - root -   Epoch: [57/300][80/200], lr: 0.00000024 	 loss = 1.7251(0.5133)
2024/03/05 06:37:31 - INFO - root -   Epoch: [57/300][100/200], lr: 0.00000024 	 loss = 0.1693(0.5077)
2024/03/05 06:38:05 - INFO - root -   Epoch: [57/300][120/200], lr: 0.00000024 	 loss = 1.9144(0.5041)
2024/03/05 06:38:45 - INFO - root -   Epoch: [57/300][140/200], lr: 0.00000024 	 loss = 1.7586(0.5241)
2024/03/05 06:39:21 - INFO - root -   Epoch: [57/300][160/200], lr: 0.00000024 	 loss = 0.1690(0.5358)
2024/03/05 06:40:06 - INFO - root -   Epoch: [57/300][180/200], lr: 0.00000024 	 loss = 0.1725(0.5614)
2024/03/05 06:40:13 - INFO - root -   Epoch: [57/300] 	 loss = 0.5599
2024/03/05 06:40:13 - INFO - root -   train_accuracy = 0.8225
2024/03/05 06:40:56 - INFO - root -   Epoch: [58/300][0/200], lr: 0.00000024 	 loss = 1.3307(1.3307)
2024/03/05 06:41:35 - INFO - root -   Epoch: [58/300][20/200], lr: 0.00000024 	 loss = 0.4258(0.7356)
2024/03/05 06:42:18 - INFO - root -   Epoch: [58/300][40/200], lr: 0.00000024 	 loss = 0.4631(0.5974)
2024/03/05 06:42:50 - INFO - root -   Epoch: [58/300][60/200], lr: 0.00000024 	 loss = 0.0745(0.5592)
2024/03/05 06:43:35 - INFO - root -   Epoch: [58/300][80/200], lr: 0.00000024 	 loss = 1.4673(0.5723)
2024/03/05 06:44:23 - INFO - root -   Epoch: [58/300][100/200], lr: 0.00000024 	 loss = 0.1881(0.5608)
2024/03/05 06:45:12 - INFO - root -   Epoch: [58/300][120/200], lr: 0.00000024 	 loss = 2.7077(0.5406)
2024/03/05 06:45:34 - INFO - root -   Epoch: [58/300][140/200], lr: 0.00000024 	 loss = 1.6281(0.5433)
2024/03/05 06:46:32 - INFO - root -   Epoch: [58/300][160/200], lr: 0.00000024 	 loss = 0.1552(0.5495)
2024/03/05 06:47:08 - INFO - root -   Epoch: [58/300][180/200], lr: 0.00000024 	 loss = 0.6465(0.5574)
2024/03/05 06:47:15 - INFO - root -   Epoch: [58/300] 	 loss = 0.5689
2024/03/05 06:47:15 - INFO - root -   train_accuracy = 0.8150
2024/03/05 06:47:45 - INFO - root -   Epoch: [59/300][0/200], lr: 0.00000025 	 loss = 1.4829(1.4829)
2024/03/05 06:48:30 - INFO - root -   Epoch: [59/300][20/200], lr: 0.00000025 	 loss = 0.2591(0.6552)
2024/03/05 06:49:08 - INFO - root -   Epoch: [59/300][40/200], lr: 0.00000025 	 loss = 0.3219(0.5940)
2024/03/05 06:49:48 - INFO - root -   Epoch: [59/300][60/200], lr: 0.00000025 	 loss = 0.0385(0.5558)
2024/03/05 06:50:36 - INFO - root -   Epoch: [59/300][80/200], lr: 0.00000025 	 loss = 1.1293(0.5556)
2024/03/05 06:51:21 - INFO - root -   Epoch: [59/300][100/200], lr: 0.00000025 	 loss = 0.1355(0.5268)
2024/03/05 06:52:02 - INFO - root -   Epoch: [59/300][120/200], lr: 0.00000025 	 loss = 3.9686(0.5366)
2024/03/05 06:52:44 - INFO - root -   Epoch: [59/300][140/200], lr: 0.00000025 	 loss = 1.5981(0.5553)
2024/03/05 06:53:24 - INFO - root -   Epoch: [59/300][160/200], lr: 0.00000025 	 loss = 0.0904(0.5558)
2024/03/05 06:54:09 - INFO - root -   Epoch: [59/300][180/200], lr: 0.00000025 	 loss = 0.2162(0.5578)
2024/03/05 06:54:18 - INFO - root -   Epoch: [59/300] 	 loss = 0.5473
2024/03/05 06:54:22 - INFO - root -   precision = 0.7778
2024/03/05 06:54:22 - INFO - root -   eval_loss = 0.7138
2024/03/05 06:54:22 - INFO - root -   eval_acc = 0.7778
2024/03/05 06:54:23 - INFO - root -   train_accuracy = 0.8150
2024/03/05 06:54:57 - INFO - root -   Epoch: [60/300][0/200], lr: 0.00000025 	 loss = 1.7631(1.7631)
2024/03/05 06:55:33 - INFO - root -   Epoch: [60/300][20/200], lr: 0.00000025 	 loss = 0.0795(0.6404)
2024/03/05 06:56:20 - INFO - root -   Epoch: [60/300][40/200], lr: 0.00000025 	 loss = 0.2665(0.5269)
2024/03/05 06:56:58 - INFO - root -   Epoch: [60/300][60/200], lr: 0.00000025 	 loss = 0.0786(0.5260)
2024/03/05 06:57:36 - INFO - root -   Epoch: [60/300][80/200], lr: 0.00000025 	 loss = 2.5381(0.5819)
2024/03/05 06:58:16 - INFO - root -   Epoch: [60/300][100/200], lr: 0.00000025 	 loss = 0.0446(0.5778)
2024/03/05 06:59:16 - INFO - root -   Epoch: [60/300][120/200], lr: 0.00000025 	 loss = 3.1741(0.5626)
2024/03/05 06:59:50 - INFO - root -   Epoch: [60/300][140/200], lr: 0.00000025 	 loss = 1.8421(0.5739)
2024/03/05 07:00:27 - INFO - root -   Epoch: [60/300][160/200], lr: 0.00000025 	 loss = 0.1693(0.5773)
2024/03/05 07:01:04 - INFO - root -   Epoch: [60/300][180/200], lr: 0.00000025 	 loss = 0.4871(0.6004)
2024/03/05 07:01:20 - INFO - root -   Epoch: [60/300] 	 loss = 0.5916
2024/03/05 07:01:20 - INFO - root -   train_accuracy = 0.8000
2024/03/05 07:01:52 - INFO - root -   Epoch: [61/300][0/200], lr: 0.00000025 	 loss = 1.9562(1.9562)
2024/03/05 07:02:38 - INFO - root -   Epoch: [61/300][20/200], lr: 0.00000025 	 loss = 0.1261(0.6045)
2024/03/05 07:03:16 - INFO - root -   Epoch: [61/300][40/200], lr: 0.00000025 	 loss = 0.5132(0.5239)
2024/03/05 07:04:01 - INFO - root -   Epoch: [61/300][60/200], lr: 0.00000025 	 loss = 0.1757(0.5246)
2024/03/05 07:04:37 - INFO - root -   Epoch: [61/300][80/200], lr: 0.00000025 	 loss = 1.7747(0.5539)
2024/03/05 07:05:29 - INFO - root -   Epoch: [61/300][100/200], lr: 0.00000025 	 loss = 0.3634(0.5324)
2024/03/05 07:06:08 - INFO - root -   Epoch: [61/300][120/200], lr: 0.00000025 	 loss = 2.8960(0.5200)
2024/03/05 07:06:44 - INFO - root -   Epoch: [61/300][140/200], lr: 0.00000025 	 loss = 1.3434(0.5213)
2024/03/05 07:07:02 - INFO - root -   Epoch: [61/300][160/200], lr: 0.00000025 	 loss = 0.1690(0.5202)
2024/03/05 07:07:48 - INFO - root -   Epoch: [61/300][180/200], lr: 0.00000025 	 loss = 0.2739(0.5413)
2024/03/05 07:08:06 - INFO - root -   Epoch: [61/300] 	 loss = 0.5439
2024/03/05 07:08:06 - INFO - root -   train_accuracy = 0.8200
2024/03/05 07:08:30 - INFO - root -   Epoch: [62/300][0/200], lr: 0.00000025 	 loss = 1.2082(1.2082)
2024/03/05 07:09:30 - INFO - root -   Epoch: [62/300][20/200], lr: 0.00000025 	 loss = 0.0529(0.5884)
2024/03/05 07:10:02 - INFO - root -   Epoch: [62/300][40/200], lr: 0.00000025 	 loss = 0.0869(0.5473)
2024/03/05 07:10:37 - INFO - root -   Epoch: [62/300][60/200], lr: 0.00000025 	 loss = 0.0946(0.5523)
2024/03/05 07:11:19 - INFO - root -   Epoch: [62/300][80/200], lr: 0.00000025 	 loss = 1.6749(0.5927)
2024/03/05 07:12:02 - INFO - root -   Epoch: [62/300][100/200], lr: 0.00000025 	 loss = 0.0425(0.5661)
2024/03/05 07:12:40 - INFO - root -   Epoch: [62/300][120/200], lr: 0.00000025 	 loss = 3.0091(0.5444)
2024/03/05 07:13:32 - INFO - root -   Epoch: [62/300][140/200], lr: 0.00000025 	 loss = 2.0743(0.5792)
2024/03/05 07:14:09 - INFO - root -   Epoch: [62/300][160/200], lr: 0.00000025 	 loss = 0.1458(0.5863)
2024/03/05 07:14:42 - INFO - root -   Epoch: [62/300][180/200], lr: 0.00000025 	 loss = 0.2147(0.5910)
2024/03/05 07:14:55 - INFO - root -   Epoch: [62/300] 	 loss = 0.5822
2024/03/05 07:14:55 - INFO - root -   train_accuracy = 0.8200
2024/03/05 07:15:02 - INFO - root -   Epoch: [63/300][0/200], lr: 0.00000026 	 loss = 1.1458(1.1458)
2024/03/05 07:16:12 - INFO - root -   Epoch: [63/300][20/200], lr: 0.00000026 	 loss = 0.1373(0.7040)
2024/03/05 07:16:42 - INFO - root -   Epoch: [63/300][40/200], lr: 0.00000026 	 loss = 0.2689(0.5596)
2024/03/05 07:17:15 - INFO - root -   Epoch: [63/300][60/200], lr: 0.00000026 	 loss = 0.0887(0.5543)
2024/03/05 07:17:58 - INFO - root -   Epoch: [63/300][80/200], lr: 0.00000026 	 loss = 0.8313(0.5511)
2024/03/05 07:18:44 - INFO - root -   Epoch: [63/300][100/200], lr: 0.00000026 	 loss = 0.1709(0.5333)
2024/03/05 07:19:23 - INFO - root -   Epoch: [63/300][120/200], lr: 0.00000026 	 loss = 2.4285(0.5274)
2024/03/05 07:20:04 - INFO - root -   Epoch: [63/300][140/200], lr: 0.00000026 	 loss = 1.6304(0.5364)
2024/03/05 07:20:46 - INFO - root -   Epoch: [63/300][160/200], lr: 0.00000026 	 loss = 0.1120(0.5321)
2024/03/05 07:21:32 - INFO - root -   Epoch: [63/300][180/200], lr: 0.00000026 	 loss = 0.3529(0.5337)
2024/03/05 07:21:39 - INFO - root -   Epoch: [63/300] 	 loss = 0.5254
2024/03/05 07:21:39 - INFO - root -   train_accuracy = 0.8200
2024/03/05 07:22:01 - INFO - root -   Epoch: [64/300][0/200], lr: 0.00000026 	 loss = 1.0552(1.0552)
2024/03/05 07:22:52 - INFO - root -   Epoch: [64/300][20/200], lr: 0.00000026 	 loss = 0.2434(0.5822)
2024/03/05 07:23:34 - INFO - root -   Epoch: [64/300][40/200], lr: 0.00000026 	 loss = 0.2743(0.5400)
2024/03/05 07:24:10 - INFO - root -   Epoch: [64/300][60/200], lr: 0.00000026 	 loss = 0.0952(0.5548)
2024/03/05 07:24:49 - INFO - root -   Epoch: [64/300][80/200], lr: 0.00000026 	 loss = 0.9721(0.5826)
2024/03/05 07:25:48 - INFO - root -   Epoch: [64/300][100/200], lr: 0.00000026 	 loss = 0.0874(0.5560)
2024/03/05 07:26:23 - INFO - root -   Epoch: [64/300][120/200], lr: 0.00000026 	 loss = 3.1839(0.5483)
2024/03/05 07:26:56 - INFO - root -   Epoch: [64/300][140/200], lr: 0.00000026 	 loss = 1.8641(0.5612)
2024/03/05 07:27:28 - INFO - root -   Epoch: [64/300][160/200], lr: 0.00000026 	 loss = 0.2017(0.5703)
2024/03/05 07:28:13 - INFO - root -   Epoch: [64/300][180/200], lr: 0.00000026 	 loss = 0.9397(0.5826)
2024/03/05 07:28:21 - INFO - root -   Epoch: [64/300] 	 loss = 0.5812
2024/03/05 07:28:24 - INFO - root -   precision = 0.7778
2024/03/05 07:28:24 - INFO - root -   eval_loss = 0.7340
2024/03/05 07:28:24 - INFO - root -   eval_acc = 0.7778
2024/03/05 07:28:25 - INFO - root -   train_accuracy = 0.8025
2024/03/05 07:28:45 - INFO - root -   Epoch: [65/300][0/200], lr: 0.00000026 	 loss = 1.5591(1.5591)
2024/03/05 07:29:42 - INFO - root -   Epoch: [65/300][20/200], lr: 0.00000026 	 loss = 0.5845(0.7422)
2024/03/05 07:30:13 - INFO - root -   Epoch: [65/300][40/200], lr: 0.00000026 	 loss = 0.2772(0.6438)
2024/03/05 07:30:48 - INFO - root -   Epoch: [65/300][60/200], lr: 0.00000026 	 loss = 0.1058(0.6008)
2024/03/05 07:31:34 - INFO - root -   Epoch: [65/300][80/200], lr: 0.00000026 	 loss = 1.4059(0.5963)
2024/03/05 07:32:22 - INFO - root -   Epoch: [65/300][100/200], lr: 0.00000026 	 loss = 0.0761(0.5844)
2024/03/05 07:32:55 - INFO - root -   Epoch: [65/300][120/200], lr: 0.00000026 	 loss = 3.9888(0.5795)
2024/03/05 07:33:35 - INFO - root -   Epoch: [65/300][140/200], lr: 0.00000026 	 loss = 1.8050(0.5853)
2024/03/05 07:34:15 - INFO - root -   Epoch: [65/300][160/200], lr: 0.00000026 	 loss = 0.0537(0.5821)
2024/03/05 07:34:55 - INFO - root -   Epoch: [65/300][180/200], lr: 0.00000026 	 loss = 0.5525(0.5859)
2024/03/05 07:35:05 - INFO - root -   Epoch: [65/300] 	 loss = 0.5702
2024/03/05 07:35:05 - INFO - root -   train_accuracy = 0.8100
2024/03/05 07:35:26 - INFO - root -   Epoch: [66/300][0/200], lr: 0.00000026 	 loss = 1.2240(1.2240)
2024/03/05 07:36:20 - INFO - root -   Epoch: [66/300][20/200], lr: 0.00000026 	 loss = 0.2293(0.6241)
2024/03/05 07:37:00 - INFO - root -   Epoch: [66/300][40/200], lr: 0.00000026 	 loss = 0.1939(0.5359)
2024/03/05 07:37:40 - INFO - root -   Epoch: [66/300][60/200], lr: 0.00000026 	 loss = 0.1069(0.5230)
2024/03/05 07:38:22 - INFO - root -   Epoch: [66/300][80/200], lr: 0.00000026 	 loss = 1.0454(0.5815)
2024/03/05 07:39:04 - INFO - root -   Epoch: [66/300][100/200], lr: 0.00000026 	 loss = 0.3026(0.5888)
2024/03/05 07:39:59 - INFO - root -   Epoch: [66/300][120/200], lr: 0.00000026 	 loss = 3.1985(0.5756)
2024/03/05 07:40:29 - INFO - root -   Epoch: [66/300][140/200], lr: 0.00000026 	 loss = 1.8219(0.5863)
2024/03/05 07:41:03 - INFO - root -   Epoch: [66/300][160/200], lr: 0.00000026 	 loss = 0.1429(0.5907)
2024/03/05 07:41:36 - INFO - root -   Epoch: [66/300][180/200], lr: 0.00000026 	 loss = 0.4668(0.5945)
2024/03/05 07:41:58 - INFO - root -   Epoch: [66/300] 	 loss = 0.5834
2024/03/05 07:41:58 - INFO - root -   train_accuracy = 0.8125
2024/03/05 07:42:36 - INFO - root -   Epoch: [67/300][0/200], lr: 0.00000027 	 loss = 2.0877(2.0877)
2024/03/05 07:43:12 - INFO - root -   Epoch: [67/300][20/200], lr: 0.00000027 	 loss = 0.8969(0.7497)
2024/03/05 07:43:48 - INFO - root -   Epoch: [67/300][40/200], lr: 0.00000027 	 loss = 0.2357(0.5935)
2024/03/05 07:44:41 - INFO - root -   Epoch: [67/300][60/200], lr: 0.00000027 	 loss = 0.0548(0.5557)
2024/03/05 07:45:13 - INFO - root -   Epoch: [67/300][80/200], lr: 0.00000027 	 loss = 1.6272(0.5640)
2024/03/05 07:45:54 - INFO - root -   Epoch: [67/300][100/200], lr: 0.00000027 	 loss = 0.0352(0.5459)
2024/03/05 07:46:29 - INFO - root -   Epoch: [67/300][120/200], lr: 0.00000027 	 loss = 3.1430(0.5383)
2024/03/05 07:47:35 - INFO - root -   Epoch: [67/300][140/200], lr: 0.00000027 	 loss = 1.5468(0.5365)
2024/03/05 07:48:10 - INFO - root -   Epoch: [67/300][160/200], lr: 0.00000027 	 loss = 0.1150(0.5309)
2024/03/05 07:48:42 - INFO - root -   Epoch: [67/300][180/200], lr: 0.00000027 	 loss = 0.2352(0.5420)
2024/03/05 07:48:50 - INFO - root -   Epoch: [67/300] 	 loss = 0.5383
2024/03/05 07:48:50 - INFO - root -   train_accuracy = 0.8125
2024/03/05 07:49:21 - INFO - root -   Epoch: [68/300][0/200], lr: 0.00000027 	 loss = 1.8167(1.8167)
2024/03/05 07:50:11 - INFO - root -   Epoch: [68/300][20/200], lr: 0.00000027 	 loss = 0.1164(0.6599)
2024/03/05 07:50:52 - INFO - root -   Epoch: [68/300][40/200], lr: 0.00000027 	 loss = 0.1687(0.5217)
2024/03/05 07:51:29 - INFO - root -   Epoch: [68/300][60/200], lr: 0.00000027 	 loss = 0.1133(0.5400)
2024/03/05 07:52:00 - INFO - root -   Epoch: [68/300][80/200], lr: 0.00000027 	 loss = 1.3631(0.5669)
2024/03/05 07:53:04 - INFO - root -   Epoch: [68/300][100/200], lr: 0.00000027 	 loss = 0.3945(0.5447)
2024/03/05 07:53:36 - INFO - root -   Epoch: [68/300][120/200], lr: 0.00000027 	 loss = 3.4201(0.5394)
2024/03/05 07:54:17 - INFO - root -   Epoch: [68/300][140/200], lr: 0.00000027 	 loss = 1.1689(0.5536)
2024/03/05 07:54:55 - INFO - root -   Epoch: [68/300][160/200], lr: 0.00000027 	 loss = 0.2398(0.5703)
2024/03/05 07:55:36 - INFO - root -   Epoch: [68/300][180/200], lr: 0.00000027 	 loss = 0.2549(0.5690)
2024/03/05 07:55:44 - INFO - root -   Epoch: [68/300] 	 loss = 0.5634
2024/03/05 07:55:44 - INFO - root -   train_accuracy = 0.8200
2024/03/05 07:56:18 - INFO - root -   Epoch: [69/300][0/200], lr: 0.00000027 	 loss = 1.5631(1.5631)
2024/03/05 07:56:56 - INFO - root -   Epoch: [69/300][20/200], lr: 0.00000027 	 loss = 0.1523(0.6234)
2024/03/05 07:57:34 - INFO - root -   Epoch: [69/300][40/200], lr: 0.00000027 	 loss = 0.1546(0.5779)
2024/03/05 07:58:14 - INFO - root -   Epoch: [69/300][60/200], lr: 0.00000027 	 loss = 0.2414(0.5492)
2024/03/05 07:59:02 - INFO - root -   Epoch: [69/300][80/200], lr: 0.00000027 	 loss = 1.5835(0.5547)
2024/03/05 07:59:34 - INFO - root -   Epoch: [69/300][100/200], lr: 0.00000027 	 loss = 0.0659(0.5407)
2024/03/05 08:00:37 - INFO - root -   Epoch: [69/300][120/200], lr: 0.00000027 	 loss = 2.9002(0.5312)
2024/03/05 08:01:13 - INFO - root -   Epoch: [69/300][140/200], lr: 0.00000027 	 loss = 2.6246(0.5439)
2024/03/05 08:01:45 - INFO - root -   Epoch: [69/300][160/200], lr: 0.00000027 	 loss = 0.1648(0.5599)
2024/03/05 08:02:17 - INFO - root -   Epoch: [69/300][180/200], lr: 0.00000027 	 loss = 0.3694(0.5714)
2024/03/05 08:02:35 - INFO - root -   Epoch: [69/300] 	 loss = 0.5682
2024/03/05 08:02:38 - INFO - root -   precision = 0.7778
2024/03/05 08:02:38 - INFO - root -   eval_loss = 0.7412
2024/03/05 08:02:38 - INFO - root -   eval_acc = 0.7778
2024/03/05 08:02:39 - INFO - root -   train_accuracy = 0.8275
2024/03/05 08:03:09 - INFO - root -   Epoch: [70/300][0/200], lr: 0.00000027 	 loss = 1.1193(1.1193)
2024/03/05 08:04:02 - INFO - root -   Epoch: [70/300][20/200], lr: 0.00000027 	 loss = 0.2362(0.6257)
2024/03/05 08:04:38 - INFO - root -   Epoch: [70/300][40/200], lr: 0.00000027 	 loss = 0.1220(0.5193)
2024/03/05 08:05:14 - INFO - root -   Epoch: [70/300][60/200], lr: 0.00000027 	 loss = 0.1818(0.5299)
2024/03/05 08:05:58 - INFO - root -   Epoch: [70/300][80/200], lr: 0.00000027 	 loss = 1.6445(0.5504)
2024/03/05 08:06:38 - INFO - root -   Epoch: [70/300][100/200], lr: 0.00000027 	 loss = 0.1738(0.5251)
2024/03/05 08:07:18 - INFO - root -   Epoch: [70/300][120/200], lr: 0.00000027 	 loss = 2.9042(0.5177)
2024/03/05 08:08:01 - INFO - root -   Epoch: [70/300][140/200], lr: 0.00000027 	 loss = 1.5549(0.5247)
2024/03/05 08:09:04 - INFO - root -   Epoch: [70/300][160/200], lr: 0.00000027 	 loss = 0.0603(0.5121)
2024/03/05 08:09:29 - INFO - root -   Epoch: [70/300][180/200], lr: 0.00000027 	 loss = 0.7948(0.5193)
2024/03/05 08:09:39 - INFO - root -   Epoch: [70/300] 	 loss = 0.5233
2024/03/05 08:09:39 - INFO - root -   train_accuracy = 0.8250
2024/03/05 08:10:16 - INFO - root -   Epoch: [71/300][0/200], lr: 0.00000028 	 loss = 1.4609(1.4609)
2024/03/05 08:10:52 - INFO - root -   Epoch: [71/300][20/200], lr: 0.00000028 	 loss = 0.4596(0.6373)
2024/03/05 08:11:32 - INFO - root -   Epoch: [71/300][40/200], lr: 0.00000028 	 loss = 0.0881(0.5618)
2024/03/05 08:12:16 - INFO - root -   Epoch: [71/300][60/200], lr: 0.00000028 	 loss = 0.1231(0.5539)
2024/03/05 08:12:47 - INFO - root -   Epoch: [71/300][80/200], lr: 0.00000028 	 loss = 2.1766(0.5701)
2024/03/05 08:13:45 - INFO - root -   Epoch: [71/300][100/200], lr: 0.00000028 	 loss = 0.1002(0.5706)
2024/03/05 08:14:20 - INFO - root -   Epoch: [71/300][120/200], lr: 0.00000028 	 loss = 3.3049(0.5687)
2024/03/05 08:14:52 - INFO - root -   Epoch: [71/300][140/200], lr: 0.00000028 	 loss = 1.7236(0.5758)
2024/03/05 08:15:32 - INFO - root -   Epoch: [71/300][160/200], lr: 0.00000028 	 loss = 0.1531(0.5837)
2024/03/05 08:16:15 - INFO - root -   Epoch: [71/300][180/200], lr: 0.00000028 	 loss = 0.1378(0.5891)
2024/03/05 08:16:26 - INFO - root -   Epoch: [71/300] 	 loss = 0.5862
2024/03/05 08:16:26 - INFO - root -   train_accuracy = 0.8225
2024/03/05 08:16:33 - INFO - root -   Epoch: [72/300][0/200], lr: 0.00000028 	 loss = 1.0919(1.0919)
2024/03/05 08:17:48 - INFO - root -   Epoch: [72/300][20/200], lr: 0.00000028 	 loss = 0.5404(0.5873)
2024/03/05 08:18:31 - INFO - root -   Epoch: [72/300][40/200], lr: 0.00000028 	 loss = 0.1707(0.5002)
2024/03/05 08:19:03 - INFO - root -   Epoch: [72/300][60/200], lr: 0.00000028 	 loss = 0.1466(0.5106)
2024/03/05 08:19:28 - INFO - root -   Epoch: [72/300][80/200], lr: 0.00000028 	 loss = 1.4958(0.5547)
2024/03/05 08:20:33 - INFO - root -   Epoch: [72/300][100/200], lr: 0.00000028 	 loss = 0.1314(0.5354)
2024/03/05 08:21:13 - INFO - root -   Epoch: [72/300][120/200], lr: 0.00000028 	 loss = 2.5375(0.5229)
2024/03/05 08:21:43 - INFO - root -   Epoch: [72/300][140/200], lr: 0.00000028 	 loss = 1.9251(0.5401)
2024/03/05 08:22:15 - INFO - root -   Epoch: [72/300][160/200], lr: 0.00000028 	 loss = 0.1245(0.5228)
2024/03/05 08:23:04 - INFO - root -   Epoch: [72/300][180/200], lr: 0.00000028 	 loss = 0.5519(0.5333)
2024/03/05 08:23:16 - INFO - root -   Epoch: [72/300] 	 loss = 0.5252
2024/03/05 08:23:16 - INFO - root -   train_accuracy = 0.8125
2024/03/05 08:23:47 - INFO - root -   Epoch: [73/300][0/200], lr: 0.00000028 	 loss = 0.9456(0.9456)
2024/03/05 08:24:31 - INFO - root -   Epoch: [73/300][20/200], lr: 0.00000028 	 loss = 0.8347(0.6301)
2024/03/05 08:25:15 - INFO - root -   Epoch: [73/300][40/200], lr: 0.00000028 	 loss = 0.2145(0.5870)
2024/03/05 08:25:51 - INFO - root -   Epoch: [73/300][60/200], lr: 0.00000028 	 loss = 0.0488(0.5448)
2024/03/05 08:26:30 - INFO - root -   Epoch: [73/300][80/200], lr: 0.00000028 	 loss = 1.1679(0.5534)
2024/03/05 08:26:59 - INFO - root -   Epoch: [73/300][100/200], lr: 0.00000028 	 loss = 0.0995(0.5290)
2024/03/05 08:28:01 - INFO - root -   Epoch: [73/300][120/200], lr: 0.00000028 	 loss = 2.7304(0.5153)
2024/03/05 08:28:40 - INFO - root -   Epoch: [73/300][140/200], lr: 0.00000028 	 loss = 1.4639(0.5155)
2024/03/05 08:29:17 - INFO - root -   Epoch: [73/300][160/200], lr: 0.00000028 	 loss = 0.3243(0.5206)
2024/03/05 08:29:46 - INFO - root -   Epoch: [73/300][180/200], lr: 0.00000028 	 loss = 0.3402(0.5321)
2024/03/05 08:30:02 - INFO - root -   Epoch: [73/300] 	 loss = 0.5366
2024/03/05 08:30:02 - INFO - root -   train_accuracy = 0.8200
2024/03/05 08:30:49 - INFO - root -   Epoch: [74/300][0/200], lr: 0.00000028 	 loss = 0.7439(0.7439)
2024/03/05 08:31:28 - INFO - root -   Epoch: [74/300][20/200], lr: 0.00000028 	 loss = 1.0878(0.6393)
2024/03/05 08:32:02 - INFO - root -   Epoch: [74/300][40/200], lr: 0.00000028 	 loss = 0.4709(0.5326)
2024/03/05 08:32:40 - INFO - root -   Epoch: [74/300][60/200], lr: 0.00000028 	 loss = 0.0674(0.5053)
2024/03/05 08:33:39 - INFO - root -   Epoch: [74/300][80/200], lr: 0.00000028 	 loss = 1.1585(0.5361)
2024/03/05 08:34:14 - INFO - root -   Epoch: [74/300][100/200], lr: 0.00000028 	 loss = 0.0497(0.5130)
2024/03/05 08:34:49 - INFO - root -   Epoch: [74/300][120/200], lr: 0.00000028 	 loss = 3.3192(0.5104)
2024/03/05 08:35:14 - INFO - root -   Epoch: [74/300][140/200], lr: 0.00000028 	 loss = 1.9744(0.5222)
2024/03/05 08:36:17 - INFO - root -   Epoch: [74/300][160/200], lr: 0.00000028 	 loss = 0.1655(0.5162)
2024/03/05 08:36:47 - INFO - root -   Epoch: [74/300][180/200], lr: 0.00000028 	 loss = 0.7739(0.5271)
2024/03/05 08:36:55 - INFO - root -   Epoch: [74/300] 	 loss = 0.5263
2024/03/05 08:36:59 - INFO - root -   precision = 0.7778
2024/03/05 08:36:59 - INFO - root -   eval_loss = 0.7792
2024/03/05 08:36:59 - INFO - root -   eval_acc = 0.7778
2024/03/05 08:37:00 - INFO - root -   train_accuracy = 0.8200
2024/03/05 08:37:38 - INFO - root -   Epoch: [75/300][0/200], lr: 0.00000029 	 loss = 1.3763(1.3763)
2024/03/05 08:38:09 - INFO - root -   Epoch: [75/300][20/200], lr: 0.00000029 	 loss = 0.6021(0.6625)
2024/03/05 08:38:44 - INFO - root -   Epoch: [75/300][40/200], lr: 0.00000029 	 loss = 0.1507(0.5873)
2024/03/05 08:39:38 - INFO - root -   Epoch: [75/300][60/200], lr: 0.00000029 	 loss = 0.1030(0.5429)
2024/03/05 08:40:15 - INFO - root -   Epoch: [75/300][80/200], lr: 0.00000029 	 loss = 1.5864(0.5611)
2024/03/05 08:40:55 - INFO - root -   Epoch: [75/300][100/200], lr: 0.00000029 	 loss = 0.0536(0.5465)
2024/03/05 08:41:39 - INFO - root -   Epoch: [75/300][120/200], lr: 0.00000029 	 loss = 3.2224(0.5341)
2024/03/05 08:42:14 - INFO - root -   Epoch: [75/300][140/200], lr: 0.00000029 	 loss = 1.5111(0.5334)
2024/03/05 08:42:51 - INFO - root -   Epoch: [75/300][160/200], lr: 0.00000029 	 loss = 0.4099(0.5381)
2024/03/05 08:43:29 - INFO - root -   Epoch: [75/300][180/200], lr: 0.00000029 	 loss = 0.2738(0.5600)
2024/03/05 08:43:42 - INFO - root -   Epoch: [75/300] 	 loss = 0.5566
2024/03/05 08:43:42 - INFO - root -   train_accuracy = 0.8125
2024/03/05 08:44:12 - INFO - root -   Epoch: [76/300][0/200], lr: 0.00000029 	 loss = 1.1480(1.1480)
2024/03/05 08:45:01 - INFO - root -   Epoch: [76/300][20/200], lr: 0.00000029 	 loss = 0.8415(0.6059)
2024/03/05 08:45:32 - INFO - root -   Epoch: [76/300][40/200], lr: 0.00000029 	 loss = 0.0581(0.5618)
2024/03/05 08:46:18 - INFO - root -   Epoch: [76/300][60/200], lr: 0.00000029 	 loss = 0.0558(0.5304)
2024/03/05 08:46:45 - INFO - root -   Epoch: [76/300][80/200], lr: 0.00000029 	 loss = 1.8801(0.5588)
2024/03/05 08:47:55 - INFO - root -   Epoch: [76/300][100/200], lr: 0.00000029 	 loss = 0.1233(0.5373)
2024/03/05 08:48:26 - INFO - root -   Epoch: [76/300][120/200], lr: 0.00000029 	 loss = 2.6928(0.5240)
2024/03/05 08:49:00 - INFO - root -   Epoch: [76/300][140/200], lr: 0.00000029 	 loss = 1.8615(0.5219)
2024/03/05 08:49:40 - INFO - root -   Epoch: [76/300][160/200], lr: 0.00000029 	 loss = 0.0639(0.5135)
2024/03/05 08:50:25 - INFO - root -   Epoch: [76/300][180/200], lr: 0.00000029 	 loss = 0.5257(0.5209)
2024/03/05 08:50:33 - INFO - root -   Epoch: [76/300] 	 loss = 0.5209
2024/03/05 08:50:33 - INFO - root -   train_accuracy = 0.8375
2024/03/05 08:51:13 - INFO - root -   Epoch: [77/300][0/200], lr: 0.00000029 	 loss = 1.7684(1.7684)
2024/03/05 08:51:56 - INFO - root -   Epoch: [77/300][20/200], lr: 0.00000029 	 loss = 0.1192(0.6765)
2024/03/05 08:52:37 - INFO - root -   Epoch: [77/300][40/200], lr: 0.00000029 	 loss = 0.1390(0.5457)
2024/03/05 08:53:08 - INFO - root -   Epoch: [77/300][60/200], lr: 0.00000029 	 loss = 0.0510(0.5133)
2024/03/05 08:53:42 - INFO - root -   Epoch: [77/300][80/200], lr: 0.00000029 	 loss = 1.9274(0.5283)
2024/03/05 08:54:39 - INFO - root -   Epoch: [77/300][100/200], lr: 0.00000029 	 loss = 0.0493(0.5124)
2024/03/05 08:55:18 - INFO - root -   Epoch: [77/300][120/200], lr: 0.00000029 	 loss = 3.7695(0.5074)
2024/03/05 08:56:00 - INFO - root -   Epoch: [77/300][140/200], lr: 0.00000029 	 loss = 1.4988(0.5088)
2024/03/05 08:56:26 - INFO - root -   Epoch: [77/300][160/200], lr: 0.00000029 	 loss = 0.2137(0.5194)
2024/03/05 08:57:15 - INFO - root -   Epoch: [77/300][180/200], lr: 0.00000029 	 loss = 0.5866(0.5315)
2024/03/05 08:57:22 - INFO - root -   Epoch: [77/300] 	 loss = 0.5302
2024/03/05 08:57:22 - INFO - root -   train_accuracy = 0.8200
2024/03/05 08:57:54 - INFO - root -   Epoch: [78/300][0/200], lr: 0.00000029 	 loss = 1.2799(1.2799)
2024/03/05 08:58:52 - INFO - root -   Epoch: [78/300][20/200], lr: 0.00000029 	 loss = 0.5671(0.6618)
2024/03/05 08:59:26 - INFO - root -   Epoch: [78/300][40/200], lr: 0.00000029 	 loss = 0.3632(0.5497)
2024/03/05 09:00:01 - INFO - root -   Epoch: [78/300][60/200], lr: 0.00000029 	 loss = 0.1753(0.5184)
2024/03/05 09:01:03 - INFO - root -   Epoch: [78/300][80/200], lr: 0.00000029 	 loss = 1.9596(0.5371)
2024/03/05 09:01:33 - INFO - root -   Epoch: [78/300][100/200], lr: 0.00000029 	 loss = 0.1384(0.5363)
2024/03/05 09:02:08 - INFO - root -   Epoch: [78/300][120/200], lr: 0.00000029 	 loss = 4.6239(0.5541)
2024/03/05 09:02:39 - INFO - root -   Epoch: [78/300][140/200], lr: 0.00000029 	 loss = 1.8372(0.5649)
2024/03/05 09:03:28 - INFO - root -   Epoch: [78/300][160/200], lr: 0.00000029 	 loss = 0.1343(0.5612)
2024/03/05 09:03:41 - INFO - root -   Epoch: [78/300][180/200], lr: 0.00000029 	 loss = 0.1996(0.5665)
2024/03/05 09:03:54 - INFO - root -   Epoch: [78/300] 	 loss = 0.5548
2024/03/05 09:03:54 - INFO - root -   train_accuracy = 0.8275
2024/03/05 09:04:24 - INFO - root -   Epoch: [79/300][0/200], lr: 0.00000030 	 loss = 1.5218(1.5218)
2024/03/05 09:05:10 - INFO - root -   Epoch: [79/300][20/200], lr: 0.00000030 	 loss = 0.9343(0.6377)
2024/03/05 09:05:59 - INFO - root -   Epoch: [79/300][40/200], lr: 0.00000030 	 loss = 0.2472(0.5355)
2024/03/05 09:06:35 - INFO - root -   Epoch: [79/300][60/200], lr: 0.00000030 	 loss = 0.0537(0.5538)
2024/03/05 09:07:14 - INFO - root -   Epoch: [79/300][80/200], lr: 0.00000030 	 loss = 2.4552(0.5735)
2024/03/05 09:08:11 - INFO - root -   Epoch: [79/300][100/200], lr: 0.00000030 	 loss = 0.1344(0.5478)
2024/03/05 09:08:41 - INFO - root -   Epoch: [79/300][120/200], lr: 0.00000030 	 loss = 3.8227(0.5410)
2024/03/05 09:09:14 - INFO - root -   Epoch: [79/300][140/200], lr: 0.00000030 	 loss = 2.1178(0.5554)
2024/03/05 09:09:38 - INFO - root -   Epoch: [79/300][160/200], lr: 0.00000030 	 loss = 0.0977(0.5613)
2024/03/05 09:10:20 - INFO - root -   Epoch: [79/300][180/200], lr: 0.00000030 	 loss = 0.4083(0.5628)
2024/03/05 09:10:36 - INFO - root -   Epoch: [79/300] 	 loss = 0.5524
2024/03/05 09:10:40 - INFO - root -   precision = 0.7556
2024/03/05 09:10:40 - INFO - root -   eval_loss = 0.7642
2024/03/05 09:10:40 - INFO - root -   eval_acc = 0.7556
2024/03/05 09:10:41 - INFO - root -   train_accuracy = 0.8150
2024/03/05 09:11:23 - INFO - root -   Epoch: [80/300][0/200], lr: 0.00000030 	 loss = 1.8969(1.8969)
2024/03/05 09:12:04 - INFO - root -   Epoch: [80/300][20/200], lr: 0.00000030 	 loss = 0.2665(0.6727)
2024/03/05 09:12:49 - INFO - root -   Epoch: [80/300][40/200], lr: 0.00000030 	 loss = 0.1937(0.5618)
2024/03/05 09:13:11 - INFO - root -   Epoch: [80/300][60/200], lr: 0.00000030 	 loss = 0.0472(0.5162)
2024/03/05 09:13:50 - INFO - root -   Epoch: [80/300][80/200], lr: 0.00000030 	 loss = 1.5282(0.5239)
2024/03/05 09:14:40 - INFO - root -   Epoch: [80/300][100/200], lr: 0.00000030 	 loss = 0.1327(0.5092)
2024/03/05 09:15:24 - INFO - root -   Epoch: [80/300][120/200], lr: 0.00000030 	 loss = 3.6253(0.5095)
2024/03/05 09:15:48 - INFO - root -   Epoch: [80/300][140/200], lr: 0.00000030 	 loss = 1.9982(0.5185)
2024/03/05 09:16:32 - INFO - root -   Epoch: [80/300][160/200], lr: 0.00000030 	 loss = 0.2741(0.5146)
2024/03/05 09:17:24 - INFO - root -   Epoch: [80/300][180/200], lr: 0.00000030 	 loss = 0.4891(0.5364)
2024/03/05 09:17:33 - INFO - root -   Epoch: [80/300] 	 loss = 0.5447
2024/03/05 09:17:33 - INFO - root -   train_accuracy = 0.8325
2024/03/05 09:18:08 - INFO - root -   Epoch: [81/300][0/200], lr: 0.00000030 	 loss = 0.7125(0.7125)
2024/03/05 09:18:55 - INFO - root -   Epoch: [81/300][20/200], lr: 0.00000030 	 loss = 0.2613(0.5382)
2024/03/05 09:19:31 - INFO - root -   Epoch: [81/300][40/200], lr: 0.00000030 	 loss = 0.1317(0.4681)
2024/03/05 09:20:11 - INFO - root -   Epoch: [81/300][60/200], lr: 0.00000030 	 loss = 0.0494(0.4999)
2024/03/05 09:20:45 - INFO - root -   Epoch: [81/300][80/200], lr: 0.00000030 	 loss = 1.1949(0.5188)
2024/03/05 09:21:24 - INFO - root -   Epoch: [81/300][100/200], lr: 0.00000030 	 loss = 0.1329(0.4936)
2024/03/05 09:22:14 - INFO - root -   Epoch: [81/300][120/200], lr: 0.00000030 	 loss = 4.8679(0.5129)
2024/03/05 09:22:37 - INFO - root -   Epoch: [81/300][140/200], lr: 0.00000030 	 loss = 1.4177(0.5356)
2024/03/05 09:23:41 - INFO - root -   Epoch: [81/300][160/200], lr: 0.00000030 	 loss = 0.3413(0.5477)
2024/03/05 09:24:08 - INFO - root -   Epoch: [81/300][180/200], lr: 0.00000030 	 loss = 0.0812(0.5626)
2024/03/05 09:24:20 - INFO - root -   Epoch: [81/300] 	 loss = 0.5526
2024/03/05 09:24:20 - INFO - root -   train_accuracy = 0.8175
2024/03/05 09:24:59 - INFO - root -   Epoch: [82/300][0/200], lr: 0.00000030 	 loss = 2.0367(2.0367)
2024/03/05 09:25:40 - INFO - root -   Epoch: [82/300][20/200], lr: 0.00000030 	 loss = 0.3736(0.6916)
2024/03/05 09:26:15 - INFO - root -   Epoch: [82/300][40/200], lr: 0.00000030 	 loss = 0.1343(0.5378)
2024/03/05 09:26:51 - INFO - root -   Epoch: [82/300][60/200], lr: 0.00000030 	 loss = 0.1274(0.5235)
2024/03/05 09:27:23 - INFO - root -   Epoch: [82/300][80/200], lr: 0.00000030 	 loss = 2.0260(0.5464)
2024/03/05 09:28:20 - INFO - root -   Epoch: [82/300][100/200], lr: 0.00000030 	 loss = 0.0694(0.5378)
2024/03/05 09:28:57 - INFO - root -   Epoch: [82/300][120/200], lr: 0.00000030 	 loss = 3.1215(0.5253)
2024/03/05 09:29:20 - INFO - root -   Epoch: [82/300][140/200], lr: 0.00000030 	 loss = 1.9001(0.5328)
2024/03/05 09:30:04 - INFO - root -   Epoch: [82/300][160/200], lr: 0.00000030 	 loss = 0.2742(0.5322)
2024/03/05 09:30:49 - INFO - root -   Epoch: [82/300][180/200], lr: 0.00000030 	 loss = 0.3667(0.5400)
2024/03/05 09:30:57 - INFO - root -   Epoch: [82/300] 	 loss = 0.5343
2024/03/05 09:30:57 - INFO - root -   train_accuracy = 0.8275
2024/03/05 09:31:38 - INFO - root -   Epoch: [83/300][0/200], lr: 0.00000031 	 loss = 1.5288(1.5288)
2024/03/05 09:32:16 - INFO - root -   Epoch: [83/300][20/200], lr: 0.00000031 	 loss = 0.3900(0.6177)
2024/03/05 09:32:51 - INFO - root -   Epoch: [83/300][40/200], lr: 0.00000031 	 loss = 0.2525(0.5170)
2024/03/05 09:33:32 - INFO - root -   Epoch: [83/300][60/200], lr: 0.00000031 	 loss = 0.0180(0.5305)
2024/03/05 09:34:29 - INFO - root -   Epoch: [83/300][80/200], lr: 0.00000031 	 loss = 1.5177(0.5588)
2024/03/05 09:35:04 - INFO - root -   Epoch: [83/300][100/200], lr: 0.00000031 	 loss = 0.1056(0.5441)
2024/03/05 09:35:42 - INFO - root -   Epoch: [83/300][120/200], lr: 0.00000031 	 loss = 2.1592(0.5160)
2024/03/05 09:36:17 - INFO - root -   Epoch: [83/300][140/200], lr: 0.00000031 	 loss = 1.0181(0.5378)
2024/03/05 09:36:52 - INFO - root -   Epoch: [83/300][160/200], lr: 0.00000031 	 loss = 0.1183(0.5232)
2024/03/05 09:37:31 - INFO - root -   Epoch: [83/300][180/200], lr: 0.00000031 	 loss = 0.1174(0.5247)
2024/03/05 09:37:48 - INFO - root -   Epoch: [83/300] 	 loss = 0.5186
2024/03/05 09:37:48 - INFO - root -   train_accuracy = 0.8250
2024/03/05 09:38:20 - INFO - root -   Epoch: [84/300][0/200], lr: 0.00000031 	 loss = 0.7312(0.7312)
2024/03/05 09:39:03 - INFO - root -   Epoch: [84/300][20/200], lr: 0.00000031 	 loss = 0.5609(0.5770)
2024/03/05 09:39:41 - INFO - root -   Epoch: [84/300][40/200], lr: 0.00000031 	 loss = 0.1772(0.5438)
2024/03/05 09:40:18 - INFO - root -   Epoch: [84/300][60/200], lr: 0.00000031 	 loss = 0.0459(0.5346)
2024/03/05 09:41:23 - INFO - root -   Epoch: [84/300][80/200], lr: 0.00000031 	 loss = 1.4178(0.5673)
2024/03/05 09:41:52 - INFO - root -   Epoch: [84/300][100/200], lr: 0.00000031 	 loss = 0.0634(0.5448)
2024/03/05 09:42:30 - INFO - root -   Epoch: [84/300][120/200], lr: 0.00000031 	 loss = 2.3731(0.5293)
2024/03/05 09:43:07 - INFO - root -   Epoch: [84/300][140/200], lr: 0.00000031 	 loss = 1.3739(0.5303)
2024/03/05 09:43:57 - INFO - root -   Epoch: [84/300][160/200], lr: 0.00000031 	 loss = 0.4198(0.5437)
2024/03/05 09:44:21 - INFO - root -   Epoch: [84/300][180/200], lr: 0.00000031 	 loss = 0.1894(0.5564)
2024/03/05 09:44:28 - INFO - root -   Epoch: [84/300] 	 loss = 0.5503
2024/03/05 09:44:32 - INFO - root -   precision = 0.7778
2024/03/05 09:44:32 - INFO - root -   eval_loss = 0.7785
2024/03/05 09:44:32 - INFO - root -   eval_acc = 0.7778
2024/03/05 09:44:33 - INFO - root -   train_accuracy = 0.8050
2024/03/05 09:45:03 - INFO - root -   Epoch: [85/300][0/200], lr: 0.00000031 	 loss = 1.6895(1.6895)
2024/03/05 09:45:43 - INFO - root -   Epoch: [85/300][20/200], lr: 0.00000031 	 loss = 0.1243(0.6620)
2024/03/05 09:46:34 - INFO - root -   Epoch: [85/300][40/200], lr: 0.00000031 	 loss = 0.1010(0.5083)
2024/03/05 09:47:03 - INFO - root -   Epoch: [85/300][60/200], lr: 0.00000031 	 loss = 0.0226(0.4986)
2024/03/05 09:47:35 - INFO - root -   Epoch: [85/300][80/200], lr: 0.00000031 	 loss = 0.9353(0.4885)
2024/03/05 09:48:15 - INFO - root -   Epoch: [85/300][100/200], lr: 0.00000031 	 loss = 0.1133(0.4877)
2024/03/05 09:49:14 - INFO - root -   Epoch: [85/300][120/200], lr: 0.00000031 	 loss = 3.1952(0.4928)
2024/03/05 09:49:33 - INFO - root -   Epoch: [85/300][140/200], lr: 0.00000031 	 loss = 1.7798(0.5145)
2024/03/05 09:50:11 - INFO - root -   Epoch: [85/300][160/200], lr: 0.00000031 	 loss = 0.0477(0.5051)
2024/03/05 09:50:59 - INFO - root -   Epoch: [85/300][180/200], lr: 0.00000031 	 loss = 0.3531(0.5090)
2024/03/05 09:51:10 - INFO - root -   Epoch: [85/300] 	 loss = 0.5085
2024/03/05 09:51:10 - INFO - root -   train_accuracy = 0.8475
2024/03/05 09:51:40 - INFO - root -   Epoch: [86/300][0/200], lr: 0.00000031 	 loss = 0.9961(0.9961)
2024/03/05 09:52:25 - INFO - root -   Epoch: [86/300][20/200], lr: 0.00000031 	 loss = 0.7864(0.6590)
2024/03/05 09:53:04 - INFO - root -   Epoch: [86/300][40/200], lr: 0.00000031 	 loss = 0.2642(0.5167)
2024/03/05 09:53:50 - INFO - root -   Epoch: [86/300][60/200], lr: 0.00000031 	 loss = 0.1233(0.4964)
2024/03/05 09:54:27 - INFO - root -   Epoch: [86/300][80/200], lr: 0.00000031 	 loss = 1.4190(0.5261)
2024/03/05 09:55:15 - INFO - root -   Epoch: [86/300][100/200], lr: 0.00000031 	 loss = 0.1829(0.5149)
2024/03/05 09:55:51 - INFO - root -   Epoch: [86/300][120/200], lr: 0.00000031 	 loss = 3.4043(0.5073)
2024/03/05 09:56:32 - INFO - root -   Epoch: [86/300][140/200], lr: 0.00000031 	 loss = 1.3536(0.5144)
2024/03/05 09:57:09 - INFO - root -   Epoch: [86/300][160/200], lr: 0.00000031 	 loss = 0.1357(0.5084)
2024/03/05 09:57:58 - INFO - root -   Epoch: [86/300][180/200], lr: 0.00000031 	 loss = 0.2492(0.5259)
2024/03/05 09:58:11 - INFO - root -   Epoch: [86/300] 	 loss = 0.5232
2024/03/05 09:58:11 - INFO - root -   train_accuracy = 0.8225
2024/03/05 09:58:35 - INFO - root -   Epoch: [87/300][0/200], lr: 0.00000032 	 loss = 1.0890(1.0890)
2024/03/05 09:59:30 - INFO - root -   Epoch: [87/300][20/200], lr: 0.00000032 	 loss = 0.4377(0.5783)
2024/03/05 10:00:05 - INFO - root -   Epoch: [87/300][40/200], lr: 0.00000032 	 loss = 0.7610(0.5265)
2024/03/05 10:00:36 - INFO - root -   Epoch: [87/300][60/200], lr: 0.00000032 	 loss = 0.0886(0.5286)
2024/03/05 10:01:19 - INFO - root -   Epoch: [87/300][80/200], lr: 0.00000032 	 loss = 1.8026(0.5338)
2024/03/05 10:02:10 - INFO - root -   Epoch: [87/300][100/200], lr: 0.00000032 	 loss = 0.0940(0.4953)
2024/03/05 10:02:48 - INFO - root -   Epoch: [87/300][120/200], lr: 0.00000032 	 loss = 2.4557(0.4900)
2024/03/05 10:03:21 - INFO - root -   Epoch: [87/300][140/200], lr: 0.00000032 	 loss = 1.3797(0.4863)
2024/03/05 10:03:54 - INFO - root -   Epoch: [87/300][160/200], lr: 0.00000032 	 loss = 0.3934(0.4886)
2024/03/05 10:04:47 - INFO - root -   Epoch: [87/300][180/200], lr: 0.00000032 	 loss = 0.4154(0.5116)
2024/03/05 10:04:55 - INFO - root -   Epoch: [87/300] 	 loss = 0.5150
2024/03/05 10:04:55 - INFO - root -   train_accuracy = 0.8175
2024/03/05 10:05:35 - INFO - root -   Epoch: [88/300][0/200], lr: 0.00000032 	 loss = 1.3785(1.3785)
2024/03/05 10:06:14 - INFO - root -   Epoch: [88/300][20/200], lr: 0.00000032 	 loss = 0.1535(0.5999)
2024/03/05 10:06:52 - INFO - root -   Epoch: [88/300][40/200], lr: 0.00000032 	 loss = 0.1540(0.5354)
2024/03/05 10:07:34 - INFO - root -   Epoch: [88/300][60/200], lr: 0.00000032 	 loss = 0.0539(0.5392)
2024/03/05 10:08:15 - INFO - root -   Epoch: [88/300][80/200], lr: 0.00000032 	 loss = 2.1977(0.5745)
2024/03/05 10:09:01 - INFO - root -   Epoch: [88/300][100/200], lr: 0.00000032 	 loss = 0.1066(0.5494)
2024/03/05 10:09:23 - INFO - root -   Epoch: [88/300][120/200], lr: 0.00000032 	 loss = 3.0738(0.5402)
2024/03/05 10:10:01 - INFO - root -   Epoch: [88/300][140/200], lr: 0.00000032 	 loss = 1.5974(0.5600)
2024/03/05 10:10:55 - INFO - root -   Epoch: [88/300][160/200], lr: 0.00000032 	 loss = 0.2765(0.5483)
2024/03/05 10:11:35 - INFO - root -   Epoch: [88/300][180/200], lr: 0.00000032 	 loss = 1.1418(0.5537)
2024/03/05 10:11:42 - INFO - root -   Epoch: [88/300] 	 loss = 0.5563
2024/03/05 10:11:42 - INFO - root -   train_accuracy = 0.8175
2024/03/05 10:12:13 - INFO - root -   Epoch: [89/300][0/200], lr: 0.00000032 	 loss = 2.0638(2.0638)
2024/03/05 10:13:05 - INFO - root -   Epoch: [89/300][20/200], lr: 0.00000032 	 loss = 0.2417(0.5427)
2024/03/05 10:13:46 - INFO - root -   Epoch: [89/300][40/200], lr: 0.00000032 	 loss = 0.3229(0.4923)
2024/03/05 10:14:17 - INFO - root -   Epoch: [89/300][60/200], lr: 0.00000032 	 loss = 0.1458(0.4870)
2024/03/05 10:15:07 - INFO - root -   Epoch: [89/300][80/200], lr: 0.00000032 	 loss = 0.8204(0.5015)
2024/03/05 10:15:56 - INFO - root -   Epoch: [89/300][100/200], lr: 0.00000032 	 loss = 0.1319(0.4776)
2024/03/05 10:16:29 - INFO - root -   Epoch: [89/300][120/200], lr: 0.00000032 	 loss = 2.3648(0.4626)
2024/03/05 10:16:55 - INFO - root -   Epoch: [89/300][140/200], lr: 0.00000032 	 loss = 1.3013(0.4763)
2024/03/05 10:17:51 - INFO - root -   Epoch: [89/300][160/200], lr: 0.00000032 	 loss = 0.1388(0.4779)
2024/03/05 10:18:17 - INFO - root -   Epoch: [89/300][180/200], lr: 0.00000032 	 loss = 0.3776(0.4846)
2024/03/05 10:18:24 - INFO - root -   Epoch: [89/300] 	 loss = 0.4815
2024/03/05 10:18:28 - INFO - root -   precision = 0.7556
2024/03/05 10:18:28 - INFO - root -   eval_loss = 0.8089
2024/03/05 10:18:28 - INFO - root -   eval_acc = 0.7556
2024/03/05 10:18:29 - INFO - root -   train_accuracy = 0.8425
2024/03/05 10:19:09 - INFO - root -   Epoch: [90/300][0/200], lr: 0.00000032 	 loss = 1.9848(1.9848)
2024/03/05 10:19:47 - INFO - root -   Epoch: [90/300][20/200], lr: 0.00000032 	 loss = 1.1241(0.6836)
2024/03/05 10:20:22 - INFO - root -   Epoch: [90/300][40/200], lr: 0.00000032 	 loss = 0.1606(0.5622)
2024/03/05 10:20:56 - INFO - root -   Epoch: [90/300][60/200], lr: 0.00000032 	 loss = 0.0694(0.5482)
2024/03/05 10:21:33 - INFO - root -   Epoch: [90/300][80/200], lr: 0.00000032 	 loss = 2.7204(0.5836)
2024/03/05 10:22:23 - INFO - root -   Epoch: [90/300][100/200], lr: 0.00000032 	 loss = 0.1217(0.5543)
2024/03/05 10:23:07 - INFO - root -   Epoch: [90/300][120/200], lr: 0.00000032 	 loss = 2.8522(0.5478)
2024/03/05 10:23:33 - INFO - root -   Epoch: [90/300][140/200], lr: 0.00000032 	 loss = 1.7624(0.5545)
2024/03/05 10:24:40 - INFO - root -   Epoch: [90/300][160/200], lr: 0.00000032 	 loss = 0.1809(0.5593)
2024/03/05 10:25:08 - INFO - root -   Epoch: [90/300][180/200], lr: 0.00000032 	 loss = 0.2678(0.5504)
2024/03/05 10:25:19 - INFO - root -   Epoch: [90/300] 	 loss = 0.5496
2024/03/05 10:25:19 - INFO - root -   train_accuracy = 0.8200
2024/03/05 10:26:01 - INFO - root -   Epoch: [91/300][0/200], lr: 0.00000033 	 loss = 1.9924(1.9924)
2024/03/05 10:26:36 - INFO - root -   Epoch: [91/300][20/200], lr: 0.00000033 	 loss = 0.1523(0.6294)
2024/03/05 10:27:25 - INFO - root -   Epoch: [91/300][40/200], lr: 0.00000033 	 loss = 0.1481(0.5458)
2024/03/05 10:28:06 - INFO - root -   Epoch: [91/300][60/200], lr: 0.00000033 	 loss = 0.1495(0.5520)
2024/03/05 10:28:40 - INFO - root -   Epoch: [91/300][80/200], lr: 0.00000033 	 loss = 1.4073(0.5623)
2024/03/05 10:29:21 - INFO - root -   Epoch: [91/300][100/200], lr: 0.00000033 	 loss = 0.0778(0.5297)
2024/03/05 10:30:16 - INFO - root -   Epoch: [91/300][120/200], lr: 0.00000033 	 loss = 2.8497(0.5346)
2024/03/05 10:30:52 - INFO - root -   Epoch: [91/300][140/200], lr: 0.00000033 	 loss = 1.6500(0.5396)
2024/03/05 10:31:28 - INFO - root -   Epoch: [91/300][160/200], lr: 0.00000033 	 loss = 0.2288(0.5373)
2024/03/05 10:32:08 - INFO - root -   Epoch: [91/300][180/200], lr: 0.00000033 	 loss = 0.3675(0.5371)
2024/03/05 10:32:17 - INFO - root -   Epoch: [91/300] 	 loss = 0.5245
2024/03/05 10:32:17 - INFO - root -   train_accuracy = 0.8225
2024/03/05 10:32:58 - INFO - root -   Epoch: [92/300][0/200], lr: 0.00000033 	 loss = 2.1112(2.1112)
2024/03/05 10:33:42 - INFO - root -   Epoch: [92/300][20/200], lr: 0.00000033 	 loss = 0.2423(0.5818)
2024/03/05 10:34:17 - INFO - root -   Epoch: [92/300][40/200], lr: 0.00000033 	 loss = 0.1619(0.4959)
2024/03/05 10:34:51 - INFO - root -   Epoch: [92/300][60/200], lr: 0.00000033 	 loss = 0.0857(0.4988)
2024/03/05 10:35:31 - INFO - root -   Epoch: [92/300][80/200], lr: 0.00000033 	 loss = 1.8344(0.5446)
2024/03/05 10:36:26 - INFO - root -   Epoch: [92/300][100/200], lr: 0.00000033 	 loss = 0.0711(0.4984)
2024/03/05 10:36:55 - INFO - root -   Epoch: [92/300][120/200], lr: 0.00000033 	 loss = 1.7296(0.4804)
2024/03/05 10:37:36 - INFO - root -   Epoch: [92/300][140/200], lr: 0.00000033 	 loss = 1.5083(0.4891)
2024/03/05 10:38:16 - INFO - root -   Epoch: [92/300][160/200], lr: 0.00000033 	 loss = 0.4246(0.5017)
2024/03/05 10:38:52 - INFO - root -   Epoch: [92/300][180/200], lr: 0.00000033 	 loss = 0.4880(0.5074)
2024/03/05 10:39:06 - INFO - root -   Epoch: [92/300] 	 loss = 0.4945
2024/03/05 10:39:06 - INFO - root -   train_accuracy = 0.8300
2024/03/05 10:39:44 - INFO - root -   Epoch: [93/300][0/200], lr: 0.00000033 	 loss = 0.4633(0.4633)
2024/03/05 10:40:24 - INFO - root -   Epoch: [93/300][20/200], lr: 0.00000033 	 loss = 0.0848(0.5480)
2024/03/05 10:41:03 - INFO - root -   Epoch: [93/300][40/200], lr: 0.00000033 	 loss = 0.1920(0.5116)
2024/03/05 10:41:38 - INFO - root -   Epoch: [93/300][60/200], lr: 0.00000033 	 loss = 0.0699(0.5048)
2024/03/05 10:42:14 - INFO - root -   Epoch: [93/300][80/200], lr: 0.00000033 	 loss = 1.7823(0.5031)
2024/03/05 10:43:12 - INFO - root -   Epoch: [93/300][100/200], lr: 0.00000033 	 loss = 0.1304(0.4767)
2024/03/05 10:43:59 - INFO - root -   Epoch: [93/300][120/200], lr: 0.00000033 	 loss = 1.8206(0.4721)
2024/03/05 10:44:31 - INFO - root -   Epoch: [93/300][140/200], lr: 0.00000033 	 loss = 1.8735(0.4792)
2024/03/05 10:45:07 - INFO - root -   Epoch: [93/300][160/200], lr: 0.00000033 	 loss = 0.2032(0.4952)
2024/03/05 10:45:46 - INFO - root -   Epoch: [93/300][180/200], lr: 0.00000033 	 loss = 0.2947(0.5134)
2024/03/05 10:46:00 - INFO - root -   Epoch: [93/300] 	 loss = 0.5137
2024/03/05 10:46:00 - INFO - root -   train_accuracy = 0.8150
2024/03/05 10:46:29 - INFO - root -   Epoch: [94/300][0/200], lr: 0.00000033 	 loss = 2.0219(2.0219)
2024/03/05 10:47:09 - INFO - root -   Epoch: [94/300][20/200], lr: 0.00000033 	 loss = 0.2224(0.6436)
2024/03/05 10:47:56 - INFO - root -   Epoch: [94/300][40/200], lr: 0.00000033 	 loss = 0.1044(0.5129)
2024/03/05 10:48:35 - INFO - root -   Epoch: [94/300][60/200], lr: 0.00000033 	 loss = 0.0337(0.5316)
2024/03/05 10:49:14 - INFO - root -   Epoch: [94/300][80/200], lr: 0.00000033 	 loss = 1.7270(0.5445)
2024/03/05 10:49:52 - INFO - root -   Epoch: [94/300][100/200], lr: 0.00000033 	 loss = 0.0957(0.5080)
2024/03/05 10:50:53 - INFO - root -   Epoch: [94/300][120/200], lr: 0.00000033 	 loss = 3.6681(0.5065)
2024/03/05 10:51:29 - INFO - root -   Epoch: [94/300][140/200], lr: 0.00000033 	 loss = 1.3705(0.5014)
2024/03/05 10:52:00 - INFO - root -   Epoch: [94/300][160/200], lr: 0.00000033 	 loss = 0.0489(0.4958)
2024/03/05 10:52:19 - INFO - root -   Epoch: [94/300][180/200], lr: 0.00000033 	 loss = 0.8040(0.5118)
2024/03/05 10:52:44 - INFO - root -   Epoch: [94/300] 	 loss = 0.5081
2024/03/05 10:52:47 - INFO - root -   precision = 0.7556
2024/03/05 10:52:47 - INFO - root -   eval_loss = 0.8139
2024/03/05 10:52:47 - INFO - root -   eval_acc = 0.7556
2024/03/05 10:52:48 - INFO - root -   train_accuracy = 0.8350
2024/03/05 10:53:30 - INFO - root -   Epoch: [95/300][0/200], lr: 0.00000034 	 loss = 1.7643(1.7643)
2024/03/05 10:54:11 - INFO - root -   Epoch: [95/300][20/200], lr: 0.00000034 	 loss = 0.4096(0.7244)
2024/03/05 10:54:49 - INFO - root -   Epoch: [95/300][40/200], lr: 0.00000034 	 loss = 0.2098(0.5633)
2024/03/05 10:55:28 - INFO - root -   Epoch: [95/300][60/200], lr: 0.00000034 	 loss = 0.0491(0.5285)
2024/03/05 10:55:49 - INFO - root -   Epoch: [95/300][80/200], lr: 0.00000034 	 loss = 2.1584(0.5664)
2024/03/05 10:56:44 - INFO - root -   Epoch: [95/300][100/200], lr: 0.00000034 	 loss = 0.0860(0.5405)
2024/03/05 10:57:20 - INFO - root -   Epoch: [95/300][120/200], lr: 0.00000034 	 loss = 3.1082(0.5239)
2024/03/05 10:58:05 - INFO - root -   Epoch: [95/300][140/200], lr: 0.00000034 	 loss = 1.8895(0.5302)
2024/03/05 10:58:43 - INFO - root -   Epoch: [95/300][160/200], lr: 0.00000034 	 loss = 0.1882(0.5260)
2024/03/05 10:59:20 - INFO - root -   Epoch: [95/300][180/200], lr: 0.00000034 	 loss = 0.4723(0.5432)
2024/03/05 10:59:33 - INFO - root -   Epoch: [95/300] 	 loss = 0.5459
2024/03/05 10:59:33 - INFO - root -   train_accuracy = 0.8225
2024/03/05 10:59:58 - INFO - root -   Epoch: [96/300][0/200], lr: 0.00000034 	 loss = 1.5974(1.5974)
2024/03/05 11:00:45 - INFO - root -   Epoch: [96/300][20/200], lr: 0.00000034 	 loss = 0.2440(0.5624)
2024/03/05 11:01:14 - INFO - root -   Epoch: [96/300][40/200], lr: 0.00000034 	 loss = 0.2541(0.5295)
2024/03/05 11:02:09 - INFO - root -   Epoch: [96/300][60/200], lr: 0.00000034 	 loss = 0.0303(0.5356)
2024/03/05 11:02:48 - INFO - root -   Epoch: [96/300][80/200], lr: 0.00000034 	 loss = 1.6179(0.5498)
2024/03/05 11:03:39 - INFO - root -   Epoch: [96/300][100/200], lr: 0.00000034 	 loss = 0.1658(0.5529)
2024/03/05 11:04:23 - INFO - root -   Epoch: [96/300][120/200], lr: 0.00000034 	 loss = 3.0053(0.5483)
2024/03/05 11:04:55 - INFO - root -   Epoch: [96/300][140/200], lr: 0.00000034 	 loss = 1.4498(0.5466)
2024/03/05 11:05:31 - INFO - root -   Epoch: [96/300][160/200], lr: 0.00000034 	 loss = 0.1328(0.5496)
2024/03/05 11:06:23 - INFO - root -   Epoch: [96/300][180/200], lr: 0.00000034 	 loss = 0.2730(0.5543)
2024/03/05 11:06:31 - INFO - root -   Epoch: [96/300] 	 loss = 0.5520
2024/03/05 11:06:31 - INFO - root -   train_accuracy = 0.8175
2024/03/05 11:07:08 - INFO - root -   Epoch: [97/300][0/200], lr: 0.00000034 	 loss = 1.7763(1.7763)
2024/03/05 11:07:51 - INFO - root -   Epoch: [97/300][20/200], lr: 0.00000034 	 loss = 0.2233(0.7582)
2024/03/05 11:08:32 - INFO - root -   Epoch: [97/300][40/200], lr: 0.00000034 	 loss = 0.1643(0.6324)
2024/03/05 11:09:04 - INFO - root -   Epoch: [97/300][60/200], lr: 0.00000034 	 loss = 0.3206(0.5907)
2024/03/05 11:09:44 - INFO - root -   Epoch: [97/300][80/200], lr: 0.00000034 	 loss = 2.1016(0.6062)
2024/03/05 11:10:27 - INFO - root -   Epoch: [97/300][100/200], lr: 0.00000034 	 loss = 0.1651(0.5631)
2024/03/05 11:11:05 - INFO - root -   Epoch: [97/300][120/200], lr: 0.00000034 	 loss = 2.8755(0.5450)
2024/03/05 11:11:44 - INFO - root -   Epoch: [97/300][140/200], lr: 0.00000034 	 loss = 1.3076(0.5511)
2024/03/05 11:12:18 - INFO - root -   Epoch: [97/300][160/200], lr: 0.00000034 	 loss = 0.0503(0.5379)
2024/03/05 11:13:13 - INFO - root -   Epoch: [97/300][180/200], lr: 0.00000034 	 loss = 0.3648(0.5472)
2024/03/05 11:13:21 - INFO - root -   Epoch: [97/300] 	 loss = 0.5338
2024/03/05 11:13:21 - INFO - root -   train_accuracy = 0.8250
2024/03/05 11:14:02 - INFO - root -   Epoch: [98/300][0/200], lr: 0.00000034 	 loss = 1.3058(1.3058)
2024/03/05 11:14:32 - INFO - root -   Epoch: [98/300][20/200], lr: 0.00000034 	 loss = 0.5100(0.6759)
2024/03/05 11:15:16 - INFO - root -   Epoch: [98/300][40/200], lr: 0.00000034 	 loss = 0.2196(0.5298)
2024/03/05 11:15:57 - INFO - root -   Epoch: [98/300][60/200], lr: 0.00000034 	 loss = 0.0251(0.5028)
2024/03/05 11:16:29 - INFO - root -   Epoch: [98/300][80/200], lr: 0.00000034 	 loss = 2.2162(0.5363)
2024/03/05 11:17:16 - INFO - root -   Epoch: [98/300][100/200], lr: 0.00000034 	 loss = 0.3224(0.5148)
2024/03/05 11:18:14 - INFO - root -   Epoch: [98/300][120/200], lr: 0.00000034 	 loss = 3.0221(0.5112)
2024/03/05 11:18:43 - INFO - root -   Epoch: [98/300][140/200], lr: 0.00000034 	 loss = 1.5902(0.5138)
2024/03/05 11:19:11 - INFO - root -   Epoch: [98/300][160/200], lr: 0.00000034 	 loss = 0.2080(0.5146)
2024/03/05 11:19:48 - INFO - root -   Epoch: [98/300][180/200], lr: 0.00000034 	 loss = 0.1246(0.5219)
2024/03/05 11:20:07 - INFO - root -   Epoch: [98/300] 	 loss = 0.5173
2024/03/05 11:20:07 - INFO - root -   train_accuracy = 0.8200
2024/03/05 11:20:45 - INFO - root -   Epoch: [99/300][0/200], lr: 0.00000035 	 loss = 1.5858(1.5858)
2024/03/05 11:21:31 - INFO - root -   Epoch: [99/300][20/200], lr: 0.00000035 	 loss = 0.0952(0.6856)
2024/03/05 11:22:07 - INFO - root -   Epoch: [99/300][40/200], lr: 0.00000035 	 loss = 0.2044(0.5931)
2024/03/05 11:22:40 - INFO - root -   Epoch: [99/300][60/200], lr: 0.00000035 	 loss = 0.0402(0.5517)
2024/03/05 11:23:17 - INFO - root -   Epoch: [99/300][80/200], lr: 0.00000035 	 loss = 1.6543(0.5691)
2024/03/05 11:24:09 - INFO - root -   Epoch: [99/300][100/200], lr: 0.00000035 	 loss = 0.0698(0.5478)
2024/03/05 11:24:50 - INFO - root -   Epoch: [99/300][120/200], lr: 0.00000035 	 loss = 2.2309(0.5353)
2024/03/05 11:25:31 - INFO - root -   Epoch: [99/300][140/200], lr: 0.00000035 	 loss = 1.7737(0.5340)
2024/03/05 11:26:00 - INFO - root -   Epoch: [99/300][160/200], lr: 0.00000035 	 loss = 0.1081(0.5237)
2024/03/05 11:26:45 - INFO - root -   Epoch: [99/300][180/200], lr: 0.00000035 	 loss = 0.3024(0.5363)
2024/03/05 11:26:52 - INFO - root -   Epoch: [99/300] 	 loss = 0.5240
2024/03/05 11:26:56 - INFO - root -   precision = 0.7778
2024/03/05 11:26:56 - INFO - root -   eval_loss = 0.8029
2024/03/05 11:26:56 - INFO - root -   eval_acc = 0.7778
2024/03/05 11:26:57 - INFO - root -   train_accuracy = 0.8075
2024/03/05 11:27:41 - INFO - root -   Epoch: [100/300][0/200], lr: 0.00000035 	 loss = 1.6408(1.6408)
2024/03/05 11:28:18 - INFO - root -   Epoch: [100/300][20/200], lr: 0.00000035 	 loss = 0.9246(0.5933)
2024/03/05 11:28:53 - INFO - root -   Epoch: [100/300][40/200], lr: 0.00000035 	 loss = 0.2195(0.4954)
2024/03/05 11:29:24 - INFO - root -   Epoch: [100/300][60/200], lr: 0.00000035 	 loss = 0.1266(0.5111)
2024/03/05 11:30:20 - INFO - root -   Epoch: [100/300][80/200], lr: 0.00000035 	 loss = 1.9157(0.5238)
2024/03/05 11:31:03 - INFO - root -   Epoch: [100/300][100/200], lr: 0.00000035 	 loss = 0.0729(0.4963)
2024/03/05 11:31:39 - INFO - root -   Epoch: [100/300][120/200], lr: 0.00000035 	 loss = 3.6403(0.4859)
2024/03/05 11:32:04 - INFO - root -   Epoch: [100/300][140/200], lr: 0.00000035 	 loss = 1.0952(0.4839)
2024/03/05 11:32:38 - INFO - root -   Epoch: [100/300][160/200], lr: 0.00000035 	 loss = 0.0833(0.4879)
2024/03/05 11:33:32 - INFO - root -   Epoch: [100/300][180/200], lr: 0.00000035 	 loss = 0.3814(0.4974)
2024/03/05 11:33:40 - INFO - root -   Epoch: [100/300] 	 loss = 0.4931
2024/03/05 11:33:40 - INFO - root -   train_accuracy = 0.8350
2024/03/05 11:34:04 - INFO - root -   Epoch: [101/300][0/200], lr: 0.00000035 	 loss = 1.2012(1.2012)
2024/03/05 11:35:05 - INFO - root -   Epoch: [101/300][20/200], lr: 0.00000035 	 loss = 0.1425(0.5308)
2024/03/05 11:35:42 - INFO - root -   Epoch: [101/300][40/200], lr: 0.00000035 	 loss = 0.2133(0.4364)
2024/03/05 11:36:11 - INFO - root -   Epoch: [101/300][60/200], lr: 0.00000035 	 loss = 0.1082(0.4484)
2024/03/05 11:36:44 - INFO - root -   Epoch: [101/300][80/200], lr: 0.00000035 	 loss = 2.1676(0.4933)
2024/03/05 11:37:30 - INFO - root -   Epoch: [101/300][100/200], lr: 0.00000035 	 loss = 0.0862(0.4804)
2024/03/05 11:38:19 - INFO - root -   Epoch: [101/300][120/200], lr: 0.00000035 	 loss = 2.7821(0.4664)
2024/03/05 11:38:51 - INFO - root -   Epoch: [101/300][140/200], lr: 0.00000035 	 loss = 2.6947(0.4799)
2024/03/05 11:39:29 - INFO - root -   Epoch: [101/300][160/200], lr: 0.00000035 	 loss = 0.1018(0.4835)
2024/03/05 11:40:04 - INFO - root -   Epoch: [101/300][180/200], lr: 0.00000035 	 loss = 0.1818(0.4858)
2024/03/05 11:40:21 - INFO - root -   Epoch: [101/300] 	 loss = 0.4837
2024/03/05 11:40:21 - INFO - root -   train_accuracy = 0.8450
2024/03/05 11:40:58 - INFO - root -   Epoch: [102/300][0/200], lr: 0.00000035 	 loss = 1.4469(1.4469)
2024/03/05 11:41:46 - INFO - root -   Epoch: [102/300][20/200], lr: 0.00000035 	 loss = 0.6985(0.5582)
2024/03/05 11:42:23 - INFO - root -   Epoch: [102/300][40/200], lr: 0.00000035 	 loss = 0.1692(0.5189)
2024/03/05 11:43:00 - INFO - root -   Epoch: [102/300][60/200], lr: 0.00000035 	 loss = 0.0451(0.4889)
2024/03/05 11:43:32 - INFO - root -   Epoch: [102/300][80/200], lr: 0.00000035 	 loss = 1.8947(0.5286)
2024/03/05 11:44:25 - INFO - root -   Epoch: [102/300][100/200], lr: 0.00000035 	 loss = 0.2540(0.4925)
2024/03/05 11:45:08 - INFO - root -   Epoch: [102/300][120/200], lr: 0.00000035 	 loss = 2.3885(0.4831)
2024/03/05 11:45:53 - INFO - root -   Epoch: [102/300][140/200], lr: 0.00000035 	 loss = 2.0813(0.4928)
2024/03/05 11:46:24 - INFO - root -   Epoch: [102/300][160/200], lr: 0.00000035 	 loss = 0.1075(0.4963)
2024/03/05 11:47:09 - INFO - root -   Epoch: [102/300][180/200], lr: 0.00000035 	 loss = 0.4238(0.5062)
2024/03/05 11:47:16 - INFO - root -   Epoch: [102/300] 	 loss = 0.4967
2024/03/05 11:47:16 - INFO - root -   train_accuracy = 0.8450
2024/03/05 11:47:54 - INFO - root -   Epoch: [103/300][0/200], lr: 0.00000035 	 loss = 1.2518(1.2518)
2024/03/05 11:48:35 - INFO - root -   Epoch: [103/300][20/200], lr: 0.00000035 	 loss = 0.4062(0.6312)
2024/03/05 11:49:12 - INFO - root -   Epoch: [103/300][40/200], lr: 0.00000035 	 loss = 0.2879(0.4849)
2024/03/05 11:49:45 - INFO - root -   Epoch: [103/300][60/200], lr: 0.00000035 	 loss = 0.0482(0.4611)
2024/03/05 11:50:56 - INFO - root -   Epoch: [103/300][80/200], lr: 0.00000035 	 loss = 1.4638(0.5297)
2024/03/05 11:51:34 - INFO - root -   Epoch: [103/300][100/200], lr: 0.00000035 	 loss = 0.1828(0.4924)
2024/03/05 11:52:04 - INFO - root -   Epoch: [103/300][120/200], lr: 0.00000035 	 loss = 2.3309(0.5014)
2024/03/05 11:52:42 - INFO - root -   Epoch: [103/300][140/200], lr: 0.00000035 	 loss = 1.5426(0.5119)
2024/03/05 11:53:22 - INFO - root -   Epoch: [103/300][160/200], lr: 0.00000035 	 loss = 0.1333(0.5272)
2024/03/05 11:53:57 - INFO - root -   Epoch: [103/300][180/200], lr: 0.00000035 	 loss = 0.7375(0.5372)
2024/03/05 11:54:12 - INFO - root -   Epoch: [103/300] 	 loss = 0.5414
2024/03/05 11:54:12 - INFO - root -   train_accuracy = 0.8225
2024/03/05 11:54:46 - INFO - root -   Epoch: [104/300][0/200], lr: 0.00000036 	 loss = 1.0611(1.0611)
2024/03/05 11:55:25 - INFO - root -   Epoch: [104/300][20/200], lr: 0.00000036 	 loss = 0.2388(0.5869)
2024/03/05 11:56:06 - INFO - root -   Epoch: [104/300][40/200], lr: 0.00000036 	 loss = 0.2633(0.4904)
2024/03/05 11:56:50 - INFO - root -   Epoch: [104/300][60/200], lr: 0.00000036 	 loss = 0.1854(0.4966)
2024/03/05 11:57:30 - INFO - root -   Epoch: [104/300][80/200], lr: 0.00000036 	 loss = 1.2031(0.5176)
2024/03/05 11:58:13 - INFO - root -   Epoch: [104/300][100/200], lr: 0.00000036 	 loss = 0.3933(0.4867)
2024/03/05 11:58:54 - INFO - root -   Epoch: [104/300][120/200], lr: 0.00000036 	 loss = 2.8855(0.4884)
2024/03/05 11:59:51 - INFO - root -   Epoch: [104/300][140/200], lr: 0.00000036 	 loss = 1.4579(0.4969)
2024/03/05 12:00:32 - INFO - root -   Epoch: [104/300][160/200], lr: 0.00000036 	 loss = 0.1057(0.4927)
2024/03/05 12:01:04 - INFO - root -   Epoch: [104/300][180/200], lr: 0.00000036 	 loss = 0.2051(0.5047)
2024/03/05 12:01:13 - INFO - root -   Epoch: [104/300] 	 loss = 0.5088
2024/03/05 12:01:16 - INFO - root -   precision = 0.7778
2024/03/05 12:01:16 - INFO - root -   eval_loss = 0.8202
2024/03/05 12:01:16 - INFO - root -   eval_acc = 0.7778
2024/03/05 12:01:17 - INFO - root -   train_accuracy = 0.8250
2024/03/05 12:01:51 - INFO - root -   Epoch: [105/300][0/200], lr: 0.00000036 	 loss = 1.0968(1.0968)
2024/03/05 12:02:34 - INFO - root -   Epoch: [105/300][20/200], lr: 0.00000036 	 loss = 0.4313(0.5249)
2024/03/05 12:03:18 - INFO - root -   Epoch: [105/300][40/200], lr: 0.00000036 	 loss = 0.1808(0.5008)
2024/03/05 12:03:46 - INFO - root -   Epoch: [105/300][60/200], lr: 0.00000036 	 loss = 0.1072(0.5021)
2024/03/05 12:04:58 - INFO - root -   Epoch: [105/300][80/200], lr: 0.00000036 	 loss = 2.0226(0.5456)
2024/03/05 12:05:18 - INFO - root -   Epoch: [105/300][100/200], lr: 0.00000036 	 loss = 0.1455(0.5030)
2024/03/05 12:05:53 - INFO - root -   Epoch: [105/300][120/200], lr: 0.00000036 	 loss = 2.5426(0.4955)
2024/03/05 12:06:20 - INFO - root -   Epoch: [105/300][140/200], lr: 0.00000036 	 loss = 2.1303(0.4952)
2024/03/05 12:06:56 - INFO - root -   Epoch: [105/300][160/200], lr: 0.00000036 	 loss = 0.0728(0.4980)
2024/03/05 12:07:40 - INFO - root -   Epoch: [105/300][180/200], lr: 0.00000036 	 loss = 0.8197(0.5063)
2024/03/05 12:07:54 - INFO - root -   Epoch: [105/300] 	 loss = 0.5019
2024/03/05 12:07:54 - INFO - root -   train_accuracy = 0.8400
2024/03/05 12:08:24 - INFO - root -   Epoch: [106/300][0/200], lr: 0.00000036 	 loss = 1.4983(1.4983)
2024/03/05 12:09:15 - INFO - root -   Epoch: [106/300][20/200], lr: 0.00000036 	 loss = 0.8105(0.5914)
2024/03/05 12:09:42 - INFO - root -   Epoch: [106/300][40/200], lr: 0.00000036 	 loss = 0.2753(0.4951)
2024/03/05 12:10:34 - INFO - root -   Epoch: [106/300][60/200], lr: 0.00000036 	 loss = 0.1212(0.5022)
2024/03/05 12:10:52 - INFO - root -   Epoch: [106/300][80/200], lr: 0.00000036 	 loss = 2.2422(0.5600)
2024/03/05 12:11:49 - INFO - root -   Epoch: [106/300][100/200], lr: 0.00000036 	 loss = 0.5278(0.5291)
2024/03/05 12:12:22 - INFO - root -   Epoch: [106/300][120/200], lr: 0.00000036 	 loss = 3.1232(0.5314)
2024/03/05 12:13:16 - INFO - root -   Epoch: [106/300][140/200], lr: 0.00000036 	 loss = 1.4339(0.5191)
2024/03/05 12:13:52 - INFO - root -   Epoch: [106/300][160/200], lr: 0.00000036 	 loss = 0.1718(0.5056)
2024/03/05 12:14:23 - INFO - root -   Epoch: [106/300][180/200], lr: 0.00000036 	 loss = 0.1664(0.5056)
2024/03/05 12:14:37 - INFO - root -   Epoch: [106/300] 	 loss = 0.4978
2024/03/05 12:14:37 - INFO - root -   train_accuracy = 0.8325
2024/03/05 12:15:17 - INFO - root -   Epoch: [107/300][0/200], lr: 0.00000036 	 loss = 1.9402(1.9402)
2024/03/05 12:15:59 - INFO - root -   Epoch: [107/300][20/200], lr: 0.00000036 	 loss = 0.0766(0.6074)
2024/03/05 12:16:36 - INFO - root -   Epoch: [107/300][40/200], lr: 0.00000036 	 loss = 0.0893(0.5095)
2024/03/05 12:17:13 - INFO - root -   Epoch: [107/300][60/200], lr: 0.00000036 	 loss = 0.0897(0.5151)
2024/03/05 12:17:45 - INFO - root -   Epoch: [107/300][80/200], lr: 0.00000036 	 loss = 2.2609(0.5463)
2024/03/05 12:18:44 - INFO - root -   Epoch: [107/300][100/200], lr: 0.00000036 	 loss = 0.1654(0.5137)
2024/03/05 12:19:21 - INFO - root -   Epoch: [107/300][120/200], lr: 0.00000036 	 loss = 3.1479(0.5075)
2024/03/05 12:19:59 - INFO - root -   Epoch: [107/300][140/200], lr: 0.00000036 	 loss = 1.3682(0.5177)
2024/03/05 12:20:27 - INFO - root -   Epoch: [107/300][160/200], lr: 0.00000036 	 loss = 0.0882(0.5205)
2024/03/05 12:21:17 - INFO - root -   Epoch: [107/300][180/200], lr: 0.00000036 	 loss = 0.3628(0.5208)
2024/03/05 12:21:25 - INFO - root -   Epoch: [107/300] 	 loss = 0.5040
2024/03/05 12:21:25 - INFO - root -   train_accuracy = 0.8375
2024/03/05 12:22:09 - INFO - root -   Epoch: [108/300][0/200], lr: 0.00000037 	 loss = 1.0338(1.0338)
2024/03/05 12:22:42 - INFO - root -   Epoch: [108/300][20/200], lr: 0.00000037 	 loss = 0.0799(0.6113)
2024/03/05 12:23:18 - INFO - root -   Epoch: [108/300][40/200], lr: 0.00000037 	 loss = 0.1148(0.5030)
2024/03/05 12:23:47 - INFO - root -   Epoch: [108/300][60/200], lr: 0.00000037 	 loss = 0.0640(0.4715)
2024/03/05 12:24:36 - INFO - root -   Epoch: [108/300][80/200], lr: 0.00000037 	 loss = 1.1615(0.4889)
2024/03/05 12:25:22 - INFO - root -   Epoch: [108/300][100/200], lr: 0.00000037 	 loss = 0.1292(0.4708)
2024/03/05 12:26:04 - INFO - root -   Epoch: [108/300][120/200], lr: 0.00000037 	 loss = 2.1492(0.4594)
2024/03/05 12:26:41 - INFO - root -   Epoch: [108/300][140/200], lr: 0.00000037 	 loss = 1.5230(0.4728)
2024/03/05 12:27:22 - INFO - root -   Epoch: [108/300][160/200], lr: 0.00000037 	 loss = 0.0869(0.4753)
2024/03/05 12:27:50 - INFO - root -   Epoch: [108/300][180/200], lr: 0.00000037 	 loss = 0.2631(0.4893)
2024/03/05 12:28:00 - INFO - root -   Epoch: [108/300] 	 loss = 0.4876
2024/03/05 12:28:00 - INFO - root -   train_accuracy = 0.8450
2024/03/05 12:28:33 - INFO - root -   Epoch: [109/300][0/200], lr: 0.00000037 	 loss = 1.4430(1.4430)
2024/03/05 12:29:22 - INFO - root -   Epoch: [109/300][20/200], lr: 0.00000037 	 loss = 0.6760(0.6474)
2024/03/05 12:29:56 - INFO - root -   Epoch: [109/300][40/200], lr: 0.00000037 	 loss = 0.1237(0.5351)
2024/03/05 12:30:33 - INFO - root -   Epoch: [109/300][60/200], lr: 0.00000037 	 loss = 0.0992(0.5325)
2024/03/05 12:31:23 - INFO - root -   Epoch: [109/300][80/200], lr: 0.00000037 	 loss = 1.7453(0.5247)
2024/03/05 12:32:09 - INFO - root -   Epoch: [109/300][100/200], lr: 0.00000037 	 loss = 0.1171(0.5058)
2024/03/05 12:32:47 - INFO - root -   Epoch: [109/300][120/200], lr: 0.00000037 	 loss = 2.5173(0.4913)
2024/03/05 12:33:19 - INFO - root -   Epoch: [109/300][140/200], lr: 0.00000037 	 loss = 1.8144(0.5143)
2024/03/05 12:34:08 - INFO - root -   Epoch: [109/300][160/200], lr: 0.00000037 	 loss = 0.1608(0.5105)
2024/03/05 12:34:44 - INFO - root -   Epoch: [109/300][180/200], lr: 0.00000037 	 loss = 0.2075(0.5136)
2024/03/05 12:34:53 - INFO - root -   Epoch: [109/300] 	 loss = 0.5128
2024/03/05 12:34:56 - INFO - root -   precision = 0.7333
2024/03/05 12:34:56 - INFO - root -   eval_loss = 0.8733
2024/03/05 12:34:56 - INFO - root -   eval_acc = 0.7333
2024/03/05 12:34:57 - INFO - root -   train_accuracy = 0.8175
2024/03/05 12:35:15 - INFO - root -   Epoch: [110/300][0/200], lr: 0.00000037 	 loss = 0.9685(0.9685)
2024/03/05 12:36:09 - INFO - root -   Epoch: [110/300][20/200], lr: 0.00000037 	 loss = 0.0784(0.5533)
2024/03/05 12:36:57 - INFO - root -   Epoch: [110/300][40/200], lr: 0.00000037 	 loss = 0.1559(0.4463)
2024/03/05 12:37:40 - INFO - root -   Epoch: [110/300][60/200], lr: 0.00000037 	 loss = 0.1957(0.4779)
2024/03/05 12:38:13 - INFO - root -   Epoch: [110/300][80/200], lr: 0.00000037 	 loss = 1.8123(0.5025)
2024/03/05 12:39:02 - INFO - root -   Epoch: [110/300][100/200], lr: 0.00000037 	 loss = 0.0726(0.4718)
2024/03/05 12:39:56 - INFO - root -   Epoch: [110/300][120/200], lr: 0.00000037 	 loss = 2.2337(0.4760)
2024/03/05 12:40:30 - INFO - root -   Epoch: [110/300][140/200], lr: 0.00000037 	 loss = 2.2552(0.4889)
2024/03/05 12:40:51 - INFO - root -   Epoch: [110/300][160/200], lr: 0.00000037 	 loss = 0.0947(0.4876)
2024/03/05 12:41:36 - INFO - root -   Epoch: [110/300][180/200], lr: 0.00000037 	 loss = 0.6258(0.5121)
2024/03/05 12:41:50 - INFO - root -   Epoch: [110/300] 	 loss = 0.5163
2024/03/05 12:41:50 - INFO - root -   train_accuracy = 0.8150
2024/03/05 12:42:26 - INFO - root -   Epoch: [111/300][0/200], lr: 0.00000037 	 loss = 1.7267(1.7267)
2024/03/05 12:43:02 - INFO - root -   Epoch: [111/300][20/200], lr: 0.00000037 	 loss = 0.1629(0.6265)
2024/03/05 12:43:40 - INFO - root -   Epoch: [111/300][40/200], lr: 0.00000037 	 loss = 0.2394(0.5737)
2024/03/05 12:44:21 - INFO - root -   Epoch: [111/300][60/200], lr: 0.00000037 	 loss = 0.1304(0.5472)
2024/03/05 12:45:04 - INFO - root -   Epoch: [111/300][80/200], lr: 0.00000037 	 loss = 2.5469(0.5749)
2024/03/05 12:45:51 - INFO - root -   Epoch: [111/300][100/200], lr: 0.00000037 	 loss = 0.1651(0.5476)
2024/03/05 12:46:43 - INFO - root -   Epoch: [111/300][120/200], lr: 0.00000037 	 loss = 2.7363(0.5357)
2024/03/05 12:47:10 - INFO - root -   Epoch: [111/300][140/200], lr: 0.00000037 	 loss = 1.4755(0.5276)
2024/03/05 12:47:49 - INFO - root -   Epoch: [111/300][160/200], lr: 0.00000037 	 loss = 0.3475(0.5222)
2024/03/05 12:48:31 - INFO - root -   Epoch: [111/300][180/200], lr: 0.00000037 	 loss = 0.2920(0.5151)
2024/03/05 12:48:39 - INFO - root -   Epoch: [111/300] 	 loss = 0.5225
2024/03/05 12:48:39 - INFO - root -   train_accuracy = 0.8250
2024/03/05 12:49:12 - INFO - root -   Epoch: [112/300][0/200], lr: 0.00000038 	 loss = 1.1581(1.1581)
2024/03/05 12:49:54 - INFO - root -   Epoch: [112/300][20/200], lr: 0.00000038 	 loss = 0.7938(0.7156)
2024/03/05 12:50:26 - INFO - root -   Epoch: [112/300][40/200], lr: 0.00000038 	 loss = 0.2686(0.5998)
2024/03/05 12:51:14 - INFO - root -   Epoch: [112/300][60/200], lr: 0.00000038 	 loss = 0.0689(0.5444)
2024/03/05 12:51:54 - INFO - root -   Epoch: [112/300][80/200], lr: 0.00000038 	 loss = 1.6878(0.5490)
2024/03/05 12:52:46 - INFO - root -   Epoch: [112/300][100/200], lr: 0.00000038 	 loss = 0.1506(0.5139)
2024/03/05 12:53:23 - INFO - root -   Epoch: [112/300][120/200], lr: 0.00000038 	 loss = 2.1985(0.4931)
2024/03/05 12:54:00 - INFO - root -   Epoch: [112/300][140/200], lr: 0.00000038 	 loss = 1.1868(0.4882)
2024/03/05 12:54:35 - INFO - root -   Epoch: [112/300][160/200], lr: 0.00000038 	 loss = 0.1078(0.4874)
2024/03/05 12:55:24 - INFO - root -   Epoch: [112/300][180/200], lr: 0.00000038 	 loss = 0.4463(0.4916)
2024/03/05 12:55:31 - INFO - root -   Epoch: [112/300] 	 loss = 0.4880
2024/03/05 12:55:31 - INFO - root -   train_accuracy = 0.8375
2024/03/05 12:55:59 - INFO - root -   Epoch: [113/300][0/200], lr: 0.00000038 	 loss = 0.7567(0.7567)
2024/03/05 12:56:44 - INFO - root -   Epoch: [113/300][20/200], lr: 0.00000038 	 loss = 0.3745(0.5759)
2024/03/05 12:57:28 - INFO - root -   Epoch: [113/300][40/200], lr: 0.00000038 	 loss = 0.2161(0.5182)
2024/03/05 12:58:06 - INFO - root -   Epoch: [113/300][60/200], lr: 0.00000038 	 loss = 0.0801(0.4822)
2024/03/05 12:58:49 - INFO - root -   Epoch: [113/300][80/200], lr: 0.00000038 	 loss = 2.3145(0.5081)
2024/03/05 12:59:20 - INFO - root -   Epoch: [113/300][100/200], lr: 0.00000038 	 loss = 0.2414(0.4847)
2024/03/05 13:00:25 - INFO - root -   Epoch: [113/300][120/200], lr: 0.00000038 	 loss = 2.9023(0.4762)
2024/03/05 13:00:57 - INFO - root -   Epoch: [113/300][140/200], lr: 0.00000038 	 loss = 1.7672(0.4777)
2024/03/05 13:01:36 - INFO - root -   Epoch: [113/300][160/200], lr: 0.00000038 	 loss = 0.4951(0.4896)
2024/03/05 13:02:17 - INFO - root -   Epoch: [113/300][180/200], lr: 0.00000038 	 loss = 0.4347(0.5035)
2024/03/05 13:02:25 - INFO - root -   Epoch: [113/300] 	 loss = 0.4982
2024/03/05 13:02:25 - INFO - root -   train_accuracy = 0.8450
2024/03/05 13:02:57 - INFO - root -   Epoch: [114/300][0/200], lr: 0.00000038 	 loss = 1.2018(1.2018)
2024/03/05 13:03:41 - INFO - root -   Epoch: [114/300][20/200], lr: 0.00000038 	 loss = 0.3056(0.5905)
2024/03/05 13:04:20 - INFO - root -   Epoch: [114/300][40/200], lr: 0.00000038 	 loss = 0.1023(0.4978)
2024/03/05 13:04:54 - INFO - root -   Epoch: [114/300][60/200], lr: 0.00000038 	 loss = 0.0627(0.4900)
2024/03/05 13:05:44 - INFO - root -   Epoch: [114/300][80/200], lr: 0.00000038 	 loss = 2.0407(0.5317)
2024/03/05 13:06:21 - INFO - root -   Epoch: [114/300][100/200], lr: 0.00000038 	 loss = 0.2277(0.4909)
2024/03/05 13:07:07 - INFO - root -   Epoch: [114/300][120/200], lr: 0.00000038 	 loss = 3.0691(0.4905)
2024/03/05 13:07:40 - INFO - root -   Epoch: [114/300][140/200], lr: 0.00000038 	 loss = 1.5668(0.4860)
2024/03/05 13:08:22 - INFO - root -   Epoch: [114/300][160/200], lr: 0.00000038 	 loss = 0.0611(0.4824)
2024/03/05 13:09:01 - INFO - root -   Epoch: [114/300][180/200], lr: 0.00000038 	 loss = 0.5809(0.4890)
2024/03/05 13:09:14 - INFO - root -   Epoch: [114/300] 	 loss = 0.4888
2024/03/05 13:09:18 - INFO - root -   precision = 0.7556
2024/03/05 13:09:18 - INFO - root -   eval_loss = 0.8645
2024/03/05 13:09:18 - INFO - root -   eval_acc = 0.7556
2024/03/05 13:09:19 - INFO - root -   train_accuracy = 0.8400
2024/03/05 13:09:37 - INFO - root -   Epoch: [115/300][0/200], lr: 0.00000038 	 loss = 0.9480(0.9480)
2024/03/05 13:10:31 - INFO - root -   Epoch: [115/300][20/200], lr: 0.00000038 	 loss = 0.8500(0.5586)
2024/03/05 13:11:14 - INFO - root -   Epoch: [115/300][40/200], lr: 0.00000038 	 loss = 0.1446(0.5011)
2024/03/05 13:11:48 - INFO - root -   Epoch: [115/300][60/200], lr: 0.00000038 	 loss = 0.0607(0.5095)
2024/03/05 13:12:32 - INFO - root -   Epoch: [115/300][80/200], lr: 0.00000038 	 loss = 1.6568(0.5314)
2024/03/05 13:13:01 - INFO - root -   Epoch: [115/300][100/200], lr: 0.00000038 	 loss = 0.1378(0.5031)
2024/03/05 13:14:01 - INFO - root -   Epoch: [115/300][120/200], lr: 0.00000038 	 loss = 3.0357(0.5028)
2024/03/05 13:14:41 - INFO - root -   Epoch: [115/300][140/200], lr: 0.00000038 	 loss = 1.5286(0.5052)
2024/03/05 13:15:14 - INFO - root -   Epoch: [115/300][160/200], lr: 0.00000038 	 loss = 0.1012(0.5113)
2024/03/05 13:15:45 - INFO - root -   Epoch: [115/300][180/200], lr: 0.00000038 	 loss = 0.2824(0.5106)
2024/03/05 13:16:05 - INFO - root -   Epoch: [115/300] 	 loss = 0.5025
2024/03/05 13:16:05 - INFO - root -   train_accuracy = 0.8350
2024/03/05 13:16:49 - INFO - root -   Epoch: [116/300][0/200], lr: 0.00000039 	 loss = 0.8196(0.8196)
2024/03/05 13:17:26 - INFO - root -   Epoch: [116/300][20/200], lr: 0.00000039 	 loss = 0.3223(0.6543)
2024/03/05 13:18:06 - INFO - root -   Epoch: [116/300][40/200], lr: 0.00000039 	 loss = 0.3265(0.5032)
2024/03/05 13:18:39 - INFO - root -   Epoch: [116/300][60/200], lr: 0.00000039 	 loss = 0.2752(0.4815)
2024/03/05 13:19:19 - INFO - root -   Epoch: [116/300][80/200], lr: 0.00000039 	 loss = 1.6403(0.4914)
2024/03/05 13:20:06 - INFO - root -   Epoch: [116/300][100/200], lr: 0.00000039 	 loss = 0.1442(0.4626)
2024/03/05 13:20:40 - INFO - root -   Epoch: [116/300][120/200], lr: 0.00000039 	 loss = 3.3541(0.4624)
2024/03/05 13:21:14 - INFO - root -   Epoch: [116/300][140/200], lr: 0.00000039 	 loss = 2.7842(0.4726)
2024/03/05 13:22:15 - INFO - root -   Epoch: [116/300][160/200], lr: 0.00000039 	 loss = 0.1331(0.4709)
2024/03/05 13:22:41 - INFO - root -   Epoch: [116/300][180/200], lr: 0.00000039 	 loss = 0.2472(0.4750)
2024/03/05 13:22:52 - INFO - root -   Epoch: [116/300] 	 loss = 0.4746
2024/03/05 13:22:52 - INFO - root -   train_accuracy = 0.8400
2024/03/05 13:23:23 - INFO - root -   Epoch: [117/300][0/200], lr: 0.00000039 	 loss = 0.9740(0.9740)
2024/03/05 13:24:09 - INFO - root -   Epoch: [117/300][20/200], lr: 0.00000039 	 loss = 0.3630(0.5468)
2024/03/05 13:24:42 - INFO - root -   Epoch: [117/300][40/200], lr: 0.00000039 	 loss = 0.3117(0.4504)
2024/03/05 13:25:23 - INFO - root -   Epoch: [117/300][60/200], lr: 0.00000039 	 loss = 0.0448(0.4326)
2024/03/05 13:25:55 - INFO - root -   Epoch: [117/300][80/200], lr: 0.00000039 	 loss = 2.4914(0.4901)
2024/03/05 13:27:01 - INFO - root -   Epoch: [117/300][100/200], lr: 0.00000039 	 loss = 0.4282(0.4730)
2024/03/05 13:27:37 - INFO - root -   Epoch: [117/300][120/200], lr: 0.00000039 	 loss = 2.0486(0.4623)
2024/03/05 13:28:12 - INFO - root -   Epoch: [117/300][140/200], lr: 0.00000039 	 loss = 1.7178(0.4775)
2024/03/05 13:28:52 - INFO - root -   Epoch: [117/300][160/200], lr: 0.00000039 	 loss = 0.1161(0.4768)
2024/03/05 13:29:28 - INFO - root -   Epoch: [117/300][180/200], lr: 0.00000039 	 loss = 0.9459(0.5092)
2024/03/05 13:29:35 - INFO - root -   Epoch: [117/300] 	 loss = 0.4960
2024/03/05 13:29:35 - INFO - root -   train_accuracy = 0.8275
2024/03/05 13:30:11 - INFO - root -   Epoch: [118/300][0/200], lr: 0.00000039 	 loss = 2.0163(2.0163)
2024/03/05 13:30:47 - INFO - root -   Epoch: [118/300][20/200], lr: 0.00000039 	 loss = 0.3325(0.5665)
2024/03/05 13:31:30 - INFO - root -   Epoch: [118/300][40/200], lr: 0.00000039 	 loss = 0.4198(0.5082)
2024/03/05 13:32:06 - INFO - root -   Epoch: [118/300][60/200], lr: 0.00000039 	 loss = 0.0480(0.4995)
2024/03/05 13:32:53 - INFO - root -   Epoch: [118/300][80/200], lr: 0.00000039 	 loss = 2.2209(0.5438)
2024/03/05 13:33:29 - INFO - root -   Epoch: [118/300][100/200], lr: 0.00000039 	 loss = 0.0911(0.5009)
2024/03/05 13:34:10 - INFO - root -   Epoch: [118/300][120/200], lr: 0.00000039 	 loss = 3.2527(0.4870)
2024/03/05 13:34:59 - INFO - root -   Epoch: [118/300][140/200], lr: 0.00000039 	 loss = 2.2283(0.4937)
2024/03/05 13:35:44 - INFO - root -   Epoch: [118/300][160/200], lr: 0.00000039 	 loss = 0.2230(0.4818)
2024/03/05 13:36:15 - INFO - root -   Epoch: [118/300][180/200], lr: 0.00000039 	 loss = 0.8991(0.4906)
2024/03/05 13:36:24 - INFO - root -   Epoch: [118/300] 	 loss = 0.4924
2024/03/05 13:36:24 - INFO - root -   train_accuracy = 0.8400
2024/03/05 13:36:44 - INFO - root -   Epoch: [119/300][0/200], lr: 0.00000039 	 loss = 1.4560(1.4560)
2024/03/05 13:37:49 - INFO - root -   Epoch: [119/300][20/200], lr: 0.00000039 	 loss = 0.3960(0.6021)
2024/03/05 13:38:28 - INFO - root -   Epoch: [119/300][40/200], lr: 0.00000039 	 loss = 0.2374(0.4738)
2024/03/05 13:39:07 - INFO - root -   Epoch: [119/300][60/200], lr: 0.00000039 	 loss = 0.0816(0.4706)
2024/03/05 13:39:47 - INFO - root -   Epoch: [119/300][80/200], lr: 0.00000039 	 loss = 2.6330(0.5139)
2024/03/05 13:40:43 - INFO - root -   Epoch: [119/300][100/200], lr: 0.00000039 	 loss = 0.0946(0.5115)
2024/03/05 13:41:17 - INFO - root -   Epoch: [119/300][120/200], lr: 0.00000039 	 loss = 2.3265(0.4947)
2024/03/05 13:41:55 - INFO - root -   Epoch: [119/300][140/200], lr: 0.00000039 	 loss = 1.3535(0.4967)
2024/03/05 13:42:48 - INFO - root -   Epoch: [119/300][160/200], lr: 0.00000039 	 loss = 0.2853(0.5002)
2024/03/05 13:43:21 - INFO - root -   Epoch: [119/300][180/200], lr: 0.00000039 	 loss = 0.2327(0.5106)
2024/03/05 13:43:31 - INFO - root -   Epoch: [119/300] 	 loss = 0.5066
2024/03/05 13:43:35 - INFO - root -   precision = 0.7778
2024/03/05 13:43:35 - INFO - root -   eval_loss = 0.8430
2024/03/05 13:43:35 - INFO - root -   eval_acc = 0.7778
2024/03/05 13:43:36 - INFO - root -   train_accuracy = 0.8450
2024/03/05 13:44:11 - INFO - root -   Epoch: [120/300][0/200], lr: 0.00000040 	 loss = 1.5374(1.5374)
2024/03/05 13:44:53 - INFO - root -   Epoch: [120/300][20/200], lr: 0.00000040 	 loss = 0.2608(0.5615)
2024/03/05 13:45:34 - INFO - root -   Epoch: [120/300][40/200], lr: 0.00000040 	 loss = 0.1143(0.4450)
2024/03/05 13:46:09 - INFO - root -   Epoch: [120/300][60/200], lr: 0.00000040 	 loss = 0.0540(0.4709)
2024/03/05 13:47:16 - INFO - root -   Epoch: [120/300][80/200], lr: 0.00000040 	 loss = 2.0846(0.4988)
2024/03/05 13:47:38 - INFO - root -   Epoch: [120/300][100/200], lr: 0.00000040 	 loss = 0.1242(0.4797)
2024/03/05 13:48:19 - INFO - root -   Epoch: [120/300][120/200], lr: 0.00000040 	 loss = 3.0155(0.4816)
2024/03/05 13:48:56 - INFO - root -   Epoch: [120/300][140/200], lr: 0.00000040 	 loss = 1.0340(0.4753)
2024/03/05 13:50:02 - INFO - root -   Epoch: [120/300][160/200], lr: 0.00000040 	 loss = 0.2073(0.4687)
2024/03/05 13:50:22 - INFO - root -   Epoch: [120/300][180/200], lr: 0.00000040 	 loss = 0.2517(0.4781)
2024/03/05 13:50:30 - INFO - root -   Epoch: [120/300] 	 loss = 0.4844
2024/03/05 13:50:30 - INFO - root -   train_accuracy = 0.8400
2024/03/05 13:50:50 - INFO - root -   Epoch: [121/300][0/200], lr: 0.00000040 	 loss = 1.6845(1.6845)
2024/03/05 13:51:51 - INFO - root -   Epoch: [121/300][20/200], lr: 0.00000040 	 loss = 0.2089(0.6236)
2024/03/05 13:52:21 - INFO - root -   Epoch: [121/300][40/200], lr: 0.00000040 	 loss = 0.1449(0.4975)
2024/03/05 13:53:04 - INFO - root -   Epoch: [121/300][60/200], lr: 0.00000040 	 loss = 0.0770(0.4781)
2024/03/05 13:53:40 - INFO - root -   Epoch: [121/300][80/200], lr: 0.00000040 	 loss = 2.6787(0.5090)
2024/03/05 13:54:36 - INFO - root -   Epoch: [121/300][100/200], lr: 0.00000040 	 loss = 0.0336(0.4799)
2024/03/05 13:55:14 - INFO - root -   Epoch: [121/300][120/200], lr: 0.00000040 	 loss = 3.0588(0.4930)
2024/03/05 13:55:49 - INFO - root -   Epoch: [121/300][140/200], lr: 0.00000040 	 loss = 1.8573(0.5025)
2024/03/05 13:56:27 - INFO - root -   Epoch: [121/300][160/200], lr: 0.00000040 	 loss = 0.2238(0.4877)
2024/03/05 13:57:10 - INFO - root -   Epoch: [121/300][180/200], lr: 0.00000040 	 loss = 0.4908(0.4986)
2024/03/05 13:57:18 - INFO - root -   Epoch: [121/300] 	 loss = 0.4860
2024/03/05 13:57:18 - INFO - root -   train_accuracy = 0.8400
2024/03/05 13:57:49 - INFO - root -   Epoch: [122/300][0/200], lr: 0.00000040 	 loss = 1.2522(1.2522)
2024/03/05 13:58:35 - INFO - root -   Epoch: [122/300][20/200], lr: 0.00000040 	 loss = 0.6827(0.5798)
2024/03/05 13:59:11 - INFO - root -   Epoch: [122/300][40/200], lr: 0.00000040 	 loss = 0.3439(0.5122)
2024/03/05 13:59:48 - INFO - root -   Epoch: [122/300][60/200], lr: 0.00000040 	 loss = 0.0819(0.4885)
2024/03/05 14:00:31 - INFO - root -   Epoch: [122/300][80/200], lr: 0.00000040 	 loss = 1.7004(0.5015)
2024/03/05 14:01:19 - INFO - root -   Epoch: [122/300][100/200], lr: 0.00000040 	 loss = 0.0798(0.4597)
2024/03/05 14:01:56 - INFO - root -   Epoch: [122/300][120/200], lr: 0.00000040 	 loss = 3.1906(0.4585)
2024/03/05 14:02:24 - INFO - root -   Epoch: [122/300][140/200], lr: 0.00000040 	 loss = 1.2050(0.4569)
2024/03/05 14:03:02 - INFO - root -   Epoch: [122/300][160/200], lr: 0.00000040 	 loss = 0.1092(0.4466)
2024/03/05 14:03:50 - INFO - root -   Epoch: [122/300][180/200], lr: 0.00000040 	 loss = 0.8309(0.4535)
2024/03/05 14:03:58 - INFO - root -   Epoch: [122/300] 	 loss = 0.4548
2024/03/05 14:03:58 - INFO - root -   train_accuracy = 0.8400
2024/03/05 14:04:17 - INFO - root -   Epoch: [123/300][0/200], lr: 0.00000040 	 loss = 1.2345(1.2345)
2024/03/05 14:05:13 - INFO - root -   Epoch: [123/300][20/200], lr: 0.00000040 	 loss = 0.1304(0.5961)
2024/03/05 14:05:45 - INFO - root -   Epoch: [123/300][40/200], lr: 0.00000040 	 loss = 0.1031(0.4888)
2024/03/05 14:06:32 - INFO - root -   Epoch: [123/300][60/200], lr: 0.00000040 	 loss = 0.2276(0.4819)
2024/03/05 14:06:57 - INFO - root -   Epoch: [123/300][80/200], lr: 0.00000040 	 loss = 1.1057(0.5196)
2024/03/05 14:07:46 - INFO - root -   Epoch: [123/300][100/200], lr: 0.00000040 	 loss = 0.0714(0.4905)
2024/03/05 14:08:19 - INFO - root -   Epoch: [123/300][120/200], lr: 0.00000040 	 loss = 3.4515(0.4981)
2024/03/05 14:09:14 - INFO - root -   Epoch: [123/300][140/200], lr: 0.00000040 	 loss = 1.0506(0.5028)
2024/03/05 14:09:47 - INFO - root -   Epoch: [123/300][160/200], lr: 0.00000040 	 loss = 0.2722(0.5005)
2024/03/05 14:10:24 - INFO - root -   Epoch: [123/300][180/200], lr: 0.00000040 	 loss = 0.3533(0.4984)
2024/03/05 14:10:37 - INFO - root -   Epoch: [123/300] 	 loss = 0.4932
2024/03/05 14:10:37 - INFO - root -   train_accuracy = 0.8350
2024/03/05 14:11:17 - INFO - root -   Epoch: [124/300][0/200], lr: 0.00000041 	 loss = 2.2421(2.2421)
2024/03/05 14:11:52 - INFO - root -   Epoch: [124/300][20/200], lr: 0.00000041 	 loss = 0.5839(0.7068)
2024/03/05 14:12:36 - INFO - root -   Epoch: [124/300][40/200], lr: 0.00000041 	 loss = 0.0967(0.5433)
2024/03/05 14:13:16 - INFO - root -   Epoch: [124/300][60/200], lr: 0.00000041 	 loss = 0.1015(0.5053)
2024/03/05 14:13:50 - INFO - root -   Epoch: [124/300][80/200], lr: 0.00000041 	 loss = 2.1864(0.5317)
2024/03/05 14:14:42 - INFO - root -   Epoch: [124/300][100/200], lr: 0.00000041 	 loss = 0.1000(0.5015)
2024/03/05 14:15:20 - INFO - root -   Epoch: [124/300][120/200], lr: 0.00000041 	 loss = 2.7813(0.4999)
2024/03/05 14:15:58 - INFO - root -   Epoch: [124/300][140/200], lr: 0.00000041 	 loss = 0.8577(0.4942)
2024/03/05 14:16:36 - INFO - root -   Epoch: [124/300][160/200], lr: 0.00000041 	 loss = 0.0887(0.4970)
2024/03/05 14:17:14 - INFO - root -   Epoch: [124/300][180/200], lr: 0.00000041 	 loss = 0.2235(0.5086)
2024/03/05 14:17:21 - INFO - root -   Epoch: [124/300] 	 loss = 0.4950
2024/03/05 14:17:25 - INFO - root -   precision = 0.7556
2024/03/05 14:17:25 - INFO - root -   eval_loss = 0.8994
2024/03/05 14:17:25 - INFO - root -   eval_acc = 0.7556
2024/03/05 14:17:26 - INFO - root -   train_accuracy = 0.8375
2024/03/05 14:17:45 - INFO - root -   Epoch: [125/300][0/200], lr: 0.00000041 	 loss = 1.7010(1.7010)
2024/03/05 14:18:43 - INFO - root -   Epoch: [125/300][20/200], lr: 0.00000041 	 loss = 0.3633(0.6482)
2024/03/05 14:19:29 - INFO - root -   Epoch: [125/300][40/200], lr: 0.00000041 	 loss = 0.5933(0.5627)
2024/03/05 14:20:10 - INFO - root -   Epoch: [125/300][60/200], lr: 0.00000041 	 loss = 0.0391(0.5670)
2024/03/05 14:20:45 - INFO - root -   Epoch: [125/300][80/200], lr: 0.00000041 	 loss = 1.2444(0.5893)
2024/03/05 14:21:25 - INFO - root -   Epoch: [125/300][100/200], lr: 0.00000041 	 loss = 0.1491(0.5460)
2024/03/05 14:22:06 - INFO - root -   Epoch: [125/300][120/200], lr: 0.00000041 	 loss = 1.6345(0.5231)
2024/03/05 14:22:36 - INFO - root -   Epoch: [125/300][140/200], lr: 0.00000041 	 loss = 1.3583(0.5215)
2024/03/05 14:23:44 - INFO - root -   Epoch: [125/300][160/200], lr: 0.00000041 	 loss = 0.1120(0.5158)
2024/03/05 14:24:03 - INFO - root -   Epoch: [125/300][180/200], lr: 0.00000041 	 loss = 0.4040(0.5249)
2024/03/05 14:24:11 - INFO - root -   Epoch: [125/300] 	 loss = 0.5145
2024/03/05 14:24:11 - INFO - root -   train_accuracy = 0.8275
2024/03/05 14:24:31 - INFO - root -   Epoch: [126/300][0/200], lr: 0.00000041 	 loss = 1.8673(1.8673)
2024/03/05 14:25:31 - INFO - root -   Epoch: [126/300][20/200], lr: 0.00000041 	 loss = 0.5932(0.6404)
2024/03/05 14:26:17 - INFO - root -   Epoch: [126/300][40/200], lr: 0.00000041 	 loss = 0.1310(0.5189)
2024/03/05 14:26:39 - INFO - root -   Epoch: [126/300][60/200], lr: 0.00000041 	 loss = 0.0687(0.5341)
2024/03/05 14:27:19 - INFO - root -   Epoch: [126/300][80/200], lr: 0.00000041 	 loss = 1.7768(0.5442)
2024/03/05 14:28:17 - INFO - root -   Epoch: [126/300][100/200], lr: 0.00000041 	 loss = 0.1402(0.5218)
2024/03/05 14:28:55 - INFO - root -   Epoch: [126/300][120/200], lr: 0.00000041 	 loss = 2.6509(0.5067)
2024/03/05 14:29:35 - INFO - root -   Epoch: [126/300][140/200], lr: 0.00000041 	 loss = 1.0446(0.4976)
2024/03/05 14:30:14 - INFO - root -   Epoch: [126/300][160/200], lr: 0.00000041 	 loss = 0.1343(0.5028)
2024/03/05 14:30:58 - INFO - root -   Epoch: [126/300][180/200], lr: 0.00000041 	 loss = 0.7404(0.5104)
2024/03/05 14:31:06 - INFO - root -   Epoch: [126/300] 	 loss = 0.5155
2024/03/05 14:31:06 - INFO - root -   train_accuracy = 0.8350
2024/03/05 14:31:27 - INFO - root -   Epoch: [127/300][0/200], lr: 0.00000041 	 loss = 0.9597(0.9597)
2024/03/05 14:32:27 - INFO - root -   Epoch: [127/300][20/200], lr: 0.00000041 	 loss = 0.3443(0.5078)
2024/03/05 14:33:09 - INFO - root -   Epoch: [127/300][40/200], lr: 0.00000041 	 loss = 0.0884(0.4743)
2024/03/05 14:33:43 - INFO - root -   Epoch: [127/300][60/200], lr: 0.00000041 	 loss = 0.0896(0.4757)
2024/03/05 14:34:18 - INFO - root -   Epoch: [127/300][80/200], lr: 0.00000041 	 loss = 1.6368(0.4806)
2024/03/05 14:34:59 - INFO - root -   Epoch: [127/300][100/200], lr: 0.00000041 	 loss = 0.1835(0.4667)
2024/03/05 14:35:36 - INFO - root -   Epoch: [127/300][120/200], lr: 0.00000041 	 loss = 2.8615(0.4639)
2024/03/05 14:36:18 - INFO - root -   Epoch: [127/300][140/200], lr: 0.00000041 	 loss = 2.1172(0.4798)
2024/03/05 14:36:53 - INFO - root -   Epoch: [127/300][160/200], lr: 0.00000041 	 loss = 0.1322(0.4902)
2024/03/05 14:37:42 - INFO - root -   Epoch: [127/300][180/200], lr: 0.00000041 	 loss = 0.3541(0.4953)
2024/03/05 14:37:51 - INFO - root -   Epoch: [127/300] 	 loss = 0.4974
2024/03/05 14:37:51 - INFO - root -   train_accuracy = 0.8300
2024/03/05 14:38:30 - INFO - root -   Epoch: [128/300][0/200], lr: 0.00000042 	 loss = 1.1833(1.1833)
2024/03/05 14:39:14 - INFO - root -   Epoch: [128/300][20/200], lr: 0.00000042 	 loss = 0.2473(0.5297)
2024/03/05 14:39:47 - INFO - root -   Epoch: [128/300][40/200], lr: 0.00000042 	 loss = 0.5740(0.4847)
2024/03/05 14:40:18 - INFO - root -   Epoch: [128/300][60/200], lr: 0.00000042 	 loss = 0.0412(0.5067)
2024/03/05 14:41:01 - INFO - root -   Epoch: [128/300][80/200], lr: 0.00000042 	 loss = 2.0410(0.5275)
2024/03/05 14:41:36 - INFO - root -   Epoch: [128/300][100/200], lr: 0.00000042 	 loss = 0.0298(0.4932)
2024/03/05 14:42:20 - INFO - root -   Epoch: [128/300][120/200], lr: 0.00000042 	 loss = 2.1969(0.4829)
2024/03/05 14:42:55 - INFO - root -   Epoch: [128/300][140/200], lr: 0.00000042 	 loss = 1.9925(0.4950)
2024/03/05 14:43:36 - INFO - root -   Epoch: [128/300][160/200], lr: 0.00000042 	 loss = 0.1843(0.4848)
2024/03/05 14:44:14 - INFO - root -   Epoch: [128/300][180/200], lr: 0.00000042 	 loss = 0.1174(0.4830)
2024/03/05 14:44:33 - INFO - root -   Epoch: [128/300] 	 loss = 0.4737
2024/03/05 14:44:33 - INFO - root -   train_accuracy = 0.8375
2024/03/05 14:44:55 - INFO - root -   Epoch: [129/300][0/200], lr: 0.00000042 	 loss = 1.6141(1.6141)
2024/03/05 14:45:53 - INFO - root -   Epoch: [129/300][20/200], lr: 0.00000042 	 loss = 0.0551(0.5413)
2024/03/05 14:46:28 - INFO - root -   Epoch: [129/300][40/200], lr: 0.00000042 	 loss = 0.1889(0.5059)
2024/03/05 14:47:06 - INFO - root -   Epoch: [129/300][60/200], lr: 0.00000042 	 loss = 0.0191(0.4907)
2024/03/05 14:47:52 - INFO - root -   Epoch: [129/300][80/200], lr: 0.00000042 	 loss = 1.5149(0.4975)
2024/03/05 14:48:41 - INFO - root -   Epoch: [129/300][100/200], lr: 0.00000042 	 loss = 0.0364(0.4924)
2024/03/05 14:49:30 - INFO - root -   Epoch: [129/300][120/200], lr: 0.00000042 	 loss = 2.8628(0.4809)
2024/03/05 14:50:04 - INFO - root -   Epoch: [129/300][140/200], lr: 0.00000042 	 loss = 1.2879(0.4848)
2024/03/05 14:50:43 - INFO - root -   Epoch: [129/300][160/200], lr: 0.00000042 	 loss = 0.0991(0.4820)
2024/03/05 14:51:19 - INFO - root -   Epoch: [129/300][180/200], lr: 0.00000042 	 loss = 0.2121(0.4843)
2024/03/05 14:51:27 - INFO - root -   Epoch: [129/300] 	 loss = 0.4918
2024/03/05 14:51:30 - INFO - root -   precision = 0.7778
2024/03/05 14:51:30 - INFO - root -   eval_loss = 0.8784
2024/03/05 14:51:30 - INFO - root -   eval_acc = 0.7778
2024/03/05 14:51:31 - INFO - root -   train_accuracy = 0.8400
2024/03/05 14:52:16 - INFO - root -   Epoch: [130/300][0/200], lr: 0.00000042 	 loss = 0.9325(0.9325)
2024/03/05 14:52:44 - INFO - root -   Epoch: [130/300][20/200], lr: 0.00000042 	 loss = 0.0840(0.6689)
2024/03/05 14:53:27 - INFO - root -   Epoch: [130/300][40/200], lr: 0.00000042 	 loss = 0.0993(0.5721)
2024/03/05 14:54:10 - INFO - root -   Epoch: [130/300][60/200], lr: 0.00000042 	 loss = 0.0857(0.5105)
2024/03/05 14:54:50 - INFO - root -   Epoch: [130/300][80/200], lr: 0.00000042 	 loss = 1.7959(0.5264)
2024/03/05 14:55:27 - INFO - root -   Epoch: [130/300][100/200], lr: 0.00000042 	 loss = 0.1069(0.5247)
2024/03/05 14:56:28 - INFO - root -   Epoch: [130/300][120/200], lr: 0.00000042 	 loss = 3.3304(0.5099)
2024/03/05 14:57:02 - INFO - root -   Epoch: [130/300][140/200], lr: 0.00000042 	 loss = 1.8934(0.5078)
2024/03/05 14:57:33 - INFO - root -   Epoch: [130/300][160/200], lr: 0.00000042 	 loss = 0.2267(0.4983)
2024/03/05 14:58:06 - INFO - root -   Epoch: [130/300][180/200], lr: 0.00000042 	 loss = 0.2817(0.4929)
2024/03/05 14:58:18 - INFO - root -   Epoch: [130/300] 	 loss = 0.4864
2024/03/05 14:58:18 - INFO - root -   train_accuracy = 0.8225
2024/03/05 14:58:43 - INFO - root -   Epoch: [131/300][0/200], lr: 0.00000042 	 loss = 0.6628(0.6628)
2024/03/05 14:59:35 - INFO - root -   Epoch: [131/300][20/200], lr: 0.00000042 	 loss = 0.2482(0.5596)
2024/03/05 15:00:12 - INFO - root -   Epoch: [131/300][40/200], lr: 0.00000042 	 loss = 0.3804(0.4495)
2024/03/05 15:00:43 - INFO - root -   Epoch: [131/300][60/200], lr: 0.00000042 	 loss = 0.1830(0.5070)
2024/03/05 15:01:38 - INFO - root -   Epoch: [131/300][80/200], lr: 0.00000042 	 loss = 1.9125(0.5333)
2024/03/05 15:02:19 - INFO - root -   Epoch: [131/300][100/200], lr: 0.00000042 	 loss = 0.0778(0.4970)
2024/03/05 15:02:55 - INFO - root -   Epoch: [131/300][120/200], lr: 0.00000042 	 loss = 3.7921(0.4966)
2024/03/05 15:03:30 - INFO - root -   Epoch: [131/300][140/200], lr: 0.00000042 	 loss = 2.1844(0.5022)
2024/03/05 15:04:23 - INFO - root -   Epoch: [131/300][160/200], lr: 0.00000042 	 loss = 0.1323(0.4896)
2024/03/05 15:04:54 - INFO - root -   Epoch: [131/300][180/200], lr: 0.00000042 	 loss = 0.3393(0.4837)
2024/03/05 15:05:01 - INFO - root -   Epoch: [131/300] 	 loss = 0.4861
2024/03/05 15:05:01 - INFO - root -   train_accuracy = 0.8350
2024/03/05 15:05:42 - INFO - root -   Epoch: [132/300][0/200], lr: 0.00000043 	 loss = 1.9156(1.9156)
2024/03/05 15:06:23 - INFO - root -   Epoch: [132/300][20/200], lr: 0.00000043 	 loss = 0.3347(0.5634)
2024/03/05 15:07:01 - INFO - root -   Epoch: [132/300][40/200], lr: 0.00000043 	 loss = 0.3458(0.4618)
2024/03/05 15:07:27 - INFO - root -   Epoch: [132/300][60/200], lr: 0.00000043 	 loss = 0.0549(0.4793)
2024/03/05 15:08:09 - INFO - root -   Epoch: [132/300][80/200], lr: 0.00000043 	 loss = 1.7729(0.4765)
2024/03/05 15:09:11 - INFO - root -   Epoch: [132/300][100/200], lr: 0.00000043 	 loss = 0.0913(0.4604)
2024/03/05 15:09:42 - INFO - root -   Epoch: [132/300][120/200], lr: 0.00000043 	 loss = 2.1767(0.4657)
2024/03/05 15:10:02 - INFO - root -   Epoch: [132/300][140/200], lr: 0.00000043 	 loss = 1.0566(0.4625)
2024/03/05 15:10:49 - INFO - root -   Epoch: [132/300][160/200], lr: 0.00000043 	 loss = 0.1323(0.4602)
2024/03/05 15:11:30 - INFO - root -   Epoch: [132/300][180/200], lr: 0.00000043 	 loss = 0.1404(0.4705)
2024/03/05 15:11:44 - INFO - root -   Epoch: [132/300] 	 loss = 0.4636
2024/03/05 15:11:44 - INFO - root -   train_accuracy = 0.8350
2024/03/05 15:12:18 - INFO - root -   Epoch: [133/300][0/200], lr: 0.00000043 	 loss = 1.5621(1.5621)
2024/03/05 15:13:02 - INFO - root -   Epoch: [133/300][20/200], lr: 0.00000043 	 loss = 0.1819(0.6355)
2024/03/05 15:13:36 - INFO - root -   Epoch: [133/300][40/200], lr: 0.00000043 	 loss = 0.1026(0.5103)
2024/03/05 15:14:13 - INFO - root -   Epoch: [133/300][60/200], lr: 0.00000043 	 loss = 0.0739(0.4902)
2024/03/05 15:15:04 - INFO - root -   Epoch: [133/300][80/200], lr: 0.00000043 	 loss = 2.3656(0.5391)
2024/03/05 15:15:52 - INFO - root -   Epoch: [133/300][100/200], lr: 0.00000043 	 loss = 0.0866(0.5050)
2024/03/05 15:16:19 - INFO - root -   Epoch: [133/300][120/200], lr: 0.00000043 	 loss = 2.2752(0.5035)
2024/03/05 15:16:56 - INFO - root -   Epoch: [133/300][140/200], lr: 0.00000043 	 loss = 1.4579(0.5024)
2024/03/05 15:17:30 - INFO - root -   Epoch: [133/300][160/200], lr: 0.00000043 	 loss = 0.1652(0.4923)
2024/03/05 15:18:29 - INFO - root -   Epoch: [133/300][180/200], lr: 0.00000043 	 loss = 0.3705(0.4974)
2024/03/05 15:18:38 - INFO - root -   Epoch: [133/300] 	 loss = 0.4921
2024/03/05 15:18:38 - INFO - root -   train_accuracy = 0.8400
2024/03/05 15:18:58 - INFO - root -   Epoch: [134/300][0/200], lr: 0.00000043 	 loss = 1.3348(1.3348)
2024/03/05 15:19:54 - INFO - root -   Epoch: [134/300][20/200], lr: 0.00000043 	 loss = 0.3194(0.5769)
2024/03/05 15:20:35 - INFO - root -   Epoch: [134/300][40/200], lr: 0.00000043 	 loss = 0.2279(0.4768)
2024/03/05 15:21:10 - INFO - root -   Epoch: [134/300][60/200], lr: 0.00000043 	 loss = 0.0426(0.4610)
2024/03/05 15:21:49 - INFO - root -   Epoch: [134/300][80/200], lr: 0.00000043 	 loss = 1.8772(0.4955)
2024/03/05 15:22:50 - INFO - root -   Epoch: [134/300][100/200], lr: 0.00000043 	 loss = 0.0431(0.4817)
2024/03/05 15:23:25 - INFO - root -   Epoch: [134/300][120/200], lr: 0.00000043 	 loss = 3.5461(0.4773)
2024/03/05 15:23:59 - INFO - root -   Epoch: [134/300][140/200], lr: 0.00000043 	 loss = 2.1510(0.4897)
2024/03/05 15:24:36 - INFO - root -   Epoch: [134/300][160/200], lr: 0.00000043 	 loss = 0.1046(0.4857)
2024/03/05 15:25:22 - INFO - root -   Epoch: [134/300][180/200], lr: 0.00000043 	 loss = 0.8199(0.4908)
2024/03/05 15:25:30 - INFO - root -   Epoch: [134/300] 	 loss = 0.4835
2024/03/05 15:25:33 - INFO - root -   precision = 0.7111
2024/03/05 15:25:33 - INFO - root -   eval_loss = 0.9423
2024/03/05 15:25:33 - INFO - root -   eval_acc = 0.7111
2024/03/05 15:25:34 - INFO - root -   train_accuracy = 0.8375
2024/03/05 15:26:14 - INFO - root -   Epoch: [135/300][0/200], lr: 0.00000043 	 loss = 0.9338(0.9338)
2024/03/05 15:27:04 - INFO - root -   Epoch: [135/300][20/200], lr: 0.00000043 	 loss = 0.1145(0.4618)
2024/03/05 15:27:29 - INFO - root -   Epoch: [135/300][40/200], lr: 0.00000043 	 loss = 0.2486(0.4148)
2024/03/05 15:28:07 - INFO - root -   Epoch: [135/300][60/200], lr: 0.00000043 	 loss = 0.0809(0.4013)
2024/03/05 15:29:03 - INFO - root -   Epoch: [135/300][80/200], lr: 0.00000043 	 loss = 1.7271(0.4381)
2024/03/05 15:29:35 - INFO - root -   Epoch: [135/300][100/200], lr: 0.00000043 	 loss = 0.0451(0.4409)
2024/03/05 15:30:12 - INFO - root -   Epoch: [135/300][120/200], lr: 0.00000043 	 loss = 1.6191(0.4230)
2024/03/05 15:30:57 - INFO - root -   Epoch: [135/300][140/200], lr: 0.00000043 	 loss = 1.5892(0.4337)
2024/03/05 15:31:36 - INFO - root -   Epoch: [135/300][160/200], lr: 0.00000043 	 loss = 0.1771(0.4360)
2024/03/05 15:32:18 - INFO - root -   Epoch: [135/300][180/200], lr: 0.00000043 	 loss = 0.1297(0.4511)
2024/03/05 15:32:25 - INFO - root -   Epoch: [135/300] 	 loss = 0.4564
2024/03/05 15:32:25 - INFO - root -   train_accuracy = 0.8525
2024/03/05 15:32:44 - INFO - root -   Epoch: [136/300][0/200], lr: 0.00000044 	 loss = 1.1018(1.1018)
2024/03/05 15:33:38 - INFO - root -   Epoch: [136/300][20/200], lr: 0.00000044 	 loss = 0.3787(0.5493)
2024/03/05 15:34:15 - INFO - root -   Epoch: [136/300][40/200], lr: 0.00000044 	 loss = 0.1114(0.4231)
2024/03/05 15:34:52 - INFO - root -   Epoch: [136/300][60/200], lr: 0.00000044 	 loss = 0.0253(0.4428)
2024/03/05 15:35:28 - INFO - root -   Epoch: [136/300][80/200], lr: 0.00000044 	 loss = 1.6900(0.4622)
2024/03/05 15:36:19 - INFO - root -   Epoch: [136/300][100/200], lr: 0.00000044 	 loss = 0.1271(0.4298)
2024/03/05 15:36:58 - INFO - root -   Epoch: [136/300][120/200], lr: 0.00000044 	 loss = 3.4227(0.4334)
2024/03/05 15:37:37 - INFO - root -   Epoch: [136/300][140/200], lr: 0.00000044 	 loss = 1.5117(0.4470)
2024/03/05 15:38:35 - INFO - root -   Epoch: [136/300][160/200], lr: 0.00000044 	 loss = 0.4832(0.4529)
2024/03/05 15:39:08 - INFO - root -   Epoch: [136/300][180/200], lr: 0.00000044 	 loss = 0.0803(0.4694)
2024/03/05 15:39:18 - INFO - root -   Epoch: [136/300] 	 loss = 0.4665
2024/03/05 15:39:18 - INFO - root -   train_accuracy = 0.8500
2024/03/05 15:39:41 - INFO - root -   Epoch: [137/300][0/200], lr: 0.00000044 	 loss = 1.0782(1.0782)
2024/03/05 15:40:41 - INFO - root -   Epoch: [137/300][20/200], lr: 0.00000044 	 loss = 1.3786(0.5532)
2024/03/05 15:41:22 - INFO - root -   Epoch: [137/300][40/200], lr: 0.00000044 	 loss = 0.1241(0.4832)
2024/03/05 15:42:00 - INFO - root -   Epoch: [137/300][60/200], lr: 0.00000044 	 loss = 0.0315(0.4553)
2024/03/05 15:42:33 - INFO - root -   Epoch: [137/300][80/200], lr: 0.00000044 	 loss = 2.6439(0.5171)
2024/03/05 15:43:39 - INFO - root -   Epoch: [137/300][100/200], lr: 0.00000044 	 loss = 0.0691(0.4824)
2024/03/05 15:44:03 - INFO - root -   Epoch: [137/300][120/200], lr: 0.00000044 	 loss = 2.2628(0.4693)
2024/03/05 15:44:39 - INFO - root -   Epoch: [137/300][140/200], lr: 0.00000044 	 loss = 1.9381(0.4776)
2024/03/05 15:45:15 - INFO - root -   Epoch: [137/300][160/200], lr: 0.00000044 	 loss = 0.1971(0.4837)
2024/03/05 15:46:05 - INFO - root -   Epoch: [137/300][180/200], lr: 0.00000044 	 loss = 0.2348(0.4868)
2024/03/05 15:46:13 - INFO - root -   Epoch: [137/300] 	 loss = 0.4863
2024/03/05 15:46:13 - INFO - root -   train_accuracy = 0.8450
2024/03/05 15:46:49 - INFO - root -   Epoch: [138/300][0/200], lr: 0.00000044 	 loss = 0.7783(0.7783)
2024/03/05 15:47:30 - INFO - root -   Epoch: [138/300][20/200], lr: 0.00000044 	 loss = 0.0791(0.5934)
2024/03/05 15:48:11 - INFO - root -   Epoch: [138/300][40/200], lr: 0.00000044 	 loss = 0.3401(0.4565)
2024/03/05 15:48:49 - INFO - root -   Epoch: [138/300][60/200], lr: 0.00000044 	 loss = 0.0396(0.4418)
2024/03/05 15:49:51 - INFO - root -   Epoch: [138/300][80/200], lr: 0.00000044 	 loss = 2.0844(0.4695)
2024/03/05 15:50:18 - INFO - root -   Epoch: [138/300][100/200], lr: 0.00000044 	 loss = 0.0574(0.4312)
2024/03/05 15:50:52 - INFO - root -   Epoch: [138/300][120/200], lr: 0.00000044 	 loss = 2.1355(0.4223)
2024/03/05 15:51:33 - INFO - root -   Epoch: [138/300][140/200], lr: 0.00000044 	 loss = 1.5211(0.4310)
2024/03/05 15:52:14 - INFO - root -   Epoch: [138/300][160/200], lr: 0.00000044 	 loss = 0.3562(0.4356)
2024/03/05 15:52:45 - INFO - root -   Epoch: [138/300][180/200], lr: 0.00000044 	 loss = 0.2119(0.4390)
2024/03/05 15:52:52 - INFO - root -   Epoch: [138/300] 	 loss = 0.4346
2024/03/05 15:52:52 - INFO - root -   train_accuracy = 0.8500
2024/03/05 15:53:24 - INFO - root -   Epoch: [139/300][0/200], lr: 0.00000044 	 loss = 2.0620(2.0620)
2024/03/05 15:54:18 - INFO - root -   Epoch: [139/300][20/200], lr: 0.00000044 	 loss = 0.1205(0.6502)
2024/03/05 15:54:54 - INFO - root -   Epoch: [139/300][40/200], lr: 0.00000044 	 loss = 0.1307(0.5384)
2024/03/05 15:55:29 - INFO - root -   Epoch: [139/300][60/200], lr: 0.00000044 	 loss = 0.0087(0.4935)
2024/03/05 15:55:58 - INFO - root -   Epoch: [139/300][80/200], lr: 0.00000044 	 loss = 1.4652(0.5197)
2024/03/05 15:56:57 - INFO - root -   Epoch: [139/300][100/200], lr: 0.00000044 	 loss = 0.1366(0.5071)
2024/03/05 15:57:27 - INFO - root -   Epoch: [139/300][120/200], lr: 0.00000044 	 loss = 3.6260(0.4913)
2024/03/05 15:58:09 - INFO - root -   Epoch: [139/300][140/200], lr: 0.00000044 	 loss = 1.7557(0.4873)
2024/03/05 15:58:41 - INFO - root -   Epoch: [139/300][160/200], lr: 0.00000044 	 loss = 0.1437(0.4846)
2024/03/05 15:59:18 - INFO - root -   Epoch: [139/300][180/200], lr: 0.00000044 	 loss = 0.3483(0.4860)
2024/03/05 15:59:30 - INFO - root -   Epoch: [139/300] 	 loss = 0.4828
2024/03/05 15:59:33 - INFO - root -   precision = 0.7333
2024/03/05 15:59:33 - INFO - root -   eval_loss = 0.9746
2024/03/05 15:59:33 - INFO - root -   eval_acc = 0.7333
2024/03/05 15:59:34 - INFO - root -   train_accuracy = 0.8500
2024/03/05 16:00:10 - INFO - root -   Epoch: [140/300][0/200], lr: 0.00000045 	 loss = 1.6661(1.6661)
2024/03/05 16:00:51 - INFO - root -   Epoch: [140/300][20/200], lr: 0.00000045 	 loss = 0.8268(0.4972)
2024/03/05 16:01:28 - INFO - root -   Epoch: [140/300][40/200], lr: 0.00000045 	 loss = 0.1066(0.4487)
2024/03/05 16:02:12 - INFO - root -   Epoch: [140/300][60/200], lr: 0.00000045 	 loss = 0.0650(0.4458)
2024/03/05 16:02:52 - INFO - root -   Epoch: [140/300][80/200], lr: 0.00000045 	 loss = 2.0934(0.4747)
2024/03/05 16:03:57 - INFO - root -   Epoch: [140/300][100/200], lr: 0.00000045 	 loss = 0.1000(0.4671)
2024/03/05 16:04:28 - INFO - root -   Epoch: [140/300][120/200], lr: 0.00000045 	 loss = 1.6785(0.4679)
2024/03/05 16:04:56 - INFO - root -   Epoch: [140/300][140/200], lr: 0.00000045 	 loss = 1.4637(0.4809)
2024/03/05 16:05:34 - INFO - root -   Epoch: [140/300][160/200], lr: 0.00000045 	 loss = 0.1165(0.4834)
2024/03/05 16:06:16 - INFO - root -   Epoch: [140/300][180/200], lr: 0.00000045 	 loss = 0.2907(0.4894)
2024/03/05 16:06:27 - INFO - root -   Epoch: [140/300] 	 loss = 0.4868
2024/03/05 16:06:27 - INFO - root -   train_accuracy = 0.8400
2024/03/05 16:07:00 - INFO - root -   Epoch: [141/300][0/200], lr: 0.00000045 	 loss = 1.2704(1.2704)
2024/03/05 16:07:47 - INFO - root -   Epoch: [141/300][20/200], lr: 0.00000045 	 loss = 0.1630(0.5152)
2024/03/05 16:08:20 - INFO - root -   Epoch: [141/300][40/200], lr: 0.00000045 	 loss = 0.3331(0.4720)
2024/03/05 16:08:56 - INFO - root -   Epoch: [141/300][60/200], lr: 0.00000045 	 loss = 0.0472(0.4711)
2024/03/05 16:09:54 - INFO - root -   Epoch: [141/300][80/200], lr: 0.00000045 	 loss = 2.0252(0.5100)
2024/03/05 16:10:31 - INFO - root -   Epoch: [141/300][100/200], lr: 0.00000045 	 loss = 0.0333(0.4754)
2024/03/05 16:11:07 - INFO - root -   Epoch: [141/300][120/200], lr: 0.00000045 	 loss = 2.5746(0.4708)
2024/03/05 16:11:30 - INFO - root -   Epoch: [141/300][140/200], lr: 0.00000045 	 loss = 1.3466(0.4745)
2024/03/05 16:12:35 - INFO - root -   Epoch: [141/300][160/200], lr: 0.00000045 	 loss = 0.1220(0.4657)
2024/03/05 16:13:04 - INFO - root -   Epoch: [141/300][180/200], lr: 0.00000045 	 loss = 0.4709(0.4792)
2024/03/05 16:13:15 - INFO - root -   Epoch: [141/300] 	 loss = 0.4776
2024/03/05 16:13:15 - INFO - root -   train_accuracy = 0.8500
2024/03/05 16:13:54 - INFO - root -   Epoch: [142/300][0/200], lr: 0.00000045 	 loss = 2.5250(2.5250)
2024/03/05 16:14:40 - INFO - root -   Epoch: [142/300][20/200], lr: 0.00000045 	 loss = 0.2851(0.8293)
2024/03/05 16:15:10 - INFO - root -   Epoch: [142/300][40/200], lr: 0.00000045 	 loss = 0.0724(0.6431)
2024/03/05 16:15:49 - INFO - root -   Epoch: [142/300][60/200], lr: 0.00000045 	 loss = 0.0529(0.5527)
2024/03/05 16:16:27 - INFO - root -   Epoch: [142/300][80/200], lr: 0.00000045 	 loss = 2.0762(0.5459)
2024/03/05 16:17:21 - INFO - root -   Epoch: [142/300][100/200], lr: 0.00000045 	 loss = 0.1221(0.5093)
2024/03/05 16:17:54 - INFO - root -   Epoch: [142/300][120/200], lr: 0.00000045 	 loss = 2.0762(0.4961)
2024/03/05 16:18:30 - INFO - root -   Epoch: [142/300][140/200], lr: 0.00000045 	 loss = 1.4621(0.4851)
2024/03/05 16:19:29 - INFO - root -   Epoch: [142/300][160/200], lr: 0.00000045 	 loss = 0.1052(0.4845)
2024/03/05 16:20:00 - INFO - root -   Epoch: [142/300][180/200], lr: 0.00000045 	 loss = 0.7637(0.4911)
2024/03/05 16:20:16 - INFO - root -   Epoch: [142/300] 	 loss = 0.4854
2024/03/05 16:20:16 - INFO - root -   train_accuracy = 0.8425
2024/03/05 16:20:57 - INFO - root -   Epoch: [143/300][0/200], lr: 0.00000045 	 loss = 0.7951(0.7951)
2024/03/05 16:21:39 - INFO - root -   Epoch: [143/300][20/200], lr: 0.00000045 	 loss = 0.5434(0.6420)
2024/03/05 16:22:09 - INFO - root -   Epoch: [143/300][40/200], lr: 0.00000045 	 loss = 0.3177(0.6038)
2024/03/05 16:22:48 - INFO - root -   Epoch: [143/300][60/200], lr: 0.00000045 	 loss = 0.0947(0.5428)
2024/03/05 16:23:37 - INFO - root -   Epoch: [143/300][80/200], lr: 0.00000045 	 loss = 2.5428(0.5754)
2024/03/05 16:24:10 - INFO - root -   Epoch: [143/300][100/200], lr: 0.00000045 	 loss = 0.0587(0.5322)
2024/03/05 16:24:56 - INFO - root -   Epoch: [143/300][120/200], lr: 0.00000045 	 loss = 3.2619(0.5131)
2024/03/05 16:25:25 - INFO - root -   Epoch: [143/300][140/200], lr: 0.00000045 	 loss = 1.0633(0.5006)
2024/03/05 16:26:04 - INFO - root -   Epoch: [143/300][160/200], lr: 0.00000045 	 loss = 0.1374(0.5099)
2024/03/05 16:26:50 - INFO - root -   Epoch: [143/300][180/200], lr: 0.00000045 	 loss = 0.2462(0.5028)
2024/03/05 16:27:00 - INFO - root -   Epoch: [143/300] 	 loss = 0.5029
2024/03/05 16:27:00 - INFO - root -   train_accuracy = 0.8350
2024/03/05 16:27:33 - INFO - root -   Epoch: [144/300][0/200], lr: 0.00000046 	 loss = 1.6673(1.6673)
2024/03/05 16:28:13 - INFO - root -   Epoch: [144/300][20/200], lr: 0.00000046 	 loss = 0.1266(0.4748)
2024/03/05 16:28:49 - INFO - root -   Epoch: [144/300][40/200], lr: 0.00000046 	 loss = 0.2168(0.4247)
2024/03/05 16:29:29 - INFO - root -   Epoch: [144/300][60/200], lr: 0.00000046 	 loss = 0.1373(0.4340)
2024/03/05 16:30:12 - INFO - root -   Epoch: [144/300][80/200], lr: 0.00000046 	 loss = 1.7421(0.4389)
2024/03/05 16:31:00 - INFO - root -   Epoch: [144/300][100/200], lr: 0.00000046 	 loss = 0.0640(0.4252)
2024/03/05 16:31:44 - INFO - root -   Epoch: [144/300][120/200], lr: 0.00000046 	 loss = 2.9564(0.4312)
2024/03/05 16:32:18 - INFO - root -   Epoch: [144/300][140/200], lr: 0.00000046 	 loss = 2.0351(0.4418)
2024/03/05 16:32:50 - INFO - root -   Epoch: [144/300][160/200], lr: 0.00000046 	 loss = 0.0644(0.4485)
2024/03/05 16:33:37 - INFO - root -   Epoch: [144/300][180/200], lr: 0.00000046 	 loss = 0.2864(0.4527)
2024/03/05 16:33:44 - INFO - root -   Epoch: [144/300] 	 loss = 0.4622
2024/03/05 16:33:48 - INFO - root -   precision = 0.7556
2024/03/05 16:33:48 - INFO - root -   eval_loss = 0.9474
2024/03/05 16:33:48 - INFO - root -   eval_acc = 0.7556
2024/03/05 16:33:49 - INFO - root -   train_accuracy = 0.8375
2024/03/05 16:34:28 - INFO - root -   Epoch: [145/300][0/200], lr: 0.00000046 	 loss = 1.1595(1.1595)
2024/03/05 16:35:09 - INFO - root -   Epoch: [145/300][20/200], lr: 0.00000046 	 loss = 0.8052(0.5347)
2024/03/05 16:35:37 - INFO - root -   Epoch: [145/300][40/200], lr: 0.00000046 	 loss = 0.0445(0.4266)
2024/03/05 16:36:09 - INFO - root -   Epoch: [145/300][60/200], lr: 0.00000046 	 loss = 0.0661(0.4566)
2024/03/05 16:37:14 - INFO - root -   Epoch: [145/300][80/200], lr: 0.00000046 	 loss = 1.5022(0.4639)
2024/03/05 16:37:49 - INFO - root -   Epoch: [145/300][100/200], lr: 0.00000046 	 loss = 0.1210(0.4478)
2024/03/05 16:38:27 - INFO - root -   Epoch: [145/300][120/200], lr: 0.00000046 	 loss = 3.2043(0.4524)
2024/03/05 16:39:07 - INFO - root -   Epoch: [145/300][140/200], lr: 0.00000046 	 loss = 1.3109(0.4599)
2024/03/05 16:39:47 - INFO - root -   Epoch: [145/300][160/200], lr: 0.00000046 	 loss = 0.1474(0.4690)
2024/03/05 16:40:24 - INFO - root -   Epoch: [145/300][180/200], lr: 0.00000046 	 loss = 0.6576(0.4695)
2024/03/05 16:40:40 - INFO - root -   Epoch: [145/300] 	 loss = 0.4681
2024/03/05 16:40:40 - INFO - root -   train_accuracy = 0.8425
2024/03/05 16:40:59 - INFO - root -   Epoch: [146/300][0/200], lr: 0.00000046 	 loss = 1.0906(1.0906)
2024/03/05 16:41:55 - INFO - root -   Epoch: [146/300][20/200], lr: 0.00000046 	 loss = 0.1089(0.5564)
2024/03/05 16:42:41 - INFO - root -   Epoch: [146/300][40/200], lr: 0.00000046 	 loss = 0.3307(0.4685)
2024/03/05 16:43:10 - INFO - root -   Epoch: [146/300][60/200], lr: 0.00000046 	 loss = 0.0818(0.4464)
2024/03/05 16:43:48 - INFO - root -   Epoch: [146/300][80/200], lr: 0.00000046 	 loss = 2.3411(0.5054)
2024/03/05 16:44:40 - INFO - root -   Epoch: [146/300][100/200], lr: 0.00000046 	 loss = 0.1375(0.4668)
2024/03/05 16:45:30 - INFO - root -   Epoch: [146/300][120/200], lr: 0.00000046 	 loss = 2.3717(0.4617)
2024/03/05 16:45:57 - INFO - root -   Epoch: [146/300][140/200], lr: 0.00000046 	 loss = 0.8990(0.4551)
2024/03/05 16:46:31 - INFO - root -   Epoch: [146/300][160/200], lr: 0.00000046 	 loss = 0.1312(0.4540)
2024/03/05 16:47:25 - INFO - root -   Epoch: [146/300][180/200], lr: 0.00000046 	 loss = 0.2497(0.4530)
2024/03/05 16:47:33 - INFO - root -   Epoch: [146/300] 	 loss = 0.4554
2024/03/05 16:47:33 - INFO - root -   train_accuracy = 0.8475
2024/03/05 16:48:05 - INFO - root -   Epoch: [147/300][0/200], lr: 0.00000046 	 loss = 2.0715(2.0715)
2024/03/05 16:48:49 - INFO - root -   Epoch: [147/300][20/200], lr: 0.00000046 	 loss = 0.3685(0.5670)
2024/03/05 16:49:29 - INFO - root -   Epoch: [147/300][40/200], lr: 0.00000046 	 loss = 0.0846(0.4559)
2024/03/05 16:50:13 - INFO - root -   Epoch: [147/300][60/200], lr: 0.00000046 	 loss = 0.1066(0.4414)
2024/03/05 16:50:50 - INFO - root -   Epoch: [147/300][80/200], lr: 0.00000046 	 loss = 1.8751(0.4894)
2024/03/05 16:51:33 - INFO - root -   Epoch: [147/300][100/200], lr: 0.00000046 	 loss = 0.1024(0.4604)
2024/03/05 16:52:21 - INFO - root -   Epoch: [147/300][120/200], lr: 0.00000046 	 loss = 3.3009(0.4709)
2024/03/05 16:52:57 - INFO - root -   Epoch: [147/300][140/200], lr: 0.00000046 	 loss = 1.4569(0.4724)
2024/03/05 16:53:34 - INFO - root -   Epoch: [147/300][160/200], lr: 0.00000046 	 loss = 0.0309(0.4774)
2024/03/05 16:54:14 - INFO - root -   Epoch: [147/300][180/200], lr: 0.00000046 	 loss = 0.4135(0.4834)
2024/03/05 16:54:22 - INFO - root -   Epoch: [147/300] 	 loss = 0.4822
2024/03/05 16:54:22 - INFO - root -   train_accuracy = 0.8425
2024/03/05 16:55:00 - INFO - root -   Epoch: [148/300][0/200], lr: 0.00000047 	 loss = 1.8370(1.8370)
2024/03/05 16:55:41 - INFO - root -   Epoch: [148/300][20/200], lr: 0.00000047 	 loss = 0.5814(0.5225)
2024/03/05 16:56:24 - INFO - root -   Epoch: [148/300][40/200], lr: 0.00000047 	 loss = 0.3994(0.4502)
2024/03/05 16:57:02 - INFO - root -   Epoch: [148/300][60/200], lr: 0.00000047 	 loss = 0.0563(0.4734)
2024/03/05 16:57:33 - INFO - root -   Epoch: [148/300][80/200], lr: 0.00000047 	 loss = 2.1785(0.5098)
2024/03/05 16:58:22 - INFO - root -   Epoch: [148/300][100/200], lr: 0.00000047 	 loss = 0.2162(0.4826)
2024/03/05 16:59:11 - INFO - root -   Epoch: [148/300][120/200], lr: 0.00000047 	 loss = 2.7224(0.4791)
2024/03/05 16:59:47 - INFO - root -   Epoch: [148/300][140/200], lr: 0.00000047 	 loss = 1.2427(0.4727)
2024/03/05 17:00:20 - INFO - root -   Epoch: [148/300][160/200], lr: 0.00000047 	 loss = 0.1839(0.4778)
2024/03/05 17:00:52 - INFO - root -   Epoch: [148/300][180/200], lr: 0.00000047 	 loss = 0.0902(0.4863)
2024/03/05 17:01:11 - INFO - root -   Epoch: [148/300] 	 loss = 0.4886
2024/03/05 17:01:11 - INFO - root -   train_accuracy = 0.8375
2024/03/05 17:01:47 - INFO - root -   Epoch: [149/300][0/200], lr: 0.00000047 	 loss = 1.5595(1.5595)
2024/03/05 17:02:34 - INFO - root -   Epoch: [149/300][20/200], lr: 0.00000047 	 loss = 0.1171(0.5434)
2024/03/05 17:03:10 - INFO - root -   Epoch: [149/300][40/200], lr: 0.00000047 	 loss = 0.4265(0.4802)
2024/03/05 17:03:46 - INFO - root -   Epoch: [149/300][60/200], lr: 0.00000047 	 loss = 0.0685(0.4629)
2024/03/05 17:04:41 - INFO - root -   Epoch: [149/300][80/200], lr: 0.00000047 	 loss = 1.9822(0.4917)
2024/03/05 17:05:17 - INFO - root -   Epoch: [149/300][100/200], lr: 0.00000047 	 loss = 0.0215(0.4925)
2024/03/05 17:05:57 - INFO - root -   Epoch: [149/300][120/200], lr: 0.00000047 	 loss = 1.9901(0.4778)
2024/03/05 17:06:41 - INFO - root -   Epoch: [149/300][140/200], lr: 0.00000047 	 loss = 1.6022(0.4837)
2024/03/05 17:07:17 - INFO - root -   Epoch: [149/300][160/200], lr: 0.00000047 	 loss = 0.0476(0.4825)
2024/03/05 17:07:54 - INFO - root -   Epoch: [149/300][180/200], lr: 0.00000047 	 loss = 0.1441(0.4812)
2024/03/05 17:08:12 - INFO - root -   Epoch: [149/300] 	 loss = 0.4696
2024/03/05 17:08:16 - INFO - root -   precision = 0.7333
2024/03/05 17:08:16 - INFO - root -   eval_loss = 1.0011
2024/03/05 17:08:16 - INFO - root -   eval_acc = 0.7333
2024/03/05 17:08:17 - INFO - root -   train_accuracy = 0.8400
2024/03/05 17:08:54 - INFO - root -   Epoch: [150/300][0/200], lr: 0.00000047 	 loss = 1.3628(1.3628)
2024/03/05 17:09:38 - INFO - root -   Epoch: [150/300][20/200], lr: 0.00000047 	 loss = 0.1572(0.6153)
2024/03/05 17:09:57 - INFO - root -   Epoch: [150/300][40/200], lr: 0.00000047 	 loss = 0.1244(0.4737)
2024/03/05 17:10:53 - INFO - root -   Epoch: [150/300][60/200], lr: 0.00000047 	 loss = 0.2475(0.4520)
2024/03/05 17:11:34 - INFO - root -   Epoch: [150/300][80/200], lr: 0.00000047 	 loss = 2.5078(0.4891)
2024/03/05 17:12:11 - INFO - root -   Epoch: [150/300][100/200], lr: 0.00000047 	 loss = 0.0572(0.4576)
2024/03/05 17:12:54 - INFO - root -   Epoch: [150/300][120/200], lr: 0.00000047 	 loss = 2.1848(0.4529)
2024/03/05 17:13:43 - INFO - root -   Epoch: [150/300][140/200], lr: 0.00000047 	 loss = 1.3359(0.4481)
2024/03/05 17:14:35 - INFO - root -   Epoch: [150/300][160/200], lr: 0.00000047 	 loss = 0.1583(0.4526)
2024/03/05 17:15:03 - INFO - root -   Epoch: [150/300][180/200], lr: 0.00000047 	 loss = 0.1339(0.4644)
2024/03/05 17:15:16 - INFO - root -   Epoch: [150/300] 	 loss = 0.4723
2024/03/05 17:15:16 - INFO - root -   train_accuracy = 0.8500
2024/03/05 17:15:34 - INFO - root -   Epoch: [151/300][0/200], lr: 0.00000047 	 loss = 1.2005(1.2005)
2024/03/05 17:16:36 - INFO - root -   Epoch: [151/300][20/200], lr: 0.00000047 	 loss = 0.1083(0.5995)
2024/03/05 17:17:13 - INFO - root -   Epoch: [151/300][40/200], lr: 0.00000047 	 loss = 0.1046(0.5039)
2024/03/05 17:17:49 - INFO - root -   Epoch: [151/300][60/200], lr: 0.00000047 	 loss = 0.0698(0.5155)
2024/03/05 17:18:21 - INFO - root -   Epoch: [151/300][80/200], lr: 0.00000047 	 loss = 1.4262(0.5004)
2024/03/05 17:19:07 - INFO - root -   Epoch: [151/300][100/200], lr: 0.00000047 	 loss = 0.2125(0.4742)
2024/03/05 17:19:53 - INFO - root -   Epoch: [151/300][120/200], lr: 0.00000047 	 loss = 3.2562(0.4741)
2024/03/05 17:20:26 - INFO - root -   Epoch: [151/300][140/200], lr: 0.00000047 	 loss = 1.3423(0.4754)
2024/03/05 17:21:04 - INFO - root -   Epoch: [151/300][160/200], lr: 0.00000047 	 loss = 0.1101(0.4730)
2024/03/05 17:21:49 - INFO - root -   Epoch: [151/300][180/200], lr: 0.00000047 	 loss = 0.1800(0.4795)
2024/03/05 17:22:05 - INFO - root -   Epoch: [151/300] 	 loss = 0.4731
2024/03/05 17:22:05 - INFO - root -   train_accuracy = 0.8425
2024/03/05 17:22:26 - INFO - root -   Epoch: [152/300][0/200], lr: 0.00000048 	 loss = 1.3243(1.3243)
2024/03/05 17:23:11 - INFO - root -   Epoch: [152/300][20/200], lr: 0.00000048 	 loss = 0.2521(0.6248)
2024/03/05 17:23:48 - INFO - root -   Epoch: [152/300][40/200], lr: 0.00000048 	 loss = 0.1110(0.5182)
2024/03/05 17:24:34 - INFO - root -   Epoch: [152/300][60/200], lr: 0.00000048 	 loss = 0.0889(0.4838)
2024/03/05 17:25:18 - INFO - root -   Epoch: [152/300][80/200], lr: 0.00000048 	 loss = 2.2844(0.5104)
2024/03/05 17:25:54 - INFO - root -   Epoch: [152/300][100/200], lr: 0.00000048 	 loss = 0.1243(0.4932)
2024/03/05 17:26:20 - INFO - root -   Epoch: [152/300][120/200], lr: 0.00000048 	 loss = 2.9903(0.4770)
2024/03/05 17:27:25 - INFO - root -   Epoch: [152/300][140/200], lr: 0.00000048 	 loss = 0.6952(0.4675)
2024/03/05 17:28:01 - INFO - root -   Epoch: [152/300][160/200], lr: 0.00000048 	 loss = 0.3267(0.4845)
2024/03/05 17:28:31 - INFO - root -   Epoch: [152/300][180/200], lr: 0.00000048 	 loss = 0.5579(0.5108)
2024/03/05 17:28:50 - INFO - root -   Epoch: [152/300] 	 loss = 0.5023
2024/03/05 17:28:50 - INFO - root -   train_accuracy = 0.8325
2024/03/05 17:29:24 - INFO - root -   Epoch: [153/300][0/200], lr: 0.00000048 	 loss = 0.9232(0.9232)
2024/03/05 17:30:19 - INFO - root -   Epoch: [153/300][20/200], lr: 0.00000048 	 loss = 0.6623(0.6062)
2024/03/05 17:30:51 - INFO - root -   Epoch: [153/300][40/200], lr: 0.00000048 	 loss = 0.1398(0.5262)
2024/03/05 17:31:35 - INFO - root -   Epoch: [153/300][60/200], lr: 0.00000048 	 loss = 0.0925(0.4965)
2024/03/05 17:32:08 - INFO - root -   Epoch: [153/300][80/200], lr: 0.00000048 	 loss = 2.1719(0.5147)
2024/03/05 17:33:09 - INFO - root -   Epoch: [153/300][100/200], lr: 0.00000048 	 loss = 0.2662(0.4846)
2024/03/05 17:33:42 - INFO - root -   Epoch: [153/300][120/200], lr: 0.00000048 	 loss = 2.1513(0.4831)
2024/03/05 17:34:21 - INFO - root -   Epoch: [153/300][140/200], lr: 0.00000048 	 loss = 1.3246(0.4867)
2024/03/05 17:34:39 - INFO - root -   Epoch: [153/300][160/200], lr: 0.00000048 	 loss = 0.1399(0.4646)
2024/03/05 17:35:27 - INFO - root -   Epoch: [153/300][180/200], lr: 0.00000048 	 loss = 0.3929(0.4783)
2024/03/05 17:35:45 - INFO - root -   Epoch: [153/300] 	 loss = 0.4792
2024/03/05 17:35:45 - INFO - root -   train_accuracy = 0.8300
2024/03/05 17:36:16 - INFO - root -   Epoch: [154/300][0/200], lr: 0.00000048 	 loss = 1.7427(1.7427)
2024/03/05 17:36:56 - INFO - root -   Epoch: [154/300][20/200], lr: 0.00000048 	 loss = 0.1481(0.5407)
2024/03/05 17:37:30 - INFO - root -   Epoch: [154/300][40/200], lr: 0.00000048 	 loss = 0.0944(0.4719)
2024/03/05 17:38:12 - INFO - root -   Epoch: [154/300][60/200], lr: 0.00000048 	 loss = 0.1856(0.4839)
2024/03/05 17:38:52 - INFO - root -   Epoch: [154/300][80/200], lr: 0.00000048 	 loss = 2.4458(0.5224)
2024/03/05 17:39:54 - INFO - root -   Epoch: [154/300][100/200], lr: 0.00000048 	 loss = 0.0336(0.5101)
2024/03/05 17:40:24 - INFO - root -   Epoch: [154/300][120/200], lr: 0.00000048 	 loss = 2.1726(0.4904)
2024/03/05 17:41:05 - INFO - root -   Epoch: [154/300][140/200], lr: 0.00000048 	 loss = 1.7351(0.4742)
2024/03/05 17:41:40 - INFO - root -   Epoch: [154/300][160/200], lr: 0.00000048 	 loss = 0.0461(0.4740)
2024/03/05 17:42:10 - INFO - root -   Epoch: [154/300][180/200], lr: 0.00000048 	 loss = 0.6835(0.4887)
2024/03/05 17:42:23 - INFO - root -   Epoch: [154/300] 	 loss = 0.4815
2024/03/05 17:42:26 - INFO - root -   precision = 0.7333
2024/03/05 17:42:26 - INFO - root -   eval_loss = 0.9783
2024/03/05 17:42:26 - INFO - root -   eval_acc = 0.7333
2024/03/05 17:42:27 - INFO - root -   train_accuracy = 0.8450
2024/03/05 17:43:16 - INFO - root -   Epoch: [155/300][0/200], lr: 0.00000048 	 loss = 1.1057(1.1057)
2024/03/05 17:43:56 - INFO - root -   Epoch: [155/300][20/200], lr: 0.00000048 	 loss = 0.3868(0.4487)
2024/03/05 17:44:28 - INFO - root -   Epoch: [155/300][40/200], lr: 0.00000048 	 loss = 0.1218(0.3940)
2024/03/05 17:45:00 - INFO - root -   Epoch: [155/300][60/200], lr: 0.00000048 	 loss = 0.1575(0.4019)
2024/03/05 17:46:06 - INFO - root -   Epoch: [155/300][80/200], lr: 0.00000048 	 loss = 1.9044(0.4318)
2024/03/05 17:46:29 - INFO - root -   Epoch: [155/300][100/200], lr: 0.00000048 	 loss = 0.1375(0.4201)
2024/03/05 17:47:08 - INFO - root -   Epoch: [155/300][120/200], lr: 0.00000048 	 loss = 2.9895(0.4247)
2024/03/05 17:47:40 - INFO - root -   Epoch: [155/300][140/200], lr: 0.00000048 	 loss = 1.7101(0.4259)
2024/03/05 17:48:40 - INFO - root -   Epoch: [155/300][160/200], lr: 0.00000048 	 loss = 0.1474(0.4335)
2024/03/05 17:49:01 - INFO - root -   Epoch: [155/300][180/200], lr: 0.00000048 	 loss = 0.1909(0.4408)
2024/03/05 17:49:08 - INFO - root -   Epoch: [155/300] 	 loss = 0.4423
2024/03/05 17:49:08 - INFO - root -   train_accuracy = 0.8575
2024/03/05 17:49:39 - INFO - root -   Epoch: [156/300][0/200], lr: 0.00000049 	 loss = 2.1007(2.1007)
2024/03/05 17:50:20 - INFO - root -   Epoch: [156/300][20/200], lr: 0.00000049 	 loss = 0.3417(0.5516)
2024/03/05 17:51:02 - INFO - root -   Epoch: [156/300][40/200], lr: 0.00000049 	 loss = 0.1635(0.4768)
2024/03/05 17:51:43 - INFO - root -   Epoch: [156/300][60/200], lr: 0.00000049 	 loss = 0.0532(0.4715)
2024/03/05 17:52:28 - INFO - root -   Epoch: [156/300][80/200], lr: 0.00000049 	 loss = 1.8278(0.4894)
2024/03/05 17:53:11 - INFO - root -   Epoch: [156/300][100/200], lr: 0.00000049 	 loss = 0.0946(0.4586)
2024/03/05 17:53:52 - INFO - root -   Epoch: [156/300][120/200], lr: 0.00000049 	 loss = 1.9996(0.4479)
2024/03/05 17:54:37 - INFO - root -   Epoch: [156/300][140/200], lr: 0.00000049 	 loss = 1.0496(0.4389)
2024/03/05 17:55:09 - INFO - root -   Epoch: [156/300][160/200], lr: 0.00000049 	 loss = 0.2509(0.4386)
2024/03/05 17:55:53 - INFO - root -   Epoch: [156/300][180/200], lr: 0.00000049 	 loss = 0.1187(0.4411)
2024/03/05 17:56:06 - INFO - root -   Epoch: [156/300] 	 loss = 0.4317
2024/03/05 17:56:06 - INFO - root -   train_accuracy = 0.8650
2024/03/05 17:56:38 - INFO - root -   Epoch: [157/300][0/200], lr: 0.00000049 	 loss = 1.5186(1.5186)
2024/03/05 17:57:32 - INFO - root -   Epoch: [157/300][20/200], lr: 0.00000049 	 loss = 0.1505(0.4927)
2024/03/05 17:58:09 - INFO - root -   Epoch: [157/300][40/200], lr: 0.00000049 	 loss = 0.2301(0.4457)
2024/03/05 17:58:48 - INFO - root -   Epoch: [157/300][60/200], lr: 0.00000049 	 loss = 0.0437(0.4630)
2024/03/05 17:59:20 - INFO - root -   Epoch: [157/300][80/200], lr: 0.00000049 	 loss = 2.1422(0.4835)
2024/03/05 18:00:27 - INFO - root -   Epoch: [157/300][100/200], lr: 0.00000049 	 loss = 0.3215(0.4548)
2024/03/05 18:00:47 - INFO - root -   Epoch: [157/300][120/200], lr: 0.00000049 	 loss = 2.4412(0.4421)
2024/03/05 18:01:15 - INFO - root -   Epoch: [157/300][140/200], lr: 0.00000049 	 loss = 1.4618(0.4460)
2024/03/05 18:01:59 - INFO - root -   Epoch: [157/300][160/200], lr: 0.00000049 	 loss = 0.3192(0.4429)
2024/03/05 18:02:49 - INFO - root -   Epoch: [157/300][180/200], lr: 0.00000049 	 loss = 0.1793(0.4517)
2024/03/05 18:02:57 - INFO - root -   Epoch: [157/300] 	 loss = 0.4453
2024/03/05 18:02:57 - INFO - root -   train_accuracy = 0.8425
2024/03/05 18:03:17 - INFO - root -   Epoch: [158/300][0/200], lr: 0.00000049 	 loss = 2.0426(2.0426)
2024/03/05 18:04:10 - INFO - root -   Epoch: [158/300][20/200], lr: 0.00000049 	 loss = 0.4317(0.6459)
2024/03/05 18:04:50 - INFO - root -   Epoch: [158/300][40/200], lr: 0.00000049 	 loss = 0.2896(0.4712)
2024/03/05 18:05:25 - INFO - root -   Epoch: [158/300][60/200], lr: 0.00000049 	 loss = 0.2221(0.4416)
2024/03/05 18:06:05 - INFO - root -   Epoch: [158/300][80/200], lr: 0.00000049 	 loss = 1.9545(0.4809)
2024/03/05 18:07:03 - INFO - root -   Epoch: [158/300][100/200], lr: 0.00000049 	 loss = 0.1068(0.4523)
2024/03/05 18:07:39 - INFO - root -   Epoch: [158/300][120/200], lr: 0.00000049 	 loss = 3.4403(0.4586)
2024/03/05 18:08:20 - INFO - root -   Epoch: [158/300][140/200], lr: 0.00000049 	 loss = 0.9888(0.4562)
2024/03/05 18:08:48 - INFO - root -   Epoch: [158/300][160/200], lr: 0.00000049 	 loss = 0.0540(0.4567)
2024/03/05 18:09:26 - INFO - root -   Epoch: [158/300][180/200], lr: 0.00000049 	 loss = 0.1559(0.4745)
2024/03/05 18:09:47 - INFO - root -   Epoch: [158/300] 	 loss = 0.4709
2024/03/05 18:09:47 - INFO - root -   train_accuracy = 0.8525
2024/03/05 18:10:27 - INFO - root -   Epoch: [159/300][0/200], lr: 0.00000049 	 loss = 0.9215(0.9215)
2024/03/05 18:11:04 - INFO - root -   Epoch: [159/300][20/200], lr: 0.00000049 	 loss = 0.0860(0.5598)
2024/03/05 18:11:38 - INFO - root -   Epoch: [159/300][40/200], lr: 0.00000049 	 loss = 0.1246(0.4518)
2024/03/05 18:12:12 - INFO - root -   Epoch: [159/300][60/200], lr: 0.00000049 	 loss = 0.0497(0.4639)
2024/03/05 18:12:58 - INFO - root -   Epoch: [159/300][80/200], lr: 0.00000049 	 loss = 1.8058(0.4829)
2024/03/05 18:13:43 - INFO - root -   Epoch: [159/300][100/200], lr: 0.00000049 	 loss = 0.0960(0.4713)
2024/03/05 18:14:24 - INFO - root -   Epoch: [159/300][120/200], lr: 0.00000049 	 loss = 2.3859(0.4607)
2024/03/05 18:14:59 - INFO - root -   Epoch: [159/300][140/200], lr: 0.00000049 	 loss = 1.2520(0.4555)
2024/03/05 18:15:34 - INFO - root -   Epoch: [159/300][160/200], lr: 0.00000049 	 loss = 0.1149(0.4669)
2024/03/05 18:16:29 - INFO - root -   Epoch: [159/300][180/200], lr: 0.00000049 	 loss = 0.1431(0.4815)
2024/03/05 18:16:36 - INFO - root -   Epoch: [159/300] 	 loss = 0.4776
2024/03/05 18:16:40 - INFO - root -   precision = 0.7556
2024/03/05 18:16:40 - INFO - root -   eval_loss = 0.9964
2024/03/05 18:16:40 - INFO - root -   eval_acc = 0.7556
2024/03/05 18:16:41 - INFO - root -   train_accuracy = 0.8425
2024/03/05 18:17:15 - INFO - root -   Epoch: [160/300][0/200], lr: 0.00000050 	 loss = 1.7278(1.7278)
2024/03/05 18:17:52 - INFO - root -   Epoch: [160/300][20/200], lr: 0.00000050 	 loss = 0.2028(0.6882)
2024/03/05 18:18:33 - INFO - root -   Epoch: [160/300][40/200], lr: 0.00000050 	 loss = 0.1434(0.5528)
2024/03/05 18:19:10 - INFO - root -   Epoch: [160/300][60/200], lr: 0.00000050 	 loss = 0.0567(0.5274)
2024/03/05 18:19:53 - INFO - root -   Epoch: [160/300][80/200], lr: 0.00000050 	 loss = 1.8723(0.5262)
2024/03/05 18:20:43 - INFO - root -   Epoch: [160/300][100/200], lr: 0.00000050 	 loss = 0.1347(0.5065)
2024/03/05 18:21:16 - INFO - root -   Epoch: [160/300][120/200], lr: 0.00000050 	 loss = 1.2769(0.4898)
2024/03/05 18:21:56 - INFO - root -   Epoch: [160/300][140/200], lr: 0.00000050 	 loss = 1.6376(0.4818)
2024/03/05 18:22:32 - INFO - root -   Epoch: [160/300][160/200], lr: 0.00000050 	 loss = 0.0538(0.4706)
2024/03/05 18:23:22 - INFO - root -   Epoch: [160/300][180/200], lr: 0.00000050 	 loss = 0.2991(0.4808)
2024/03/05 18:23:30 - INFO - root -   Epoch: [160/300] 	 loss = 0.4732
2024/03/05 18:23:30 - INFO - root -   train_accuracy = 0.8400
2024/03/05 18:23:50 - INFO - root -   Epoch: [161/300][0/200], lr: 0.00000050 	 loss = 1.7268(1.7268)
2024/03/05 18:24:44 - INFO - root -   Epoch: [161/300][20/200], lr: 0.00000050 	 loss = 0.1257(0.6917)
2024/03/05 18:25:25 - INFO - root -   Epoch: [161/300][40/200], lr: 0.00000050 	 loss = 0.3340(0.5150)
2024/03/05 18:25:57 - INFO - root -   Epoch: [161/300][60/200], lr: 0.00000050 	 loss = 0.0417(0.4798)
2024/03/05 18:26:36 - INFO - root -   Epoch: [161/300][80/200], lr: 0.00000050 	 loss = 1.7651(0.5225)
2024/03/05 18:27:16 - INFO - root -   Epoch: [161/300][100/200], lr: 0.00000050 	 loss = 0.0285(0.5005)
2024/03/05 18:27:52 - INFO - root -   Epoch: [161/300][120/200], lr: 0.00000050 	 loss = 2.2829(0.4927)
2024/03/05 18:28:45 - INFO - root -   Epoch: [161/300][140/200], lr: 0.00000050 	 loss = 2.3954(0.4888)
2024/03/05 18:29:15 - INFO - root -   Epoch: [161/300][160/200], lr: 0.00000050 	 loss = 0.3534(0.5052)
2024/03/05 18:29:45 - INFO - root -   Epoch: [161/300][180/200], lr: 0.00000050 	 loss = 0.2807(0.5013)
2024/03/05 18:30:02 - INFO - root -   Epoch: [161/300] 	 loss = 0.5064
2024/03/05 18:30:02 - INFO - root -   train_accuracy = 0.8300
2024/03/05 18:30:35 - INFO - root -   Epoch: [162/300][0/200], lr: 0.00000050 	 loss = 1.4064(1.4064)
2024/03/05 18:31:15 - INFO - root -   Epoch: [162/300][20/200], lr: 0.00000050 	 loss = 0.1048(0.5963)
2024/03/05 18:32:03 - INFO - root -   Epoch: [162/300][40/200], lr: 0.00000050 	 loss = 0.0849(0.5247)
2024/03/05 18:32:46 - INFO - root -   Epoch: [162/300][60/200], lr: 0.00000050 	 loss = 0.0696(0.5414)
2024/03/05 18:33:22 - INFO - root -   Epoch: [162/300][80/200], lr: 0.00000050 	 loss = 2.4873(0.5620)
2024/03/05 18:34:13 - INFO - root -   Epoch: [162/300][100/200], lr: 0.00000050 	 loss = 0.1433(0.5210)
2024/03/05 18:34:41 - INFO - root -   Epoch: [162/300][120/200], lr: 0.00000050 	 loss = 2.2253(0.5019)
2024/03/05 18:35:20 - INFO - root -   Epoch: [162/300][140/200], lr: 0.00000050 	 loss = 1.1296(0.4962)
2024/03/05 18:35:59 - INFO - root -   Epoch: [162/300][160/200], lr: 0.00000050 	 loss = 0.1696(0.4936)
2024/03/05 18:36:55 - INFO - root -   Epoch: [162/300][180/200], lr: 0.00000050 	 loss = 0.7051(0.4919)
2024/03/05 18:37:03 - INFO - root -   Epoch: [162/300] 	 loss = 0.4814
2024/03/05 18:37:03 - INFO - root -   train_accuracy = 0.8400
2024/03/05 18:37:39 - INFO - root -   Epoch: [163/300][0/200], lr: 0.00000050 	 loss = 1.1140(1.1140)
2024/03/05 18:38:20 - INFO - root -   Epoch: [163/300][20/200], lr: 0.00000050 	 loss = 0.1301(0.5888)
2024/03/05 18:39:03 - INFO - root -   Epoch: [163/300][40/200], lr: 0.00000050 	 loss = 0.2500(0.4754)
2024/03/05 18:39:41 - INFO - root -   Epoch: [163/300][60/200], lr: 0.00000050 	 loss = 0.0255(0.4550)
2024/03/05 18:40:11 - INFO - root -   Epoch: [163/300][80/200], lr: 0.00000050 	 loss = 1.6559(0.4755)
2024/03/05 18:41:09 - INFO - root -   Epoch: [163/300][100/200], lr: 0.00000050 	 loss = 0.0528(0.4618)
2024/03/05 18:41:47 - INFO - root -   Epoch: [163/300][120/200], lr: 0.00000050 	 loss = 2.5608(0.4532)
2024/03/05 18:42:20 - INFO - root -   Epoch: [163/300][140/200], lr: 0.00000050 	 loss = 1.4243(0.4513)
2024/03/05 18:42:59 - INFO - root -   Epoch: [163/300][160/200], lr: 0.00000050 	 loss = 0.1193(0.4605)
2024/03/05 18:43:46 - INFO - root -   Epoch: [163/300][180/200], lr: 0.00000050 	 loss = 0.2234(0.4628)
2024/03/05 18:43:54 - INFO - root -   Epoch: [163/300] 	 loss = 0.4569
2024/03/05 18:43:54 - INFO - root -   train_accuracy = 0.8475
2024/03/05 18:44:33 - INFO - root -   Epoch: [164/300][0/200], lr: 0.00000051 	 loss = 1.5776(1.5776)
2024/03/05 18:45:21 - INFO - root -   Epoch: [164/300][20/200], lr: 0.00000051 	 loss = 0.0753(0.4549)
2024/03/05 18:45:52 - INFO - root -   Epoch: [164/300][40/200], lr: 0.00000051 	 loss = 0.2129(0.4473)
2024/03/05 18:46:24 - INFO - root -   Epoch: [164/300][60/200], lr: 0.00000051 	 loss = 0.0272(0.4496)
2024/03/05 18:47:19 - INFO - root -   Epoch: [164/300][80/200], lr: 0.00000051 	 loss = 2.4909(0.4979)
2024/03/05 18:47:56 - INFO - root -   Epoch: [164/300][100/200], lr: 0.00000051 	 loss = 0.0881(0.4529)
2024/03/05 18:48:27 - INFO - root -   Epoch: [164/300][120/200], lr: 0.00000051 	 loss = 3.2793(0.4503)
2024/03/05 18:49:03 - INFO - root -   Epoch: [164/300][140/200], lr: 0.00000051 	 loss = 1.0972(0.4544)
2024/03/05 18:50:10 - INFO - root -   Epoch: [164/300][160/200], lr: 0.00000051 	 loss = 0.1194(0.4629)
2024/03/05 18:50:32 - INFO - root -   Epoch: [164/300][180/200], lr: 0.00000051 	 loss = 0.2469(0.4617)
2024/03/05 18:50:40 - INFO - root -   Epoch: [164/300] 	 loss = 0.4638
2024/03/05 18:50:43 - INFO - root -   precision = 0.7333
2024/03/05 18:50:43 - INFO - root -   eval_loss = 1.0503
2024/03/05 18:50:43 - INFO - root -   eval_acc = 0.7333
2024/03/05 18:50:44 - INFO - root -   train_accuracy = 0.8450
2024/03/05 18:51:17 - INFO - root -   Epoch: [165/300][0/200], lr: 0.00000051 	 loss = 1.9632(1.9632)
2024/03/05 18:51:54 - INFO - root -   Epoch: [165/300][20/200], lr: 0.00000051 	 loss = 0.0424(0.4791)
2024/03/05 18:52:41 - INFO - root -   Epoch: [165/300][40/200], lr: 0.00000051 	 loss = 0.1217(0.4243)
2024/03/05 18:53:14 - INFO - root -   Epoch: [165/300][60/200], lr: 0.00000051 	 loss = 0.0229(0.4195)
2024/03/05 18:53:47 - INFO - root -   Epoch: [165/300][80/200], lr: 0.00000051 	 loss = 1.7021(0.4560)
2024/03/05 18:54:53 - INFO - root -   Epoch: [165/300][100/200], lr: 0.00000051 	 loss = 0.0424(0.4284)
2024/03/05 18:55:25 - INFO - root -   Epoch: [165/300][120/200], lr: 0.00000051 	 loss = 1.5881(0.4247)
2024/03/05 18:56:01 - INFO - root -   Epoch: [165/300][140/200], lr: 0.00000051 	 loss = 1.3766(0.4389)
2024/03/05 18:56:36 - INFO - root -   Epoch: [165/300][160/200], lr: 0.00000051 	 loss = 0.1104(0.4350)
2024/03/05 18:57:19 - INFO - root -   Epoch: [165/300][180/200], lr: 0.00000051 	 loss = 0.8131(0.4462)
2024/03/05 18:57:29 - INFO - root -   Epoch: [165/300] 	 loss = 0.4448
2024/03/05 18:57:29 - INFO - root -   train_accuracy = 0.8475
2024/03/05 18:57:54 - INFO - root -   Epoch: [166/300][0/200], lr: 0.00000051 	 loss = 1.1749(1.1749)
2024/03/05 18:58:40 - INFO - root -   Epoch: [166/300][20/200], lr: 0.00000051 	 loss = 0.5604(0.5048)
2024/03/05 18:59:22 - INFO - root -   Epoch: [166/300][40/200], lr: 0.00000051 	 loss = 0.2658(0.4475)
2024/03/05 18:59:58 - INFO - root -   Epoch: [166/300][60/200], lr: 0.00000051 	 loss = 0.0281(0.4378)
2024/03/05 19:00:39 - INFO - root -   Epoch: [166/300][80/200], lr: 0.00000051 	 loss = 1.4427(0.4432)
2024/03/05 19:01:25 - INFO - root -   Epoch: [166/300][100/200], lr: 0.00000051 	 loss = 0.1661(0.4251)
2024/03/05 19:02:09 - INFO - root -   Epoch: [166/300][120/200], lr: 0.00000051 	 loss = 3.0993(0.4307)
2024/03/05 19:02:44 - INFO - root -   Epoch: [166/300][140/200], lr: 0.00000051 	 loss = 1.7154(0.4426)
2024/03/05 19:03:32 - INFO - root -   Epoch: [166/300][160/200], lr: 0.00000051 	 loss = 0.2249(0.4514)
2024/03/05 19:04:04 - INFO - root -   Epoch: [166/300][180/200], lr: 0.00000051 	 loss = 0.1120(0.4678)
2024/03/05 19:04:20 - INFO - root -   Epoch: [166/300] 	 loss = 0.4581
2024/03/05 19:04:20 - INFO - root -   train_accuracy = 0.8425
2024/03/05 19:04:41 - INFO - root -   Epoch: [167/300][0/200], lr: 0.00000051 	 loss = 1.7930(1.7930)
2024/03/05 19:05:46 - INFO - root -   Epoch: [167/300][20/200], lr: 0.00000051 	 loss = 0.0982(0.4617)
2024/03/05 19:06:25 - INFO - root -   Epoch: [167/300][40/200], lr: 0.00000051 	 loss = 0.1843(0.3981)
2024/03/05 19:07:01 - INFO - root -   Epoch: [167/300][60/200], lr: 0.00000051 	 loss = 0.0302(0.3895)
2024/03/05 19:07:34 - INFO - root -   Epoch: [167/300][80/200], lr: 0.00000051 	 loss = 1.5672(0.4056)
2024/03/05 19:08:31 - INFO - root -   Epoch: [167/300][100/200], lr: 0.00000051 	 loss = 0.2270(0.3801)
2024/03/05 19:09:06 - INFO - root -   Epoch: [167/300][120/200], lr: 0.00000051 	 loss = 3.1220(0.3847)
2024/03/05 19:09:45 - INFO - root -   Epoch: [167/300][140/200], lr: 0.00000051 	 loss = 1.6311(0.3931)
2024/03/05 19:10:07 - INFO - root -   Epoch: [167/300][160/200], lr: 0.00000051 	 loss = 0.0375(0.4038)
2024/03/05 19:11:00 - INFO - root -   Epoch: [167/300][180/200], lr: 0.00000051 	 loss = 0.2117(0.4218)
2024/03/05 19:11:08 - INFO - root -   Epoch: [167/300] 	 loss = 0.4237
2024/03/05 19:11:08 - INFO - root -   train_accuracy = 0.8625
2024/03/05 19:11:28 - INFO - root -   Epoch: [168/300][0/200], lr: 0.00000052 	 loss = 1.5404(1.5404)
2024/03/05 19:12:26 - INFO - root -   Epoch: [168/300][20/200], lr: 0.00000052 	 loss = 0.1656(0.4923)
2024/03/05 19:13:06 - INFO - root -   Epoch: [168/300][40/200], lr: 0.00000052 	 loss = 0.7828(0.4373)
2024/03/05 19:13:44 - INFO - root -   Epoch: [168/300][60/200], lr: 0.00000052 	 loss = 0.0353(0.4404)
2024/03/05 19:14:23 - INFO - root -   Epoch: [168/300][80/200], lr: 0.00000052 	 loss = 1.7356(0.4561)
2024/03/05 19:15:12 - INFO - root -   Epoch: [168/300][100/200], lr: 0.00000052 	 loss = 0.1134(0.4360)
2024/03/05 19:15:53 - INFO - root -   Epoch: [168/300][120/200], lr: 0.00000052 	 loss = 3.3967(0.4315)
2024/03/05 19:16:27 - INFO - root -   Epoch: [168/300][140/200], lr: 0.00000052 	 loss = 1.1029(0.4328)
2024/03/05 19:17:08 - INFO - root -   Epoch: [168/300][160/200], lr: 0.00000052 	 loss = 0.0999(0.4418)
2024/03/05 19:17:54 - INFO - root -   Epoch: [168/300][180/200], lr: 0.00000052 	 loss = 0.2392(0.4495)
2024/03/05 19:18:01 - INFO - root -   Epoch: [168/300] 	 loss = 0.4413
2024/03/05 19:18:01 - INFO - root -   train_accuracy = 0.8525
2024/03/05 19:18:42 - INFO - root -   Epoch: [169/300][0/200], lr: 0.00000052 	 loss = 0.7709(0.7709)
2024/03/05 19:19:17 - INFO - root -   Epoch: [169/300][20/200], lr: 0.00000052 	 loss = 0.1282(0.5031)
2024/03/05 19:19:56 - INFO - root -   Epoch: [169/300][40/200], lr: 0.00000052 	 loss = 0.1635(0.4579)
2024/03/05 19:20:19 - INFO - root -   Epoch: [169/300][60/200], lr: 0.00000052 	 loss = 0.0269(0.4297)
2024/03/05 19:21:03 - INFO - root -   Epoch: [169/300][80/200], lr: 0.00000052 	 loss = 1.2651(0.4335)
2024/03/05 19:21:56 - INFO - root -   Epoch: [169/300][100/200], lr: 0.00000052 	 loss = 0.1948(0.4130)
2024/03/05 19:22:46 - INFO - root -   Epoch: [169/300][120/200], lr: 0.00000052 	 loss = 3.2721(0.4168)
2024/03/05 19:23:14 - INFO - root -   Epoch: [169/300][140/200], lr: 0.00000052 	 loss = 1.4813(0.4348)
2024/03/05 19:23:48 - INFO - root -   Epoch: [169/300][160/200], lr: 0.00000052 	 loss = 0.2874(0.4364)
2024/03/05 19:24:29 - INFO - root -   Epoch: [169/300][180/200], lr: 0.00000052 	 loss = 0.2886(0.4530)
2024/03/05 19:24:45 - INFO - root -   Epoch: [169/300] 	 loss = 0.4608
2024/03/05 19:24:49 - INFO - root -   precision = 0.7333
2024/03/05 19:24:49 - INFO - root -   eval_loss = 1.0647
2024/03/05 19:24:49 - INFO - root -   eval_acc = 0.7333
2024/03/05 19:24:50 - INFO - root -   train_accuracy = 0.8450
2024/03/05 19:25:21 - INFO - root -   Epoch: [170/300][0/200], lr: 0.00000052 	 loss = 2.3684(2.3684)
2024/03/05 19:26:06 - INFO - root -   Epoch: [170/300][20/200], lr: 0.00000052 	 loss = 0.1204(0.6613)
2024/03/05 19:26:51 - INFO - root -   Epoch: [170/300][40/200], lr: 0.00000052 	 loss = 0.0412(0.5185)
2024/03/05 19:27:28 - INFO - root -   Epoch: [170/300][60/200], lr: 0.00000052 	 loss = 0.0229(0.5065)
2024/03/05 19:28:09 - INFO - root -   Epoch: [170/300][80/200], lr: 0.00000052 	 loss = 1.0162(0.5157)
2024/03/05 19:29:08 - INFO - root -   Epoch: [170/300][100/200], lr: 0.00000052 	 loss = 0.3825(0.4939)
2024/03/05 19:29:44 - INFO - root -   Epoch: [170/300][120/200], lr: 0.00000052 	 loss = 2.9589(0.4985)
2024/03/05 19:30:24 - INFO - root -   Epoch: [170/300][140/200], lr: 0.00000052 	 loss = 1.3426(0.4879)
2024/03/05 19:30:56 - INFO - root -   Epoch: [170/300][160/200], lr: 0.00000052 	 loss = 0.0710(0.4896)
2024/03/05 19:31:25 - INFO - root -   Epoch: [170/300][180/200], lr: 0.00000052 	 loss = 0.3312(0.4902)
2024/03/05 19:31:34 - INFO - root -   Epoch: [170/300] 	 loss = 0.4850
2024/03/05 19:31:34 - INFO - root -   train_accuracy = 0.8300
2024/03/05 19:31:59 - INFO - root -   Epoch: [171/300][0/200], lr: 0.00000052 	 loss = 0.7377(0.7377)
2024/03/05 19:32:52 - INFO - root -   Epoch: [171/300][20/200], lr: 0.00000052 	 loss = 0.8384(0.5583)
2024/03/05 19:33:23 - INFO - root -   Epoch: [171/300][40/200], lr: 0.00000052 	 loss = 0.0618(0.4761)
2024/03/05 19:33:54 - INFO - root -   Epoch: [171/300][60/200], lr: 0.00000052 	 loss = 0.0242(0.4436)
2024/03/05 19:34:32 - INFO - root -   Epoch: [171/300][80/200], lr: 0.00000052 	 loss = 0.9280(0.4710)
2024/03/05 19:35:35 - INFO - root -   Epoch: [171/300][100/200], lr: 0.00000052 	 loss = 0.0438(0.4713)
2024/03/05 19:36:06 - INFO - root -   Epoch: [171/300][120/200], lr: 0.00000052 	 loss = 3.1081(0.4631)
2024/03/05 19:36:41 - INFO - root -   Epoch: [171/300][140/200], lr: 0.00000052 	 loss = 1.7301(0.4651)
2024/03/05 19:37:15 - INFO - root -   Epoch: [171/300][160/200], lr: 0.00000052 	 loss = 0.3593(0.4880)
2024/03/05 19:38:05 - INFO - root -   Epoch: [171/300][180/200], lr: 0.00000052 	 loss = 0.8862(0.4966)
2024/03/05 19:38:13 - INFO - root -   Epoch: [171/300] 	 loss = 0.4820
2024/03/05 19:38:13 - INFO - root -   train_accuracy = 0.8300
2024/03/05 19:38:51 - INFO - root -   Epoch: [172/300][0/200], lr: 0.00000053 	 loss = 1.1948(1.1948)
2024/03/05 19:39:34 - INFO - root -   Epoch: [172/300][20/200], lr: 0.00000053 	 loss = 0.2403(0.5471)
2024/03/05 19:40:18 - INFO - root -   Epoch: [172/300][40/200], lr: 0.00000053 	 loss = 0.2451(0.4839)
2024/03/05 19:40:52 - INFO - root -   Epoch: [172/300][60/200], lr: 0.00000053 	 loss = 0.0436(0.4687)
2024/03/05 19:41:48 - INFO - root -   Epoch: [172/300][80/200], lr: 0.00000053 	 loss = 0.6850(0.4693)
2024/03/05 19:42:27 - INFO - root -   Epoch: [172/300][100/200], lr: 0.00000053 	 loss = 0.0471(0.4457)
2024/03/05 19:43:11 - INFO - root -   Epoch: [172/300][120/200], lr: 0.00000053 	 loss = 2.3573(0.4412)
2024/03/05 19:43:48 - INFO - root -   Epoch: [172/300][140/200], lr: 0.00000053 	 loss = 1.4011(0.4346)
2024/03/05 19:44:31 - INFO - root -   Epoch: [172/300][160/200], lr: 0.00000053 	 loss = 0.0394(0.4386)
2024/03/05 19:45:01 - INFO - root -   Epoch: [172/300][180/200], lr: 0.00000053 	 loss = 0.3512(0.4592)
2024/03/05 19:45:14 - INFO - root -   Epoch: [172/300] 	 loss = 0.4472
2024/03/05 19:45:14 - INFO - root -   train_accuracy = 0.8425
2024/03/05 19:45:58 - INFO - root -   Epoch: [173/300][0/200], lr: 0.00000053 	 loss = 1.1126(1.1126)
2024/03/05 19:46:28 - INFO - root -   Epoch: [173/300][20/200], lr: 0.00000053 	 loss = 0.2970(0.5370)
2024/03/05 19:47:11 - INFO - root -   Epoch: [173/300][40/200], lr: 0.00000053 	 loss = 0.1679(0.4590)
2024/03/05 19:47:51 - INFO - root -   Epoch: [173/300][60/200], lr: 0.00000053 	 loss = 0.0148(0.4030)
2024/03/05 19:48:27 - INFO - root -   Epoch: [173/300][80/200], lr: 0.00000053 	 loss = 1.0951(0.4043)
2024/03/05 19:49:04 - INFO - root -   Epoch: [173/300][100/200], lr: 0.00000053 	 loss = 0.0554(0.4004)
2024/03/05 19:50:06 - INFO - root -   Epoch: [173/300][120/200], lr: 0.00000053 	 loss = 1.9744(0.3969)
2024/03/05 19:50:28 - INFO - root -   Epoch: [173/300][140/200], lr: 0.00000053 	 loss = 1.9526(0.4036)
2024/03/05 19:51:14 - INFO - root -   Epoch: [173/300][160/200], lr: 0.00000053 	 loss = 0.0886(0.4031)
2024/03/05 19:51:49 - INFO - root -   Epoch: [173/300][180/200], lr: 0.00000053 	 loss = 0.3174(0.4207)
2024/03/05 19:52:05 - INFO - root -   Epoch: [173/300] 	 loss = 0.4212
2024/03/05 19:52:05 - INFO - root -   train_accuracy = 0.8600
2024/03/05 19:52:40 - INFO - root -   Epoch: [174/300][0/200], lr: 0.00000053 	 loss = 1.4840(1.4840)
2024/03/05 19:53:24 - INFO - root -   Epoch: [174/300][20/200], lr: 0.00000053 	 loss = 0.1414(0.5709)
2024/03/05 19:54:00 - INFO - root -   Epoch: [174/300][40/200], lr: 0.00000053 	 loss = 0.1432(0.5241)
2024/03/05 19:54:39 - INFO - root -   Epoch: [174/300][60/200], lr: 0.00000053 	 loss = 0.2056(0.4833)
2024/03/05 19:55:09 - INFO - root -   Epoch: [174/300][80/200], lr: 0.00000053 	 loss = 1.4471(0.4932)
2024/03/05 19:56:13 - INFO - root -   Epoch: [174/300][100/200], lr: 0.00000053 	 loss = 0.2270(0.4686)
2024/03/05 19:56:47 - INFO - root -   Epoch: [174/300][120/200], lr: 0.00000053 	 loss = 2.4102(0.4664)
2024/03/05 19:57:12 - INFO - root -   Epoch: [174/300][140/200], lr: 0.00000053 	 loss = 1.3561(0.4696)
2024/03/05 19:57:52 - INFO - root -   Epoch: [174/300][160/200], lr: 0.00000053 	 loss = 0.2165(0.4643)
2024/03/05 19:58:43 - INFO - root -   Epoch: [174/300][180/200], lr: 0.00000053 	 loss = 0.1301(0.4659)
2024/03/05 19:58:51 - INFO - root -   Epoch: [174/300] 	 loss = 0.4641
2024/03/05 19:58:55 - INFO - root -   precision = 0.7333
2024/03/05 19:58:55 - INFO - root -   eval_loss = 1.0942
2024/03/05 19:58:55 - INFO - root -   eval_acc = 0.7333
2024/03/05 19:58:56 - INFO - root -   train_accuracy = 0.8250
2024/03/05 19:59:34 - INFO - root -   Epoch: [175/300][0/200], lr: 0.00000053 	 loss = 0.8671(0.8671)
2024/03/05 20:00:14 - INFO - root -   Epoch: [175/300][20/200], lr: 0.00000053 	 loss = 0.0599(0.4401)
2024/03/05 20:00:53 - INFO - root -   Epoch: [175/300][40/200], lr: 0.00000053 	 loss = 0.1184(0.4023)
2024/03/05 20:01:33 - INFO - root -   Epoch: [175/300][60/200], lr: 0.00000053 	 loss = 0.0119(0.4182)
2024/03/05 20:02:28 - INFO - root -   Epoch: [175/300][80/200], lr: 0.00000053 	 loss = 1.6555(0.4343)
2024/03/05 20:03:10 - INFO - root -   Epoch: [175/300][100/200], lr: 0.00000053 	 loss = 0.2797(0.4172)
2024/03/05 20:03:48 - INFO - root -   Epoch: [175/300][120/200], lr: 0.00000053 	 loss = 2.3405(0.4127)
2024/03/05 20:04:23 - INFO - root -   Epoch: [175/300][140/200], lr: 0.00000053 	 loss = 1.2837(0.4102)
2024/03/05 20:05:02 - INFO - root -   Epoch: [175/300][160/200], lr: 0.00000053 	 loss = 0.1671(0.4178)
2024/03/05 20:05:46 - INFO - root -   Epoch: [175/300][180/200], lr: 0.00000053 	 loss = 0.0345(0.4347)
2024/03/05 20:05:54 - INFO - root -   Epoch: [175/300] 	 loss = 0.4324
2024/03/05 20:05:54 - INFO - root -   train_accuracy = 0.8525
2024/03/05 20:06:19 - INFO - root -   Epoch: [176/300][0/200], lr: 0.00000054 	 loss = 0.9757(0.9757)
2024/03/05 20:07:20 - INFO - root -   Epoch: [176/300][20/200], lr: 0.00000054 	 loss = 0.5587(0.5867)
2024/03/05 20:07:57 - INFO - root -   Epoch: [176/300][40/200], lr: 0.00000054 	 loss = 0.0504(0.5134)
2024/03/05 20:08:28 - INFO - root -   Epoch: [176/300][60/200], lr: 0.00000054 	 loss = 0.0639(0.4658)
2024/03/05 20:08:58 - INFO - root -   Epoch: [176/300][80/200], lr: 0.00000054 	 loss = 0.2415(0.4794)
2024/03/05 20:10:00 - INFO - root -   Epoch: [176/300][100/200], lr: 0.00000054 	 loss = 0.0778(0.4642)
2024/03/05 20:10:42 - INFO - root -   Epoch: [176/300][120/200], lr: 0.00000054 	 loss = 2.4223(0.4437)
2024/03/05 20:11:16 - INFO - root -   Epoch: [176/300][140/200], lr: 0.00000054 	 loss = 1.8393(0.4476)
2024/03/05 20:11:48 - INFO - root -   Epoch: [176/300][160/200], lr: 0.00000054 	 loss = 0.1557(0.4510)
2024/03/05 20:12:33 - INFO - root -   Epoch: [176/300][180/200], lr: 0.00000054 	 loss = 0.2907(0.4599)
2024/03/05 20:12:40 - INFO - root -   Epoch: [176/300] 	 loss = 0.4618
2024/03/05 20:12:40 - INFO - root -   train_accuracy = 0.8400
2024/03/05 20:13:09 - INFO - root -   Epoch: [177/300][0/200], lr: 0.00000054 	 loss = 1.7607(1.7607)
2024/03/05 20:13:48 - INFO - root -   Epoch: [177/300][20/200], lr: 0.00000054 	 loss = 0.0762(0.4992)
2024/03/05 20:14:39 - INFO - root -   Epoch: [177/300][40/200], lr: 0.00000054 	 loss = 0.3123(0.4221)
2024/03/05 20:15:14 - INFO - root -   Epoch: [177/300][60/200], lr: 0.00000054 	 loss = 0.0273(0.4193)
2024/03/05 20:15:53 - INFO - root -   Epoch: [177/300][80/200], lr: 0.00000054 	 loss = 1.3439(0.4531)
2024/03/05 20:16:33 - INFO - root -   Epoch: [177/300][100/200], lr: 0.00000054 	 loss = 0.0435(0.4492)
2024/03/05 20:17:21 - INFO - root -   Epoch: [177/300][120/200], lr: 0.00000054 	 loss = 2.9560(0.4580)
2024/03/05 20:18:04 - INFO - root -   Epoch: [177/300][140/200], lr: 0.00000054 	 loss = 1.3604(0.4490)
2024/03/05 20:18:38 - INFO - root -   Epoch: [177/300][160/200], lr: 0.00000054 	 loss = 0.1609(0.4493)
2024/03/05 20:19:17 - INFO - root -   Epoch: [177/300][180/200], lr: 0.00000054 	 loss = 0.0863(0.4492)
2024/03/05 20:19:29 - INFO - root -   Epoch: [177/300] 	 loss = 0.4495
2024/03/05 20:19:29 - INFO - root -   train_accuracy = 0.8450
2024/03/05 20:20:05 - INFO - root -   Epoch: [178/300][0/200], lr: 0.00000054 	 loss = 2.0051(2.0051)
2024/03/05 20:20:43 - INFO - root -   Epoch: [178/300][20/200], lr: 0.00000054 	 loss = 0.2259(0.5863)
2024/03/05 20:21:14 - INFO - root -   Epoch: [178/300][40/200], lr: 0.00000054 	 loss = 0.2944(0.5001)
2024/03/05 20:21:51 - INFO - root -   Epoch: [178/300][60/200], lr: 0.00000054 	 loss = 0.0534(0.4731)
2024/03/05 20:22:56 - INFO - root -   Epoch: [178/300][80/200], lr: 0.00000054 	 loss = 1.1178(0.4565)
2024/03/05 20:23:33 - INFO - root -   Epoch: [178/300][100/200], lr: 0.00000054 	 loss = 0.0412(0.4264)
2024/03/05 20:24:01 - INFO - root -   Epoch: [178/300][120/200], lr: 0.00000054 	 loss = 4.0807(0.4444)
2024/03/05 20:24:39 - INFO - root -   Epoch: [178/300][140/200], lr: 0.00000054 	 loss = 1.0435(0.4452)
2024/03/05 20:25:38 - INFO - root -   Epoch: [178/300][160/200], lr: 0.00000054 	 loss = 0.0793(0.4617)
2024/03/05 20:26:07 - INFO - root -   Epoch: [178/300][180/200], lr: 0.00000054 	 loss = 0.1336(0.4615)
2024/03/05 20:26:14 - INFO - root -   Epoch: [178/300] 	 loss = 0.4524
2024/03/05 20:26:14 - INFO - root -   train_accuracy = 0.8350
2024/03/05 20:26:54 - INFO - root -   Epoch: [179/300][0/200], lr: 0.00000054 	 loss = 0.6573(0.6573)
2024/03/05 20:27:32 - INFO - root -   Epoch: [179/300][20/200], lr: 0.00000054 	 loss = 0.0649(0.5269)
2024/03/05 20:28:13 - INFO - root -   Epoch: [179/300][40/200], lr: 0.00000054 	 loss = 0.0928(0.4322)
2024/03/05 20:28:52 - INFO - root -   Epoch: [179/300][60/200], lr: 0.00000054 	 loss = 0.0981(0.4600)
2024/03/05 20:29:28 - INFO - root -   Epoch: [179/300][80/200], lr: 0.00000054 	 loss = 1.1772(0.4537)
2024/03/05 20:30:20 - INFO - root -   Epoch: [179/300][100/200], lr: 0.00000054 	 loss = 0.1077(0.4325)
2024/03/05 20:31:02 - INFO - root -   Epoch: [179/300][120/200], lr: 0.00000054 	 loss = 2.6764(0.4319)
2024/03/05 20:31:37 - INFO - root -   Epoch: [179/300][140/200], lr: 0.00000054 	 loss = 1.6506(0.4337)
2024/03/05 20:32:24 - INFO - root -   Epoch: [179/300][160/200], lr: 0.00000054 	 loss = 0.0939(0.4378)
2024/03/05 20:32:55 - INFO - root -   Epoch: [179/300][180/200], lr: 0.00000054 	 loss = 0.3165(0.4391)
2024/03/05 20:33:07 - INFO - root -   Epoch: [179/300] 	 loss = 0.4344
2024/03/05 20:33:11 - INFO - root -   precision = 0.7333
2024/03/05 20:33:11 - INFO - root -   eval_loss = 1.1511
2024/03/05 20:33:11 - INFO - root -   eval_acc = 0.7333
2024/03/05 20:33:12 - INFO - root -   train_accuracy = 0.8375
2024/03/05 20:33:40 - INFO - root -   Epoch: [180/300][0/200], lr: 0.00000055 	 loss = 1.6899(1.6899)
2024/03/05 20:34:34 - INFO - root -   Epoch: [180/300][20/200], lr: 0.00000055 	 loss = 1.6423(0.5604)
2024/03/05 20:35:16 - INFO - root -   Epoch: [180/300][40/200], lr: 0.00000055 	 loss = 0.2873(0.4794)
2024/03/05 20:35:50 - INFO - root -   Epoch: [180/300][60/200], lr: 0.00000055 	 loss = 0.2120(0.4478)
2024/03/05 20:36:16 - INFO - root -   Epoch: [180/300][80/200], lr: 0.00000055 	 loss = 2.3345(0.4890)
2024/03/05 20:37:23 - INFO - root -   Epoch: [180/300][100/200], lr: 0.00000055 	 loss = 0.0356(0.4724)
2024/03/05 20:37:55 - INFO - root -   Epoch: [180/300][120/200], lr: 0.00000055 	 loss = 3.1907(0.4558)
2024/03/05 20:38:31 - INFO - root -   Epoch: [180/300][140/200], lr: 0.00000055 	 loss = 1.9616(0.4556)
2024/03/05 20:39:12 - INFO - root -   Epoch: [180/300][160/200], lr: 0.00000055 	 loss = 0.2043(0.4544)
2024/03/05 20:40:02 - INFO - root -   Epoch: [180/300][180/200], lr: 0.00000055 	 loss = 0.3888(0.4711)
2024/03/05 20:40:10 - INFO - root -   Epoch: [180/300] 	 loss = 0.4744
2024/03/05 20:40:10 - INFO - root -   train_accuracy = 0.8550
2024/03/05 20:40:40 - INFO - root -   Epoch: [181/300][0/200], lr: 0.00000055 	 loss = 2.2149(2.2149)
2024/03/05 20:41:28 - INFO - root -   Epoch: [181/300][20/200], lr: 0.00000055 	 loss = 0.0892(0.5641)
2024/03/05 20:42:05 - INFO - root -   Epoch: [181/300][40/200], lr: 0.00000055 	 loss = 0.2988(0.4390)
2024/03/05 20:42:42 - INFO - root -   Epoch: [181/300][60/200], lr: 0.00000055 	 loss = 0.0677(0.4478)
2024/03/05 20:43:24 - INFO - root -   Epoch: [181/300][80/200], lr: 0.00000055 	 loss = 0.8051(0.4530)
2024/03/05 20:44:08 - INFO - root -   Epoch: [181/300][100/200], lr: 0.00000055 	 loss = 0.1964(0.4243)
2024/03/05 20:44:48 - INFO - root -   Epoch: [181/300][120/200], lr: 0.00000055 	 loss = 3.4624(0.4391)
2024/03/05 20:45:43 - INFO - root -   Epoch: [181/300][140/200], lr: 0.00000055 	 loss = 1.6764(0.4392)
2024/03/05 20:46:18 - INFO - root -   Epoch: [181/300][160/200], lr: 0.00000055 	 loss = 0.1041(0.4299)
2024/03/05 20:46:47 - INFO - root -   Epoch: [181/300][180/200], lr: 0.00000055 	 loss = 0.2541(0.4289)
2024/03/05 20:47:03 - INFO - root -   Epoch: [181/300] 	 loss = 0.4219
2024/03/05 20:47:03 - INFO - root -   train_accuracy = 0.8600
2024/03/05 20:47:42 - INFO - root -   Epoch: [182/300][0/200], lr: 0.00000055 	 loss = 2.2576(2.2576)
2024/03/05 20:48:15 - INFO - root -   Epoch: [182/300][20/200], lr: 0.00000055 	 loss = 0.2342(0.5060)
2024/03/05 20:49:12 - INFO - root -   Epoch: [182/300][40/200], lr: 0.00000055 	 loss = 0.0671(0.4265)
2024/03/05 20:49:40 - INFO - root -   Epoch: [182/300][60/200], lr: 0.00000055 	 loss = 0.0226(0.4224)
2024/03/05 20:50:22 - INFO - root -   Epoch: [182/300][80/200], lr: 0.00000055 	 loss = 1.7979(0.4408)
2024/03/05 20:50:55 - INFO - root -   Epoch: [182/300][100/200], lr: 0.00000055 	 loss = 0.0755(0.4238)
2024/03/05 20:51:51 - INFO - root -   Epoch: [182/300][120/200], lr: 0.00000055 	 loss = 2.5341(0.4244)
2024/03/05 20:52:27 - INFO - root -   Epoch: [182/300][140/200], lr: 0.00000055 	 loss = 2.1153(0.4453)
2024/03/05 20:52:58 - INFO - root -   Epoch: [182/300][160/200], lr: 0.00000055 	 loss = 0.2402(0.4450)
2024/03/05 20:53:35 - INFO - root -   Epoch: [182/300][180/200], lr: 0.00000055 	 loss = 0.2922(0.4550)
2024/03/05 20:53:45 - INFO - root -   Epoch: [182/300] 	 loss = 0.4482
2024/03/05 20:53:45 - INFO - root -   train_accuracy = 0.8525
2024/03/05 20:54:13 - INFO - root -   Epoch: [183/300][0/200], lr: 0.00000055 	 loss = 2.0342(2.0342)
2024/03/05 20:55:00 - INFO - root -   Epoch: [183/300][20/200], lr: 0.00000055 	 loss = 0.0768(0.6216)
2024/03/05 20:55:42 - INFO - root -   Epoch: [183/300][40/200], lr: 0.00000055 	 loss = 0.3277(0.4869)
2024/03/05 20:56:18 - INFO - root -   Epoch: [183/300][60/200], lr: 0.00000055 	 loss = 0.1014(0.4496)
2024/03/05 20:56:43 - INFO - root -   Epoch: [183/300][80/200], lr: 0.00000055 	 loss = 2.2106(0.4679)
2024/03/05 20:57:31 - INFO - root -   Epoch: [183/300][100/200], lr: 0.00000055 	 loss = 0.1244(0.4545)
2024/03/05 20:58:14 - INFO - root -   Epoch: [183/300][120/200], lr: 0.00000055 	 loss = 2.8143(0.4486)
2024/03/05 20:58:51 - INFO - root -   Epoch: [183/300][140/200], lr: 0.00000055 	 loss = 2.1194(0.4447)
2024/03/05 20:59:23 - INFO - root -   Epoch: [183/300][160/200], lr: 0.00000055 	 loss = 0.0773(0.4484)
2024/03/05 21:00:13 - INFO - root -   Epoch: [183/300][180/200], lr: 0.00000055 	 loss = 0.6113(0.4520)
2024/03/05 21:00:24 - INFO - root -   Epoch: [183/300] 	 loss = 0.4450
2024/03/05 21:00:24 - INFO - root -   train_accuracy = 0.8550
2024/03/05 21:00:57 - INFO - root -   Epoch: [184/300][0/200], lr: 0.00000056 	 loss = 0.5447(0.5447)
2024/03/05 21:01:47 - INFO - root -   Epoch: [184/300][20/200], lr: 0.00000056 	 loss = 0.0727(0.4320)
2024/03/05 21:02:30 - INFO - root -   Epoch: [184/300][40/200], lr: 0.00000056 	 loss = 0.1412(0.4165)
2024/03/05 21:03:02 - INFO - root -   Epoch: [184/300][60/200], lr: 0.00000056 	 loss = 0.0487(0.4151)
2024/03/05 21:03:41 - INFO - root -   Epoch: [184/300][80/200], lr: 0.00000056 	 loss = 2.4309(0.4437)
2024/03/05 21:04:37 - INFO - root -   Epoch: [184/300][100/200], lr: 0.00000056 	 loss = 0.0644(0.4269)
2024/03/05 21:05:17 - INFO - root -   Epoch: [184/300][120/200], lr: 0.00000056 	 loss = 3.2003(0.4236)
2024/03/05 21:05:52 - INFO - root -   Epoch: [184/300][140/200], lr: 0.00000056 	 loss = 1.1423(0.4220)
2024/03/05 21:06:24 - INFO - root -   Epoch: [184/300][160/200], lr: 0.00000056 	 loss = 0.1955(0.4265)
2024/03/05 21:07:09 - INFO - root -   Epoch: [184/300][180/200], lr: 0.00000056 	 loss = 0.1289(0.4277)
2024/03/05 21:07:17 - INFO - root -   Epoch: [184/300] 	 loss = 0.4231
2024/03/05 21:07:21 - INFO - root -   precision = 0.7556
2024/03/05 21:07:21 - INFO - root -   eval_loss = 1.1250
2024/03/05 21:07:21 - INFO - root -   eval_acc = 0.7556
2024/03/05 21:07:22 - INFO - root -   train_accuracy = 0.8525
2024/03/05 21:07:44 - INFO - root -   Epoch: [185/300][0/200], lr: 0.00000056 	 loss = 0.9439(0.9439)
2024/03/05 21:08:46 - INFO - root -   Epoch: [185/300][20/200], lr: 0.00000056 	 loss = 0.1989(0.4893)
2024/03/05 21:09:28 - INFO - root -   Epoch: [185/300][40/200], lr: 0.00000056 	 loss = 0.1678(0.4129)
2024/03/05 21:10:03 - INFO - root -   Epoch: [185/300][60/200], lr: 0.00000056 	 loss = 0.1612(0.4050)
2024/03/05 21:10:36 - INFO - root -   Epoch: [185/300][80/200], lr: 0.00000056 	 loss = 1.3565(0.4354)
2024/03/05 21:11:39 - INFO - root -   Epoch: [185/300][100/200], lr: 0.00000056 	 loss = 0.0495(0.4220)
2024/03/05 21:12:17 - INFO - root -   Epoch: [185/300][120/200], lr: 0.00000056 	 loss = 2.6161(0.4217)
2024/03/05 21:12:46 - INFO - root -   Epoch: [185/300][140/200], lr: 0.00000056 	 loss = 2.1931(0.4326)
2024/03/05 21:13:22 - INFO - root -   Epoch: [185/300][160/200], lr: 0.00000056 	 loss = 0.6222(0.4476)
2024/03/05 21:14:15 - INFO - root -   Epoch: [185/300][180/200], lr: 0.00000056 	 loss = 0.0901(0.4513)
2024/03/05 21:14:22 - INFO - root -   Epoch: [185/300] 	 loss = 0.4444
2024/03/05 21:14:22 - INFO - root -   train_accuracy = 0.8600
2024/03/05 21:14:44 - INFO - root -   Epoch: [186/300][0/200], lr: 0.00000056 	 loss = 1.4967(1.4967)
2024/03/05 21:15:39 - INFO - root -   Epoch: [186/300][20/200], lr: 0.00000056 	 loss = 0.1866(0.5334)
2024/03/05 21:16:22 - INFO - root -   Epoch: [186/300][40/200], lr: 0.00000056 	 loss = 0.2223(0.4180)
2024/03/05 21:17:02 - INFO - root -   Epoch: [186/300][60/200], lr: 0.00000056 	 loss = 0.0202(0.4126)
2024/03/05 21:17:38 - INFO - root -   Epoch: [186/300][80/200], lr: 0.00000056 	 loss = 1.1160(0.4256)
2024/03/05 21:18:15 - INFO - root -   Epoch: [186/300][100/200], lr: 0.00000056 	 loss = 0.0370(0.4164)
2024/03/05 21:19:04 - INFO - root -   Epoch: [186/300][120/200], lr: 0.00000056 	 loss = 1.6750(0.4166)
2024/03/05 21:19:24 - INFO - root -   Epoch: [186/300][140/200], lr: 0.00000056 	 loss = 1.4093(0.4157)
2024/03/05 21:20:05 - INFO - root -   Epoch: [186/300][160/200], lr: 0.00000056 	 loss = 0.0242(0.4180)
2024/03/05 21:20:45 - INFO - root -   Epoch: [186/300][180/200], lr: 0.00000056 	 loss = 0.4080(0.4185)
2024/03/05 21:21:01 - INFO - root -   Epoch: [186/300] 	 loss = 0.4054
2024/03/05 21:21:01 - INFO - root -   train_accuracy = 0.8750
2024/03/05 21:21:22 - INFO - root -   Epoch: [187/300][0/200], lr: 0.00000056 	 loss = 1.3256(1.3256)
2024/03/05 21:22:11 - INFO - root -   Epoch: [187/300][20/200], lr: 0.00000056 	 loss = 0.4272(0.4713)
2024/03/05 21:23:00 - INFO - root -   Epoch: [187/300][40/200], lr: 0.00000056 	 loss = 0.0630(0.3872)
2024/03/05 21:23:36 - INFO - root -   Epoch: [187/300][60/200], lr: 0.00000056 	 loss = 0.0697(0.4128)
2024/03/05 21:24:12 - INFO - root -   Epoch: [187/300][80/200], lr: 0.00000056 	 loss = 1.4891(0.4108)
2024/03/05 21:25:05 - INFO - root -   Epoch: [187/300][100/200], lr: 0.00000056 	 loss = 0.0225(0.4022)
2024/03/05 21:25:43 - INFO - root -   Epoch: [187/300][120/200], lr: 0.00000056 	 loss = 2.0403(0.4036)
2024/03/05 21:26:20 - INFO - root -   Epoch: [187/300][140/200], lr: 0.00000056 	 loss = 0.7150(0.4101)
2024/03/05 21:26:49 - INFO - root -   Epoch: [187/300][160/200], lr: 0.00000056 	 loss = 0.1687(0.4315)
2024/03/05 21:27:33 - INFO - root -   Epoch: [187/300][180/200], lr: 0.00000056 	 loss = 0.8848(0.4336)
2024/03/05 21:27:44 - INFO - root -   Epoch: [187/300] 	 loss = 0.4319
2024/03/05 21:27:44 - INFO - root -   train_accuracy = 0.8575
2024/03/05 21:28:23 - INFO - root -   Epoch: [188/300][0/200], lr: 0.00000057 	 loss = 1.6820(1.6820)
2024/03/05 21:29:01 - INFO - root -   Epoch: [188/300][20/200], lr: 0.00000057 	 loss = 0.0681(0.4894)
2024/03/05 21:29:40 - INFO - root -   Epoch: [188/300][40/200], lr: 0.00000057 	 loss = 0.3307(0.4339)
2024/03/05 21:30:23 - INFO - root -   Epoch: [188/300][60/200], lr: 0.00000057 	 loss = 0.0344(0.4522)
2024/03/05 21:30:55 - INFO - root -   Epoch: [188/300][80/200], lr: 0.00000057 	 loss = 2.3179(0.4781)
2024/03/05 21:31:43 - INFO - root -   Epoch: [188/300][100/200], lr: 0.00000057 	 loss = 0.0448(0.4682)
2024/03/05 21:32:21 - INFO - root -   Epoch: [188/300][120/200], lr: 0.00000057 	 loss = 2.4622(0.4669)
2024/03/05 21:33:14 - INFO - root -   Epoch: [188/300][140/200], lr: 0.00000057 	 loss = 1.4274(0.4664)
2024/03/05 21:33:52 - INFO - root -   Epoch: [188/300][160/200], lr: 0.00000057 	 loss = 0.0960(0.4701)
2024/03/05 21:34:24 - INFO - root -   Epoch: [188/300][180/200], lr: 0.00000057 	 loss = 0.4067(0.4665)
2024/03/05 21:34:36 - INFO - root -   Epoch: [188/300] 	 loss = 0.4551
2024/03/05 21:34:36 - INFO - root -   train_accuracy = 0.8500
2024/03/05 21:35:15 - INFO - root -   Epoch: [189/300][0/200], lr: 0.00000057 	 loss = 1.3009(1.3009)
2024/03/05 21:35:56 - INFO - root -   Epoch: [189/300][20/200], lr: 0.00000057 	 loss = 0.1154(0.4504)
2024/03/05 21:36:41 - INFO - root -   Epoch: [189/300][40/200], lr: 0.00000057 	 loss = 0.1492(0.4369)
2024/03/05 21:37:11 - INFO - root -   Epoch: [189/300][60/200], lr: 0.00000057 	 loss = 0.0365(0.4652)
2024/03/05 21:38:01 - INFO - root -   Epoch: [189/300][80/200], lr: 0.00000057 	 loss = 2.3767(0.4974)
2024/03/05 21:38:56 - INFO - root -   Epoch: [189/300][100/200], lr: 0.00000057 	 loss = 0.0345(0.4515)
2024/03/05 21:39:14 - INFO - root -   Epoch: [189/300][120/200], lr: 0.00000057 	 loss = 3.4554(0.4585)
2024/03/05 21:39:50 - INFO - root -   Epoch: [189/300][140/200], lr: 0.00000057 	 loss = 1.3587(0.4623)
2024/03/05 21:40:27 - INFO - root -   Epoch: [189/300][160/200], lr: 0.00000057 	 loss = 0.2621(0.4634)
2024/03/05 21:41:12 - INFO - root -   Epoch: [189/300][180/200], lr: 0.00000057 	 loss = 0.7329(0.4585)
2024/03/05 21:41:20 - INFO - root -   Epoch: [189/300] 	 loss = 0.4515
2024/03/05 21:41:23 - INFO - root -   precision = 0.7111
2024/03/05 21:41:23 - INFO - root -   eval_loss = 1.1225
2024/03/05 21:41:23 - INFO - root -   eval_acc = 0.7111
2024/03/05 21:41:24 - INFO - root -   train_accuracy = 0.8400
2024/03/05 21:41:47 - INFO - root -   Epoch: [190/300][0/200], lr: 0.00000057 	 loss = 0.4110(0.4110)
2024/03/05 21:42:32 - INFO - root -   Epoch: [190/300][20/200], lr: 0.00000057 	 loss = 0.1831(0.5701)
2024/03/05 21:43:14 - INFO - root -   Epoch: [190/300][40/200], lr: 0.00000057 	 loss = 0.1676(0.4456)
2024/03/05 21:43:58 - INFO - root -   Epoch: [190/300][60/200], lr: 0.00000057 	 loss = 0.0382(0.4384)
2024/03/05 21:44:56 - INFO - root -   Epoch: [190/300][80/200], lr: 0.00000057 	 loss = 0.8995(0.4721)
2024/03/05 21:45:24 - INFO - root -   Epoch: [190/300][100/200], lr: 0.00000057 	 loss = 0.0931(0.4387)
2024/03/05 21:46:08 - INFO - root -   Epoch: [190/300][120/200], lr: 0.00000057 	 loss = 2.2263(0.4309)
2024/03/05 21:46:46 - INFO - root -   Epoch: [190/300][140/200], lr: 0.00000057 	 loss = 0.8439(0.4233)
2024/03/05 21:47:20 - INFO - root -   Epoch: [190/300][160/200], lr: 0.00000057 	 loss = 0.1494(0.4329)
2024/03/05 21:47:54 - INFO - root -   Epoch: [190/300][180/200], lr: 0.00000057 	 loss = 0.1764(0.4397)
2024/03/05 21:48:07 - INFO - root -   Epoch: [190/300] 	 loss = 0.4400
2024/03/05 21:48:07 - INFO - root -   train_accuracy = 0.8400
2024/03/05 21:48:44 - INFO - root -   Epoch: [191/300][0/200], lr: 0.00000057 	 loss = 1.6717(1.6717)
2024/03/05 21:49:27 - INFO - root -   Epoch: [191/300][20/200], lr: 0.00000057 	 loss = 0.0678(0.4067)
2024/03/05 21:50:12 - INFO - root -   Epoch: [191/300][40/200], lr: 0.00000057 	 loss = 0.1675(0.3743)
2024/03/05 21:50:44 - INFO - root -   Epoch: [191/300][60/200], lr: 0.00000057 	 loss = 0.0220(0.3591)
2024/03/05 21:51:51 - INFO - root -   Epoch: [191/300][80/200], lr: 0.00000057 	 loss = 1.9445(0.3847)
2024/03/05 21:52:19 - INFO - root -   Epoch: [191/300][100/200], lr: 0.00000057 	 loss = 0.0358(0.3657)
2024/03/05 21:52:49 - INFO - root -   Epoch: [191/300][120/200], lr: 0.00000057 	 loss = 2.5526(0.3780)
2024/03/05 21:53:24 - INFO - root -   Epoch: [191/300][140/200], lr: 0.00000057 	 loss = 1.3325(0.3853)
2024/03/05 21:54:02 - INFO - root -   Epoch: [191/300][160/200], lr: 0.00000057 	 loss = 0.5719(0.3813)
2024/03/05 21:54:36 - INFO - root -   Epoch: [191/300][180/200], lr: 0.00000057 	 loss = 0.1371(0.3884)
2024/03/05 21:55:00 - INFO - root -   Epoch: [191/300] 	 loss = 0.3943
2024/03/05 21:55:00 - INFO - root -   train_accuracy = 0.8450
2024/03/05 21:55:41 - INFO - root -   Epoch: [192/300][0/200], lr: 0.00000058 	 loss = 0.5669(0.5669)
2024/03/05 21:56:17 - INFO - root -   Epoch: [192/300][20/200], lr: 0.00000058 	 loss = 0.0517(0.5351)
2024/03/05 21:57:00 - INFO - root -   Epoch: [192/300][40/200], lr: 0.00000058 	 loss = 0.0883(0.4635)
2024/03/05 21:57:35 - INFO - root -   Epoch: [192/300][60/200], lr: 0.00000058 	 loss = 0.0307(0.4031)
2024/03/05 21:58:25 - INFO - root -   Epoch: [192/300][80/200], lr: 0.00000058 	 loss = 3.1105(0.4578)
2024/03/05 21:59:01 - INFO - root -   Epoch: [192/300][100/200], lr: 0.00000058 	 loss = 0.2210(0.4454)
2024/03/05 21:59:51 - INFO - root -   Epoch: [192/300][120/200], lr: 0.00000058 	 loss = 2.8403(0.4441)
2024/03/05 22:00:29 - INFO - root -   Epoch: [192/300][140/200], lr: 0.00000058 	 loss = 1.5377(0.4450)
2024/03/05 22:01:11 - INFO - root -   Epoch: [192/300][160/200], lr: 0.00000058 	 loss = 0.0803(0.4484)
2024/03/05 22:01:53 - INFO - root -   Epoch: [192/300][180/200], lr: 0.00000058 	 loss = 0.3949(0.4618)
2024/03/05 22:02:05 - INFO - root -   Epoch: [192/300] 	 loss = 0.4603
2024/03/05 22:02:05 - INFO - root -   train_accuracy = 0.8500
2024/03/05 22:02:38 - INFO - root -   Epoch: [193/300][0/200], lr: 0.00000058 	 loss = 1.9096(1.9096)
2024/03/05 22:03:33 - INFO - root -   Epoch: [193/300][20/200], lr: 0.00000058 	 loss = 0.2457(0.6519)
2024/03/05 22:04:03 - INFO - root -   Epoch: [193/300][40/200], lr: 0.00000058 	 loss = 0.1644(0.4769)
2024/03/05 22:04:39 - INFO - root -   Epoch: [193/300][60/200], lr: 0.00000058 	 loss = 0.1559(0.4614)
2024/03/05 22:05:23 - INFO - root -   Epoch: [193/300][80/200], lr: 0.00000058 	 loss = 0.6154(0.4451)
2024/03/05 22:06:27 - INFO - root -   Epoch: [193/300][100/200], lr: 0.00000058 	 loss = 0.0605(0.4147)
2024/03/05 22:06:59 - INFO - root -   Epoch: [193/300][120/200], lr: 0.00000058 	 loss = 4.0125(0.4287)
2024/03/05 22:07:20 - INFO - root -   Epoch: [193/300][140/200], lr: 0.00000058 	 loss = 1.9292(0.4300)
2024/03/05 22:08:00 - INFO - root -   Epoch: [193/300][160/200], lr: 0.00000058 	 loss = 0.1264(0.4416)
2024/03/05 22:08:40 - INFO - root -   Epoch: [193/300][180/200], lr: 0.00000058 	 loss = 0.3438(0.4510)
2024/03/05 22:08:58 - INFO - root -   Epoch: [193/300] 	 loss = 0.4505
2024/03/05 22:08:58 - INFO - root -   train_accuracy = 0.8450
2024/03/05 22:09:36 - INFO - root -   Epoch: [194/300][0/200], lr: 0.00000058 	 loss = 0.8978(0.8978)
2024/03/05 22:10:12 - INFO - root -   Epoch: [194/300][20/200], lr: 0.00000058 	 loss = 0.3105(0.4460)
2024/03/05 22:10:52 - INFO - root -   Epoch: [194/300][40/200], lr: 0.00000058 	 loss = 0.2317(0.3950)
2024/03/05 22:11:32 - INFO - root -   Epoch: [194/300][60/200], lr: 0.00000058 	 loss = 0.1944(0.3641)
2024/03/05 22:12:21 - INFO - root -   Epoch: [194/300][80/200], lr: 0.00000058 	 loss = 1.7850(0.3899)
2024/03/05 22:13:00 - INFO - root -   Epoch: [194/300][100/200], lr: 0.00000058 	 loss = 0.1245(0.3845)
2024/03/05 22:13:41 - INFO - root -   Epoch: [194/300][120/200], lr: 0.00000058 	 loss = 2.4934(0.4014)
2024/03/05 22:14:23 - INFO - root -   Epoch: [194/300][140/200], lr: 0.00000058 	 loss = 1.8025(0.4084)
2024/03/05 22:14:59 - INFO - root -   Epoch: [194/300][160/200], lr: 0.00000058 	 loss = 0.0850(0.4107)
2024/03/05 22:15:38 - INFO - root -   Epoch: [194/300][180/200], lr: 0.00000058 	 loss = 0.0779(0.4128)
2024/03/05 22:15:50 - INFO - root -   Epoch: [194/300] 	 loss = 0.4152
2024/03/05 22:15:54 - INFO - root -   precision = 0.7333
2024/03/05 22:15:54 - INFO - root -   eval_loss = 1.1739
2024/03/05 22:15:54 - INFO - root -   eval_acc = 0.7333
2024/03/05 22:15:55 - INFO - root -   train_accuracy = 0.8550
2024/03/05 22:16:31 - INFO - root -   Epoch: [195/300][0/200], lr: 0.00000058 	 loss = 1.8650(1.8650)
2024/03/05 22:17:12 - INFO - root -   Epoch: [195/300][20/200], lr: 0.00000058 	 loss = 0.0876(0.4414)
2024/03/05 22:17:51 - INFO - root -   Epoch: [195/300][40/200], lr: 0.00000058 	 loss = 0.2303(0.3547)
2024/03/05 22:18:24 - INFO - root -   Epoch: [195/300][60/200], lr: 0.00000058 	 loss = 0.0329(0.3374)
2024/03/05 22:19:22 - INFO - root -   Epoch: [195/300][80/200], lr: 0.00000058 	 loss = 2.6069(0.3847)
2024/03/05 22:19:58 - INFO - root -   Epoch: [195/300][100/200], lr: 0.00000058 	 loss = 0.0307(0.3707)
2024/03/05 22:20:27 - INFO - root -   Epoch: [195/300][120/200], lr: 0.00000058 	 loss = 2.0528(0.3538)
2024/03/05 22:20:59 - INFO - root -   Epoch: [195/300][140/200], lr: 0.00000058 	 loss = 1.3623(0.3591)
2024/03/05 22:22:03 - INFO - root -   Epoch: [195/300][160/200], lr: 0.00000058 	 loss = 0.2190(0.3771)
2024/03/05 22:22:29 - INFO - root -   Epoch: [195/300][180/200], lr: 0.00000058 	 loss = 0.3180(0.3759)
2024/03/05 22:22:37 - INFO - root -   Epoch: [195/300] 	 loss = 0.3753
2024/03/05 22:22:37 - INFO - root -   train_accuracy = 0.8675
2024/03/05 22:23:22 - INFO - root -   Epoch: [196/300][0/200], lr: 0.00000059 	 loss = 0.8042(0.8042)
2024/03/05 22:23:59 - INFO - root -   Epoch: [196/300][20/200], lr: 0.00000059 	 loss = 0.3237(0.5548)
2024/03/05 22:24:41 - INFO - root -   Epoch: [196/300][40/200], lr: 0.00000059 	 loss = 0.0550(0.4468)
2024/03/05 22:25:15 - INFO - root -   Epoch: [196/300][60/200], lr: 0.00000059 	 loss = 0.0275(0.4306)
2024/03/05 22:25:49 - INFO - root -   Epoch: [196/300][80/200], lr: 0.00000059 	 loss = 1.3413(0.4106)
2024/03/05 22:26:40 - INFO - root -   Epoch: [196/300][100/200], lr: 0.00000059 	 loss = 0.0387(0.4023)
2024/03/05 22:27:19 - INFO - root -   Epoch: [196/300][120/200], lr: 0.00000059 	 loss = 3.7304(0.4099)
2024/03/05 22:27:55 - INFO - root -   Epoch: [196/300][140/200], lr: 0.00000059 	 loss = 0.8741(0.4063)
2024/03/05 22:28:37 - INFO - root -   Epoch: [196/300][160/200], lr: 0.00000059 	 loss = 0.1121(0.4155)
2024/03/05 22:29:19 - INFO - root -   Epoch: [196/300][180/200], lr: 0.00000059 	 loss = 0.3398(0.4247)
2024/03/05 22:29:26 - INFO - root -   Epoch: [196/300] 	 loss = 0.4241
2024/03/05 22:29:26 - INFO - root -   train_accuracy = 0.8500
2024/03/05 22:30:12 - INFO - root -   Epoch: [197/300][0/200], lr: 0.00000059 	 loss = 1.1198(1.1198)
2024/03/05 22:30:46 - INFO - root -   Epoch: [197/300][20/200], lr: 0.00000059 	 loss = 0.1426(0.5729)
2024/03/05 22:31:15 - INFO - root -   Epoch: [197/300][40/200], lr: 0.00000059 	 loss = 0.6270(0.4475)
2024/03/05 22:31:52 - INFO - root -   Epoch: [197/300][60/200], lr: 0.00000059 	 loss = 0.0914(0.4167)
2024/03/05 22:32:45 - INFO - root -   Epoch: [197/300][80/200], lr: 0.00000059 	 loss = 2.2895(0.4329)
2024/03/05 22:33:30 - INFO - root -   Epoch: [197/300][100/200], lr: 0.00000059 	 loss = 0.0367(0.4213)
2024/03/05 22:34:09 - INFO - root -   Epoch: [197/300][120/200], lr: 0.00000059 	 loss = 3.5322(0.4324)
2024/03/05 22:34:52 - INFO - root -   Epoch: [197/300][140/200], lr: 0.00000059 	 loss = 0.9045(0.4245)
2024/03/05 22:35:40 - INFO - root -   Epoch: [197/300][160/200], lr: 0.00000059 	 loss = 0.0830(0.4215)
2024/03/05 22:36:12 - INFO - root -   Epoch: [197/300][180/200], lr: 0.00000059 	 loss = 0.0438(0.4314)
2024/03/05 22:36:23 - INFO - root -   Epoch: [197/300] 	 loss = 0.4296
2024/03/05 22:36:23 - INFO - root -   train_accuracy = 0.8625
2024/03/05 22:37:00 - INFO - root -   Epoch: [198/300][0/200], lr: 0.00000059 	 loss = 1.4770(1.4770)
2024/03/05 22:37:47 - INFO - root -   Epoch: [198/300][20/200], lr: 0.00000059 	 loss = 0.1690(0.5132)
2024/03/05 22:38:20 - INFO - root -   Epoch: [198/300][40/200], lr: 0.00000059 	 loss = 0.1497(0.4299)
2024/03/05 22:39:05 - INFO - root -   Epoch: [198/300][60/200], lr: 0.00000059 	 loss = 0.2527(0.4305)
2024/03/05 22:39:42 - INFO - root -   Epoch: [198/300][80/200], lr: 0.00000059 	 loss = 2.4461(0.4690)
2024/03/05 22:40:18 - INFO - root -   Epoch: [198/300][100/200], lr: 0.00000059 	 loss = 0.0193(0.4351)
2024/03/05 22:41:13 - INFO - root -   Epoch: [198/300][120/200], lr: 0.00000059 	 loss = 3.0154(0.4244)
2024/03/05 22:41:41 - INFO - root -   Epoch: [198/300][140/200], lr: 0.00000059 	 loss = 1.3087(0.4303)
2024/03/05 22:42:35 - INFO - root -   Epoch: [198/300][160/200], lr: 0.00000059 	 loss = 0.1962(0.4365)
2024/03/05 22:43:04 - INFO - root -   Epoch: [198/300][180/200], lr: 0.00000059 	 loss = 0.3988(0.4540)
2024/03/05 22:43:15 - INFO - root -   Epoch: [198/300] 	 loss = 0.4482
2024/03/05 22:43:15 - INFO - root -   train_accuracy = 0.8525
2024/03/05 22:43:50 - INFO - root -   Epoch: [199/300][0/200], lr: 0.00000059 	 loss = 0.5866(0.5866)
2024/03/05 22:44:43 - INFO - root -   Epoch: [199/300][20/200], lr: 0.00000059 	 loss = 0.0358(0.4788)
2024/03/05 22:45:15 - INFO - root -   Epoch: [199/300][40/200], lr: 0.00000059 	 loss = 0.3546(0.3826)
2024/03/05 22:45:51 - INFO - root -   Epoch: [199/300][60/200], lr: 0.00000059 	 loss = 0.0228(0.4099)
2024/03/05 22:46:43 - INFO - root -   Epoch: [199/300][80/200], lr: 0.00000059 	 loss = 2.5950(0.4602)
2024/03/05 22:47:18 - INFO - root -   Epoch: [199/300][100/200], lr: 0.00000059 	 loss = 0.0225(0.4379)
2024/03/05 22:48:25 - INFO - root -   Epoch: [199/300][120/200], lr: 0.00000059 	 loss = 1.3748(0.4261)
2024/03/05 22:49:06 - INFO - root -   Epoch: [199/300][140/200], lr: 0.00000059 	 loss = 1.8524(0.4295)
2024/03/05 22:49:39 - INFO - root -   Epoch: [199/300][160/200], lr: 0.00000059 	 loss = 0.0579(0.4296)
2024/03/05 22:50:09 - INFO - root -   Epoch: [199/300][180/200], lr: 0.00000059 	 loss = 0.4347(0.4207)
2024/03/05 22:50:21 - INFO - root -   Epoch: [199/300] 	 loss = 0.4169
2024/03/05 22:50:25 - INFO - root -   precision = 0.7111
2024/03/05 22:50:25 - INFO - root -   eval_loss = 1.1776
2024/03/05 22:50:25 - INFO - root -   eval_acc = 0.7111
2024/03/05 22:50:26 - INFO - root -   train_accuracy = 0.8375
2024/03/05 22:51:01 - INFO - root -   Epoch: [200/300][0/200], lr: 0.00000060 	 loss = 1.0398(1.0398)
2024/03/05 22:51:47 - INFO - root -   Epoch: [200/300][20/200], lr: 0.00000060 	 loss = 0.1592(0.5255)
2024/03/05 22:52:23 - INFO - root -   Epoch: [200/300][40/200], lr: 0.00000060 	 loss = 0.1060(0.4735)
2024/03/05 22:52:59 - INFO - root -   Epoch: [200/300][60/200], lr: 0.00000060 	 loss = 0.0623(0.4304)
2024/03/05 22:53:32 - INFO - root -   Epoch: [200/300][80/200], lr: 0.00000060 	 loss = 2.3743(0.4774)
2024/03/05 22:54:35 - INFO - root -   Epoch: [200/300][100/200], lr: 0.00000060 	 loss = 0.0570(0.4636)
2024/03/05 22:55:00 - INFO - root -   Epoch: [200/300][120/200], lr: 0.00000060 	 loss = 2.0588(0.4441)
2024/03/05 22:55:39 - INFO - root -   Epoch: [200/300][140/200], lr: 0.00000060 	 loss = 1.4689(0.4319)
2024/03/05 22:56:24 - INFO - root -   Epoch: [200/300][160/200], lr: 0.00000060 	 loss = 0.3323(0.4361)
2024/03/05 22:57:02 - INFO - root -   Epoch: [200/300][180/200], lr: 0.00000060 	 loss = 0.0591(0.4501)
2024/03/05 22:57:13 - INFO - root -   Epoch: [200/300] 	 loss = 0.4380
2024/03/05 22:57:13 - INFO - root -   train_accuracy = 0.8625
2024/03/05 22:57:34 - INFO - root -   Epoch: [201/300][0/200], lr: 0.00000060 	 loss = 0.6895(0.6895)
2024/03/05 22:58:31 - INFO - root -   Epoch: [201/300][20/200], lr: 0.00000060 	 loss = 0.2400(0.4767)
2024/03/05 22:59:04 - INFO - root -   Epoch: [201/300][40/200], lr: 0.00000060 	 loss = 0.1177(0.4396)
2024/03/05 22:59:40 - INFO - root -   Epoch: [201/300][60/200], lr: 0.00000060 	 loss = 0.0217(0.4072)
2024/03/05 23:00:21 - INFO - root -   Epoch: [201/300][80/200], lr: 0.00000060 	 loss = 1.8158(0.4565)
2024/03/05 23:01:22 - INFO - root -   Epoch: [201/300][100/200], lr: 0.00000060 	 loss = 0.1287(0.4252)
2024/03/05 23:02:01 - INFO - root -   Epoch: [201/300][120/200], lr: 0.00000060 	 loss = 3.4716(0.4307)
2024/03/05 23:02:31 - INFO - root -   Epoch: [201/300][140/200], lr: 0.00000060 	 loss = 1.0149(0.4171)
2024/03/05 23:03:10 - INFO - root -   Epoch: [201/300][160/200], lr: 0.00000060 	 loss = 0.2377(0.4223)
2024/03/05 23:03:56 - INFO - root -   Epoch: [201/300][180/200], lr: 0.00000060 	 loss = 0.1612(0.4341)
2024/03/05 23:04:05 - INFO - root -   Epoch: [201/300] 	 loss = 0.4245
2024/03/05 23:04:05 - INFO - root -   train_accuracy = 0.8450
2024/03/05 23:04:48 - INFO - root -   Epoch: [202/300][0/200], lr: 0.00000060 	 loss = 1.3936(1.3936)
2024/03/05 23:05:21 - INFO - root -   Epoch: [202/300][20/200], lr: 0.00000060 	 loss = 0.0415(0.5115)
2024/03/05 23:06:01 - INFO - root -   Epoch: [202/300][40/200], lr: 0.00000060 	 loss = 0.4649(0.4158)
2024/03/05 23:06:48 - INFO - root -   Epoch: [202/300][60/200], lr: 0.00000060 	 loss = 0.0281(0.4090)
2024/03/05 23:07:24 - INFO - root -   Epoch: [202/300][80/200], lr: 0.00000060 	 loss = 2.3965(0.4606)
2024/03/05 23:08:00 - INFO - root -   Epoch: [202/300][100/200], lr: 0.00000060 	 loss = 0.1008(0.4514)
2024/03/05 23:08:40 - INFO - root -   Epoch: [202/300][120/200], lr: 0.00000060 	 loss = 3.5026(0.4512)
2024/03/05 23:09:20 - INFO - root -   Epoch: [202/300][140/200], lr: 0.00000060 	 loss = 1.0319(0.4453)
2024/03/05 23:10:07 - INFO - root -   Epoch: [202/300][160/200], lr: 0.00000060 	 loss = 0.1949(0.4381)
2024/03/05 23:10:39 - INFO - root -   Epoch: [202/300][180/200], lr: 0.00000060 	 loss = 0.0775(0.4328)
2024/03/05 23:10:49 - INFO - root -   Epoch: [202/300] 	 loss = 0.4264
2024/03/05 23:10:49 - INFO - root -   train_accuracy = 0.8550
2024/03/05 23:11:23 - INFO - root -   Epoch: [203/300][0/200], lr: 0.00000060 	 loss = 1.5001(1.5001)
2024/03/05 23:12:05 - INFO - root -   Epoch: [203/300][20/200], lr: 0.00000060 	 loss = 0.1491(0.4422)
2024/03/05 23:12:49 - INFO - root -   Epoch: [203/300][40/200], lr: 0.00000060 	 loss = 0.1314(0.3789)
2024/03/05 23:13:32 - INFO - root -   Epoch: [203/300][60/200], lr: 0.00000060 	 loss = 0.0275(0.3586)
2024/03/05 23:14:03 - INFO - root -   Epoch: [203/300][80/200], lr: 0.00000060 	 loss = 2.2822(0.4246)
2024/03/05 23:15:00 - INFO - root -   Epoch: [203/300][100/200], lr: 0.00000060 	 loss = 0.3129(0.4203)
2024/03/05 23:15:51 - INFO - root -   Epoch: [203/300][120/200], lr: 0.00000060 	 loss = 3.6129(0.4382)
2024/03/05 23:16:22 - INFO - root -   Epoch: [203/300][140/200], lr: 0.00000060 	 loss = 1.1972(0.4418)
2024/03/05 23:16:48 - INFO - root -   Epoch: [203/300][160/200], lr: 0.00000060 	 loss = 0.0423(0.4413)
2024/03/05 23:17:26 - INFO - root -   Epoch: [203/300][180/200], lr: 0.00000060 	 loss = 0.0776(0.4451)
2024/03/05 23:17:44 - INFO - root -   Epoch: [203/300] 	 loss = 0.4361
2024/03/05 23:17:44 - INFO - root -   train_accuracy = 0.8350
2024/03/05 23:18:03 - INFO - root -   Epoch: [204/300][0/200], lr: 0.00000060 	 loss = 0.9936(0.9936)
2024/03/05 23:19:06 - INFO - root -   Epoch: [204/300][20/200], lr: 0.00000060 	 loss = 0.0742(0.4847)
2024/03/05 23:19:53 - INFO - root -   Epoch: [204/300][40/200], lr: 0.00000060 	 loss = 0.0967(0.4631)
2024/03/05 23:20:26 - INFO - root -   Epoch: [204/300][60/200], lr: 0.00000060 	 loss = 0.0834(0.4513)
2024/03/05 23:20:58 - INFO - root -   Epoch: [204/300][80/200], lr: 0.00000060 	 loss = 2.3899(0.4588)
2024/03/05 23:22:01 - INFO - root -   Epoch: [204/300][100/200], lr: 0.00000060 	 loss = 0.0573(0.4291)
2024/03/05 23:22:33 - INFO - root -   Epoch: [204/300][120/200], lr: 0.00000060 	 loss = 2.2676(0.4175)
2024/03/05 23:23:03 - INFO - root -   Epoch: [204/300][140/200], lr: 0.00000060 	 loss = 0.5157(0.4058)
2024/03/05 23:23:41 - INFO - root -   Epoch: [204/300][160/200], lr: 0.00000060 	 loss = 0.0520(0.4203)
2024/03/05 23:24:23 - INFO - root -   Epoch: [204/300][180/200], lr: 0.00000060 	 loss = 0.0560(0.4156)
2024/03/05 23:24:31 - INFO - root -   Epoch: [204/300] 	 loss = 0.4117
2024/03/05 23:24:35 - INFO - root -   precision = 0.7111
2024/03/05 23:24:35 - INFO - root -   eval_loss = 1.1709
2024/03/05 23:24:35 - INFO - root -   eval_acc = 0.7111
2024/03/05 23:24:36 - INFO - root -   train_accuracy = 0.8475
2024/03/05 23:25:13 - INFO - root -   Epoch: [205/300][0/200], lr: 0.00000061 	 loss = 0.9456(0.9456)
2024/03/05 23:25:53 - INFO - root -   Epoch: [205/300][20/200], lr: 0.00000061 	 loss = 0.2293(0.4123)
2024/03/05 23:26:28 - INFO - root -   Epoch: [205/300][40/200], lr: 0.00000061 	 loss = 0.0571(0.4033)
2024/03/05 23:27:10 - INFO - root -   Epoch: [205/300][60/200], lr: 0.00000061 	 loss = 0.0238(0.4218)
2024/03/05 23:27:55 - INFO - root -   Epoch: [205/300][80/200], lr: 0.00000061 	 loss = 0.7856(0.4520)
2024/03/05 23:28:27 - INFO - root -   Epoch: [205/300][100/200], lr: 0.00000061 	 loss = 0.0883(0.4189)
2024/03/05 23:29:16 - INFO - root -   Epoch: [205/300][120/200], lr: 0.00000061 	 loss = 2.3420(0.4331)
2024/03/05 23:29:53 - INFO - root -   Epoch: [205/300][140/200], lr: 0.00000061 	 loss = 1.8096(0.4311)
2024/03/05 23:30:44 - INFO - root -   Epoch: [205/300][160/200], lr: 0.00000061 	 loss = 0.3243(0.4202)
2024/03/05 23:31:10 - INFO - root -   Epoch: [205/300][180/200], lr: 0.00000061 	 loss = 0.4755(0.4295)
2024/03/05 23:31:29 - INFO - root -   Epoch: [205/300] 	 loss = 0.4223
2024/03/05 23:31:29 - INFO - root -   train_accuracy = 0.8700
2024/03/05 23:31:58 - INFO - root -   Epoch: [206/300][0/200], lr: 0.00000061 	 loss = 0.8966(0.8966)
2024/03/05 23:32:59 - INFO - root -   Epoch: [206/300][20/200], lr: 0.00000061 	 loss = 0.0863(0.4004)
2024/03/05 23:33:31 - INFO - root -   Epoch: [206/300][40/200], lr: 0.00000061 	 loss = 0.4914(0.3750)
2024/03/05 23:34:03 - INFO - root -   Epoch: [206/300][60/200], lr: 0.00000061 	 loss = 0.1146(0.3602)
2024/03/05 23:34:41 - INFO - root -   Epoch: [206/300][80/200], lr: 0.00000061 	 loss = 1.6683(0.3749)
2024/03/05 23:35:32 - INFO - root -   Epoch: [206/300][100/200], lr: 0.00000061 	 loss = 0.1050(0.3670)
2024/03/05 23:36:11 - INFO - root -   Epoch: [206/300][120/200], lr: 0.00000061 	 loss = 2.3066(0.3668)
2024/03/05 23:36:47 - INFO - root -   Epoch: [206/300][140/200], lr: 0.00000061 	 loss = 2.0771(0.3770)
2024/03/05 23:37:12 - INFO - root -   Epoch: [206/300][160/200], lr: 0.00000061 	 loss = 0.7570(0.3982)
2024/03/05 23:38:00 - INFO - root -   Epoch: [206/300][180/200], lr: 0.00000061 	 loss = 0.0685(0.4083)
2024/03/05 23:38:11 - INFO - root -   Epoch: [206/300] 	 loss = 0.4221
2024/03/05 23:38:11 - INFO - root -   train_accuracy = 0.8325
2024/03/05 23:38:48 - INFO - root -   Epoch: [207/300][0/200], lr: 0.00000061 	 loss = 2.0726(2.0726)
2024/03/05 23:39:33 - INFO - root -   Epoch: [207/300][20/200], lr: 0.00000061 	 loss = 0.3356(0.5550)
2024/03/05 23:40:20 - INFO - root -   Epoch: [207/300][40/200], lr: 0.00000061 	 loss = 0.2374(0.4572)
2024/03/05 23:40:59 - INFO - root -   Epoch: [207/300][60/200], lr: 0.00000061 	 loss = 0.0503(0.4194)
2024/03/05 23:41:32 - INFO - root -   Epoch: [207/300][80/200], lr: 0.00000061 	 loss = 1.8952(0.4411)
2024/03/05 23:42:31 - INFO - root -   Epoch: [207/300][100/200], lr: 0.00000061 	 loss = 0.0429(0.4277)
2024/03/05 23:42:59 - INFO - root -   Epoch: [207/300][120/200], lr: 0.00000061 	 loss = 2.5165(0.4153)
2024/03/05 23:43:36 - INFO - root -   Epoch: [207/300][140/200], lr: 0.00000061 	 loss = 1.5286(0.4191)
2024/03/05 23:44:12 - INFO - root -   Epoch: [207/300][160/200], lr: 0.00000061 	 loss = 0.0822(0.4208)
2024/03/05 23:44:54 - INFO - root -   Epoch: [207/300][180/200], lr: 0.00000061 	 loss = 0.1765(0.4254)
2024/03/05 23:45:07 - INFO - root -   Epoch: [207/300] 	 loss = 0.4153
2024/03/05 23:45:07 - INFO - root -   train_accuracy = 0.8625
2024/03/05 23:45:46 - INFO - root -   Epoch: [208/300][0/200], lr: 0.00000061 	 loss = 0.6483(0.6483)
2024/03/05 23:46:30 - INFO - root -   Epoch: [208/300][20/200], lr: 0.00000061 	 loss = 0.2474(0.4757)
2024/03/05 23:47:09 - INFO - root -   Epoch: [208/300][40/200], lr: 0.00000061 	 loss = 0.3727(0.3984)
2024/03/05 23:47:40 - INFO - root -   Epoch: [208/300][60/200], lr: 0.00000061 	 loss = 0.0271(0.3718)
2024/03/05 23:48:15 - INFO - root -   Epoch: [208/300][80/200], lr: 0.00000061 	 loss = 1.8739(0.4296)
2024/03/05 23:49:19 - INFO - root -   Epoch: [208/300][100/200], lr: 0.00000061 	 loss = 0.1947(0.4033)
2024/03/05 23:49:39 - INFO - root -   Epoch: [208/300][120/200], lr: 0.00000061 	 loss = 3.7422(0.4064)
2024/03/05 23:50:21 - INFO - root -   Epoch: [208/300][140/200], lr: 0.00000061 	 loss = 1.7608(0.4107)
2024/03/05 23:50:58 - INFO - root -   Epoch: [208/300][160/200], lr: 0.00000061 	 loss = 0.0586(0.4113)
2024/03/05 23:51:48 - INFO - root -   Epoch: [208/300][180/200], lr: 0.00000061 	 loss = 0.0246(0.4196)
2024/03/05 23:51:56 - INFO - root -   Epoch: [208/300] 	 loss = 0.4049
2024/03/05 23:51:56 - INFO - root -   train_accuracy = 0.8600
2024/03/05 23:52:20 - INFO - root -   Epoch: [209/300][0/200], lr: 0.00000062 	 loss = 0.5550(0.5550)
2024/03/05 23:53:11 - INFO - root -   Epoch: [209/300][20/200], lr: 0.00000062 	 loss = 0.1012(0.3749)
2024/03/05 23:54:01 - INFO - root -   Epoch: [209/300][40/200], lr: 0.00000062 	 loss = 0.0954(0.3235)
2024/03/05 23:54:33 - INFO - root -   Epoch: [209/300][60/200], lr: 0.00000062 	 loss = 0.0453(0.3581)
2024/03/05 23:55:23 - INFO - root -   Epoch: [209/300][80/200], lr: 0.00000062 	 loss = 1.2830(0.3819)
2024/03/05 23:55:52 - INFO - root -   Epoch: [209/300][100/200], lr: 0.00000062 	 loss = 0.0986(0.3797)
2024/03/05 23:56:29 - INFO - root -   Epoch: [209/300][120/200], lr: 0.00000062 	 loss = 1.0941(0.3641)
2024/03/05 23:57:08 - INFO - root -   Epoch: [209/300][140/200], lr: 0.00000062 	 loss = 0.9118(0.3762)
2024/03/05 23:57:45 - INFO - root -   Epoch: [209/300][160/200], lr: 0.00000062 	 loss = 0.4425(0.3964)
2024/03/05 23:58:37 - INFO - root -   Epoch: [209/300][180/200], lr: 0.00000062 	 loss = 1.1701(0.4129)
2024/03/05 23:58:47 - INFO - root -   Epoch: [209/300] 	 loss = 0.4092
2024/03/05 23:58:50 - INFO - root -   precision = 0.7556
2024/03/05 23:58:50 - INFO - root -   eval_loss = 1.2538
2024/03/05 23:58:50 - INFO - root -   eval_acc = 0.7556
2024/03/05 23:58:51 - INFO - root -   train_accuracy = 0.8675
2024/03/05 23:59:27 - INFO - root -   Epoch: [210/300][0/200], lr: 0.00000062 	 loss = 1.4413(1.4413)
2024/03/06 00:00:12 - INFO - root -   Epoch: [210/300][20/200], lr: 0.00000062 	 loss = 0.2417(0.4643)
2024/03/06 00:00:44 - INFO - root -   Epoch: [210/300][40/200], lr: 0.00000062 	 loss = 0.0333(0.4349)
2024/03/06 00:01:22 - INFO - root -   Epoch: [210/300][60/200], lr: 0.00000062 	 loss = 0.0534(0.3977)
2024/03/06 00:02:21 - INFO - root -   Epoch: [210/300][80/200], lr: 0.00000062 	 loss = 1.3311(0.4198)
2024/03/06 00:03:02 - INFO - root -   Epoch: [210/300][100/200], lr: 0.00000062 	 loss = 0.7616(0.4257)
2024/03/06 00:03:34 - INFO - root -   Epoch: [210/300][120/200], lr: 0.00000062 	 loss = 2.6923(0.4235)
2024/03/06 00:04:10 - INFO - root -   Epoch: [210/300][140/200], lr: 0.00000062 	 loss = 1.9276(0.4221)
2024/03/06 00:05:16 - INFO - root -   Epoch: [210/300][160/200], lr: 0.00000062 	 loss = 0.2837(0.4254)
2024/03/06 00:05:33 - INFO - root -   Epoch: [210/300][180/200], lr: 0.00000062 	 loss = 0.1128(0.4258)
2024/03/06 00:05:46 - INFO - root -   Epoch: [210/300] 	 loss = 0.4182
2024/03/06 00:05:46 - INFO - root -   train_accuracy = 0.8625
2024/03/06 00:06:28 - INFO - root -   Epoch: [211/300][0/200], lr: 0.00000062 	 loss = 1.1626(1.1626)
2024/03/06 00:07:12 - INFO - root -   Epoch: [211/300][20/200], lr: 0.00000062 	 loss = 0.0474(0.4481)
2024/03/06 00:07:48 - INFO - root -   Epoch: [211/300][40/200], lr: 0.00000062 	 loss = 0.4213(0.4211)
2024/03/06 00:08:26 - INFO - root -   Epoch: [211/300][60/200], lr: 0.00000062 	 loss = 0.0274(0.4142)
2024/03/06 00:08:57 - INFO - root -   Epoch: [211/300][80/200], lr: 0.00000062 	 loss = 1.6846(0.4374)
2024/03/06 00:09:52 - INFO - root -   Epoch: [211/300][100/200], lr: 0.00000062 	 loss = 0.1104(0.4314)
2024/03/06 00:10:28 - INFO - root -   Epoch: [211/300][120/200], lr: 0.00000062 	 loss = 3.9718(0.4339)
2024/03/06 00:10:59 - INFO - root -   Epoch: [211/300][140/200], lr: 0.00000062 	 loss = 1.2504(0.4209)
2024/03/06 00:11:41 - INFO - root -   Epoch: [211/300][160/200], lr: 0.00000062 	 loss = 0.2375(0.4381)
2024/03/06 00:12:30 - INFO - root -   Epoch: [211/300][180/200], lr: 0.00000062 	 loss = 0.0755(0.4448)
2024/03/06 00:12:38 - INFO - root -   Epoch: [211/300] 	 loss = 0.4381
2024/03/06 00:12:38 - INFO - root -   train_accuracy = 0.8500
2024/03/06 00:13:02 - INFO - root -   Epoch: [212/300][0/200], lr: 0.00000062 	 loss = 0.7183(0.7183)
2024/03/06 00:13:51 - INFO - root -   Epoch: [212/300][20/200], lr: 0.00000062 	 loss = 0.0489(0.3094)
2024/03/06 00:14:29 - INFO - root -   Epoch: [212/300][40/200], lr: 0.00000062 	 loss = 0.0816(0.2839)
2024/03/06 00:15:09 - INFO - root -   Epoch: [212/300][60/200], lr: 0.00000062 	 loss = 0.0575(0.3107)
2024/03/06 00:15:53 - INFO - root -   Epoch: [212/300][80/200], lr: 0.00000062 	 loss = 1.8296(0.3887)
2024/03/06 00:16:49 - INFO - root -   Epoch: [212/300][100/200], lr: 0.00000062 	 loss = 0.0910(0.3668)
2024/03/06 00:17:20 - INFO - root -   Epoch: [212/300][120/200], lr: 0.00000062 	 loss = 2.7511(0.3776)
2024/03/06 00:17:51 - INFO - root -   Epoch: [212/300][140/200], lr: 0.00000062 	 loss = 1.6902(0.3817)
2024/03/06 00:18:36 - INFO - root -   Epoch: [212/300][160/200], lr: 0.00000062 	 loss = 0.1579(0.3937)
2024/03/06 00:19:08 - INFO - root -   Epoch: [212/300][180/200], lr: 0.00000062 	 loss = 0.8484(0.4008)
2024/03/06 00:19:18 - INFO - root -   Epoch: [212/300] 	 loss = 0.4038
2024/03/06 00:19:18 - INFO - root -   train_accuracy = 0.8625
2024/03/06 00:19:41 - INFO - root -   Epoch: [213/300][0/200], lr: 0.00000063 	 loss = 1.8514(1.8514)
2024/03/06 00:20:26 - INFO - root -   Epoch: [213/300][20/200], lr: 0.00000063 	 loss = 0.0410(0.5442)
2024/03/06 00:21:11 - INFO - root -   Epoch: [213/300][40/200], lr: 0.00000063 	 loss = 0.0405(0.4875)
2024/03/06 00:21:45 - INFO - root -   Epoch: [213/300][60/200], lr: 0.00000063 	 loss = 0.0093(0.4964)
2024/03/06 00:22:25 - INFO - root -   Epoch: [213/300][80/200], lr: 0.00000063 	 loss = 0.9027(0.4694)
2024/03/06 00:23:08 - INFO - root -   Epoch: [213/300][100/200], lr: 0.00000063 	 loss = 0.0649(0.4416)
2024/03/06 00:23:54 - INFO - root -   Epoch: [213/300][120/200], lr: 0.00000063 	 loss = 2.5651(0.4391)
2024/03/06 00:24:33 - INFO - root -   Epoch: [213/300][140/200], lr: 0.00000063 	 loss = 1.1249(0.4283)
2024/03/06 00:25:07 - INFO - root -   Epoch: [213/300][160/200], lr: 0.00000063 	 loss = 0.1449(0.4237)
2024/03/06 00:25:57 - INFO - root -   Epoch: [213/300][180/200], lr: 0.00000063 	 loss = 0.9739(0.4351)
2024/03/06 00:26:05 - INFO - root -   Epoch: [213/300] 	 loss = 0.4310
2024/03/06 00:26:05 - INFO - root -   train_accuracy = 0.8550
2024/03/06 00:26:39 - INFO - root -   Epoch: [214/300][0/200], lr: 0.00000063 	 loss = 1.5551(1.5551)
2024/03/06 00:27:10 - INFO - root -   Epoch: [214/300][20/200], lr: 0.00000063 	 loss = 0.0785(0.5566)
2024/03/06 00:27:56 - INFO - root -   Epoch: [214/300][40/200], lr: 0.00000063 	 loss = 0.1835(0.4407)
2024/03/06 00:28:32 - INFO - root -   Epoch: [214/300][60/200], lr: 0.00000063 	 loss = 0.0392(0.4311)
2024/03/06 00:29:27 - INFO - root -   Epoch: [214/300][80/200], lr: 0.00000063 	 loss = 1.9275(0.4637)
2024/03/06 00:30:11 - INFO - root -   Epoch: [214/300][100/200], lr: 0.00000063 	 loss = 0.1663(0.4413)
2024/03/06 00:30:51 - INFO - root -   Epoch: [214/300][120/200], lr: 0.00000063 	 loss = 2.5855(0.4385)
2024/03/06 00:31:29 - INFO - root -   Epoch: [214/300][140/200], lr: 0.00000063 	 loss = 0.4804(0.4231)
2024/03/06 00:32:16 - INFO - root -   Epoch: [214/300][160/200], lr: 0.00000063 	 loss = 0.2344(0.4279)
2024/03/06 00:32:36 - INFO - root -   Epoch: [214/300][180/200], lr: 0.00000063 	 loss = 0.1374(0.4188)
2024/03/06 00:32:54 - INFO - root -   Epoch: [214/300] 	 loss = 0.4261
2024/03/06 00:32:57 - INFO - root -   precision = 0.7111
2024/03/06 00:32:57 - INFO - root -   eval_loss = 1.2926
2024/03/06 00:32:57 - INFO - root -   eval_acc = 0.7111
2024/03/06 00:32:58 - INFO - root -   train_accuracy = 0.8500
2024/03/06 00:33:22 - INFO - root -   Epoch: [215/300][0/200], lr: 0.00000063 	 loss = 0.2850(0.2850)
2024/03/06 00:34:22 - INFO - root -   Epoch: [215/300][20/200], lr: 0.00000063 	 loss = 0.0730(0.3781)
2024/03/06 00:34:58 - INFO - root -   Epoch: [215/300][40/200], lr: 0.00000063 	 loss = 0.7710(0.3572)
2024/03/06 00:35:34 - INFO - root -   Epoch: [215/300][60/200], lr: 0.00000063 	 loss = 0.1286(0.3639)
2024/03/06 00:36:23 - INFO - root -   Epoch: [215/300][80/200], lr: 0.00000063 	 loss = 2.2643(0.4092)
2024/03/06 00:36:54 - INFO - root -   Epoch: [215/300][100/200], lr: 0.00000063 	 loss = 0.0652(0.3959)
2024/03/06 00:37:32 - INFO - root -   Epoch: [215/300][120/200], lr: 0.00000063 	 loss = 3.0636(0.3861)
2024/03/06 00:38:28 - INFO - root -   Epoch: [215/300][140/200], lr: 0.00000063 	 loss = 1.5683(0.3846)
2024/03/06 00:39:11 - INFO - root -   Epoch: [215/300][160/200], lr: 0.00000063 	 loss = 0.0436(0.3965)
2024/03/06 00:39:46 - INFO - root -   Epoch: [215/300][180/200], lr: 0.00000063 	 loss = 0.1473(0.3962)
2024/03/06 00:39:55 - INFO - root -   Epoch: [215/300] 	 loss = 0.4130
2024/03/06 00:39:55 - INFO - root -   train_accuracy = 0.8450
2024/03/06 00:40:35 - INFO - root -   Epoch: [216/300][0/200], lr: 0.00000063 	 loss = 1.9686(1.9686)
2024/03/06 00:41:24 - INFO - root -   Epoch: [216/300][20/200], lr: 0.00000063 	 loss = 0.1666(0.5453)
2024/03/06 00:41:55 - INFO - root -   Epoch: [216/300][40/200], lr: 0.00000063 	 loss = 0.0992(0.4484)
2024/03/06 00:42:38 - INFO - root -   Epoch: [216/300][60/200], lr: 0.00000063 	 loss = 0.0741(0.4382)
2024/03/06 00:43:17 - INFO - root -   Epoch: [216/300][80/200], lr: 0.00000063 	 loss = 0.4739(0.4271)
2024/03/06 00:44:07 - INFO - root -   Epoch: [216/300][100/200], lr: 0.00000063 	 loss = 0.0220(0.4258)
2024/03/06 00:44:39 - INFO - root -   Epoch: [216/300][120/200], lr: 0.00000063 	 loss = 2.9962(0.4211)
2024/03/06 00:45:15 - INFO - root -   Epoch: [216/300][140/200], lr: 0.00000063 	 loss = 0.7930(0.4157)
2024/03/06 00:45:53 - INFO - root -   Epoch: [216/300][160/200], lr: 0.00000063 	 loss = 0.0509(0.4138)
2024/03/06 00:46:47 - INFO - root -   Epoch: [216/300][180/200], lr: 0.00000063 	 loss = 0.2524(0.4196)
2024/03/06 00:46:55 - INFO - root -   Epoch: [216/300] 	 loss = 0.4157
2024/03/06 00:46:55 - INFO - root -   train_accuracy = 0.8550
2024/03/06 00:59:06 - INFO - root -   Num train examples = 400
2024/03/06 00:59:06 - INFO - root -   Num val examples = 45
2024/03/06 00:59:24 - INFO - root -   Num train examples = 400
2024/03/06 00:59:24 - INFO - root -   Num val examples = 45
2024/03/06 01:03:23 - INFO - root -   Num train examples = 400
2024/03/06 01:03:23 - INFO - root -   Num val examples = 45
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.0181818176060915
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.036363635212183
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.05454545468091965
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.072727270424366
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.09090908616781235
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.10909091681241989
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.12727272510528564
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.1454545557498932
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Drop path rate: 0.16363637149333954
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:23 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Drop path rate: 0.1818181872367859
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Drop path rate: 0.20000000298023224
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   No L_MHRA: True
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Use checkpoint: False
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Checkpoint number: [0]
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Drop path rate: 0.13333334028720856
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Drop path rate: 0.2666666507720947
2024/03/06 01:03:24 - INFO - models.uniformerv2_model -   Drop path rate: 0.4000000059604645
2024/03/06 01:03:24 - INFO - root -   backend = nccl
2024/03/06 01:03:24 - INFO - root -   batch_size = 2
2024/03/06 01:03:24 - INFO - root -   dropout = 0.5
2024/03/06 01:03:24 - INFO - root -   epochs = 100
2024/03/06 01:03:24 - INFO - root -   eval_freq = 5
2024/03/06 01:03:24 - INFO - root -   focal_loss = False
2024/03/06 01:03:24 - INFO - root -   input_size = 128
2024/03/06 01:03:24 - INFO - root -   is_pretrained = False
2024/03/06 01:03:24 - INFO - root -   label_smooth = False
2024/03/06 01:03:24 - INFO - root -   local_rank = -1
2024/03/06 01:03:24 - INFO - root -   lr = 1e-05
2024/03/06 01:03:24 - INFO - root -   lr_decay_rate = 0.1
2024/03/06 01:03:24 - INFO - root -   lr_steps = [50, 100]
2024/03/06 01:03:24 - INFO - root -   lr_type = cosine
2024/03/06 01:03:24 - INFO - root -   model_depth = 34
2024/03/06 01:03:24 - INFO - root -   model_name = resnet50
2024/03/06 01:03:24 - INFO - root -   momentum = 0.9
2024/03/06 01:03:24 - INFO - root -   num_classes = 3
2024/03/06 01:03:24 - INFO - root -   output = ./ucsf_roi_3grade_outputs
2024/03/06 01:03:24 - INFO - root -   print_freq = 20
2024/03/06 01:03:24 - INFO - root -   resume = 
2024/03/06 01:03:24 - INFO - root -   start_epoch = 0
2024/03/06 01:03:24 - INFO - root -   test_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_test_patients.txt
2024/03/06 01:03:24 - INFO - root -   train_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_train_patients.txt
2024/03/06 01:03:24 - INFO - root -   tune_from = 
2024/03/06 01:03:24 - INFO - root -   val_list = /media/spgou/FAST/ZYJ/Glioma_MTTU/data/ucsf_val_patients.txt
2024/03/06 01:03:24 - INFO - root -   warmup_epoch = 20
2024/03/06 01:03:24 - INFO - root -   warmup_multiplier = 100
2024/03/06 01:03:24 - INFO - root -   weight_decay = 0.0005
2024/03/06 01:03:24 - INFO - root -   workers = 16
2024/03/06 01:04:14 - INFO - root -   Epoch: [0/100][0/200], lr: 0.00000010 	 loss = 1.4877(1.4877)
