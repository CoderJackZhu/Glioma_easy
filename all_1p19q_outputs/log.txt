2023/10/31 19:57:46 - INFO - root -   Num train examples = 107
2023/10/31 19:57:46 - INFO - root -   Num val examples = 27
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.0181818176060915
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.036363635212183
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.05454545468091965
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.072727270424366
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.09090908616781235
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.10909091681241989
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.12727272510528564
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.1454545557498932
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.16363637149333954
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.1818181872367859
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.20000000298023224
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Use checkpoint: False
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Checkpoint number: [0]
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.13333334028720856
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.2666666507720947
2023/10/31 19:57:46 - INFO - models.uniformerv2_model -   Drop path rate: 0.4000000059604645
2023/10/31 19:57:46 - INFO - root -   backend = nccl
2023/10/31 19:57:46 - INFO - root -   batch_size = 2
2023/10/31 19:57:46 - INFO - root -   dropout = 0.5
2023/10/31 19:57:46 - INFO - root -   epochs = 300
2023/10/31 19:57:46 - INFO - root -   eval_freq = 5
2023/10/31 19:57:46 - INFO - root -   focal_loss = False
2023/10/31 19:57:46 - INFO - root -   input_size = 224
2023/10/31 19:57:46 - INFO - root -   is_pretrained = False
2023/10/31 19:57:46 - INFO - root -   label_smooth = False
2023/10/31 19:57:46 - INFO - root -   local_rank = -1
2023/10/31 19:57:46 - INFO - root -   lr = 1e-05
2023/10/31 19:57:46 - INFO - root -   lr_decay_rate = 0.1
2023/10/31 19:57:46 - INFO - root -   lr_steps = [50, 100]
2023/10/31 19:57:46 - INFO - root -   lr_type = cosine
2023/10/31 19:57:46 - INFO - root -   model_depth = 34
2023/10/31 19:57:46 - INFO - root -   model_name = resnet50
2023/10/31 19:57:46 - INFO - root -   momentum = 0.9
2023/10/31 19:57:46 - INFO - root -   num_classes = 2
2023/10/31 19:57:46 - INFO - root -   output = ./all_1p19q_outputs
2023/10/31 19:57:46 - INFO - root -   print_freq = 20
2023/10/31 19:57:46 - INFO - root -   resume = 
2023/10/31 19:57:46 - INFO - root -   start_epoch = 0
2023/10/31 19:57:46 - INFO - root -   train_list = /media/spgou/DATA/ZYJ/Glioma_easy/dataset/train_patients.txt
2023/10/31 19:57:46 - INFO - root -   tune_from = 
2023/10/31 19:57:46 - INFO - root -   val_list = /media/spgou/DATA/ZYJ/Glioma_easy/dataset/test_patients.txt
2023/10/31 19:57:46 - INFO - root -   warmup_epoch = 20
2023/10/31 19:57:46 - INFO - root -   warmup_multiplier = 100
2023/10/31 19:57:46 - INFO - root -   weight_decay = 0.0005
2023/10/31 19:57:46 - INFO - root -   workers = 8
2023/10/31 19:58:24 - INFO - root -   Epoch: [0/300][0/53], lr: 0.00000010 	 loss = 0.9803(0.9803)
2023/10/31 19:59:21 - INFO - root -   Epoch: [0/300][20/53], lr: 0.00000010 	 loss = 0.6304(0.9844)
2023/10/31 20:00:25 - INFO - root -   Epoch: [0/300][40/53], lr: 0.00000010 	 loss = 0.4005(0.9830)
2023/10/31 20:00:49 - INFO - root -   Epoch: [0/300] 	 loss = 0.9522
2023/10/31 20:00:49 - INFO - root -   train_accuracy = 0.4245
2023/10/31 20:01:34 - INFO - root -   Epoch: [1/300][0/53], lr: 0.00000011 	 loss = 0.4725(0.4725)
2023/10/31 20:02:29 - INFO - root -   Epoch: [1/300][20/53], lr: 0.00000011 	 loss = 0.9122(0.8245)
2023/10/31 20:03:41 - INFO - root -   Epoch: [1/300][40/53], lr: 0.00000011 	 loss = 0.5435(0.8081)
2023/10/31 20:03:50 - INFO - root -   Epoch: [1/300] 	 loss = 0.8087
2023/10/31 20:03:50 - INFO - root -   train_accuracy = 0.4340
2023/10/31 20:04:21 - INFO - root -   Epoch: [2/300][0/53], lr: 0.00000012 	 loss = 0.9399(0.9399)
2023/10/31 20:05:14 - INFO - root -   Epoch: [2/300][20/53], lr: 0.00000012 	 loss = 0.4372(0.7629)
2023/10/31 20:06:45 - INFO - root -   Epoch: [2/300][40/53], lr: 0.00000012 	 loss = 0.4078(0.7812)
2023/10/31 20:06:53 - INFO - root -   Epoch: [2/300] 	 loss = 0.7634
2023/10/31 20:06:53 - INFO - root -   train_accuracy = 0.5566
2023/10/31 20:07:15 - INFO - root -   Epoch: [3/300][0/53], lr: 0.00000013 	 loss = 0.6495(0.6495)
2023/10/31 20:08:35 - INFO - root -   Epoch: [3/300][20/53], lr: 0.00000013 	 loss = 1.0979(0.6775)
2023/10/31 20:09:47 - INFO - root -   Epoch: [3/300][40/53], lr: 0.00000013 	 loss = 0.6147(0.6243)
2023/10/31 20:09:55 - INFO - root -   Epoch: [3/300] 	 loss = 0.5954
2023/10/31 20:09:55 - INFO - root -   train_accuracy = 0.6981
2023/10/31 20:10:27 - INFO - root -   Epoch: [4/300][0/53], lr: 0.00000014 	 loss = 0.3440(0.3440)
2023/10/31 20:11:27 - INFO - root -   Epoch: [4/300][20/53], lr: 0.00000014 	 loss = 0.9497(0.6134)
2023/10/31 20:12:43 - INFO - root -   Epoch: [4/300][40/53], lr: 0.00000014 	 loss = 1.3426(0.6335)
2023/10/31 20:12:51 - INFO - root -   Epoch: [4/300] 	 loss = 0.6320
2023/10/31 20:13:36 - INFO - root -   precision = 0.7407
2023/10/31 20:13:36 - INFO - root -   eval_loss = 0.5834
2023/10/31 20:13:36 - INFO - root -   eval_acc = 0.7407
2023/10/31 20:13:37 - INFO - root -   train_accuracy = 0.6887
2023/10/31 20:13:59 - INFO - root -   Epoch: [5/300][0/53], lr: 0.00000015 	 loss = 0.1949(0.1949)
2023/10/31 20:15:27 - INFO - root -   Epoch: [5/300][20/53], lr: 0.00000015 	 loss = 0.7749(0.7317)
2023/10/31 20:16:16 - INFO - root -   Epoch: [5/300][40/53], lr: 0.00000015 	 loss = 1.0441(0.6544)
2023/10/31 20:16:50 - INFO - root -   Epoch: [5/300] 	 loss = 0.6486
2023/10/31 20:16:50 - INFO - root -   train_accuracy = 0.6698
2023/10/31 20:17:13 - INFO - root -   Epoch: [6/300][0/53], lr: 0.00000016 	 loss = 0.2663(0.2663)
2023/10/31 20:18:18 - INFO - root -   Epoch: [6/300][20/53], lr: 0.00000016 	 loss = 1.1403(0.6724)
2023/10/31 20:19:22 - INFO - root -   Epoch: [6/300][40/53], lr: 0.00000016 	 loss = 0.6171(0.6178)
2023/10/31 20:19:47 - INFO - root -   Epoch: [6/300] 	 loss = 0.6648
2023/10/31 20:19:47 - INFO - root -   train_accuracy = 0.6226
2023/10/31 20:20:32 - INFO - root -   Epoch: [7/300][0/53], lr: 0.00000017 	 loss = 0.5109(0.5109)
2023/10/31 20:21:31 - INFO - root -   Epoch: [7/300][20/53], lr: 0.00000017 	 loss = 1.0784(0.7510)
2023/10/31 20:22:34 - INFO - root -   Epoch: [7/300][40/53], lr: 0.00000017 	 loss = 0.8807(0.6498)
2023/10/31 20:22:49 - INFO - root -   Epoch: [7/300] 	 loss = 0.6810
2023/10/31 20:22:49 - INFO - root -   train_accuracy = 0.6415
2023/10/31 20:23:19 - INFO - root -   Epoch: [8/300][0/53], lr: 0.00000017 	 loss = 0.5353(0.5353)
2023/10/31 20:24:24 - INFO - root -   Epoch: [8/300][20/53], lr: 0.00000017 	 loss = 0.2701(0.6549)
2023/10/31 20:25:50 - INFO - root -   Epoch: [8/300][40/53], lr: 0.00000017 	 loss = 0.6460(0.6984)
2023/10/31 20:25:56 - INFO - root -   Epoch: [8/300] 	 loss = 0.6788
2023/10/31 20:25:56 - INFO - root -   train_accuracy = 0.6792
2023/10/31 20:26:26 - INFO - root -   Epoch: [9/300][0/53], lr: 0.00000018 	 loss = 0.2231(0.2231)
2023/10/31 20:27:26 - INFO - root -   Epoch: [9/300][20/53], lr: 0.00000018 	 loss = 0.7729(0.6631)
2023/10/31 20:28:39 - INFO - root -   Epoch: [9/300][40/53], lr: 0.00000018 	 loss = 1.2445(0.6136)
2023/10/31 20:28:58 - INFO - root -   Epoch: [9/300] 	 loss = 0.6246
2023/10/31 20:29:34 - INFO - root -   precision = 0.7407
2023/10/31 20:29:34 - INFO - root -   eval_loss = 0.5889
2023/10/31 20:29:34 - INFO - root -   eval_acc = 0.7407
2023/10/31 20:29:35 - INFO - root -   train_accuracy = 0.7170
2023/10/31 20:29:57 - INFO - root -   Epoch: [10/300][0/53], lr: 0.00000019 	 loss = 0.6671(0.6671)
2023/10/31 20:31:06 - INFO - root -   Epoch: [10/300][20/53], lr: 0.00000019 	 loss = 0.8466(0.6687)
2023/10/31 20:32:22 - INFO - root -   Epoch: [10/300][40/53], lr: 0.00000019 	 loss = 0.6648(0.6339)
2023/10/31 20:32:38 - INFO - root -   Epoch: [10/300] 	 loss = 0.6311
2023/10/31 20:32:38 - INFO - root -   train_accuracy = 0.6887
2023/10/31 20:33:07 - INFO - root -   Epoch: [11/300][0/53], lr: 0.00000020 	 loss = 0.1299(0.1299)
2023/10/31 20:34:08 - INFO - root -   Epoch: [11/300][20/53], lr: 0.00000020 	 loss = 1.1265(0.6830)
2023/10/31 20:35:13 - INFO - root -   Epoch: [11/300][40/53], lr: 0.00000020 	 loss = 1.1550(0.6324)
2023/10/31 20:35:29 - INFO - root -   Epoch: [11/300] 	 loss = 0.6488
2023/10/31 20:35:29 - INFO - root -   train_accuracy = 0.6981
2023/10/31 20:36:09 - INFO - root -   Epoch: [12/300][0/53], lr: 0.00000021 	 loss = 0.2614(0.2614)
2023/10/31 20:37:05 - INFO - root -   Epoch: [12/300][20/53], lr: 0.00000021 	 loss = 0.7059(0.6629)
2023/10/31 20:38:06 - INFO - root -   Epoch: [12/300][40/53], lr: 0.00000021 	 loss = 1.1285(0.6247)
2023/10/31 20:38:27 - INFO - root -   Epoch: [12/300] 	 loss = 0.6162
2023/10/31 20:38:27 - INFO - root -   train_accuracy = 0.6415
2023/10/31 20:38:56 - INFO - root -   Epoch: [13/300][0/53], lr: 0.00000022 	 loss = 0.0846(0.0846)
2023/10/31 20:39:57 - INFO - root -   Epoch: [13/300][20/53], lr: 0.00000022 	 loss = 0.9124(0.6609)
2023/10/31 20:41:09 - INFO - root -   Epoch: [13/300][40/53], lr: 0.00000022 	 loss = 0.3792(0.6007)
2023/10/31 20:41:19 - INFO - root -   Epoch: [13/300] 	 loss = 0.5951
2023/10/31 20:41:19 - INFO - root -   train_accuracy = 0.7547
2023/10/31 20:41:50 - INFO - root -   Epoch: [14/300][0/53], lr: 0.00000023 	 loss = 0.1158(0.1158)
2023/10/31 20:42:49 - INFO - root -   Epoch: [14/300][20/53], lr: 0.00000023 	 loss = 0.5929(0.6110)
2023/10/31 20:43:56 - INFO - root -   Epoch: [14/300][40/53], lr: 0.00000023 	 loss = 0.4505(0.5766)
2023/10/31 20:44:14 - INFO - root -   Epoch: [14/300] 	 loss = 0.5708
2023/10/31 20:44:50 - INFO - root -   precision = 0.7407
2023/10/31 20:44:50 - INFO - root -   eval_loss = 0.5833
2023/10/31 20:44:50 - INFO - root -   eval_acc = 0.7407
2023/10/31 20:44:51 - INFO - root -   train_accuracy = 0.7453
2023/10/31 20:45:13 - INFO - root -   Epoch: [15/300][0/53], lr: 0.00000024 	 loss = 0.5458(0.5458)
2023/10/31 20:46:20 - INFO - root -   Epoch: [15/300][20/53], lr: 0.00000024 	 loss = 0.5183(0.6665)
2023/10/31 20:47:24 - INFO - root -   Epoch: [15/300][40/53], lr: 0.00000024 	 loss = 0.8167(0.6418)
2023/10/31 20:47:49 - INFO - root -   Epoch: [15/300] 	 loss = 0.6363
2023/10/31 20:47:49 - INFO - root -   train_accuracy = 0.6792
2023/10/31 20:48:10 - INFO - root -   Epoch: [16/300][0/53], lr: 0.00000025 	 loss = 0.1908(0.1908)
2023/10/31 20:49:09 - INFO - root -   Epoch: [16/300][20/53], lr: 0.00000025 	 loss = 1.0037(0.7547)
2023/10/31 20:50:25 - INFO - root -   Epoch: [16/300][40/53], lr: 0.00000025 	 loss = 0.7675(0.6411)
2023/10/31 20:50:40 - INFO - root -   Epoch: [16/300] 	 loss = 0.6784
2023/10/31 20:50:40 - INFO - root -   train_accuracy = 0.6604
2023/10/31 20:51:03 - INFO - root -   Epoch: [17/300][0/53], lr: 0.00000026 	 loss = 0.2762(0.2762)
2023/10/31 20:52:04 - INFO - root -   Epoch: [17/300][20/53], lr: 0.00000026 	 loss = 1.5767(0.7812)
2023/10/31 20:53:14 - INFO - root -   Epoch: [17/300][40/53], lr: 0.00000026 	 loss = 0.5972(0.6445)
2023/10/31 20:53:26 - INFO - root -   Epoch: [17/300] 	 loss = 0.6252
2023/10/31 20:53:26 - INFO - root -   train_accuracy = 0.6887
2023/10/31 20:53:48 - INFO - root -   Epoch: [18/300][0/53], lr: 0.00000027 	 loss = 0.4661(0.4661)
2023/10/31 20:55:10 - INFO - root -   Epoch: [18/300][20/53], lr: 0.00000027 	 loss = 0.9269(0.7301)
2023/10/31 20:56:17 - INFO - root -   Epoch: [18/300][40/53], lr: 0.00000027 	 loss = 0.5790(0.6698)
2023/10/31 20:56:36 - INFO - root -   Epoch: [18/300] 	 loss = 0.6819
2023/10/31 20:56:36 - INFO - root -   train_accuracy = 0.6887
2023/10/31 20:57:06 - INFO - root -   Epoch: [19/300][0/53], lr: 0.00000028 	 loss = 0.2899(0.2899)
2023/10/31 20:58:06 - INFO - root -   Epoch: [19/300][20/53], lr: 0.00000028 	 loss = 0.5656(0.5870)
2023/10/31 20:59:16 - INFO - root -   Epoch: [19/300][40/53], lr: 0.00000028 	 loss = 0.3654(0.5740)
2023/10/31 20:59:38 - INFO - root -   Epoch: [19/300] 	 loss = 0.6156
2023/10/31 21:00:14 - INFO - root -   precision = 0.7407
2023/10/31 21:00:14 - INFO - root -   eval_loss = 0.5782
2023/10/31 21:00:14 - INFO - root -   eval_acc = 0.7407
2023/10/31 21:00:15 - INFO - root -   train_accuracy = 0.7075
2023/10/31 21:00:38 - INFO - root -   Epoch: [20/300][0/53], lr: 0.00000029 	 loss = 0.7693(0.7693)
2023/10/31 21:01:51 - INFO - root -   Epoch: [20/300][20/53], lr: 0.00000029 	 loss = 0.5823(0.7288)
2023/10/31 21:02:49 - INFO - root -   Epoch: [20/300][40/53], lr: 0.00000029 	 loss = 0.7420(0.6795)
2023/10/31 21:03:19 - INFO - root -   Epoch: [20/300] 	 loss = 0.7014
2023/10/31 21:03:19 - INFO - root -   train_accuracy = 0.6604
2023/10/31 21:03:42 - INFO - root -   Epoch: [21/300][0/53], lr: 0.00000030 	 loss = 0.3246(0.3246)
2023/10/31 21:04:48 - INFO - root -   Epoch: [21/300][20/53], lr: 0.00000030 	 loss = 0.5810(0.5480)
2023/10/31 21:05:47 - INFO - root -   Epoch: [21/300][40/53], lr: 0.00000030 	 loss = 0.9602(0.5593)
2023/10/31 21:06:15 - INFO - root -   Epoch: [21/300] 	 loss = 0.5963
2023/10/31 21:06:15 - INFO - root -   train_accuracy = 0.7170
2023/10/31 21:06:45 - INFO - root -   Epoch: [22/300][0/53], lr: 0.00000031 	 loss = 0.1965(0.1965)
2023/10/31 21:07:51 - INFO - root -   Epoch: [22/300][20/53], lr: 0.00000031 	 loss = 1.2588(0.6427)
2023/10/31 21:09:06 - INFO - root -   Epoch: [22/300][40/53], lr: 0.00000031 	 loss = 0.4973(0.5793)
2023/10/31 21:09:11 - INFO - root -   Epoch: [22/300] 	 loss = 0.5939
2023/10/31 21:09:11 - INFO - root -   train_accuracy = 0.6981
2023/10/31 21:09:41 - INFO - root -   Epoch: [23/300][0/53], lr: 0.00000031 	 loss = 0.1393(0.1393)
2023/10/31 21:10:50 - INFO - root -   Epoch: [23/300][20/53], lr: 0.00000031 	 loss = 0.7720(0.6946)
2023/10/31 21:11:50 - INFO - root -   Epoch: [23/300][40/53], lr: 0.00000031 	 loss = 0.7379(0.6386)
2023/10/31 21:12:15 - INFO - root -   Epoch: [23/300] 	 loss = 0.6406
2023/10/31 21:12:15 - INFO - root -   train_accuracy = 0.6698
2023/10/31 21:12:45 - INFO - root -   Epoch: [24/300][0/53], lr: 0.00000032 	 loss = 0.3077(0.3077)
2023/10/31 21:13:52 - INFO - root -   Epoch: [24/300][20/53], lr: 0.00000032 	 loss = 0.6951(0.7191)
2023/10/31 21:14:59 - INFO - root -   Epoch: [24/300][40/53], lr: 0.00000032 	 loss = 1.4084(0.6668)
2023/10/31 21:15:14 - INFO - root -   Epoch: [24/300] 	 loss = 0.6597
2023/10/31 21:15:50 - INFO - root -   precision = 0.7407
2023/10/31 21:15:50 - INFO - root -   eval_loss = 0.5633
2023/10/31 21:15:50 - INFO - root -   eval_acc = 0.7407
2023/10/31 21:15:51 - INFO - root -   train_accuracy = 0.6698
2023/10/31 21:16:21 - INFO - root -   Epoch: [25/300][0/53], lr: 0.00000033 	 loss = 0.3649(0.3649)
2023/10/31 21:17:21 - INFO - root -   Epoch: [25/300][20/53], lr: 0.00000033 	 loss = 1.2208(0.6835)
2023/10/31 21:18:31 - INFO - root -   Epoch: [25/300][40/53], lr: 0.00000033 	 loss = 0.5428(0.6230)
2023/10/31 21:18:41 - INFO - root -   Epoch: [25/300] 	 loss = 0.6273
2023/10/31 21:18:41 - INFO - root -   train_accuracy = 0.6887
2023/10/31 21:19:03 - INFO - root -   Epoch: [26/300][0/53], lr: 0.00000034 	 loss = 0.1729(0.1729)
2023/10/31 21:20:10 - INFO - root -   Epoch: [26/300][20/53], lr: 0.00000034 	 loss = 0.8652(0.6827)
2023/10/31 21:21:08 - INFO - root -   Epoch: [26/300][40/53], lr: 0.00000034 	 loss = 0.7130(0.5924)
2023/10/31 21:21:32 - INFO - root -   Epoch: [26/300] 	 loss = 0.5994
2023/10/31 21:21:32 - INFO - root -   train_accuracy = 0.7075
2023/10/31 21:21:54 - INFO - root -   Epoch: [27/300][0/53], lr: 0.00000035 	 loss = 0.3388(0.3388)
2023/10/31 21:23:10 - INFO - root -   Epoch: [27/300][20/53], lr: 0.00000035 	 loss = 0.8973(0.6393)
2023/10/31 21:24:07 - INFO - root -   Epoch: [27/300][40/53], lr: 0.00000035 	 loss = 1.3245(0.6397)
2023/10/31 21:24:31 - INFO - root -   Epoch: [27/300] 	 loss = 0.6535
2023/10/31 21:24:31 - INFO - root -   train_accuracy = 0.6604
2023/10/31 21:25:01 - INFO - root -   Epoch: [28/300][0/53], lr: 0.00000036 	 loss = 0.1866(0.1866)
2023/10/31 21:26:05 - INFO - root -   Epoch: [28/300][20/53], lr: 0.00000036 	 loss = 1.7485(0.6908)
2023/10/31 21:27:01 - INFO - root -   Epoch: [28/300][40/53], lr: 0.00000036 	 loss = 0.9464(0.6152)
2023/10/31 21:27:22 - INFO - root -   Epoch: [28/300] 	 loss = 0.6529
2023/10/31 21:27:22 - INFO - root -   train_accuracy = 0.6887
2023/10/31 21:27:44 - INFO - root -   Epoch: [29/300][0/53], lr: 0.00000037 	 loss = 0.0926(0.0926)
2023/10/31 21:29:07 - INFO - root -   Epoch: [29/300][20/53], lr: 0.00000037 	 loss = 1.1880(0.6072)
2023/10/31 21:30:14 - INFO - root -   Epoch: [29/300][40/53], lr: 0.00000037 	 loss = 0.9810(0.6141)
2023/10/31 21:30:28 - INFO - root -   Epoch: [29/300] 	 loss = 0.6061
2023/10/31 21:31:04 - INFO - root -   precision = 0.7407
2023/10/31 21:31:04 - INFO - root -   eval_loss = 0.5689
2023/10/31 21:31:04 - INFO - root -   eval_acc = 0.7407
2023/10/31 21:31:05 - INFO - root -   train_accuracy = 0.7075
2023/10/31 21:31:27 - INFO - root -   Epoch: [30/300][0/53], lr: 0.00000038 	 loss = 0.1101(0.1101)
2023/10/31 21:32:33 - INFO - root -   Epoch: [30/300][20/53], lr: 0.00000038 	 loss = 1.0445(0.6397)
2023/10/31 21:33:48 - INFO - root -   Epoch: [30/300][40/53], lr: 0.00000038 	 loss = 0.3270(0.5587)
2023/10/31 21:34:00 - INFO - root -   Epoch: [30/300] 	 loss = 0.5830
2023/10/31 21:34:00 - INFO - root -   train_accuracy = 0.6887
2023/10/31 21:34:30 - INFO - root -   Epoch: [31/300][0/53], lr: 0.00000039 	 loss = 0.1703(0.1703)
2023/10/31 21:35:32 - INFO - root -   Epoch: [31/300][20/53], lr: 0.00000039 	 loss = 0.4595(0.7121)
2023/10/31 21:36:32 - INFO - root -   Epoch: [31/300][40/53], lr: 0.00000039 	 loss = 0.5652(0.6715)
2023/10/31 21:37:00 - INFO - root -   Epoch: [31/300] 	 loss = 0.6899
2023/10/31 21:37:00 - INFO - root -   train_accuracy = 0.6321
2023/10/31 21:37:22 - INFO - root -   Epoch: [32/300][0/53], lr: 0.00000040 	 loss = 0.3381(0.3381)
2023/10/31 21:38:22 - INFO - root -   Epoch: [32/300][20/53], lr: 0.00000040 	 loss = 0.7837(0.6940)
2023/10/31 21:39:33 - INFO - root -   Epoch: [32/300][40/53], lr: 0.00000040 	 loss = 1.1773(0.6512)
2023/10/31 21:39:57 - INFO - root -   Epoch: [32/300] 	 loss = 0.6859
2023/10/31 21:39:57 - INFO - root -   train_accuracy = 0.6887
2023/10/31 21:40:20 - INFO - root -   Epoch: [33/300][0/53], lr: 0.00000041 	 loss = 0.2521(0.2521)
2023/10/31 21:41:19 - INFO - root -   Epoch: [33/300][20/53], lr: 0.00000041 	 loss = 1.0247(0.6432)
2023/10/31 21:42:36 - INFO - root -   Epoch: [33/300][40/53], lr: 0.00000041 	 loss = 0.6084(0.5931)
2023/10/31 21:42:57 - INFO - root -   Epoch: [33/300] 	 loss = 0.6338
2023/10/31 21:42:57 - INFO - root -   train_accuracy = 0.7170
2023/10/31 21:43:19 - INFO - root -   Epoch: [34/300][0/53], lr: 0.00000042 	 loss = 1.2106(1.2106)
2023/10/31 21:44:27 - INFO - root -   Epoch: [34/300][20/53], lr: 0.00000042 	 loss = 0.7832(0.8075)
2023/10/31 21:45:30 - INFO - root -   Epoch: [34/300][40/53], lr: 0.00000042 	 loss = 0.6220(0.7721)
2023/10/31 21:45:50 - INFO - root -   Epoch: [34/300] 	 loss = 0.7507
2023/10/31 21:46:26 - INFO - root -   precision = 0.7407
2023/10/31 21:46:26 - INFO - root -   eval_loss = 0.5764
2023/10/31 21:46:26 - INFO - root -   eval_acc = 0.7407
2023/10/31 21:46:27 - INFO - root -   train_accuracy = 0.6509
2023/10/31 21:46:49 - INFO - root -   Epoch: [35/300][0/53], lr: 0.00000043 	 loss = 0.2137(0.2137)
2023/10/31 21:47:50 - INFO - root -   Epoch: [35/300][20/53], lr: 0.00000043 	 loss = 1.1875(0.6344)
2023/10/31 21:48:54 - INFO - root -   Epoch: [35/300][40/53], lr: 0.00000043 	 loss = 0.6369(0.5486)
2023/10/31 21:49:18 - INFO - root -   Epoch: [35/300] 	 loss = 0.5607
2023/10/31 21:49:18 - INFO - root -   train_accuracy = 0.7358
2023/10/31 21:49:40 - INFO - root -   Epoch: [36/300][0/53], lr: 0.00000044 	 loss = 0.4017(0.4017)
2023/10/31 21:50:56 - INFO - root -   Epoch: [36/300][20/53], lr: 0.00000044 	 loss = 0.9478(0.6806)
2023/10/31 21:52:00 - INFO - root -   Epoch: [36/300][40/53], lr: 0.00000044 	 loss = 0.8262(0.6442)
2023/10/31 21:52:18 - INFO - root -   Epoch: [36/300] 	 loss = 0.6472
2023/10/31 21:52:18 - INFO - root -   train_accuracy = 0.6509
2023/10/31 21:52:39 - INFO - root -   Epoch: [37/300][0/53], lr: 0.00000045 	 loss = 0.1714(0.1714)
2023/10/31 21:53:38 - INFO - root -   Epoch: [37/300][20/53], lr: 0.00000045 	 loss = 1.1500(0.7185)
2023/10/31 21:54:55 - INFO - root -   Epoch: [37/300][40/53], lr: 0.00000045 	 loss = 0.4753(0.6382)
2023/10/31 21:55:14 - INFO - root -   Epoch: [37/300] 	 loss = 0.6546
2023/10/31 21:55:14 - INFO - root -   train_accuracy = 0.6981
2023/10/31 21:55:44 - INFO - root -   Epoch: [38/300][0/53], lr: 0.00000045 	 loss = 0.5528(0.5528)
2023/10/31 21:56:52 - INFO - root -   Epoch: [38/300][20/53], lr: 0.00000045 	 loss = 1.5722(0.7205)
2023/10/31 21:57:47 - INFO - root -   Epoch: [38/300][40/53], lr: 0.00000045 	 loss = 0.3442(0.6372)
2023/10/31 21:58:16 - INFO - root -   Epoch: [38/300] 	 loss = 0.6055
2023/10/31 21:58:16 - INFO - root -   train_accuracy = 0.6792
2023/10/31 21:58:38 - INFO - root -   Epoch: [39/300][0/53], lr: 0.00000046 	 loss = 0.1946(0.1946)
2023/10/31 21:59:51 - INFO - root -   Epoch: [39/300][20/53], lr: 0.00000046 	 loss = 0.8265(0.5971)
2023/10/31 22:01:04 - INFO - root -   Epoch: [39/300][40/53], lr: 0.00000046 	 loss = 0.9323(0.6321)
2023/10/31 22:01:14 - INFO - root -   Epoch: [39/300] 	 loss = 0.6417
2023/10/31 22:01:50 - INFO - root -   precision = 0.7407
2023/10/31 22:01:50 - INFO - root -   eval_loss = 0.5858
2023/10/31 22:01:50 - INFO - root -   eval_acc = 0.7407
2023/10/31 22:01:51 - INFO - root -   train_accuracy = 0.7170
2023/10/31 22:02:40 - INFO - root -   Epoch: [40/300][0/53], lr: 0.00000047 	 loss = 0.4466(0.4466)
2023/10/31 22:03:32 - INFO - root -   Epoch: [40/300][20/53], lr: 0.00000047 	 loss = 1.8971(0.6778)
2023/10/31 22:04:31 - INFO - root -   Epoch: [40/300][40/53], lr: 0.00000047 	 loss = 0.8736(0.6742)
2023/10/31 22:04:49 - INFO - root -   Epoch: [40/300] 	 loss = 0.6703
2023/10/31 22:04:49 - INFO - root -   train_accuracy = 0.6792
2023/10/31 22:05:12 - INFO - root -   Epoch: [41/300][0/53], lr: 0.00000048 	 loss = 0.1565(0.1565)
2023/10/31 22:06:18 - INFO - root -   Epoch: [41/300][20/53], lr: 0.00000048 	 loss = 0.9244(0.5665)
2023/10/31 22:07:26 - INFO - root -   Epoch: [41/300][40/53], lr: 0.00000048 	 loss = 0.5946(0.5738)
2023/10/31 22:07:40 - INFO - root -   Epoch: [41/300] 	 loss = 0.5915
2023/10/31 22:07:40 - INFO - root -   train_accuracy = 0.6509
2023/10/31 22:08:02 - INFO - root -   Epoch: [42/300][0/53], lr: 0.00000049 	 loss = 0.1118(0.1118)
2023/10/31 22:09:27 - INFO - root -   Epoch: [42/300][20/53], lr: 0.00000049 	 loss = 0.9427(0.5801)
2023/10/31 22:10:22 - INFO - root -   Epoch: [42/300][40/53], lr: 0.00000049 	 loss = 0.5410(0.5788)
2023/10/31 22:10:44 - INFO - root -   Epoch: [42/300] 	 loss = 0.5917
2023/10/31 22:10:44 - INFO - root -   train_accuracy = 0.6981
2023/10/31 22:11:22 - INFO - root -   Epoch: [43/300][0/53], lr: 0.00000050 	 loss = 0.2583(0.2583)
2023/10/31 22:12:26 - INFO - root -   Epoch: [43/300][20/53], lr: 0.00000050 	 loss = 0.6177(0.5970)
2023/10/31 22:13:29 - INFO - root -   Epoch: [43/300][40/53], lr: 0.00000050 	 loss = 1.1113(0.6219)
2023/10/31 22:13:43 - INFO - root -   Epoch: [43/300] 	 loss = 0.6354
2023/10/31 22:13:43 - INFO - root -   train_accuracy = 0.6792
2023/10/31 22:14:05 - INFO - root -   Epoch: [44/300][0/53], lr: 0.00000051 	 loss = 0.1984(0.1984)
2023/10/31 22:15:06 - INFO - root -   Epoch: [44/300][20/53], lr: 0.00000051 	 loss = 0.7483(0.5772)
2023/10/31 22:16:31 - INFO - root -   Epoch: [44/300][40/53], lr: 0.00000051 	 loss = 0.4023(0.5855)
2023/10/31 22:16:47 - INFO - root -   Epoch: [44/300] 	 loss = 0.5963
2023/10/31 22:17:24 - INFO - root -   precision = 0.7778
2023/10/31 22:17:24 - INFO - root -   eval_loss = 0.5634
2023/10/31 22:17:24 - INFO - root -   eval_acc = 0.7778
2023/10/31 22:17:25 - INFO - root -   train_accuracy = 0.7358
2023/10/31 22:17:47 - INFO - root -   Epoch: [45/300][0/53], lr: 0.00000052 	 loss = 0.1379(0.1379)
2023/10/31 22:19:00 - INFO - root -   Epoch: [45/300][20/53], lr: 0.00000052 	 loss = 0.9053(0.7123)
2023/10/31 22:19:52 - INFO - root -   Epoch: [45/300][40/53], lr: 0.00000052 	 loss = 0.5348(0.6419)
2023/10/31 22:20:17 - INFO - root -   Epoch: [45/300] 	 loss = 0.6607
2023/10/31 22:20:17 - INFO - root -   train_accuracy = 0.6792
2023/10/31 22:20:39 - INFO - root -   Epoch: [46/300][0/53], lr: 0.00000053 	 loss = 0.2634(0.2634)
2023/10/31 22:21:52 - INFO - root -   Epoch: [46/300][20/53], lr: 0.00000053 	 loss = 0.8454(0.6511)
2023/10/31 22:22:58 - INFO - root -   Epoch: [46/300][40/53], lr: 0.00000053 	 loss = 0.5311(0.5982)
2023/10/31 22:23:15 - INFO - root -   Epoch: [46/300] 	 loss = 0.5972
2023/10/31 22:23:15 - INFO - root -   train_accuracy = 0.6981
2023/10/31 22:23:36 - INFO - root -   Epoch: [47/300][0/53], lr: 0.00000054 	 loss = 0.4539(0.4539)
2023/10/31 22:24:59 - INFO - root -   Epoch: [47/300][20/53], lr: 0.00000054 	 loss = 0.7179(0.7368)
2023/10/31 22:25:52 - INFO - root -   Epoch: [47/300][40/53], lr: 0.00000054 	 loss = 0.8601(0.6768)
2023/10/31 22:26:17 - INFO - root -   Epoch: [47/300] 	 loss = 0.6666
2023/10/31 22:26:17 - INFO - root -   train_accuracy = 0.6604
2023/10/31 22:26:38 - INFO - root -   Epoch: [48/300][0/53], lr: 0.00000055 	 loss = 0.3109(0.3109)
2023/10/31 22:27:49 - INFO - root -   Epoch: [48/300][20/53], lr: 0.00000055 	 loss = 1.2462(0.6861)
2023/10/31 22:28:55 - INFO - root -   Epoch: [48/300][40/53], lr: 0.00000055 	 loss = 0.8486(0.6161)
2023/10/31 22:29:20 - INFO - root -   Epoch: [48/300] 	 loss = 0.6183
2023/10/31 22:29:20 - INFO - root -   train_accuracy = 0.6698
2023/10/31 22:29:50 - INFO - root -   Epoch: [49/300][0/53], lr: 0.00000056 	 loss = 0.1807(0.1807)
2023/10/31 22:30:55 - INFO - root -   Epoch: [49/300][20/53], lr: 0.00000056 	 loss = 0.8979(0.6694)
2023/10/31 22:32:06 - INFO - root -   Epoch: [49/300][40/53], lr: 0.00000056 	 loss = 0.6360(0.6117)
2023/10/31 22:32:23 - INFO - root -   Epoch: [49/300] 	 loss = 0.6398
2023/10/31 22:32:59 - INFO - root -   precision = 0.7407
2023/10/31 22:32:59 - INFO - root -   eval_loss = 0.5696
2023/10/31 22:32:59 - INFO - root -   eval_acc = 0.7407
2023/10/31 22:33:00 - INFO - root -   train_accuracy = 0.6981
2023/10/31 22:33:30 - INFO - root -   Epoch: [50/300][0/53], lr: 0.00000057 	 loss = 0.4050(0.4050)
2023/10/31 22:34:43 - INFO - root -   Epoch: [50/300][20/53], lr: 0.00000057 	 loss = 0.8054(0.7357)
2023/10/31 22:35:33 - INFO - root -   Epoch: [50/300][40/53], lr: 0.00000057 	 loss = 0.9008(0.6491)
2023/10/31 22:36:05 - INFO - root -   Epoch: [50/300] 	 loss = 0.6298
2023/10/31 22:36:05 - INFO - root -   train_accuracy = 0.6792
2023/10/31 22:36:27 - INFO - root -   Epoch: [51/300][0/53], lr: 0.00000058 	 loss = 0.2472(0.2472)
2023/10/31 22:37:49 - INFO - root -   Epoch: [51/300][20/53], lr: 0.00000058 	 loss = 0.9235(0.5789)
2023/10/31 22:38:57 - INFO - root -   Epoch: [51/300][40/53], lr: 0.00000058 	 loss = 0.8285(0.5692)
2023/10/31 22:39:12 - INFO - root -   Epoch: [51/300] 	 loss = 0.5889
2023/10/31 22:39:12 - INFO - root -   train_accuracy = 0.6887
2023/10/31 22:39:42 - INFO - root -   Epoch: [52/300][0/53], lr: 0.00000059 	 loss = 0.1490(0.1490)
2023/10/31 22:40:47 - INFO - root -   Epoch: [52/300][20/53], lr: 0.00000059 	 loss = 1.0031(0.6985)
2023/10/31 22:42:01 - INFO - root -   Epoch: [52/300][40/53], lr: 0.00000059 	 loss = 0.6842(0.5743)
2023/10/31 22:42:09 - INFO - root -   Epoch: [52/300] 	 loss = 0.5600
2023/10/31 22:42:09 - INFO - root -   train_accuracy = 0.6887
2023/10/31 22:42:32 - INFO - root -   Epoch: [53/300][0/53], lr: 0.00000060 	 loss = 0.2618(0.2618)
2023/10/31 22:43:48 - INFO - root -   Epoch: [53/300][20/53], lr: 0.00000060 	 loss = 0.6013(0.6506)
2023/10/31 22:44:58 - INFO - root -   Epoch: [53/300][40/53], lr: 0.00000060 	 loss = 0.5586(0.5764)
2023/10/31 22:45:07 - INFO - root -   Epoch: [53/300] 	 loss = 0.5905
2023/10/31 22:45:07 - INFO - root -   train_accuracy = 0.7075
2023/10/31 22:45:29 - INFO - root -   Epoch: [54/300][0/53], lr: 0.00000060 	 loss = 0.1860(0.1860)
2023/10/31 22:46:49 - INFO - root -   Epoch: [54/300][20/53], lr: 0.00000060 	 loss = 0.6842(0.5910)
2023/10/31 22:47:45 - INFO - root -   Epoch: [54/300][40/53], lr: 0.00000060 	 loss = 0.7616(0.5794)
2023/10/31 22:48:04 - INFO - root -   Epoch: [54/300] 	 loss = 0.6031
2023/10/31 22:48:41 - INFO - root -   precision = 0.7407
2023/10/31 22:48:41 - INFO - root -   eval_loss = 0.5726
2023/10/31 22:48:41 - INFO - root -   eval_acc = 0.7407
2023/10/31 22:48:42 - INFO - root -   train_accuracy = 0.6887
2023/10/31 22:49:13 - INFO - root -   Epoch: [55/300][0/53], lr: 0.00000061 	 loss = 0.1771(0.1771)
2023/10/31 22:50:20 - INFO - root -   Epoch: [55/300][20/53], lr: 0.00000061 	 loss = 0.8059(0.5881)
2023/10/31 22:51:25 - INFO - root -   Epoch: [55/300][40/53], lr: 0.00000061 	 loss = 0.9190(0.5808)
2023/10/31 22:51:41 - INFO - root -   Epoch: [55/300] 	 loss = 0.6103
2023/10/31 22:51:41 - INFO - root -   train_accuracy = 0.6981
2023/10/31 22:52:19 - INFO - root -   Epoch: [56/300][0/53], lr: 0.00000062 	 loss = 0.8026(0.8026)
2023/10/31 22:53:18 - INFO - root -   Epoch: [56/300][20/53], lr: 0.00000062 	 loss = 0.5580(0.6759)
2023/10/31 22:54:26 - INFO - root -   Epoch: [56/300][40/53], lr: 0.00000062 	 loss = 0.4699(0.5924)
2023/10/31 22:54:40 - INFO - root -   Epoch: [56/300] 	 loss = 0.6023
2023/10/31 22:54:40 - INFO - root -   train_accuracy = 0.6981
2023/10/31 22:55:02 - INFO - root -   Epoch: [57/300][0/53], lr: 0.00000063 	 loss = 0.1024(0.1024)
2023/10/31 22:56:19 - INFO - root -   Epoch: [57/300][20/53], lr: 0.00000063 	 loss = 0.5381(0.7607)
2023/10/31 22:57:16 - INFO - root -   Epoch: [57/300][40/53], lr: 0.00000063 	 loss = 0.6329(0.6665)
2023/10/31 22:57:36 - INFO - root -   Epoch: [57/300] 	 loss = 0.6553
2023/10/31 22:57:36 - INFO - root -   train_accuracy = 0.6415
2023/10/31 22:58:06 - INFO - root -   Epoch: [58/300][0/53], lr: 0.00000064 	 loss = 0.1946(0.1946)
2023/10/31 22:59:16 - INFO - root -   Epoch: [58/300][20/53], lr: 0.00000064 	 loss = 1.2254(0.5859)
2023/10/31 23:00:24 - INFO - root -   Epoch: [58/300][40/53], lr: 0.00000064 	 loss = 0.7003(0.5755)
2023/10/31 23:00:46 - INFO - root -   Epoch: [58/300] 	 loss = 0.5938
2023/10/31 23:00:46 - INFO - root -   train_accuracy = 0.6887
2023/10/31 23:01:07 - INFO - root -   Epoch: [59/300][0/53], lr: 0.00000065 	 loss = 0.1678(0.1678)
2023/10/31 23:02:07 - INFO - root -   Epoch: [59/300][20/53], lr: 0.00000065 	 loss = 0.8463(0.6252)
2023/10/31 23:03:15 - INFO - root -   Epoch: [59/300][40/53], lr: 0.00000065 	 loss = 0.7236(0.5989)
2023/10/31 23:03:41 - INFO - root -   Epoch: [59/300] 	 loss = 0.6784
2023/10/31 23:04:17 - INFO - root -   precision = 0.7407
2023/10/31 23:04:17 - INFO - root -   eval_loss = 0.5978
2023/10/31 23:04:17 - INFO - root -   eval_acc = 0.7407
2023/10/31 23:04:18 - INFO - root -   train_accuracy = 0.6698
2023/10/31 23:04:41 - INFO - root -   Epoch: [60/300][0/53], lr: 0.00000066 	 loss = 0.1985(0.1985)
2023/10/31 23:05:48 - INFO - root -   Epoch: [60/300][20/53], lr: 0.00000066 	 loss = 0.9232(0.6298)
2023/10/31 23:07:02 - INFO - root -   Epoch: [60/300][40/53], lr: 0.00000066 	 loss = 0.4873(0.5646)
2023/10/31 23:07:19 - INFO - root -   Epoch: [60/300] 	 loss = 0.5744
2023/10/31 23:07:19 - INFO - root -   train_accuracy = 0.7075
2023/10/31 23:07:42 - INFO - root -   Epoch: [61/300][0/53], lr: 0.00000067 	 loss = 0.2999(0.2999)
2023/10/31 23:08:49 - INFO - root -   Epoch: [61/300][20/53], lr: 0.00000067 	 loss = 0.7373(0.5958)
2023/10/31 23:10:03 - INFO - root -   Epoch: [61/300][40/53], lr: 0.00000067 	 loss = 0.4798(0.5543)
2023/10/31 23:10:17 - INFO - root -   Epoch: [61/300] 	 loss = 0.5842
2023/10/31 23:10:17 - INFO - root -   train_accuracy = 0.6887
2023/10/31 23:10:39 - INFO - root -   Epoch: [62/300][0/53], lr: 0.00000068 	 loss = 0.1205(0.1205)
2023/10/31 23:11:52 - INFO - root -   Epoch: [62/300][20/53], lr: 0.00000068 	 loss = 1.3991(0.6694)
2023/10/31 23:12:52 - INFO - root -   Epoch: [62/300][40/53], lr: 0.00000068 	 loss = 0.5197(0.6212)
2023/10/31 23:13:06 - INFO - root -   Epoch: [62/300] 	 loss = 0.6541
2023/10/31 23:13:06 - INFO - root -   train_accuracy = 0.6321
2023/10/31 23:13:35 - INFO - root -   Epoch: [63/300][0/53], lr: 0.00000069 	 loss = 0.2157(0.2157)
2023/10/31 23:14:41 - INFO - root -   Epoch: [63/300][20/53], lr: 0.00000069 	 loss = 1.0517(0.5573)
2023/10/31 23:15:48 - INFO - root -   Epoch: [63/300][40/53], lr: 0.00000069 	 loss = 0.7800(0.5471)
2023/10/31 23:16:05 - INFO - root -   Epoch: [63/300] 	 loss = 0.5729
2023/10/31 23:16:05 - INFO - root -   train_accuracy = 0.6981
2023/10/31 23:16:34 - INFO - root -   Epoch: [64/300][0/53], lr: 0.00000070 	 loss = 0.0981(0.0981)
2023/10/31 23:17:42 - INFO - root -   Epoch: [64/300][20/53], lr: 0.00000070 	 loss = 0.9214(0.7221)
2023/10/31 23:18:55 - INFO - root -   Epoch: [64/300][40/53], lr: 0.00000070 	 loss = 0.6949(0.6920)
2023/10/31 23:19:14 - INFO - root -   Epoch: [64/300] 	 loss = 0.6817
2023/10/31 23:19:50 - INFO - root -   precision = 0.7407
2023/10/31 23:19:50 - INFO - root -   eval_loss = 0.5750
2023/10/31 23:19:50 - INFO - root -   eval_acc = 0.7407
2023/10/31 23:19:51 - INFO - root -   train_accuracy = 0.6226
2023/10/31 23:20:20 - INFO - root -   Epoch: [65/300][0/53], lr: 0.00000071 	 loss = 0.2456(0.2456)
2023/10/31 23:21:33 - INFO - root -   Epoch: [65/300][20/53], lr: 0.00000071 	 loss = 0.8769(0.7280)
2023/10/31 23:22:26 - INFO - root -   Epoch: [65/300][40/53], lr: 0.00000071 	 loss = 0.5001(0.6087)
2023/10/31 23:22:50 - INFO - root -   Epoch: [65/300] 	 loss = 0.6352
2023/10/31 23:22:50 - INFO - root -   train_accuracy = 0.7358
2023/10/31 23:23:20 - INFO - root -   Epoch: [66/300][0/53], lr: 0.00000072 	 loss = 0.2444(0.2444)
2023/10/31 23:24:18 - INFO - root -   Epoch: [66/300][20/53], lr: 0.00000072 	 loss = 0.8740(0.5528)
2023/10/31 23:25:29 - INFO - root -   Epoch: [66/300][40/53], lr: 0.00000072 	 loss = 0.3437(0.5489)
2023/10/31 23:25:47 - INFO - root -   Epoch: [66/300] 	 loss = 0.5796
2023/10/31 23:25:47 - INFO - root -   train_accuracy = 0.6981
2023/10/31 23:26:09 - INFO - root -   Epoch: [67/300][0/53], lr: 0.00000073 	 loss = 0.4844(0.4844)
2023/10/31 23:27:17 - INFO - root -   Epoch: [67/300][20/53], lr: 0.00000073 	 loss = 0.7607(0.5645)
2023/10/31 23:28:21 - INFO - root -   Epoch: [67/300][40/53], lr: 0.00000073 	 loss = 0.7983(0.5735)
2023/10/31 23:28:47 - INFO - root -   Epoch: [67/300] 	 loss = 0.5832
2023/10/31 23:28:47 - INFO - root -   train_accuracy = 0.7075
2023/10/31 23:29:24 - INFO - root -   Epoch: [68/300][0/53], lr: 0.00000074 	 loss = 0.1401(0.1401)
2023/10/31 23:30:24 - INFO - root -   Epoch: [68/300][20/53], lr: 0.00000074 	 loss = 1.0207(0.5287)
2023/10/31 23:31:41 - INFO - root -   Epoch: [68/300][40/53], lr: 0.00000074 	 loss = 0.7070(0.5875)
2023/10/31 23:31:48 - INFO - root -   Epoch: [68/300] 	 loss = 0.6159
2023/10/31 23:31:48 - INFO - root -   train_accuracy = 0.6981
2023/10/31 23:32:10 - INFO - root -   Epoch: [69/300][0/53], lr: 0.00000074 	 loss = 0.5191(0.5191)
2023/10/31 23:33:24 - INFO - root -   Epoch: [69/300][20/53], lr: 0.00000074 	 loss = 0.5870(0.6083)
2023/10/31 23:34:24 - INFO - root -   Epoch: [69/300][40/53], lr: 0.00000074 	 loss = 0.7034(0.6129)
2023/10/31 23:34:47 - INFO - root -   Epoch: [69/300] 	 loss = 0.6032
2023/10/31 23:35:24 - INFO - root -   precision = 0.7778
2023/10/31 23:35:24 - INFO - root -   eval_loss = 0.5680
2023/10/31 23:35:24 - INFO - root -   eval_acc = 0.7778
2023/10/31 23:35:25 - INFO - root -   train_accuracy = 0.6981
2023/10/31 23:35:47 - INFO - root -   Epoch: [70/300][0/53], lr: 0.00000075 	 loss = 0.1871(0.1871)
2023/10/31 23:36:54 - INFO - root -   Epoch: [70/300][20/53], lr: 0.00000075 	 loss = 1.1222(0.7247)
2023/10/31 23:38:01 - INFO - root -   Epoch: [70/300][40/53], lr: 0.00000075 	 loss = 0.8273(0.6359)
2023/10/31 23:38:20 - INFO - root -   Epoch: [70/300] 	 loss = 0.6900
2023/10/31 23:38:20 - INFO - root -   train_accuracy = 0.6981
2023/10/31 23:38:50 - INFO - root -   Epoch: [71/300][0/53], lr: 0.00000076 	 loss = 0.1768(0.1768)
2023/10/31 23:39:59 - INFO - root -   Epoch: [71/300][20/53], lr: 0.00000076 	 loss = 0.9176(0.5850)
2023/10/31 23:41:12 - INFO - root -   Epoch: [71/300][40/53], lr: 0.00000076 	 loss = 0.8165(0.5919)
2023/10/31 23:41:27 - INFO - root -   Epoch: [71/300] 	 loss = 0.6237
2023/10/31 23:41:27 - INFO - root -   train_accuracy = 0.6698
2023/10/31 23:41:58 - INFO - root -   Epoch: [72/300][0/53], lr: 0.00000077 	 loss = 0.3600(0.3600)
2023/10/31 23:43:07 - INFO - root -   Epoch: [72/300][20/53], lr: 0.00000077 	 loss = 0.7287(0.6580)
2023/10/31 23:44:05 - INFO - root -   Epoch: [72/300][40/53], lr: 0.00000077 	 loss = 1.1285(0.5997)
2023/10/31 23:44:23 - INFO - root -   Epoch: [72/300] 	 loss = 0.6278
2023/10/31 23:44:23 - INFO - root -   train_accuracy = 0.6981
2023/10/31 23:44:59 - INFO - root -   Epoch: [73/300][0/53], lr: 0.00000078 	 loss = 0.2808(0.2808)
2023/10/31 23:45:51 - INFO - root -   Epoch: [73/300][20/53], lr: 0.00000078 	 loss = 0.4507(0.5148)
2023/10/31 23:47:03 - INFO - root -   Epoch: [73/300][40/53], lr: 0.00000078 	 loss = 0.9998(0.5058)
2023/10/31 23:47:26 - INFO - root -   Epoch: [73/300] 	 loss = 0.5343
2023/10/31 23:47:26 - INFO - root -   train_accuracy = 0.7736
2023/10/31 23:47:48 - INFO - root -   Epoch: [74/300][0/53], lr: 0.00000079 	 loss = 0.1428(0.1428)
2023/10/31 23:48:57 - INFO - root -   Epoch: [74/300][20/53], lr: 0.00000079 	 loss = 0.7935(0.5756)
2023/10/31 23:50:06 - INFO - root -   Epoch: [74/300][40/53], lr: 0.00000079 	 loss = 0.7911(0.5920)
2023/10/31 23:50:22 - INFO - root -   Epoch: [74/300] 	 loss = 0.6036
2023/10/31 23:50:58 - INFO - root -   precision = 0.7778
2023/10/31 23:50:58 - INFO - root -   eval_loss = 0.5756
2023/10/31 23:50:58 - INFO - root -   eval_acc = 0.7778
2023/10/31 23:50:59 - INFO - root -   train_accuracy = 0.6887
2023/10/31 23:51:20 - INFO - root -   Epoch: [75/300][0/53], lr: 0.00000080 	 loss = 0.2404(0.2404)
2023/10/31 23:52:34 - INFO - root -   Epoch: [75/300][20/53], lr: 0.00000080 	 loss = 0.8302(0.6381)
2023/10/31 23:53:28 - INFO - root -   Epoch: [75/300][40/53], lr: 0.00000080 	 loss = 0.8796(0.5768)
2023/10/31 23:53:56 - INFO - root -   Epoch: [75/300] 	 loss = 0.6052
2023/10/31 23:53:56 - INFO - root -   train_accuracy = 0.7075
2023/10/31 23:54:18 - INFO - root -   Epoch: [76/300][0/53], lr: 0.00000081 	 loss = 0.1975(0.1975)
2023/10/31 23:55:23 - INFO - root -   Epoch: [76/300][20/53], lr: 0.00000081 	 loss = 0.8517(0.6516)
2023/10/31 23:56:31 - INFO - root -   Epoch: [76/300][40/53], lr: 0.00000081 	 loss = 0.7872(0.5885)
2023/10/31 23:56:57 - INFO - root -   Epoch: [76/300] 	 loss = 0.6091
2023/10/31 23:56:57 - INFO - root -   train_accuracy = 0.6981
2023/10/31 23:57:18 - INFO - root -   Epoch: [77/300][0/53], lr: 0.00000082 	 loss = 0.1237(0.1237)
2023/10/31 23:58:36 - INFO - root -   Epoch: [77/300][20/53], lr: 0.00000082 	 loss = 0.5147(0.5109)
2023/10/31 23:59:33 - INFO - root -   Epoch: [77/300][40/53], lr: 0.00000082 	 loss = 0.6882(0.5259)
2023/10/31 23:59:56 - INFO - root -   Epoch: [77/300] 	 loss = 0.5603
2023/10/31 23:59:56 - INFO - root -   train_accuracy = 0.7642
2023/11/01 00:00:26 - INFO - root -   Epoch: [78/300][0/53], lr: 0.00000083 	 loss = 0.0804(0.0804)
2023/11/01 00:01:25 - INFO - root -   Epoch: [78/300][20/53], lr: 0.00000083 	 loss = 0.9731(0.7156)
2023/11/01 00:02:33 - INFO - root -   Epoch: [78/300][40/53], lr: 0.00000083 	 loss = 0.3935(0.6446)
2023/11/01 00:02:58 - INFO - root -   Epoch: [78/300] 	 loss = 0.6600
2023/11/01 00:02:58 - INFO - root -   train_accuracy = 0.6981
2023/11/01 00:03:38 - INFO - root -   Epoch: [79/300][0/53], lr: 0.00000084 	 loss = 0.1689(0.1689)
2023/11/01 00:04:31 - INFO - root -   Epoch: [79/300][20/53], lr: 0.00000084 	 loss = 0.8891(0.5978)
2023/11/01 00:05:28 - INFO - root -   Epoch: [79/300][40/53], lr: 0.00000084 	 loss = 0.4772(0.6016)
2023/11/01 00:05:49 - INFO - root -   Epoch: [79/300] 	 loss = 0.6291
2023/11/01 00:06:25 - INFO - root -   precision = 0.7407
2023/11/01 00:06:25 - INFO - root -   eval_loss = 0.5994
2023/11/01 00:06:25 - INFO - root -   eval_acc = 0.7407
2023/11/01 00:06:26 - INFO - root -   train_accuracy = 0.6792
2023/11/01 00:07:06 - INFO - root -   Epoch: [80/300][0/53], lr: 0.00000085 	 loss = 0.1676(0.1676)
2023/11/01 00:07:59 - INFO - root -   Epoch: [80/300][20/53], lr: 0.00000085 	 loss = 1.5588(0.6240)
2023/11/01 00:08:58 - INFO - root -   Epoch: [80/300][40/53], lr: 0.00000085 	 loss = 0.4531(0.6173)
2023/11/01 00:09:22 - INFO - root -   Epoch: [80/300] 	 loss = 0.5914
2023/11/01 00:09:22 - INFO - root -   train_accuracy = 0.6792
2023/11/01 00:10:01 - INFO - root -   Epoch: [81/300][0/53], lr: 0.00000086 	 loss = 0.7016(0.7016)
2023/11/01 00:10:59 - INFO - root -   Epoch: [81/300][20/53], lr: 0.00000086 	 loss = 0.9768(0.6534)
2023/11/01 00:12:15 - INFO - root -   Epoch: [81/300][40/53], lr: 0.00000086 	 loss = 0.6521(0.5538)
2023/11/01 00:12:30 - INFO - root -   Epoch: [81/300] 	 loss = 0.6085
2023/11/01 00:12:30 - INFO - root -   train_accuracy = 0.7358
2023/11/01 00:13:01 - INFO - root -   Epoch: [82/300][0/53], lr: 0.00000087 	 loss = 0.5970(0.5970)
2023/11/01 00:13:58 - INFO - root -   Epoch: [82/300][20/53], lr: 0.00000087 	 loss = 1.0257(0.6501)
2023/11/01 00:14:58 - INFO - root -   Epoch: [82/300][40/53], lr: 0.00000087 	 loss = 1.1515(0.5878)
2023/11/01 00:15:20 - INFO - root -   Epoch: [82/300] 	 loss = 0.6132
2023/11/01 00:15:20 - INFO - root -   train_accuracy = 0.6981
2023/11/01 00:15:43 - INFO - root -   Epoch: [83/300][0/53], lr: 0.00000088 	 loss = 0.4627(0.4627)
2023/11/01 00:16:48 - INFO - root -   Epoch: [83/300][20/53], lr: 0.00000088 	 loss = 1.1197(0.6014)
2023/11/01 00:17:50 - INFO - root -   Epoch: [83/300][40/53], lr: 0.00000088 	 loss = 0.6268(0.6318)
2023/11/01 00:18:14 - INFO - root -   Epoch: [83/300] 	 loss = 0.5971
2023/11/01 00:18:14 - INFO - root -   train_accuracy = 0.6698
2023/11/01 00:18:36 - INFO - root -   Epoch: [84/300][0/53], lr: 0.00000088 	 loss = 0.2143(0.2143)
2023/11/01 00:19:46 - INFO - root -   Epoch: [84/300][20/53], lr: 0.00000088 	 loss = 1.0901(0.7278)
2023/11/01 00:21:07 - INFO - root -   Epoch: [84/300][40/53], lr: 0.00000088 	 loss = 0.7119(0.6263)
2023/11/01 00:21:22 - INFO - root -   Epoch: [84/300] 	 loss = 0.6367
2023/11/01 00:21:59 - INFO - root -   precision = 0.7407
2023/11/01 00:21:59 - INFO - root -   eval_loss = 0.5788
2023/11/01 00:21:59 - INFO - root -   eval_acc = 0.7407
2023/11/01 00:22:00 - INFO - root -   train_accuracy = 0.6981
2023/11/01 00:22:30 - INFO - root -   Epoch: [85/300][0/53], lr: 0.00000089 	 loss = 0.2832(0.2832)
2023/11/01 00:23:29 - INFO - root -   Epoch: [85/300][20/53], lr: 0.00000089 	 loss = 0.5803(0.6403)
2023/11/01 00:24:45 - INFO - root -   Epoch: [85/300][40/53], lr: 0.00000089 	 loss = 0.6220(0.6209)
2023/11/01 00:25:04 - INFO - root -   Epoch: [85/300] 	 loss = 0.6449
2023/11/01 00:25:04 - INFO - root -   train_accuracy = 0.6415
2023/11/01 00:25:26 - INFO - root -   Epoch: [86/300][0/53], lr: 0.00000090 	 loss = 0.3039(0.3039)
2023/11/01 00:26:41 - INFO - root -   Epoch: [86/300][20/53], lr: 0.00000090 	 loss = 1.2748(0.6812)
2023/11/01 00:27:47 - INFO - root -   Epoch: [86/300][40/53], lr: 0.00000090 	 loss = 0.8256(0.6434)
2023/11/01 00:28:07 - INFO - root -   Epoch: [86/300] 	 loss = 0.6850
2023/11/01 00:28:07 - INFO - root -   train_accuracy = 0.6604
2023/11/01 00:28:37 - INFO - root -   Epoch: [87/300][0/53], lr: 0.00000091 	 loss = 0.1133(0.1133)
2023/11/01 00:29:47 - INFO - root -   Epoch: [87/300][20/53], lr: 0.00000091 	 loss = 1.1325(0.5802)
2023/11/01 00:30:38 - INFO - root -   Epoch: [87/300][40/53], lr: 0.00000091 	 loss = 0.3331(0.5602)
2023/11/01 00:31:03 - INFO - root -   Epoch: [87/300] 	 loss = 0.5866
2023/11/01 00:31:03 - INFO - root -   train_accuracy = 0.7170
2023/11/01 00:31:33 - INFO - root -   Epoch: [88/300][0/53], lr: 0.00000092 	 loss = 0.1935(0.1935)
2023/11/01 00:32:40 - INFO - root -   Epoch: [88/300][20/53], lr: 0.00000092 	 loss = 0.8836(0.6565)
2023/11/01 00:33:56 - INFO - root -   Epoch: [88/300][40/53], lr: 0.00000092 	 loss = 0.4401(0.5647)
2023/11/01 00:34:07 - INFO - root -   Epoch: [88/300] 	 loss = 0.6060
2023/11/01 00:34:07 - INFO - root -   train_accuracy = 0.6981
2023/11/01 00:34:36 - INFO - root -   Epoch: [89/300][0/53], lr: 0.00000093 	 loss = 0.4139(0.4139)
2023/11/01 00:35:26 - INFO - root -   Epoch: [89/300][20/53], lr: 0.00000093 	 loss = 0.2857(0.5589)
2023/11/01 00:36:48 - INFO - root -   Epoch: [89/300][40/53], lr: 0.00000093 	 loss = 0.7667(0.5152)
2023/11/01 00:36:59 - INFO - root -   Epoch: [89/300] 	 loss = 0.5249
2023/11/01 00:37:35 - INFO - root -   precision = 0.7407
2023/11/01 00:37:35 - INFO - root -   eval_loss = 0.5818
2023/11/01 00:37:35 - INFO - root -   eval_acc = 0.7407
2023/11/01 00:37:36 - INFO - root -   train_accuracy = 0.7264
2023/11/01 00:37:58 - INFO - root -   Epoch: [90/300][0/53], lr: 0.00000094 	 loss = 0.2169(0.2169)
2023/11/01 00:39:00 - INFO - root -   Epoch: [90/300][20/53], lr: 0.00000094 	 loss = 0.9027(0.5753)
2023/11/01 00:40:18 - INFO - root -   Epoch: [90/300][40/53], lr: 0.00000094 	 loss = 0.5447(0.5697)
2023/11/01 00:40:40 - INFO - root -   Epoch: [90/300] 	 loss = 0.5817
2023/11/01 00:40:40 - INFO - root -   train_accuracy = 0.7170
2023/11/01 00:41:02 - INFO - root -   Epoch: [91/300][0/53], lr: 0.00000095 	 loss = 0.1449(0.1449)
2023/11/01 00:42:07 - INFO - root -   Epoch: [91/300][20/53], lr: 0.00000095 	 loss = 1.0001(0.6171)
2023/11/01 00:43:17 - INFO - root -   Epoch: [91/300][40/53], lr: 0.00000095 	 loss = 1.1576(0.5834)
2023/11/01 00:43:41 - INFO - root -   Epoch: [91/300] 	 loss = 0.6332
2023/11/01 00:43:41 - INFO - root -   train_accuracy = 0.6792
2023/11/01 00:44:03 - INFO - root -   Epoch: [92/300][0/53], lr: 0.00000096 	 loss = 0.1926(0.1926)
2023/11/01 00:45:10 - INFO - root -   Epoch: [92/300][20/53], lr: 0.00000096 	 loss = 1.2230(0.7030)
2023/11/01 00:45:54 - INFO - root -   Epoch: [92/300][40/53], lr: 0.00000096 	 loss = 0.7664(0.6532)
2023/11/01 00:46:24 - INFO - root -   Epoch: [92/300] 	 loss = 0.6492
2023/11/01 00:46:24 - INFO - root -   train_accuracy = 0.6509
2023/11/01 00:46:46 - INFO - root -   Epoch: [93/300][0/53], lr: 0.00000097 	 loss = 0.4385(0.4385)
2023/11/01 00:48:02 - INFO - root -   Epoch: [93/300][20/53], lr: 0.00000097 	 loss = 0.7324(0.6214)
2023/11/01 00:49:06 - INFO - root -   Epoch: [93/300][40/53], lr: 0.00000097 	 loss = 1.2219(0.6324)
2023/11/01 00:49:25 - INFO - root -   Epoch: [93/300] 	 loss = 0.6528
2023/11/01 00:49:25 - INFO - root -   train_accuracy = 0.7170
2023/11/01 00:49:48 - INFO - root -   Epoch: [94/300][0/53], lr: 0.00000098 	 loss = 0.1044(0.1044)
2023/11/01 00:50:46 - INFO - root -   Epoch: [94/300][20/53], lr: 0.00000098 	 loss = 0.9705(0.5243)
2023/11/01 00:52:05 - INFO - root -   Epoch: [94/300][40/53], lr: 0.00000098 	 loss = 0.6937(0.5373)
2023/11/01 00:52:21 - INFO - root -   Epoch: [94/300] 	 loss = 0.5780
2023/11/01 00:52:57 - INFO - root -   precision = 0.7407
2023/11/01 00:52:57 - INFO - root -   eval_loss = 0.5945
2023/11/01 00:52:57 - INFO - root -   eval_acc = 0.7407
2023/11/01 00:52:58 - INFO - root -   train_accuracy = 0.6981
2023/11/01 00:53:20 - INFO - root -   Epoch: [95/300][0/53], lr: 0.00000099 	 loss = 0.3419(0.3419)
2023/11/01 00:54:29 - INFO - root -   Epoch: [95/300][20/53], lr: 0.00000099 	 loss = 1.2245(0.5782)
2023/11/01 00:55:35 - INFO - root -   Epoch: [95/300][40/53], lr: 0.00000099 	 loss = 0.4893(0.5075)
2023/11/01 00:55:58 - INFO - root -   Epoch: [95/300] 	 loss = 0.5167
2023/11/01 00:55:58 - INFO - root -   train_accuracy = 0.7642
2023/11/01 00:56:36 - INFO - root -   Epoch: [96/300][0/53], lr: 0.00000100 	 loss = 0.2668(0.2668)
2023/11/01 00:57:36 - INFO - root -   Epoch: [96/300][20/53], lr: 0.00000100 	 loss = 0.7295(0.5809)
2023/11/01 00:58:34 - INFO - root -   Epoch: [96/300][40/53], lr: 0.00000100 	 loss = 1.0576(0.5695)
2023/11/01 00:58:53 - INFO - root -   Epoch: [96/300] 	 loss = 0.5802
2023/11/01 00:58:53 - INFO - root -   train_accuracy = 0.6698
2023/11/01 00:59:24 - INFO - root -   Epoch: [97/300][0/53], lr: 0.00000101 	 loss = 0.0856(0.0856)
2023/11/01 01:00:46 - INFO - root -   Epoch: [97/300][20/53], lr: 0.00000101 	 loss = 0.4951(0.6282)
2023/11/01 01:01:47 - INFO - root -   Epoch: [97/300][40/53], lr: 0.00000101 	 loss = 0.7845(0.5507)
2023/11/01 01:02:04 - INFO - root -   Epoch: [97/300] 	 loss = 0.5645
2023/11/01 01:02:04 - INFO - root -   train_accuracy = 0.6698
2023/11/01 01:02:34 - INFO - root -   Epoch: [98/300][0/53], lr: 0.00000102 	 loss = 0.1408(0.1408)
2023/11/01 01:03:32 - INFO - root -   Epoch: [98/300][20/53], lr: 0.00000102 	 loss = 0.6100(0.5504)
2023/11/01 01:04:39 - INFO - root -   Epoch: [98/300][40/53], lr: 0.00000102 	 loss = 0.7029(0.5760)
2023/11/01 01:05:00 - INFO - root -   Epoch: [98/300] 	 loss = 0.5912
2023/11/01 01:05:00 - INFO - root -   train_accuracy = 0.7075
2023/11/01 01:05:40 - INFO - root -   Epoch: [99/300][0/53], lr: 0.00000102 	 loss = 0.2099(0.2099)
2023/11/01 01:06:37 - INFO - root -   Epoch: [99/300][20/53], lr: 0.00000102 	 loss = 1.2030(0.6212)
2023/11/01 01:07:41 - INFO - root -   Epoch: [99/300][40/53], lr: 0.00000102 	 loss = 0.4776(0.5808)
2023/11/01 01:07:55 - INFO - root -   Epoch: [99/300] 	 loss = 0.5699
2023/11/01 01:08:31 - INFO - root -   precision = 0.7778
2023/11/01 01:08:31 - INFO - root -   eval_loss = 0.6075
2023/11/01 01:08:31 - INFO - root -   eval_acc = 0.7778
2023/11/01 01:08:32 - INFO - root -   train_accuracy = 0.7264
2023/11/01 01:09:10 - INFO - root -   Epoch: [100/300][0/53], lr: 0.00000103 	 loss = 0.1967(0.1967)
2023/11/01 01:10:09 - INFO - root -   Epoch: [100/300][20/53], lr: 0.00000103 	 loss = 0.7069(0.5665)
2023/11/01 01:11:08 - INFO - root -   Epoch: [100/300][40/53], lr: 0.00000103 	 loss = 0.3346(0.5034)
2023/11/01 01:11:29 - INFO - root -   Epoch: [100/300] 	 loss = 0.5217
2023/11/01 01:11:29 - INFO - root -   train_accuracy = 0.7358
2023/11/01 01:11:50 - INFO - root -   Epoch: [101/300][0/53], lr: 0.00000104 	 loss = 0.2115(0.2115)
2023/11/01 01:13:02 - INFO - root -   Epoch: [101/300][20/53], lr: 0.00000104 	 loss = 0.5886(0.5551)
2023/11/01 01:13:55 - INFO - root -   Epoch: [101/300][40/53], lr: 0.00000104 	 loss = 0.9450(0.5310)
2023/11/01 01:14:11 - INFO - root -   Epoch: [101/300] 	 loss = 0.5425
2023/11/01 01:14:11 - INFO - root -   train_accuracy = 0.7358
2023/11/01 01:14:32 - INFO - root -   Epoch: [102/300][0/53], lr: 0.00000105 	 loss = 0.3332(0.3332)
2023/11/01 01:15:40 - INFO - root -   Epoch: [102/300][20/53], lr: 0.00000105 	 loss = 0.7102(0.5834)
2023/11/01 01:16:57 - INFO - root -   Epoch: [102/300][40/53], lr: 0.00000105 	 loss = 0.3449(0.5330)
2023/11/01 01:17:03 - INFO - root -   Epoch: [102/300] 	 loss = 0.5509
2023/11/01 01:17:03 - INFO - root -   train_accuracy = 0.7170
2023/11/01 01:17:35 - INFO - root -   Epoch: [103/300][0/53], lr: 0.00000106 	 loss = 0.3425(0.3425)
2023/11/01 01:18:37 - INFO - root -   Epoch: [103/300][20/53], lr: 0.00000106 	 loss = 0.8659(0.6232)
2023/11/01 01:19:56 - INFO - root -   Epoch: [103/300][40/53], lr: 0.00000106 	 loss = 1.2136(0.5906)
2023/11/01 01:20:09 - INFO - root -   Epoch: [103/300] 	 loss = 0.6209
2023/11/01 01:20:09 - INFO - root -   train_accuracy = 0.6981
2023/11/01 01:20:40 - INFO - root -   Epoch: [104/300][0/53], lr: 0.00000107 	 loss = 0.4910(0.4910)
2023/11/01 01:21:31 - INFO - root -   Epoch: [104/300][20/53], lr: 0.00000107 	 loss = 1.1235(0.5976)
2023/11/01 01:22:40 - INFO - root -   Epoch: [104/300][40/53], lr: 0.00000107 	 loss = 0.8973(0.5896)
2023/11/01 01:22:58 - INFO - root -   Epoch: [104/300] 	 loss = 0.5593
2023/11/01 01:23:35 - INFO - root -   precision = 0.7407
2023/11/01 01:23:35 - INFO - root -   eval_loss = 0.6146
2023/11/01 01:23:35 - INFO - root -   eval_acc = 0.7407
2023/11/01 01:23:36 - INFO - root -   train_accuracy = 0.7358
2023/11/01 01:24:06 - INFO - root -   Epoch: [105/300][0/53], lr: 0.00000108 	 loss = 0.8449(0.8449)
2023/11/01 01:24:56 - INFO - root -   Epoch: [105/300][20/53], lr: 0.00000108 	 loss = 0.6373(0.6589)
2023/11/01 01:26:05 - INFO - root -   Epoch: [105/300][40/53], lr: 0.00000108 	 loss = 0.4232(0.5903)
2023/11/01 01:26:28 - INFO - root -   Epoch: [105/300] 	 loss = 0.5970
2023/11/01 01:26:28 - INFO - root -   train_accuracy = 0.7075
2023/11/01 01:26:58 - INFO - root -   Epoch: [106/300][0/53], lr: 0.00000109 	 loss = 0.2108(0.2108)
2023/11/01 01:28:03 - INFO - root -   Epoch: [106/300][20/53], lr: 0.00000109 	 loss = 0.9586(0.6117)
2023/11/01 01:29:03 - INFO - root -   Epoch: [106/300][40/53], lr: 0.00000109 	 loss = 0.8755(0.5648)
2023/11/01 01:29:18 - INFO - root -   Epoch: [106/300] 	 loss = 0.5418
2023/11/01 01:29:18 - INFO - root -   train_accuracy = 0.7453
2023/11/01 01:29:57 - INFO - root -   Epoch: [107/300][0/53], lr: 0.00000110 	 loss = 0.4167(0.4167)
2023/11/01 01:30:50 - INFO - root -   Epoch: [107/300][20/53], lr: 0.00000110 	 loss = 0.6398(0.6363)
2023/11/01 01:32:06 - INFO - root -   Epoch: [107/300][40/53], lr: 0.00000110 	 loss = 0.6395(0.5778)
2023/11/01 01:32:29 - INFO - root -   Epoch: [107/300] 	 loss = 0.5724
2023/11/01 01:32:29 - INFO - root -   train_accuracy = 0.7075
2023/11/01 01:32:51 - INFO - root -   Epoch: [108/300][0/53], lr: 0.00000111 	 loss = 0.2536(0.2536)
2023/11/01 01:34:05 - INFO - root -   Epoch: [108/300][20/53], lr: 0.00000111 	 loss = 0.8068(0.5803)
2023/11/01 01:34:58 - INFO - root -   Epoch: [108/300][40/53], lr: 0.00000111 	 loss = 0.3602(0.6111)
2023/11/01 01:35:22 - INFO - root -   Epoch: [108/300] 	 loss = 0.6046
2023/11/01 01:35:22 - INFO - root -   train_accuracy = 0.6604
2023/11/01 01:35:44 - INFO - root -   Epoch: [109/300][0/53], lr: 0.00000112 	 loss = 0.2893(0.2893)
2023/11/01 01:37:07 - INFO - root -   Epoch: [109/300][20/53], lr: 0.00000112 	 loss = 0.5550(0.5771)
2023/11/01 01:38:06 - INFO - root -   Epoch: [109/300][40/53], lr: 0.00000112 	 loss = 0.2927(0.5498)
2023/11/01 01:38:29 - INFO - root -   Epoch: [109/300] 	 loss = 0.5868
2023/11/01 01:39:05 - INFO - root -   precision = 0.7407
2023/11/01 01:39:05 - INFO - root -   eval_loss = 0.6567
2023/11/01 01:39:05 - INFO - root -   eval_acc = 0.7407
2023/11/01 01:39:06 - INFO - root -   train_accuracy = 0.7170
2023/11/01 01:39:28 - INFO - root -   Epoch: [110/300][0/53], lr: 0.00000113 	 loss = 0.2353(0.2353)
2023/11/01 01:40:41 - INFO - root -   Epoch: [110/300][20/53], lr: 0.00000113 	 loss = 0.7246(0.6793)
2023/11/01 01:41:58 - INFO - root -   Epoch: [110/300][40/53], lr: 0.00000113 	 loss = 0.8392(0.6182)
2023/11/01 01:42:12 - INFO - root -   Epoch: [110/300] 	 loss = 0.6635
2023/11/01 01:42:12 - INFO - root -   train_accuracy = 0.6792
2023/11/01 01:42:33 - INFO - root -   Epoch: [111/300][0/53], lr: 0.00000114 	 loss = 0.4628(0.4628)
2023/11/01 01:43:57 - INFO - root -   Epoch: [111/300][20/53], lr: 0.00000114 	 loss = 0.8157(0.6381)
2023/11/01 01:44:49 - INFO - root -   Epoch: [111/300][40/53], lr: 0.00000114 	 loss = 0.3305(0.5952)
2023/11/01 01:45:15 - INFO - root -   Epoch: [111/300] 	 loss = 0.6108
2023/11/01 01:45:15 - INFO - root -   train_accuracy = 0.6887
2023/11/01 01:45:53 - INFO - root -   Epoch: [112/300][0/53], lr: 0.00000115 	 loss = 0.0656(0.0656)
2023/11/01 01:47:00 - INFO - root -   Epoch: [112/300][20/53], lr: 0.00000115 	 loss = 0.7116(0.4982)
2023/11/01 01:48:14 - INFO - root -   Epoch: [112/300][40/53], lr: 0.00000115 	 loss = 0.3587(0.5058)
2023/11/01 01:48:31 - INFO - root -   Epoch: [112/300] 	 loss = 0.5336
2023/11/01 01:48:31 - INFO - root -   train_accuracy = 0.7453
2023/11/01 01:49:01 - INFO - root -   Epoch: [113/300][0/53], lr: 0.00000116 	 loss = 0.1841(0.1841)
2023/11/01 01:50:00 - INFO - root -   Epoch: [113/300][20/53], lr: 0.00000116 	 loss = 0.7514(0.6225)
2023/11/01 01:51:11 - INFO - root -   Epoch: [113/300][40/53], lr: 0.00000116 	 loss = 0.5478(0.5735)
2023/11/01 01:51:29 - INFO - root -   Epoch: [113/300] 	 loss = 0.5816
2023/11/01 01:51:29 - INFO - root -   train_accuracy = 0.6698
2023/11/01 01:52:00 - INFO - root -   Epoch: [114/300][0/53], lr: 0.00000116 	 loss = 0.2456(0.2456)
2023/11/01 01:53:06 - INFO - root -   Epoch: [114/300][20/53], lr: 0.00000116 	 loss = 0.4408(0.6560)
2023/11/01 01:54:18 - INFO - root -   Epoch: [114/300][40/53], lr: 0.00000116 	 loss = 0.7269(0.6438)
2023/11/01 01:54:43 - INFO - root -   Epoch: [114/300] 	 loss = 0.6537
2023/11/01 01:55:20 - INFO - root -   precision = 0.7407
2023/11/01 01:55:20 - INFO - root -   eval_loss = 0.6099
2023/11/01 01:55:20 - INFO - root -   eval_acc = 0.7407
2023/11/01 01:55:22 - INFO - root -   train_accuracy = 0.6604
2023/11/01 01:56:08 - INFO - root -   Epoch: [115/300][0/53], lr: 0.00000117 	 loss = 0.5267(0.5267)
2023/11/01 01:57:06 - INFO - root -   Epoch: [115/300][20/53], lr: 0.00000117 	 loss = 0.7551(0.6346)
2023/11/01 01:58:12 - INFO - root -   Epoch: [115/300][40/53], lr: 0.00000117 	 loss = 0.5786(0.5543)
2023/11/01 01:58:26 - INFO - root -   Epoch: [115/300] 	 loss = 0.5901
2023/11/01 01:58:26 - INFO - root -   train_accuracy = 0.7264
2023/11/01 01:59:04 - INFO - root -   Epoch: [116/300][0/53], lr: 0.00000118 	 loss = 0.2333(0.2333)
2023/11/01 02:00:04 - INFO - root -   Epoch: [116/300][20/53], lr: 0.00000118 	 loss = 1.1816(0.6221)
2023/11/01 02:01:20 - INFO - root -   Epoch: [116/300][40/53], lr: 0.00000118 	 loss = 0.3891(0.5552)
2023/11/01 02:01:27 - INFO - root -   Epoch: [116/300] 	 loss = 0.5850
2023/11/01 02:01:27 - INFO - root -   train_accuracy = 0.7170
2023/11/01 02:02:00 - INFO - root -   Epoch: [117/300][0/53], lr: 0.00000119 	 loss = 0.1976(0.1976)
2023/11/01 02:03:12 - INFO - root -   Epoch: [117/300][20/53], lr: 0.00000119 	 loss = 0.9189(0.6455)
2023/11/01 02:04:13 - INFO - root -   Epoch: [117/300][40/53], lr: 0.00000119 	 loss = 0.6900(0.5732)
2023/11/01 02:04:34 - INFO - root -   Epoch: [117/300] 	 loss = 0.5450
2023/11/01 02:04:35 - INFO - root -   train_accuracy = 0.7075
2023/11/01 02:04:57 - INFO - root -   Epoch: [118/300][0/53], lr: 0.00000120 	 loss = 0.3743(0.3743)
2023/11/01 02:06:12 - INFO - root -   Epoch: [118/300][20/53], lr: 0.00000120 	 loss = 1.2814(0.6344)
2023/11/01 02:07:28 - INFO - root -   Epoch: [118/300][40/53], lr: 0.00000120 	 loss = 0.3728(0.6051)
2023/11/01 02:07:36 - INFO - root -   Epoch: [118/300] 	 loss = 0.6248
2023/11/01 02:07:36 - INFO - root -   train_accuracy = 0.6698
2023/11/01 02:08:07 - INFO - root -   Epoch: [119/300][0/53], lr: 0.00000121 	 loss = 0.1949(0.1949)
2023/11/01 02:09:12 - INFO - root -   Epoch: [119/300][20/53], lr: 0.00000121 	 loss = 1.0675(0.6047)
2023/11/01 02:10:29 - INFO - root -   Epoch: [119/300][40/53], lr: 0.00000121 	 loss = 0.8593(0.5800)
2023/11/01 02:10:35 - INFO - root -   Epoch: [119/300] 	 loss = 0.5863
2023/11/01 02:11:13 - INFO - root -   precision = 0.7037
2023/11/01 02:11:13 - INFO - root -   eval_loss = 0.6130
2023/11/01 02:11:13 - INFO - root -   eval_acc = 0.7037
2023/11/01 02:11:14 - INFO - root -   train_accuracy = 0.6887
2023/11/01 02:11:36 - INFO - root -   Epoch: [120/300][0/53], lr: 0.00000122 	 loss = 0.1751(0.1751)
2023/11/01 02:12:37 - INFO - root -   Epoch: [120/300][20/53], lr: 0.00000122 	 loss = 0.9444(0.6278)
2023/11/01 02:13:55 - INFO - root -   Epoch: [120/300][40/53], lr: 0.00000122 	 loss = 0.6567(0.5670)
2023/11/01 02:14:10 - INFO - root -   Epoch: [120/300] 	 loss = 0.5926
2023/11/01 02:14:10 - INFO - root -   train_accuracy = 0.6981
2023/11/01 02:14:41 - INFO - root -   Epoch: [121/300][0/53], lr: 0.00000123 	 loss = 0.5425(0.5425)
2023/11/01 02:15:58 - INFO - root -   Epoch: [121/300][20/53], lr: 0.00000123 	 loss = 1.6124(0.6128)
2023/11/01 02:16:51 - INFO - root -   Epoch: [121/300][40/53], lr: 0.00000123 	 loss = 0.6888(0.5716)
2023/11/01 02:17:08 - INFO - root -   Epoch: [121/300] 	 loss = 0.5702
2023/11/01 02:17:08 - INFO - root -   train_accuracy = 0.7170
2023/11/01 02:17:30 - INFO - root -   Epoch: [122/300][0/53], lr: 0.00000124 	 loss = 0.4445(0.4445)
2023/11/01 02:18:30 - INFO - root -   Epoch: [122/300][20/53], lr: 0.00000124 	 loss = 0.7815(0.5840)
2023/11/01 02:19:51 - INFO - root -   Epoch: [122/300][40/53], lr: 0.00000124 	 loss = 0.6152(0.5465)
2023/11/01 02:20:19 - INFO - root -   Epoch: [122/300] 	 loss = 0.5774
2023/11/01 02:20:19 - INFO - root -   train_accuracy = 0.7170
2023/11/01 02:20:43 - INFO - root -   Epoch: [123/300][0/53], lr: 0.00000125 	 loss = 0.7743(0.7743)
2023/11/01 02:22:03 - INFO - root -   Epoch: [123/300][20/53], lr: 0.00000125 	 loss = 0.9468(0.5805)
2023/11/01 02:22:55 - INFO - root -   Epoch: [123/300][40/53], lr: 0.00000125 	 loss = 0.3948(0.4879)
2023/11/01 02:23:25 - INFO - root -   Epoch: [123/300] 	 loss = 0.5063
2023/11/01 02:23:25 - INFO - root -   train_accuracy = 0.7642
2023/11/01 02:24:07 - INFO - root -   Epoch: [124/300][0/53], lr: 0.00000126 	 loss = 0.1063(0.1063)
2023/11/01 02:25:03 - INFO - root -   Epoch: [124/300][20/53], lr: 0.00000126 	 loss = 0.5297(0.4638)
2023/11/01 02:26:11 - INFO - root -   Epoch: [124/300][40/53], lr: 0.00000126 	 loss = 0.3483(0.4741)
2023/11/01 02:26:24 - INFO - root -   Epoch: [124/300] 	 loss = 0.5007
2023/11/01 02:27:03 - INFO - root -   precision = 0.7407
2023/11/01 02:27:03 - INFO - root -   eval_loss = 0.6347
2023/11/01 02:27:03 - INFO - root -   eval_acc = 0.7407
2023/11/01 02:27:05 - INFO - root -   train_accuracy = 0.7830
2023/11/01 02:27:28 - INFO - root -   Epoch: [125/300][0/53], lr: 0.00000127 	 loss = 0.3962(0.3962)
2023/11/01 02:28:34 - INFO - root -   Epoch: [125/300][20/53], lr: 0.00000127 	 loss = 0.3948(0.6472)
2023/11/01 02:29:35 - INFO - root -   Epoch: [125/300][40/53], lr: 0.00000127 	 loss = 1.0098(0.5789)
2023/11/01 02:30:09 - INFO - root -   Epoch: [125/300] 	 loss = 0.5834
2023/11/01 02:30:09 - INFO - root -   train_accuracy = 0.7642
2023/11/01 02:30:32 - INFO - root -   Epoch: [126/300][0/53], lr: 0.00000128 	 loss = 0.1015(0.1015)
2023/11/01 02:31:43 - INFO - root -   Epoch: [126/300][20/53], lr: 0.00000128 	 loss = 0.4546(0.5309)
2023/11/01 02:32:36 - INFO - root -   Epoch: [126/300][40/53], lr: 0.00000128 	 loss = 0.6524(0.5443)
2023/11/01 02:33:03 - INFO - root -   Epoch: [126/300] 	 loss = 0.5501
2023/11/01 02:33:03 - INFO - root -   train_accuracy = 0.7264
2023/11/01 02:33:41 - INFO - root -   Epoch: [127/300][0/53], lr: 0.00000129 	 loss = 0.2396(0.2396)
2023/11/01 02:34:44 - INFO - root -   Epoch: [127/300][20/53], lr: 0.00000129 	 loss = 0.4535(0.5455)
2023/11/01 02:35:52 - INFO - root -   Epoch: [127/300][40/53], lr: 0.00000129 	 loss = 0.5059(0.5403)
2023/11/01 02:36:10 - INFO - root -   Epoch: [127/300] 	 loss = 0.5499
2023/11/01 02:36:10 - INFO - root -   train_accuracy = 0.7453
2023/11/01 02:36:43 - INFO - root -   Epoch: [128/300][0/53], lr: 0.00000130 	 loss = 0.2319(0.2319)
2023/11/01 02:37:46 - INFO - root -   Epoch: [128/300][20/53], lr: 0.00000130 	 loss = 0.5268(0.5059)
2023/11/01 02:38:46 - INFO - root -   Epoch: [128/300][40/53], lr: 0.00000130 	 loss = 0.5593(0.5215)
2023/11/01 02:39:06 - INFO - root -   Epoch: [128/300] 	 loss = 0.5435
2023/11/01 02:39:06 - INFO - root -   train_accuracy = 0.7358
2023/11/01 02:39:40 - INFO - root -   Epoch: [129/300][0/53], lr: 0.00000130 	 loss = 0.2797(0.2797)
2023/11/01 02:40:47 - INFO - root -   Epoch: [129/300][20/53], lr: 0.00000130 	 loss = 0.4730(0.6146)
2023/11/01 02:42:00 - INFO - root -   Epoch: [129/300][40/53], lr: 0.00000130 	 loss = 0.4244(0.5827)
2023/11/01 02:42:19 - INFO - root -   Epoch: [129/300] 	 loss = 0.6067
2023/11/01 02:43:00 - INFO - root -   precision = 0.7407
2023/11/01 02:43:00 - INFO - root -   eval_loss = 0.6497
2023/11/01 02:43:00 - INFO - root -   eval_acc = 0.7407
2023/11/01 02:43:04 - INFO - root -   train_accuracy = 0.7264
2023/11/01 02:43:38 - INFO - root -   Epoch: [130/300][0/53], lr: 0.00000131 	 loss = 0.2749(0.2749)
2023/11/01 02:44:35 - INFO - root -   Epoch: [130/300][20/53], lr: 0.00000131 	 loss = 0.7371(0.4858)
2023/11/01 02:45:39 - INFO - root -   Epoch: [130/300][40/53], lr: 0.00000131 	 loss = 0.4677(0.4820)
2023/11/01 02:46:04 - INFO - root -   Epoch: [130/300] 	 loss = 0.4993
2023/11/01 02:46:04 - INFO - root -   train_accuracy = 0.7358
2023/11/01 02:46:44 - INFO - root -   Epoch: [131/300][0/53], lr: 0.00000132 	 loss = 0.1023(0.1023)
2023/11/01 02:47:37 - INFO - root -   Epoch: [131/300][20/53], lr: 0.00000132 	 loss = 0.4000(0.6005)
2023/11/01 02:48:49 - INFO - root -   Epoch: [131/300][40/53], lr: 0.00000132 	 loss = 0.9196(0.5145)
2023/11/01 02:49:01 - INFO - root -   Epoch: [131/300] 	 loss = 0.5335
2023/11/01 02:49:01 - INFO - root -   train_accuracy = 0.7358
2023/11/01 02:49:23 - INFO - root -   Epoch: [132/300][0/53], lr: 0.00000133 	 loss = 0.5109(0.5109)
2023/11/01 02:50:34 - INFO - root -   Epoch: [132/300][20/53], lr: 0.00000133 	 loss = 0.7093(0.5693)
2023/11/01 02:51:49 - INFO - root -   Epoch: [132/300][40/53], lr: 0.00000133 	 loss = 0.8793(0.5419)
2023/11/01 02:52:01 - INFO - root -   Epoch: [132/300] 	 loss = 0.5732
2023/11/01 02:52:01 - INFO - root -   train_accuracy = 0.6698
2023/11/01 02:52:32 - INFO - root -   Epoch: [133/300][0/53], lr: 0.00000134 	 loss = 0.1963(0.1963)
2023/11/01 02:53:34 - INFO - root -   Epoch: [133/300][20/53], lr: 0.00000134 	 loss = 1.0353(0.4955)
2023/11/01 02:54:38 - INFO - root -   Epoch: [133/300][40/53], lr: 0.00000134 	 loss = 0.3404(0.4980)
2023/11/01 02:54:54 - INFO - root -   Epoch: [133/300] 	 loss = 0.5187
2023/11/01 02:54:54 - INFO - root -   train_accuracy = 0.7547
2023/11/01 02:55:32 - INFO - root -   Epoch: [134/300][0/53], lr: 0.00000135 	 loss = 0.2248(0.2248)
2023/11/01 02:56:24 - INFO - root -   Epoch: [134/300][20/53], lr: 0.00000135 	 loss = 0.4670(0.4975)
2023/11/01 02:57:38 - INFO - root -   Epoch: [134/300][40/53], lr: 0.00000135 	 loss = 0.5535(0.5122)
2023/11/01 02:57:51 - INFO - root -   Epoch: [134/300] 	 loss = 0.5453
2023/11/01 02:58:29 - INFO - root -   precision = 0.7407
2023/11/01 02:58:29 - INFO - root -   eval_loss = 0.6283
2023/11/01 02:58:29 - INFO - root -   eval_acc = 0.7407
2023/11/01 02:58:30 - INFO - root -   train_accuracy = 0.7170
2023/11/01 02:58:59 - INFO - root -   Epoch: [135/300][0/53], lr: 0.00000136 	 loss = 0.3973(0.3973)
2023/11/01 03:00:16 - INFO - root -   Epoch: [135/300][20/53], lr: 0.00000136 	 loss = 0.7266(0.6260)
2023/11/01 03:01:06 - INFO - root -   Epoch: [135/300][40/53], lr: 0.00000136 	 loss = 0.6529(0.5858)
2023/11/01 03:01:39 - INFO - root -   Epoch: [135/300] 	 loss = 0.5908
2023/11/01 03:01:39 - INFO - root -   train_accuracy = 0.6792
2023/11/01 03:02:15 - INFO - root -   Epoch: [136/300][0/53], lr: 0.00000137 	 loss = 0.1439(0.1439)
2023/11/01 03:03:18 - INFO - root -   Epoch: [136/300][20/53], lr: 0.00000137 	 loss = 0.3052(0.5369)
2023/11/01 03:04:16 - INFO - root -   Epoch: [136/300][40/53], lr: 0.00000137 	 loss = 0.8883(0.5579)
2023/11/01 03:04:39 - INFO - root -   Epoch: [136/300] 	 loss = 0.5681
2023/11/01 03:04:39 - INFO - root -   train_accuracy = 0.7170
2023/11/01 03:05:01 - INFO - root -   Epoch: [137/300][0/53], lr: 0.00000138 	 loss = 0.4833(0.4833)
2023/11/01 03:06:18 - INFO - root -   Epoch: [137/300][20/53], lr: 0.00000138 	 loss = 0.7182(0.6047)
2023/11/01 03:07:32 - INFO - root -   Epoch: [137/300][40/53], lr: 0.00000138 	 loss = 0.5855(0.5766)
2023/11/01 03:07:54 - INFO - root -   Epoch: [137/300] 	 loss = 0.5919
2023/11/01 03:07:54 - INFO - root -   train_accuracy = 0.7358
2023/11/01 03:08:16 - INFO - root -   Epoch: [138/300][0/53], lr: 0.00000139 	 loss = 0.3280(0.3280)
2023/11/01 03:09:17 - INFO - root -   Epoch: [138/300][20/53], lr: 0.00000139 	 loss = 0.8674(0.5807)
2023/11/01 03:10:32 - INFO - root -   Epoch: [138/300][40/53], lr: 0.00000139 	 loss = 0.8644(0.5999)
2023/11/01 03:10:58 - INFO - root -   Epoch: [138/300] 	 loss = 0.6177
2023/11/01 03:10:58 - INFO - root -   train_accuracy = 0.7075
2023/11/01 03:11:32 - INFO - root -   Epoch: [139/300][0/53], lr: 0.00000140 	 loss = 0.5339(0.5339)
2023/11/01 03:12:23 - INFO - root -   Epoch: [139/300][20/53], lr: 0.00000140 	 loss = 0.6803(0.6182)
2023/11/01 03:13:39 - INFO - root -   Epoch: [139/300][40/53], lr: 0.00000140 	 loss = 0.5164(0.5914)
2023/11/01 03:13:57 - INFO - root -   Epoch: [139/300] 	 loss = 0.5922
2023/11/01 03:14:36 - INFO - root -   precision = 0.6667
2023/11/01 03:14:36 - INFO - root -   eval_loss = 0.6232
2023/11/01 03:14:36 - INFO - root -   eval_acc = 0.6667
2023/11/01 03:14:37 - INFO - root -   train_accuracy = 0.6509
2023/11/01 03:15:17 - INFO - root -   Epoch: [140/300][0/53], lr: 0.00000141 	 loss = 0.5445(0.5445)
2023/11/01 03:16:16 - INFO - root -   Epoch: [140/300][20/53], lr: 0.00000141 	 loss = 0.8672(0.5348)
2023/11/01 03:17:30 - INFO - root -   Epoch: [140/300][40/53], lr: 0.00000141 	 loss = 0.6131(0.5233)
2023/11/01 03:17:40 - INFO - root -   Epoch: [140/300] 	 loss = 0.5493
2023/11/01 03:17:40 - INFO - root -   train_accuracy = 0.7358
2023/11/01 03:18:13 - INFO - root -   Epoch: [141/300][0/53], lr: 0.00000142 	 loss = 0.3258(0.3258)
2023/11/01 03:19:20 - INFO - root -   Epoch: [141/300][20/53], lr: 0.00000142 	 loss = 0.7323(0.5500)
2023/11/01 03:20:35 - INFO - root -   Epoch: [141/300][40/53], lr: 0.00000142 	 loss = 0.6112(0.5873)
2023/11/01 03:20:45 - INFO - root -   Epoch: [141/300] 	 loss = 0.5851
2023/11/01 03:20:45 - INFO - root -   train_accuracy = 0.6792
2023/11/01 03:21:16 - INFO - root -   Epoch: [142/300][0/53], lr: 0.00000143 	 loss = 0.5882(0.5882)
2023/11/01 03:22:21 - INFO - root -   Epoch: [142/300][20/53], lr: 0.00000143 	 loss = 0.6026(0.4955)
2023/11/01 03:23:30 - INFO - root -   Epoch: [142/300][40/53], lr: 0.00000143 	 loss = 0.3998(0.4863)
2023/11/01 03:23:47 - INFO - root -   Epoch: [142/300] 	 loss = 0.5263
2023/11/01 03:23:47 - INFO - root -   train_accuracy = 0.7547
2023/11/01 03:24:19 - INFO - root -   Epoch: [143/300][0/53], lr: 0.00000144 	 loss = 0.3271(0.3271)
2023/11/01 03:25:35 - INFO - root -   Epoch: [143/300][20/53], lr: 0.00000144 	 loss = 0.4491(0.5989)
2023/11/01 03:26:38 - INFO - root -   Epoch: [143/300][40/53], lr: 0.00000144 	 loss = 0.7358(0.5653)
2023/11/01 03:26:58 - INFO - root -   Epoch: [143/300] 	 loss = 0.5681
2023/11/01 03:26:58 - INFO - root -   train_accuracy = 0.7453
2023/11/01 03:27:29 - INFO - root -   Epoch: [144/300][0/53], lr: 0.00000144 	 loss = 0.2055(0.2055)
2023/11/01 03:28:32 - INFO - root -   Epoch: [144/300][20/53], lr: 0.00000144 	 loss = 0.6472(0.5216)
2023/11/01 03:29:55 - INFO - root -   Epoch: [144/300][40/53], lr: 0.00000144 	 loss = 0.5167(0.5081)
2023/11/01 03:30:06 - INFO - root -   Epoch: [144/300] 	 loss = 0.5188
2023/11/01 03:30:46 - INFO - root -   precision = 0.7037
2023/11/01 03:30:46 - INFO - root -   eval_loss = 0.6264
2023/11/01 03:30:46 - INFO - root -   eval_acc = 0.7037
2023/11/01 03:30:47 - INFO - root -   train_accuracy = 0.7453
2023/11/01 03:31:12 - INFO - root -   Epoch: [145/300][0/53], lr: 0.00000145 	 loss = 0.4376(0.4376)
2023/11/01 03:32:37 - INFO - root -   Epoch: [145/300][20/53], lr: 0.00000145 	 loss = 0.6672(0.4866)
2023/11/01 03:33:30 - INFO - root -   Epoch: [145/300][40/53], lr: 0.00000145 	 loss = 0.8096(0.4999)
2023/11/01 03:33:48 - INFO - root -   Epoch: [145/300] 	 loss = 0.4897
2023/11/01 03:33:48 - INFO - root -   train_accuracy = 0.7358
2023/11/01 03:34:10 - INFO - root -   Epoch: [146/300][0/53], lr: 0.00000146 	 loss = 0.1691(0.1691)
2023/11/01 03:35:19 - INFO - root -   Epoch: [146/300][20/53], lr: 0.00000146 	 loss = 0.9167(0.5313)
2023/11/01 03:36:13 - INFO - root -   Epoch: [146/300][40/53], lr: 0.00000146 	 loss = 0.2855(0.5220)
2023/11/01 03:36:41 - INFO - root -   Epoch: [146/300] 	 loss = 0.5249
2023/11/01 03:36:41 - INFO - root -   train_accuracy = 0.7642
2023/11/01 03:37:04 - INFO - root -   Epoch: [147/300][0/53], lr: 0.00000147 	 loss = 0.4062(0.4062)
2023/11/01 03:38:10 - INFO - root -   Epoch: [147/300][20/53], lr: 0.00000147 	 loss = 1.8267(0.5419)
2023/11/01 03:39:07 - INFO - root -   Epoch: [147/300][40/53], lr: 0.00000147 	 loss = 0.6779(0.4996)
2023/11/01 03:39:39 - INFO - root -   Epoch: [147/300] 	 loss = 0.5367
2023/11/01 03:39:39 - INFO - root -   train_accuracy = 0.7547
2023/11/01 03:40:09 - INFO - root -   Epoch: [148/300][0/53], lr: 0.00000148 	 loss = 0.5075(0.5075)
2023/11/01 03:41:14 - INFO - root -   Epoch: [148/300][20/53], lr: 0.00000148 	 loss = 0.8654(0.6087)
2023/11/01 03:42:15 - INFO - root -   Epoch: [148/300][40/53], lr: 0.00000148 	 loss = 0.3917(0.5777)
2023/11/01 03:42:35 - INFO - root -   Epoch: [148/300] 	 loss = 0.5789
2023/11/01 03:42:35 - INFO - root -   train_accuracy = 0.7075
2023/11/01 03:43:08 - INFO - root -   Epoch: [149/300][0/53], lr: 0.00000149 	 loss = 0.1215(0.1215)
2023/11/01 03:44:09 - INFO - root -   Epoch: [149/300][20/53], lr: 0.00000149 	 loss = 1.2447(0.5098)
2023/11/01 03:45:16 - INFO - root -   Epoch: [149/300][40/53], lr: 0.00000149 	 loss = 0.7267(0.5149)
2023/11/01 03:45:37 - INFO - root -   Epoch: [149/300] 	 loss = 0.5764
2023/11/01 03:46:16 - INFO - root -   precision = 0.7037
2023/11/01 03:46:16 - INFO - root -   eval_loss = 0.6232
2023/11/01 03:46:16 - INFO - root -   eval_acc = 0.7037
2023/11/01 03:46:18 - INFO - root -   train_accuracy = 0.7264
2023/11/01 03:46:42 - INFO - root -   Epoch: [150/300][0/53], lr: 0.00000150 	 loss = 0.2869(0.2869)
2023/11/01 03:47:55 - INFO - root -   Epoch: [150/300][20/53], lr: 0.00000150 	 loss = 0.9062(0.5741)
2023/11/01 03:49:16 - INFO - root -   Epoch: [150/300][40/53], lr: 0.00000150 	 loss = 0.4830(0.5512)
2023/11/01 03:49:28 - INFO - root -   Epoch: [150/300] 	 loss = 0.5603
2023/11/01 03:49:28 - INFO - root -   train_accuracy = 0.7170
2023/11/01 03:50:00 - INFO - root -   Epoch: [151/300][0/53], lr: 0.00000151 	 loss = 0.2698(0.2698)
2023/11/01 03:51:13 - INFO - root -   Epoch: [151/300][20/53], lr: 0.00000151 	 loss = 1.0494(0.6050)
2023/11/01 03:52:27 - INFO - root -   Epoch: [151/300][40/53], lr: 0.00000151 	 loss = 0.2887(0.5728)
2023/11/01 03:52:40 - INFO - root -   Epoch: [151/300] 	 loss = 0.5848
2023/11/01 03:52:40 - INFO - root -   train_accuracy = 0.7264
2023/11/01 03:53:19 - INFO - root -   Epoch: [152/300][0/53], lr: 0.00000152 	 loss = 0.1765(0.1765)
2023/11/01 03:54:22 - INFO - root -   Epoch: [152/300][20/53], lr: 0.00000152 	 loss = 0.3430(0.5034)
2023/11/01 03:55:30 - INFO - root -   Epoch: [152/300][40/53], lr: 0.00000152 	 loss = 0.9799(0.4775)
2023/11/01 03:55:50 - INFO - root -   Epoch: [152/300] 	 loss = 0.4999
2023/11/01 03:55:50 - INFO - root -   train_accuracy = 0.7453
2023/11/01 03:56:13 - INFO - root -   Epoch: [153/300][0/53], lr: 0.00000153 	 loss = 0.2883(0.2883)
2023/11/01 03:57:22 - INFO - root -   Epoch: [153/300][20/53], lr: 0.00000153 	 loss = 1.1596(0.5211)
2023/11/01 03:58:33 - INFO - root -   Epoch: [153/300][40/53], lr: 0.00000153 	 loss = 0.9337(0.5077)
2023/11/01 03:58:58 - INFO - root -   Epoch: [153/300] 	 loss = 0.5333
2023/11/01 03:58:58 - INFO - root -   train_accuracy = 0.7264
2023/11/01 03:59:29 - INFO - root -   Epoch: [154/300][0/53], lr: 0.00000154 	 loss = 0.5326(0.5326)
2023/11/01 04:00:36 - INFO - root -   Epoch: [154/300][20/53], lr: 0.00000154 	 loss = 0.5058(0.4919)
2023/11/01 04:01:35 - INFO - root -   Epoch: [154/300][40/53], lr: 0.00000154 	 loss = 0.4163(0.4950)
2023/11/01 04:01:57 - INFO - root -   Epoch: [154/300] 	 loss = 0.4982
2023/11/01 04:02:34 - INFO - root -   precision = 0.7037
2023/11/01 04:02:34 - INFO - root -   eval_loss = 0.6399
2023/11/01 04:02:34 - INFO - root -   eval_acc = 0.7037
2023/11/01 04:02:35 - INFO - root -   train_accuracy = 0.7358
2023/11/01 04:03:00 - INFO - root -   Epoch: [155/300][0/53], lr: 0.00000155 	 loss = 0.4115(0.4115)
2023/11/01 04:04:15 - INFO - root -   Epoch: [155/300][20/53], lr: 0.00000155 	 loss = 0.5834(0.5351)
2023/11/01 04:05:21 - INFO - root -   Epoch: [155/300][40/53], lr: 0.00000155 	 loss = 0.8100(0.5245)
2023/11/01 04:05:37 - INFO - root -   Epoch: [155/300] 	 loss = 0.5231
2023/11/01 04:05:37 - INFO - root -   train_accuracy = 0.6981
2023/11/01 04:06:16 - INFO - root -   Epoch: [156/300][0/53], lr: 0.00000156 	 loss = 0.5782(0.5782)
2023/11/01 04:07:24 - INFO - root -   Epoch: [156/300][20/53], lr: 0.00000156 	 loss = 1.5091(0.5426)
2023/11/01 04:08:28 - INFO - root -   Epoch: [156/300][40/53], lr: 0.00000156 	 loss = 0.4608(0.5630)
2023/11/01 04:08:38 - INFO - root -   Epoch: [156/300] 	 loss = 0.5876
2023/11/01 04:08:38 - INFO - root -   train_accuracy = 0.6509
2023/11/01 04:09:01 - INFO - root -   Epoch: [157/300][0/53], lr: 0.00000157 	 loss = 0.3313(0.3313)
2023/11/01 04:10:21 - INFO - root -   Epoch: [157/300][20/53], lr: 0.00000157 	 loss = 0.7664(0.5600)
2023/11/01 04:11:09 - INFO - root -   Epoch: [157/300][40/53], lr: 0.00000157 	 loss = 0.7830(0.5194)
2023/11/01 04:11:41 - INFO - root -   Epoch: [157/300] 	 loss = 0.5333
2023/11/01 04:11:41 - INFO - root -   train_accuracy = 0.7547
2023/11/01 04:12:04 - INFO - root -   Epoch: [158/300][0/53], lr: 0.00000158 	 loss = 0.4314(0.4314)
2023/11/01 04:13:05 - INFO - root -   Epoch: [158/300][20/53], lr: 0.00000158 	 loss = 1.5622(0.5808)
2023/11/01 04:14:07 - INFO - root -   Epoch: [158/300][40/53], lr: 0.00000158 	 loss = 0.5358(0.5299)
2023/11/01 04:14:39 - INFO - root -   Epoch: [158/300] 	 loss = 0.5600
2023/11/01 04:14:39 - INFO - root -   train_accuracy = 0.7547
2023/11/01 04:15:18 - INFO - root -   Epoch: [159/300][0/53], lr: 0.00000159 	 loss = 0.1029(0.1029)
2023/11/01 04:16:18 - INFO - root -   Epoch: [159/300][20/53], lr: 0.00000159 	 loss = 1.4024(0.5116)
2023/11/01 04:17:30 - INFO - root -   Epoch: [159/300][40/53], lr: 0.00000159 	 loss = 0.5201(0.4723)
2023/11/01 04:17:53 - INFO - root -   Epoch: [159/300] 	 loss = 0.4932
2023/11/01 04:18:30 - INFO - root -   precision = 0.6667
2023/11/01 04:18:30 - INFO - root -   eval_loss = 0.6339
2023/11/01 04:18:30 - INFO - root -   eval_acc = 0.6667
2023/11/01 04:18:32 - INFO - root -   train_accuracy = 0.7453
2023/11/01 04:18:54 - INFO - root -   Epoch: [160/300][0/53], lr: 0.00000159 	 loss = 0.1434(0.1434)
2023/11/01 04:19:54 - INFO - root -   Epoch: [160/300][20/53], lr: 0.00000159 	 loss = 0.4910(0.4484)
2023/11/01 04:21:08 - INFO - root -   Epoch: [160/300][40/53], lr: 0.00000159 	 loss = 0.4356(0.4172)
2023/11/01 04:21:21 - INFO - root -   Epoch: [160/300] 	 loss = 0.4356
2023/11/01 04:21:21 - INFO - root -   train_accuracy = 0.7925
2023/11/01 04:21:53 - INFO - root -   Epoch: [161/300][0/53], lr: 0.00000160 	 loss = 0.4371(0.4371)
2023/11/01 04:23:03 - INFO - root -   Epoch: [161/300][20/53], lr: 0.00000160 	 loss = 0.5583(0.4368)
2023/11/01 04:24:09 - INFO - root -   Epoch: [161/300][40/53], lr: 0.00000160 	 loss = 0.5241(0.4251)
2023/11/01 04:24:31 - INFO - root -   Epoch: [161/300] 	 loss = 0.5193
2023/11/01 04:24:31 - INFO - root -   train_accuracy = 0.7547
2023/11/01 04:24:54 - INFO - root -   Epoch: [162/300][0/53], lr: 0.00000161 	 loss = 0.1567(0.1567)
2023/11/01 04:26:17 - INFO - root -   Epoch: [162/300][20/53], lr: 0.00000161 	 loss = 0.3523(0.5928)
2023/11/01 04:27:19 - INFO - root -   Epoch: [162/300][40/53], lr: 0.00000161 	 loss = 0.5995(0.5266)
2023/11/01 04:27:36 - INFO - root -   Epoch: [162/300] 	 loss = 0.5240
2023/11/01 04:27:36 - INFO - root -   train_accuracy = 0.7736
2023/11/01 04:28:07 - INFO - root -   Epoch: [163/300][0/53], lr: 0.00000162 	 loss = 0.6297(0.6297)
2023/11/01 04:29:07 - INFO - root -   Epoch: [163/300][20/53], lr: 0.00000162 	 loss = 0.7315(0.4966)
2023/11/01 04:30:11 - INFO - root -   Epoch: [163/300][40/53], lr: 0.00000162 	 loss = 0.2225(0.4788)
2023/11/01 04:30:36 - INFO - root -   Epoch: [163/300] 	 loss = 0.5019
2023/11/01 04:30:36 - INFO - root -   train_accuracy = 0.7642
2023/11/01 04:31:00 - INFO - root -   Epoch: [164/300][0/53], lr: 0.00000163 	 loss = 0.4740(0.4740)
2023/11/01 04:32:06 - INFO - root -   Epoch: [164/300][20/53], lr: 0.00000163 	 loss = 1.3765(0.5542)
2023/11/01 04:33:12 - INFO - root -   Epoch: [164/300][40/53], lr: 0.00000163 	 loss = 0.6710(0.5443)
2023/11/01 04:33:32 - INFO - root -   Epoch: [164/300] 	 loss = 0.5551
2023/11/01 04:34:10 - INFO - root -   precision = 0.7407
2023/11/01 04:34:10 - INFO - root -   eval_loss = 0.6914
2023/11/01 04:34:10 - INFO - root -   eval_acc = 0.7407
2023/11/01 04:34:11 - INFO - root -   train_accuracy = 0.7547
2023/11/01 04:34:37 - INFO - root -   Epoch: [165/300][0/53], lr: 0.00000164 	 loss = 0.2311(0.2311)
2023/11/01 04:35:43 - INFO - root -   Epoch: [165/300][20/53], lr: 0.00000164 	 loss = 0.9154(0.4522)
2023/11/01 04:36:44 - INFO - root -   Epoch: [165/300][40/53], lr: 0.00000164 	 loss = 0.3728(0.4442)
2023/11/01 04:37:05 - INFO - root -   Epoch: [165/300] 	 loss = 0.4745
2023/11/01 04:37:05 - INFO - root -   train_accuracy = 0.7830
2023/11/01 04:37:36 - INFO - root -   Epoch: [166/300][0/53], lr: 0.00000165 	 loss = 0.1994(0.1994)
2023/11/01 04:38:43 - INFO - root -   Epoch: [166/300][20/53], lr: 0.00000165 	 loss = 0.6514(0.6081)
2023/11/01 04:39:47 - INFO - root -   Epoch: [166/300][40/53], lr: 0.00000165 	 loss = 0.6312(0.5748)
2023/11/01 04:40:13 - INFO - root -   Epoch: [166/300] 	 loss = 0.5636
2023/11/01 04:40:13 - INFO - root -   train_accuracy = 0.7075
2023/11/01 04:40:35 - INFO - root -   Epoch: [167/300][0/53], lr: 0.00000166 	 loss = 0.6582(0.6582)
2023/11/01 04:41:56 - INFO - root -   Epoch: [167/300][20/53], lr: 0.00000166 	 loss = 0.3740(0.4382)
2023/11/01 04:43:00 - INFO - root -   Epoch: [167/300][40/53], lr: 0.00000166 	 loss = 0.8886(0.4199)
2023/11/01 04:43:14 - INFO - root -   Epoch: [167/300] 	 loss = 0.4728
2023/11/01 04:43:14 - INFO - root -   train_accuracy = 0.7830
2023/11/01 04:43:37 - INFO - root -   Epoch: [168/300][0/53], lr: 0.00000167 	 loss = 0.5016(0.5016)
2023/11/01 04:44:55 - INFO - root -   Epoch: [168/300][20/53], lr: 0.00000167 	 loss = 0.7419(0.4854)
2023/11/01 04:45:53 - INFO - root -   Epoch: [168/300][40/53], lr: 0.00000167 	 loss = 0.6213(0.4840)
2023/11/01 04:46:17 - INFO - root -   Epoch: [168/300] 	 loss = 0.5225
2023/11/01 04:46:17 - INFO - root -   train_accuracy = 0.7264
2023/11/01 04:46:47 - INFO - root -   Epoch: [169/300][0/53], lr: 0.00000168 	 loss = 0.5649(0.5649)
2023/11/01 04:47:40 - INFO - root -   Epoch: [169/300][20/53], lr: 0.00000168 	 loss = 0.3798(0.4707)
2023/11/01 04:49:08 - INFO - root -   Epoch: [169/300][40/53], lr: 0.00000168 	 loss = 0.2544(0.4231)
2023/11/01 04:49:19 - INFO - root -   Epoch: [169/300] 	 loss = 0.4638
2023/11/01 04:49:56 - INFO - root -   precision = 0.6667
2023/11/01 04:49:56 - INFO - root -   eval_loss = 0.7125
2023/11/01 04:49:56 - INFO - root -   eval_acc = 0.6667
2023/11/01 04:49:57 - INFO - root -   train_accuracy = 0.7547
2023/11/01 04:50:19 - INFO - root -   Epoch: [170/300][0/53], lr: 0.00000169 	 loss = 0.5014(0.5014)
2023/11/01 04:51:33 - INFO - root -   Epoch: [170/300][20/53], lr: 0.00000169 	 loss = 0.4389(0.4256)
2023/11/01 04:52:39 - INFO - root -   Epoch: [170/300][40/53], lr: 0.00000169 	 loss = 1.4126(0.4096)
2023/11/01 04:52:55 - INFO - root -   Epoch: [170/300] 	 loss = 0.4600
2023/11/01 04:52:55 - INFO - root -   train_accuracy = 0.7547
2023/11/01 04:53:17 - INFO - root -   Epoch: [171/300][0/53], lr: 0.00000170 	 loss = 0.3124(0.3124)
2023/11/01 04:54:32 - INFO - root -   Epoch: [171/300][20/53], lr: 0.00000170 	 loss = 1.0139(0.5869)
2023/11/01 04:55:42 - INFO - root -   Epoch: [171/300][40/53], lr: 0.00000170 	 loss = 1.3928(0.5719)
2023/11/01 04:56:04 - INFO - root -   Epoch: [171/300] 	 loss = 0.5879
2023/11/01 04:56:04 - INFO - root -   train_accuracy = 0.7170
2023/11/01 04:56:35 - INFO - root -   Epoch: [172/300][0/53], lr: 0.00000171 	 loss = 0.2140(0.2140)
2023/11/01 04:57:44 - INFO - root -   Epoch: [172/300][20/53], lr: 0.00000171 	 loss = 0.8289(0.5247)
2023/11/01 04:58:46 - INFO - root -   Epoch: [172/300][40/53], lr: 0.00000171 	 loss = 0.5280(0.5014)
2023/11/01 04:59:06 - INFO - root -   Epoch: [172/300] 	 loss = 0.5497
2023/11/01 04:59:06 - INFO - root -   train_accuracy = 0.7075
2023/11/01 04:59:36 - INFO - root -   Epoch: [173/300][0/53], lr: 0.00000172 	 loss = 0.1732(0.1732)
2023/11/01 05:00:36 - INFO - root -   Epoch: [173/300][20/53], lr: 0.00000172 	 loss = 1.3119(0.5240)
2023/11/01 05:01:38 - INFO - root -   Epoch: [173/300][40/53], lr: 0.00000172 	 loss = 0.4338(0.4904)
2023/11/01 05:02:05 - INFO - root -   Epoch: [173/300] 	 loss = 0.5449
2023/11/01 05:02:05 - INFO - root -   train_accuracy = 0.7358
2023/11/01 05:02:29 - INFO - root -   Epoch: [174/300][0/53], lr: 0.00000173 	 loss = 0.3642(0.3642)
2023/11/01 05:03:25 - INFO - root -   Epoch: [174/300][20/53], lr: 0.00000173 	 loss = 1.3402(0.5121)
2023/11/01 05:04:46 - INFO - root -   Epoch: [174/300][40/53], lr: 0.00000173 	 loss = 0.3422(0.5241)
2023/11/01 05:05:03 - INFO - root -   Epoch: [174/300] 	 loss = 0.5480
2023/11/01 05:05:41 - INFO - root -   precision = 0.6667
2023/11/01 05:05:41 - INFO - root -   eval_loss = 0.7318
2023/11/01 05:05:41 - INFO - root -   eval_acc = 0.6667
2023/11/01 05:05:43 - INFO - root -   train_accuracy = 0.7358
2023/11/01 05:06:21 - INFO - root -   Epoch: [175/300][0/53], lr: 0.00000173 	 loss = 0.3923(0.3923)
2023/11/01 05:07:22 - INFO - root -   Epoch: [175/300][20/53], lr: 0.00000173 	 loss = 0.6793(0.5984)
2023/11/01 05:08:42 - INFO - root -   Epoch: [175/300][40/53], lr: 0.00000173 	 loss = 0.4996(0.5539)
2023/11/01 05:08:55 - INFO - root -   Epoch: [175/300] 	 loss = 0.5554
2023/11/01 05:08:55 - INFO - root -   train_accuracy = 0.7547
2023/11/01 05:09:17 - INFO - root -   Epoch: [176/300][0/53], lr: 0.00000174 	 loss = 0.2594(0.2594)
2023/11/01 05:10:23 - INFO - root -   Epoch: [176/300][20/53], lr: 0.00000174 	 loss = 1.2385(0.5267)
2023/11/01 05:11:22 - INFO - root -   Epoch: [176/300][40/53], lr: 0.00000174 	 loss = 0.6699(0.5090)
2023/11/01 05:11:49 - INFO - root -   Epoch: [176/300] 	 loss = 0.5535
2023/11/01 05:11:49 - INFO - root -   train_accuracy = 0.7264
2023/11/01 05:12:12 - INFO - root -   Epoch: [177/300][0/53], lr: 0.00000175 	 loss = 0.2789(0.2789)
2023/11/01 05:13:21 - INFO - root -   Epoch: [177/300][20/53], lr: 0.00000175 	 loss = 0.4108(0.4916)
2023/11/01 05:14:27 - INFO - root -   Epoch: [177/300][40/53], lr: 0.00000175 	 loss = 0.4050(0.4504)
2023/11/01 05:14:48 - INFO - root -   Epoch: [177/300] 	 loss = 0.4534
2023/11/01 05:14:48 - INFO - root -   train_accuracy = 0.7736
2023/11/01 05:15:11 - INFO - root -   Epoch: [178/300][0/53], lr: 0.00000176 	 loss = 0.2259(0.2259)
2023/11/01 05:16:26 - INFO - root -   Epoch: [178/300][20/53], lr: 0.00000176 	 loss = 1.1644(0.5491)
2023/11/01 05:17:28 - INFO - root -   Epoch: [178/300][40/53], lr: 0.00000176 	 loss = 0.2550(0.5209)
2023/11/01 05:17:51 - INFO - root -   Epoch: [178/300] 	 loss = 0.5215
2023/11/01 05:17:51 - INFO - root -   train_accuracy = 0.7736
2023/11/01 05:18:14 - INFO - root -   Epoch: [179/300][0/53], lr: 0.00000177 	 loss = 0.3418(0.3418)
2023/11/01 05:19:28 - INFO - root -   Epoch: [179/300][20/53], lr: 0.00000177 	 loss = 0.4919(0.4931)
2023/11/01 05:20:36 - INFO - root -   Epoch: [179/300][40/53], lr: 0.00000177 	 loss = 0.2103(0.5088)
2023/11/01 05:20:51 - INFO - root -   Epoch: [179/300] 	 loss = 0.5827
2023/11/01 05:21:28 - INFO - root -   precision = 0.6667
2023/11/01 05:21:28 - INFO - root -   eval_loss = 0.7048
2023/11/01 05:21:28 - INFO - root -   eval_acc = 0.6667
2023/11/01 05:21:29 - INFO - root -   train_accuracy = 0.6981
2023/11/01 05:22:00 - INFO - root -   Epoch: [180/300][0/53], lr: 0.00000178 	 loss = 0.2277(0.2277)
2023/11/01 05:23:03 - INFO - root -   Epoch: [180/300][20/53], lr: 0.00000178 	 loss = 0.5266(0.5511)
2023/11/01 05:24:00 - INFO - root -   Epoch: [180/300][40/53], lr: 0.00000178 	 loss = 0.7702(0.5355)
2023/11/01 05:24:29 - INFO - root -   Epoch: [180/300] 	 loss = 0.5196
2023/11/01 05:24:29 - INFO - root -   train_accuracy = 0.7642
2023/11/01 05:24:59 - INFO - root -   Epoch: [181/300][0/53], lr: 0.00000179 	 loss = 0.1313(0.1313)
2023/11/01 05:26:06 - INFO - root -   Epoch: [181/300][20/53], lr: 0.00000179 	 loss = 0.4595(0.5055)
2023/11/01 05:27:09 - INFO - root -   Epoch: [181/300][40/53], lr: 0.00000179 	 loss = 0.5184(0.4143)
2023/11/01 05:27:25 - INFO - root -   Epoch: [181/300] 	 loss = 0.4623
2023/11/01 05:27:25 - INFO - root -   train_accuracy = 0.8019
2023/11/01 05:27:54 - INFO - root -   Epoch: [182/300][0/53], lr: 0.00000180 	 loss = 0.6538(0.6538)
2023/11/01 05:29:02 - INFO - root -   Epoch: [182/300][20/53], lr: 0.00000180 	 loss = 0.5150(0.4660)
2023/11/01 05:30:03 - INFO - root -   Epoch: [182/300][40/53], lr: 0.00000180 	 loss = 0.7595(0.5152)
2023/11/01 05:30:30 - INFO - root -   Epoch: [182/300] 	 loss = 0.5074
2023/11/01 05:30:30 - INFO - root -   train_accuracy = 0.7358
2023/11/01 05:30:52 - INFO - root -   Epoch: [183/300][0/53], lr: 0.00000181 	 loss = 0.3799(0.3799)
2023/11/01 05:31:55 - INFO - root -   Epoch: [183/300][20/53], lr: 0.00000181 	 loss = 1.2116(0.5756)
2023/11/01 05:33:19 - INFO - root -   Epoch: [183/300][40/53], lr: 0.00000181 	 loss = 0.8097(0.4864)
2023/11/01 05:33:29 - INFO - root -   Epoch: [183/300] 	 loss = 0.5476
2023/11/01 05:33:29 - INFO - root -   train_accuracy = 0.7925
2023/11/01 05:33:59 - INFO - root -   Epoch: [184/300][0/53], lr: 0.00000182 	 loss = 0.4878(0.4878)
2023/11/01 05:35:03 - INFO - root -   Epoch: [184/300][20/53], lr: 0.00000182 	 loss = 0.7293(0.5150)
2023/11/01 05:36:14 - INFO - root -   Epoch: [184/300][40/53], lr: 0.00000182 	 loss = 0.9421(0.4745)
2023/11/01 05:36:24 - INFO - root -   Epoch: [184/300] 	 loss = 0.5381
2023/11/01 05:37:01 - INFO - root -   precision = 0.6667
2023/11/01 05:37:01 - INFO - root -   eval_loss = 0.6993
2023/11/01 05:37:01 - INFO - root -   eval_acc = 0.6667
2023/11/01 05:37:02 - INFO - root -   train_accuracy = 0.7642
2023/11/01 05:37:37 - INFO - root -   Epoch: [185/300][0/53], lr: 0.00000183 	 loss = 0.4320(0.4320)
2023/11/01 05:39:00 - INFO - root -   Epoch: [185/300][20/53], lr: 0.00000183 	 loss = 0.6930(0.5386)
2023/11/01 05:39:49 - INFO - root -   Epoch: [185/300][40/53], lr: 0.00000183 	 loss = 0.5248(0.4720)
2023/11/01 05:40:08 - INFO - root -   Epoch: [185/300] 	 loss = 0.4808
2023/11/01 05:40:08 - INFO - root -   train_accuracy = 0.7547
2023/11/01 05:40:31 - INFO - root -   Epoch: [186/300][0/53], lr: 0.00000184 	 loss = 0.2027(0.2027)
2023/11/01 05:41:54 - INFO - root -   Epoch: [186/300][20/53], lr: 0.00000184 	 loss = 0.7461(0.4607)
2023/11/01 05:42:42 - INFO - root -   Epoch: [186/300][40/53], lr: 0.00000184 	 loss = 1.2899(0.4950)
2023/11/01 05:43:11 - INFO - root -   Epoch: [186/300] 	 loss = 0.5350
2023/11/01 05:43:11 - INFO - root -   train_accuracy = 0.7547
2023/11/01 05:43:41 - INFO - root -   Epoch: [187/300][0/53], lr: 0.00000185 	 loss = 0.2581(0.2581)
2023/11/01 05:44:38 - INFO - root -   Epoch: [187/300][20/53], lr: 0.00000185 	 loss = 1.2719(0.4659)
2023/11/01 05:46:00 - INFO - root -   Epoch: [187/300][40/53], lr: 0.00000185 	 loss = 0.2953(0.5099)
2023/11/01 05:46:22 - INFO - root -   Epoch: [187/300] 	 loss = 0.5226
2023/11/01 05:46:22 - INFO - root -   train_accuracy = 0.7453
2023/11/01 05:46:44 - INFO - root -   Epoch: [188/300][0/53], lr: 0.00000186 	 loss = 0.4602(0.4602)
2023/11/01 05:48:08 - INFO - root -   Epoch: [188/300][20/53], lr: 0.00000186 	 loss = 0.8663(0.5963)
2023/11/01 05:49:15 - INFO - root -   Epoch: [188/300][40/53], lr: 0.00000186 	 loss = 0.5369(0.5141)
2023/11/01 05:49:40 - INFO - root -   Epoch: [188/300] 	 loss = 0.5340
2023/11/01 05:49:40 - INFO - root -   train_accuracy = 0.7453
2023/11/01 05:50:11 - INFO - root -   Epoch: [189/300][0/53], lr: 0.00000187 	 loss = 0.5887(0.5887)
2023/11/01 05:51:20 - INFO - root -   Epoch: [189/300][20/53], lr: 0.00000187 	 loss = 0.4568(0.4608)
2023/11/01 05:52:22 - INFO - root -   Epoch: [189/300][40/53], lr: 0.00000187 	 loss = 0.3985(0.4679)
2023/11/01 05:52:39 - INFO - root -   Epoch: [189/300] 	 loss = 0.4803
2023/11/01 05:53:16 - INFO - root -   precision = 0.6667
2023/11/01 05:53:16 - INFO - root -   eval_loss = 0.7373
2023/11/01 05:53:16 - INFO - root -   eval_acc = 0.6667
2023/11/01 05:53:17 - INFO - root -   train_accuracy = 0.7925
2023/11/01 05:53:40 - INFO - root -   Epoch: [190/300][0/53], lr: 0.00000187 	 loss = 0.2933(0.2933)
2023/11/01 05:54:48 - INFO - root -   Epoch: [190/300][20/53], lr: 0.00000187 	 loss = 1.1837(0.6451)
2023/11/01 05:56:06 - INFO - root -   Epoch: [190/300][40/53], lr: 0.00000187 	 loss = 0.6217(0.5289)
2023/11/01 05:56:22 - INFO - root -   Epoch: [190/300] 	 loss = 0.5671
2023/11/01 05:56:22 - INFO - root -   train_accuracy = 0.7547
2023/11/01 05:56:45 - INFO - root -   Epoch: [191/300][0/53], lr: 0.00000188 	 loss = 0.6254(0.6254)
2023/11/01 05:57:50 - INFO - root -   Epoch: [191/300][20/53], lr: 0.00000188 	 loss = 1.0961(0.4849)
2023/11/01 05:59:15 - INFO - root -   Epoch: [191/300][40/53], lr: 0.00000188 	 loss = 1.0831(0.4925)
2023/11/01 05:59:29 - INFO - root -   Epoch: [191/300] 	 loss = 0.5528
2023/11/01 05:59:29 - INFO - root -   train_accuracy = 0.7547
2023/11/01 06:00:00 - INFO - root -   Epoch: [192/300][0/53], lr: 0.00000189 	 loss = 0.4478(0.4478)
2023/11/01 06:01:02 - INFO - root -   Epoch: [192/300][20/53], lr: 0.00000189 	 loss = 1.1766(0.5347)
2023/11/01 06:02:12 - INFO - root -   Epoch: [192/300][40/53], lr: 0.00000189 	 loss = 0.5636(0.4830)
2023/11/01 06:02:31 - INFO - root -   Epoch: [192/300] 	 loss = 0.4999
2023/11/01 06:02:31 - INFO - root -   train_accuracy = 0.7925
2023/11/01 06:02:55 - INFO - root -   Epoch: [193/300][0/53], lr: 0.00000190 	 loss = 0.5358(0.5358)
2023/11/01 06:04:06 - INFO - root -   Epoch: [193/300][20/53], lr: 0.00000190 	 loss = 1.4561(0.5661)
2023/11/01 06:05:03 - INFO - root -   Epoch: [193/300][40/53], lr: 0.00000190 	 loss = 0.8248(0.5095)
2023/11/01 06:05:35 - INFO - root -   Epoch: [193/300] 	 loss = 0.5000
2023/11/01 06:05:35 - INFO - root -   train_accuracy = 0.8113
2023/11/01 06:05:58 - INFO - root -   Epoch: [194/300][0/53], lr: 0.00000191 	 loss = 0.4383(0.4383)
2023/11/01 06:07:23 - INFO - root -   Epoch: [194/300][20/53], lr: 0.00000191 	 loss = 0.4319(0.5487)
2023/11/01 06:08:22 - INFO - root -   Epoch: [194/300][40/53], lr: 0.00000191 	 loss = 1.0110(0.4972)
2023/11/01 06:08:46 - INFO - root -   Epoch: [194/300] 	 loss = 0.5208
2023/11/01 06:09:25 - INFO - root -   precision = 0.7407
2023/11/01 06:09:25 - INFO - root -   eval_loss = 0.8548
2023/11/01 06:09:25 - INFO - root -   eval_acc = 0.7407
2023/11/01 06:09:26 - INFO - root -   train_accuracy = 0.7830
2023/11/01 06:10:04 - INFO - root -   Epoch: [195/300][0/53], lr: 0.00000192 	 loss = 0.5160(0.5160)
2023/11/01 06:10:54 - INFO - root -   Epoch: [195/300][20/53], lr: 0.00000192 	 loss = 0.7401(0.6543)
2023/11/01 06:12:15 - INFO - root -   Epoch: [195/300][40/53], lr: 0.00000192 	 loss = 0.3825(0.6139)
2023/11/01 06:12:31 - INFO - root -   Epoch: [195/300] 	 loss = 0.6138
2023/11/01 06:12:31 - INFO - root -   train_accuracy = 0.6698
2023/11/01 06:12:56 - INFO - root -   Epoch: [196/300][0/53], lr: 0.00000193 	 loss = 0.2354(0.2354)
2023/11/01 06:14:00 - INFO - root -   Epoch: [196/300][20/53], lr: 0.00000193 	 loss = 1.3896(0.5660)
2023/11/01 06:15:13 - INFO - root -   Epoch: [196/300][40/53], lr: 0.00000193 	 loss = 0.5867(0.4979)
2023/11/01 06:15:27 - INFO - root -   Epoch: [196/300] 	 loss = 0.5367
2023/11/01 06:15:27 - INFO - root -   train_accuracy = 0.7547
2023/11/01 06:15:59 - INFO - root -   Epoch: [197/300][0/53], lr: 0.00000194 	 loss = 0.1366(0.1366)
2023/11/01 06:17:07 - INFO - root -   Epoch: [197/300][20/53], lr: 0.00000194 	 loss = 0.6542(0.4761)
2023/11/01 06:18:14 - INFO - root -   Epoch: [197/300][40/53], lr: 0.00000194 	 loss = 0.5385(0.5228)
2023/11/01 06:18:39 - INFO - root -   Epoch: [197/300] 	 loss = 0.5545
2023/11/01 06:18:39 - INFO - root -   train_accuracy = 0.7358
2023/11/01 06:19:01 - INFO - root -   Epoch: [198/300][0/53], lr: 0.00000195 	 loss = 0.1790(0.1790)
2023/11/01 06:20:08 - INFO - root -   Epoch: [198/300][20/53], lr: 0.00000195 	 loss = 0.9168(0.5030)
2023/11/01 06:21:09 - INFO - root -   Epoch: [198/300][40/53], lr: 0.00000195 	 loss = 0.3287(0.5214)
2023/11/01 06:21:36 - INFO - root -   Epoch: [198/300] 	 loss = 0.4972
2023/11/01 06:21:36 - INFO - root -   train_accuracy = 0.7736
2023/11/01 06:22:06 - INFO - root -   Epoch: [199/300][0/53], lr: 0.00000196 	 loss = 0.3221(0.3221)
2023/11/01 06:23:05 - INFO - root -   Epoch: [199/300][20/53], lr: 0.00000196 	 loss = 0.9388(0.5397)
2023/11/01 06:24:21 - INFO - root -   Epoch: [199/300][40/53], lr: 0.00000196 	 loss = 0.3874(0.4971)
2023/11/01 06:24:35 - INFO - root -   Epoch: [199/300] 	 loss = 0.5121
2023/11/01 06:25:15 - INFO - root -   precision = 0.6667
2023/11/01 06:25:15 - INFO - root -   eval_loss = 0.7175
2023/11/01 06:25:15 - INFO - root -   eval_acc = 0.6667
2023/11/01 06:25:19 - INFO - root -   train_accuracy = 0.7736
2023/11/01 06:26:06 - INFO - root -   Epoch: [200/300][0/53], lr: 0.00000197 	 loss = 0.1356(0.1356)
2023/11/01 06:27:10 - INFO - root -   Epoch: [200/300][20/53], lr: 0.00000197 	 loss = 0.6476(0.5141)
2023/11/01 06:28:11 - INFO - root -   Epoch: [200/300][40/53], lr: 0.00000197 	 loss = 0.2936(0.4554)
2023/11/01 06:28:27 - INFO - root -   Epoch: [200/300] 	 loss = 0.4803
2023/11/01 06:28:27 - INFO - root -   train_accuracy = 0.7547
2023/11/01 06:28:49 - INFO - root -   Epoch: [201/300][0/53], lr: 0.00000198 	 loss = 0.3017(0.3017)
2023/11/01 06:30:09 - INFO - root -   Epoch: [201/300][20/53], lr: 0.00000198 	 loss = 0.3767(0.5276)
2023/11/01 06:31:07 - INFO - root -   Epoch: [201/300][40/53], lr: 0.00000198 	 loss = 0.5407(0.4646)
2023/11/01 06:31:25 - INFO - root -   Epoch: [201/300] 	 loss = 0.4651
2023/11/01 06:31:25 - INFO - root -   train_accuracy = 0.8019
2023/11/01 06:31:55 - INFO - root -   Epoch: [202/300][0/53], lr: 0.00000199 	 loss = 0.2807(0.2807)
2023/11/01 06:32:57 - INFO - root -   Epoch: [202/300][20/53], lr: 0.00000199 	 loss = 1.5355(0.4406)
2023/11/01 06:34:00 - INFO - root -   Epoch: [202/300][40/53], lr: 0.00000199 	 loss = 0.2795(0.4591)
2023/11/01 06:34:18 - INFO - root -   Epoch: [202/300] 	 loss = 0.5021
2023/11/01 06:34:18 - INFO - root -   train_accuracy = 0.7830
2023/11/01 06:34:42 - INFO - root -   Epoch: [203/300][0/53], lr: 0.00000200 	 loss = 0.2537(0.2537)
2023/11/01 06:35:51 - INFO - root -   Epoch: [203/300][20/53], lr: 0.00000200 	 loss = 1.9397(0.6088)
2023/11/01 06:36:57 - INFO - root -   Epoch: [203/300][40/53], lr: 0.00000200 	 loss = 1.3745(0.5771)
2023/11/01 06:37:20 - INFO - root -   Epoch: [203/300] 	 loss = 0.5641
2023/11/01 06:37:20 - INFO - root -   train_accuracy = 0.7170
2023/11/01 06:37:43 - INFO - root -   Epoch: [204/300][0/53], lr: 0.00000201 	 loss = 0.5614(0.5614)
2023/11/01 06:38:48 - INFO - root -   Epoch: [204/300][20/53], lr: 0.00000201 	 loss = 0.5536(0.4312)
2023/11/01 06:39:59 - INFO - root -   Epoch: [204/300][40/53], lr: 0.00000201 	 loss = 0.7265(0.4359)
2023/11/01 06:40:16 - INFO - root -   Epoch: [204/300] 	 loss = 0.4618
2023/11/01 06:40:54 - INFO - root -   precision = 0.4815
2023/11/01 06:40:54 - INFO - root -   eval_loss = 0.7776
2023/11/01 06:40:54 - INFO - root -   eval_acc = 0.4815
2023/11/01 06:40:55 - INFO - root -   train_accuracy = 0.7736
2023/11/01 06:41:20 - INFO - root -   Epoch: [205/300][0/53], lr: 0.00000201 	 loss = 0.3833(0.3833)
2023/11/01 06:42:29 - INFO - root -   Epoch: [205/300][20/53], lr: 0.00000201 	 loss = 1.0086(0.4959)
2023/11/01 06:43:49 - INFO - root -   Epoch: [205/300][40/53], lr: 0.00000201 	 loss = 1.1744(0.4557)
2023/11/01 06:44:07 - INFO - root -   Epoch: [205/300] 	 loss = 0.4692
2023/11/01 06:44:07 - INFO - root -   train_accuracy = 0.8302
2023/11/01 06:44:39 - INFO - root -   Epoch: [206/300][0/53], lr: 0.00000202 	 loss = 0.6209(0.6209)
2023/11/01 06:45:51 - INFO - root -   Epoch: [206/300][20/53], lr: 0.00000202 	 loss = 1.2066(0.5636)
2023/11/01 06:46:43 - INFO - root -   Epoch: [206/300][40/53], lr: 0.00000202 	 loss = 0.2667(0.4931)
2023/11/01 06:47:14 - INFO - root -   Epoch: [206/300] 	 loss = 0.5219
2023/11/01 06:47:14 - INFO - root -   train_accuracy = 0.7736
2023/11/01 06:47:37 - INFO - root -   Epoch: [207/300][0/53], lr: 0.00000203 	 loss = 0.1310(0.1310)
2023/11/01 06:48:49 - INFO - root -   Epoch: [207/300][20/53], lr: 0.00000203 	 loss = 1.3214(0.4445)
2023/11/01 06:50:01 - INFO - root -   Epoch: [207/300][40/53], lr: 0.00000203 	 loss = 0.1396(0.4209)
2023/11/01 06:50:13 - INFO - root -   Epoch: [207/300] 	 loss = 0.4807
2023/11/01 06:50:13 - INFO - root -   train_accuracy = 0.8113
2023/11/01 06:50:35 - INFO - root -   Epoch: [208/300][0/53], lr: 0.00000204 	 loss = 0.3156(0.3156)
2023/11/01 06:51:43 - INFO - root -   Epoch: [208/300][20/53], lr: 0.00000204 	 loss = 1.1612(0.5214)
2023/11/01 06:52:58 - INFO - root -   Epoch: [208/300][40/53], lr: 0.00000204 	 loss = 0.3132(0.4636)
2023/11/01 06:53:22 - INFO - root -   Epoch: [208/300] 	 loss = 0.5187
2023/11/01 06:53:22 - INFO - root -   train_accuracy = 0.7925
2023/11/01 06:53:45 - INFO - root -   Epoch: [209/300][0/53], lr: 0.00000205 	 loss = 0.2737(0.2737)
2023/11/01 06:54:56 - INFO - root -   Epoch: [209/300][20/53], lr: 0.00000205 	 loss = 0.7916(0.4802)
2023/11/01 06:56:10 - INFO - root -   Epoch: [209/300][40/53], lr: 0.00000205 	 loss = 0.0650(0.4420)
2023/11/01 06:56:20 - INFO - root -   Epoch: [209/300] 	 loss = 0.4444
2023/11/01 06:56:59 - INFO - root -   precision = 0.6667
2023/11/01 06:56:59 - INFO - root -   eval_loss = 0.8513
2023/11/01 06:56:59 - INFO - root -   eval_acc = 0.6667
2023/11/01 06:57:00 - INFO - root -   train_accuracy = 0.7736
2023/11/01 06:57:23 - INFO - root -   Epoch: [210/300][0/53], lr: 0.00000206 	 loss = 0.2178(0.2178)
2023/11/01 06:58:40 - INFO - root -   Epoch: [210/300][20/53], lr: 0.00000206 	 loss = 0.3703(0.4939)
2023/11/01 06:59:35 - INFO - root -   Epoch: [210/300][40/53], lr: 0.00000206 	 loss = 0.2644(0.4425)
2023/11/01 07:00:05 - INFO - root -   Epoch: [210/300] 	 loss = 0.4914
2023/11/01 07:00:05 - INFO - root -   train_accuracy = 0.7830
2023/11/01 07:00:44 - INFO - root -   Epoch: [211/300][0/53], lr: 0.00000207 	 loss = 0.1902(0.1902)
2023/11/01 07:01:38 - INFO - root -   Epoch: [211/300][20/53], lr: 0.00000207 	 loss = 0.9229(0.5958)
2023/11/01 07:02:51 - INFO - root -   Epoch: [211/300][40/53], lr: 0.00000207 	 loss = 0.4154(0.4504)
2023/11/01 07:03:04 - INFO - root -   Epoch: [211/300] 	 loss = 0.4799
2023/11/01 07:03:04 - INFO - root -   train_accuracy = 0.7453
2023/11/01 07:03:35 - INFO - root -   Epoch: [212/300][0/53], lr: 0.00000208 	 loss = 0.1753(0.1753)
2023/11/01 07:04:43 - INFO - root -   Epoch: [212/300][20/53], lr: 0.00000208 	 loss = 0.7880(0.5217)
2023/11/01 07:05:46 - INFO - root -   Epoch: [212/300][40/53], lr: 0.00000208 	 loss = 0.5085(0.4494)
2023/11/01 07:05:59 - INFO - root -   Epoch: [212/300] 	 loss = 0.4959
2023/11/01 07:05:59 - INFO - root -   train_accuracy = 0.8019
2023/11/01 07:06:29 - INFO - root -   Epoch: [213/300][0/53], lr: 0.00000209 	 loss = 0.4107(0.4107)
2023/11/01 07:07:39 - INFO - root -   Epoch: [213/300][20/53], lr: 0.00000209 	 loss = 0.4530(0.4581)
2023/11/01 07:08:43 - INFO - root -   Epoch: [213/300][40/53], lr: 0.00000209 	 loss = 0.8767(0.4500)
2023/11/01 07:08:58 - INFO - root -   Epoch: [213/300] 	 loss = 0.5389
2023/11/01 07:08:58 - INFO - root -   train_accuracy = 0.8208
2023/11/01 07:09:28 - INFO - root -   Epoch: [214/300][0/53], lr: 0.00000210 	 loss = 0.4802(0.4802)
2023/11/01 07:10:30 - INFO - root -   Epoch: [214/300][20/53], lr: 0.00000210 	 loss = 1.0991(0.5481)
2023/11/01 07:11:43 - INFO - root -   Epoch: [214/300][40/53], lr: 0.00000210 	 loss = 0.8619(0.4805)
2023/11/01 07:11:56 - INFO - root -   Epoch: [214/300] 	 loss = 0.5074
2023/11/01 07:12:34 - INFO - root -   precision = 0.6667
2023/11/01 07:12:34 - INFO - root -   eval_loss = 0.6926
2023/11/01 07:12:34 - INFO - root -   eval_acc = 0.6667
2023/11/01 07:12:35 - INFO - root -   train_accuracy = 0.7453
2023/11/01 07:13:16 - INFO - root -   Epoch: [215/300][0/53], lr: 0.00000211 	 loss = 0.2326(0.2326)
2023/11/01 07:14:01 - INFO - root -   Epoch: [215/300][20/53], lr: 0.00000211 	 loss = 0.2345(0.3790)
2023/11/01 07:15:27 - INFO - root -   Epoch: [215/300][40/53], lr: 0.00000211 	 loss = 0.4484(0.4040)
2023/11/01 07:15:38 - INFO - root -   Epoch: [215/300] 	 loss = 0.4157
2023/11/01 07:15:38 - INFO - root -   train_accuracy = 0.8302
2023/11/01 07:16:10 - INFO - root -   Epoch: [216/300][0/53], lr: 0.00000212 	 loss = 0.3574(0.3574)
2023/11/01 07:17:15 - INFO - root -   Epoch: [216/300][20/53], lr: 0.00000212 	 loss = 0.5750(0.4551)
2023/11/01 07:18:19 - INFO - root -   Epoch: [216/300][40/53], lr: 0.00000212 	 loss = 0.0736(0.3907)
2023/11/01 07:18:45 - INFO - root -   Epoch: [216/300] 	 loss = 0.4020
2023/11/01 07:18:45 - INFO - root -   train_accuracy = 0.7830
2023/11/01 07:19:16 - INFO - root -   Epoch: [217/300][0/53], lr: 0.00000213 	 loss = 0.3690(0.3690)
2023/11/01 07:20:25 - INFO - root -   Epoch: [217/300][20/53], lr: 0.00000213 	 loss = 0.5488(0.5879)
2023/11/01 07:21:22 - INFO - root -   Epoch: [217/300][40/53], lr: 0.00000213 	 loss = 0.8956(0.5921)
2023/11/01 07:21:52 - INFO - root -   Epoch: [217/300] 	 loss = 0.5808
2023/11/01 07:21:52 - INFO - root -   train_accuracy = 0.6792
2023/11/01 07:22:15 - INFO - root -   Epoch: [218/300][0/53], lr: 0.00000214 	 loss = 0.0594(0.0594)
2023/11/01 07:23:34 - INFO - root -   Epoch: [218/300][20/53], lr: 0.00000214 	 loss = 0.4124(0.4458)
2023/11/01 07:24:40 - INFO - root -   Epoch: [218/300][40/53], lr: 0.00000214 	 loss = 0.3696(0.4974)
2023/11/01 07:24:52 - INFO - root -   Epoch: [218/300] 	 loss = 0.5028
2023/11/01 07:24:52 - INFO - root -   train_accuracy = 0.7830
2023/11/01 07:25:32 - INFO - root -   Epoch: [219/300][0/53], lr: 0.00000215 	 loss = 0.3498(0.3498)
2023/11/01 07:26:37 - INFO - root -   Epoch: [219/300][20/53], lr: 0.00000215 	 loss = 0.4182(0.4071)
2023/11/01 07:27:43 - INFO - root -   Epoch: [219/300][40/53], lr: 0.00000215 	 loss = 0.1979(0.4000)
2023/11/01 07:27:58 - INFO - root -   Epoch: [219/300] 	 loss = 0.4359
2023/11/01 07:28:36 - INFO - root -   precision = 0.5556
2023/11/01 07:28:36 - INFO - root -   eval_loss = 0.9021
2023/11/01 07:28:36 - INFO - root -   eval_acc = 0.5556
2023/11/01 07:28:37 - INFO - root -   train_accuracy = 0.8019
2023/11/01 07:29:00 - INFO - root -   Epoch: [220/300][0/53], lr: 0.00000215 	 loss = 0.6813(0.6813)
2023/11/01 07:30:03 - INFO - root -   Epoch: [220/300][20/53], lr: 0.00000215 	 loss = 0.2559(0.4875)
2023/11/01 07:31:19 - INFO - root -   Epoch: [220/300][40/53], lr: 0.00000215 	 loss = 0.1194(0.5068)
2023/11/01 07:31:37 - INFO - root -   Epoch: [220/300] 	 loss = 0.4977
2023/11/01 07:31:37 - INFO - root -   train_accuracy = 0.8208
2023/11/01 07:32:00 - INFO - root -   Epoch: [221/300][0/53], lr: 0.00000216 	 loss = 0.5161(0.5161)
2023/11/01 07:33:25 - INFO - root -   Epoch: [221/300][20/53], lr: 0.00000216 	 loss = 0.8293(0.5416)
2023/11/01 07:34:31 - INFO - root -   Epoch: [221/300][40/53], lr: 0.00000216 	 loss = 0.9350(0.5133)
2023/11/01 07:34:42 - INFO - root -   Epoch: [221/300] 	 loss = 0.5167
2023/11/01 07:34:42 - INFO - root -   train_accuracy = 0.7075
2023/11/01 07:35:12 - INFO - root -   Epoch: [222/300][0/53], lr: 0.00000217 	 loss = 0.2990(0.2990)
2023/11/01 07:36:18 - INFO - root -   Epoch: [222/300][20/53], lr: 0.00000217 	 loss = 0.3979(0.3768)
2023/11/01 07:37:21 - INFO - root -   Epoch: [222/300][40/53], lr: 0.00000217 	 loss = 1.0600(0.4234)
2023/11/01 07:37:42 - INFO - root -   Epoch: [222/300] 	 loss = 0.4308
2023/11/01 07:37:42 - INFO - root -   train_accuracy = 0.7830
2023/11/01 07:38:12 - INFO - root -   Epoch: [223/300][0/53], lr: 0.00000218 	 loss = 0.4772(0.4772)
2023/11/01 07:39:30 - INFO - root -   Epoch: [223/300][20/53], lr: 0.00000218 	 loss = 0.7705(0.3441)
2023/11/01 07:40:26 - INFO - root -   Epoch: [223/300][40/53], lr: 0.00000218 	 loss = 0.2117(0.3623)
2023/11/01 07:40:40 - INFO - root -   Epoch: [223/300] 	 loss = 0.4308
2023/11/01 07:40:40 - INFO - root -   train_accuracy = 0.7830
2023/11/01 07:41:03 - INFO - root -   Epoch: [224/300][0/53], lr: 0.00000219 	 loss = 0.1913(0.1913)
2023/11/01 07:42:20 - INFO - root -   Epoch: [224/300][20/53], lr: 0.00000219 	 loss = 0.3771(0.4300)
2023/11/01 07:43:21 - INFO - root -   Epoch: [224/300][40/53], lr: 0.00000219 	 loss = 0.1824(0.4361)
2023/11/01 07:43:42 - INFO - root -   Epoch: [224/300] 	 loss = 0.4674
2023/11/01 07:44:21 - INFO - root -   precision = 0.6667
2023/11/01 07:44:21 - INFO - root -   eval_loss = 0.7456
2023/11/01 07:44:21 - INFO - root -   eval_acc = 0.6667
2023/11/01 07:44:22 - INFO - root -   train_accuracy = 0.7547
2023/11/01 07:44:55 - INFO - root -   Epoch: [225/300][0/53], lr: 0.00000220 	 loss = 0.1071(0.1071)
2023/11/01 07:45:51 - INFO - root -   Epoch: [225/300][20/53], lr: 0.00000220 	 loss = 1.4785(0.3867)
2023/11/01 07:47:02 - INFO - root -   Epoch: [225/300][40/53], lr: 0.00000220 	 loss = 0.1949(0.4274)
2023/11/01 07:47:22 - INFO - root -   Epoch: [225/300] 	 loss = 0.4651
2023/11/01 07:47:22 - INFO - root -   train_accuracy = 0.7736
2023/11/01 07:47:46 - INFO - root -   Epoch: [226/300][0/53], lr: 0.00000221 	 loss = 0.0859(0.0859)
2023/11/01 07:48:46 - INFO - root -   Epoch: [226/300][20/53], lr: 0.00000221 	 loss = 0.5579(0.3661)
2023/11/01 07:50:03 - INFO - root -   Epoch: [226/300][40/53], lr: 0.00000221 	 loss = 1.1190(0.4138)
2023/11/01 07:50:19 - INFO - root -   Epoch: [226/300] 	 loss = 0.4313
2023/11/01 07:50:19 - INFO - root -   train_accuracy = 0.7925
2023/11/01 07:50:50 - INFO - root -   Epoch: [227/300][0/53], lr: 0.00000222 	 loss = 0.4649(0.4649)
2023/11/01 07:51:57 - INFO - root -   Epoch: [227/300][20/53], lr: 0.00000222 	 loss = 0.4701(0.4004)
2023/11/01 07:52:52 - INFO - root -   Epoch: [227/300][40/53], lr: 0.00000222 	 loss = 0.0697(0.3462)
2023/11/01 07:53:24 - INFO - root -   Epoch: [227/300] 	 loss = 0.3903
2023/11/01 07:53:24 - INFO - root -   train_accuracy = 0.8585
2023/11/01 07:53:56 - INFO - root -   Epoch: [228/300][0/53], lr: 0.00000223 	 loss = 0.5590(0.5590)
2023/11/01 07:54:54 - INFO - root -   Epoch: [228/300][20/53], lr: 0.00000223 	 loss = 0.3745(0.4161)
2023/11/01 07:56:05 - INFO - root -   Epoch: [228/300][40/53], lr: 0.00000223 	 loss = 0.3235(0.4821)
2023/11/01 07:56:28 - INFO - root -   Epoch: [228/300] 	 loss = 0.5660
2023/11/01 07:56:28 - INFO - root -   train_accuracy = 0.7736
2023/11/01 07:56:51 - INFO - root -   Epoch: [229/300][0/53], lr: 0.00000224 	 loss = 0.1668(0.1668)
2023/11/01 07:58:09 - INFO - root -   Epoch: [229/300][20/53], lr: 0.00000224 	 loss = 0.2699(0.4222)
2023/11/01 07:59:02 - INFO - root -   Epoch: [229/300][40/53], lr: 0.00000224 	 loss = 0.3849(0.4388)
2023/11/01 07:59:27 - INFO - root -   Epoch: [229/300] 	 loss = 0.4365
2023/11/01 08:00:06 - INFO - root -   precision = 0.6667
2023/11/01 08:00:06 - INFO - root -   eval_loss = 0.8445
2023/11/01 08:00:06 - INFO - root -   eval_acc = 0.6667
2023/11/01 08:00:07 - INFO - root -   train_accuracy = 0.7642
2023/11/01 08:00:37 - INFO - root -   Epoch: [230/300][0/53], lr: 0.00000225 	 loss = 0.1019(0.1019)
2023/11/01 08:01:41 - INFO - root -   Epoch: [230/300][20/53], lr: 0.00000225 	 loss = 0.8761(0.5166)
2023/11/01 08:02:49 - INFO - root -   Epoch: [230/300][40/53], lr: 0.00000225 	 loss = 0.3082(0.5141)
2023/11/01 08:03:06 - INFO - root -   Epoch: [230/300] 	 loss = 0.5214
2023/11/01 08:03:06 - INFO - root -   train_accuracy = 0.7358
2023/11/01 08:03:30 - INFO - root -   Epoch: [231/300][0/53], lr: 0.00000226 	 loss = 0.2570(0.2570)
2023/11/01 08:04:47 - INFO - root -   Epoch: [231/300][20/53], lr: 0.00000226 	 loss = 0.3639(0.5306)
2023/11/01 08:05:45 - INFO - root -   Epoch: [231/300][40/53], lr: 0.00000226 	 loss = 0.8480(0.4428)
2023/11/01 08:06:14 - INFO - root -   Epoch: [231/300] 	 loss = 0.4842
2023/11/01 08:06:14 - INFO - root -   train_accuracy = 0.8396
2023/11/01 08:06:37 - INFO - root -   Epoch: [232/300][0/53], lr: 0.00000227 	 loss = 0.3140(0.3140)
2023/11/01 08:07:59 - INFO - root -   Epoch: [232/300][20/53], lr: 0.00000227 	 loss = 1.5130(0.5947)
2023/11/01 08:08:52 - INFO - root -   Epoch: [232/300][40/53], lr: 0.00000227 	 loss = 0.3874(0.5248)
2023/11/01 08:09:15 - INFO - root -   Epoch: [232/300] 	 loss = 0.5056
2023/11/01 08:09:15 - INFO - root -   train_accuracy = 0.7547
2023/11/01 08:09:46 - INFO - root -   Epoch: [233/300][0/53], lr: 0.00000228 	 loss = 0.2246(0.2246)
2023/11/01 08:10:56 - INFO - root -   Epoch: [233/300][20/53], lr: 0.00000228 	 loss = 0.3959(0.4715)
2023/11/01 08:12:01 - INFO - root -   Epoch: [233/300][40/53], lr: 0.00000228 	 loss = 0.6351(0.4525)
2023/11/01 08:12:18 - INFO - root -   Epoch: [233/300] 	 loss = 0.4552
2023/11/01 08:12:18 - INFO - root -   train_accuracy = 0.8302
2023/11/01 08:12:50 - INFO - root -   Epoch: [234/300][0/53], lr: 0.00000229 	 loss = 0.1511(0.1511)
2023/11/01 08:13:41 - INFO - root -   Epoch: [234/300][20/53], lr: 0.00000229 	 loss = 0.2135(0.3018)
2023/11/01 08:15:08 - INFO - root -   Epoch: [234/300][40/53], lr: 0.00000229 	 loss = 0.8330(0.3572)
2023/11/01 08:15:24 - INFO - root -   Epoch: [234/300] 	 loss = 0.4150
2023/11/01 08:16:01 - INFO - root -   precision = 0.6296
2023/11/01 08:16:01 - INFO - root -   eval_loss = 0.9387
2023/11/01 08:16:01 - INFO - root -   eval_acc = 0.6296
2023/11/01 08:16:02 - INFO - root -   train_accuracy = 0.8208
2023/11/01 08:16:34 - INFO - root -   Epoch: [235/300][0/53], lr: 0.00000229 	 loss = 0.2986(0.2986)
2023/11/01 08:17:50 - INFO - root -   Epoch: [235/300][20/53], lr: 0.00000229 	 loss = 1.0201(0.5496)
2023/11/01 08:18:50 - INFO - root -   Epoch: [235/300][40/53], lr: 0.00000229 	 loss = 0.0813(0.4588)
2023/11/01 08:19:06 - INFO - root -   Epoch: [235/300] 	 loss = 0.4744
2023/11/01 08:19:06 - INFO - root -   train_accuracy = 0.7642
2023/11/01 08:19:29 - INFO - root -   Epoch: [236/300][0/53], lr: 0.00000230 	 loss = 0.1023(0.1023)
2023/11/01 08:20:31 - INFO - root -   Epoch: [236/300][20/53], lr: 0.00000230 	 loss = 1.8787(0.4755)
2023/11/01 08:21:44 - INFO - root -   Epoch: [236/300][40/53], lr: 0.00000230 	 loss = 0.0734(0.4176)
2023/11/01 08:22:06 - INFO - root -   Epoch: [236/300] 	 loss = 0.4142
2023/11/01 08:22:06 - INFO - root -   train_accuracy = 0.8679
2023/11/01 08:22:43 - INFO - root -   Epoch: [237/300][0/53], lr: 0.00000231 	 loss = 0.4225(0.4225)
2023/11/01 08:23:52 - INFO - root -   Epoch: [237/300][20/53], lr: 0.00000231 	 loss = 0.7242(0.4637)
2023/11/01 08:24:50 - INFO - root -   Epoch: [237/300][40/53], lr: 0.00000231 	 loss = 0.1960(0.5189)
2023/11/01 08:25:14 - INFO - root -   Epoch: [237/300] 	 loss = 0.4844
2023/11/01 08:25:14 - INFO - root -   train_accuracy = 0.7925
2023/11/01 08:25:36 - INFO - root -   Epoch: [238/300][0/53], lr: 0.00000232 	 loss = 0.1758(0.1758)
2023/11/01 08:26:47 - INFO - root -   Epoch: [238/300][20/53], lr: 0.00000232 	 loss = 0.4204(0.4295)
2023/11/01 08:27:49 - INFO - root -   Epoch: [238/300][40/53], lr: 0.00000232 	 loss = 0.2653(0.3712)
2023/11/01 08:28:10 - INFO - root -   Epoch: [238/300] 	 loss = 0.4186
2023/11/01 08:28:10 - INFO - root -   train_accuracy = 0.8208
2023/11/01 08:28:41 - INFO - root -   Epoch: [239/300][0/53], lr: 0.00000233 	 loss = 0.1875(0.1875)
2023/11/01 08:29:52 - INFO - root -   Epoch: [239/300][20/53], lr: 0.00000233 	 loss = 0.4076(0.4961)
2023/11/01 08:31:10 - INFO - root -   Epoch: [239/300][40/53], lr: 0.00000233 	 loss = 0.6562(0.4800)
2023/11/01 08:31:21 - INFO - root -   Epoch: [239/300] 	 loss = 0.4930
2023/11/01 08:31:59 - INFO - root -   precision = 0.4815
2023/11/01 08:31:59 - INFO - root -   eval_loss = 0.9167
2023/11/01 08:31:59 - INFO - root -   eval_acc = 0.4815
2023/11/01 08:32:00 - INFO - root -   train_accuracy = 0.8019
2023/11/01 08:32:22 - INFO - root -   Epoch: [240/300][0/53], lr: 0.00000234 	 loss = 0.3703(0.3703)
2023/11/01 08:33:23 - INFO - root -   Epoch: [240/300][20/53], lr: 0.00000234 	 loss = 0.5911(0.5025)
2023/11/01 08:34:31 - INFO - root -   Epoch: [240/300][40/53], lr: 0.00000234 	 loss = 0.3073(0.4959)
2023/11/01 08:35:02 - INFO - root -   Epoch: [240/300] 	 loss = 0.4969
2023/11/01 08:35:02 - INFO - root -   train_accuracy = 0.8019
2023/11/01 08:35:33 - INFO - root -   Epoch: [241/300][0/53], lr: 0.00000235 	 loss = 0.6368(0.6368)
2023/11/01 08:36:33 - INFO - root -   Epoch: [241/300][20/53], lr: 0.00000235 	 loss = 1.0965(0.4413)
2023/11/01 08:37:35 - INFO - root -   Epoch: [241/300][40/53], lr: 0.00000235 	 loss = 0.7888(0.4698)
2023/11/01 08:38:04 - INFO - root -   Epoch: [241/300] 	 loss = 0.4933
2023/11/01 08:38:04 - INFO - root -   train_accuracy = 0.7736
2023/11/01 08:38:35 - INFO - root -   Epoch: [242/300][0/53], lr: 0.00000236 	 loss = 0.1937(0.1937)
2023/11/01 08:39:35 - INFO - root -   Epoch: [242/300][20/53], lr: 0.00000236 	 loss = 0.5637(0.4109)
2023/11/01 08:40:43 - INFO - root -   Epoch: [242/300][40/53], lr: 0.00000236 	 loss = 0.4803(0.3923)
2023/11/01 08:41:04 - INFO - root -   Epoch: [242/300] 	 loss = 0.4352
2023/11/01 08:41:04 - INFO - root -   train_accuracy = 0.7547
2023/11/01 08:41:34 - INFO - root -   Epoch: [243/300][0/53], lr: 0.00000237 	 loss = 0.3033(0.3033)
2023/11/01 08:42:36 - INFO - root -   Epoch: [243/300][20/53], lr: 0.00000237 	 loss = 0.8695(0.4285)
2023/11/01 08:43:47 - INFO - root -   Epoch: [243/300][40/53], lr: 0.00000237 	 loss = 0.3449(0.4264)
2023/11/01 08:44:07 - INFO - root -   Epoch: [243/300] 	 loss = 0.4629
2023/11/01 08:44:07 - INFO - root -   train_accuracy = 0.7830
2023/11/01 08:44:30 - INFO - root -   Epoch: [244/300][0/53], lr: 0.00000238 	 loss = 0.3823(0.3823)
2023/11/01 08:45:46 - INFO - root -   Epoch: [244/300][20/53], lr: 0.00000238 	 loss = 0.7058(0.3586)
2023/11/01 08:46:45 - INFO - root -   Epoch: [244/300][40/53], lr: 0.00000238 	 loss = 0.6882(0.3870)
2023/11/01 08:47:08 - INFO - root -   Epoch: [244/300] 	 loss = 0.4088
2023/11/01 08:47:44 - INFO - root -   precision = 0.6667
2023/11/01 08:47:44 - INFO - root -   eval_loss = 1.0021
2023/11/01 08:47:44 - INFO - root -   eval_acc = 0.6667
2023/11/01 08:47:49 - INFO - root -   train_accuracy = 0.7925
2023/11/01 08:48:11 - INFO - root -   Epoch: [245/300][0/53], lr: 0.00000239 	 loss = 0.0385(0.0385)
2023/11/01 08:49:21 - INFO - root -   Epoch: [245/300][20/53], lr: 0.00000239 	 loss = 0.9848(0.4150)
2023/11/01 08:50:42 - INFO - root -   Epoch: [245/300][40/53], lr: 0.00000239 	 loss = 0.1350(0.4413)
2023/11/01 08:50:58 - INFO - root -   Epoch: [245/300] 	 loss = 0.4386
2023/11/01 08:50:58 - INFO - root -   train_accuracy = 0.8113
2023/11/01 08:51:29 - INFO - root -   Epoch: [246/300][0/53], lr: 0.00000240 	 loss = 0.3876(0.3876)
2023/11/01 08:52:40 - INFO - root -   Epoch: [246/300][20/53], lr: 0.00000240 	 loss = 0.6589(0.4367)
2023/11/01 08:53:30 - INFO - root -   Epoch: [246/300][40/53], lr: 0.00000240 	 loss = 0.1876(0.3887)
2023/11/01 08:53:52 - INFO - root -   Epoch: [246/300] 	 loss = 0.4037
2023/11/01 08:53:52 - INFO - root -   train_accuracy = 0.7925
2023/11/01 08:54:23 - INFO - root -   Epoch: [247/300][0/53], lr: 0.00000241 	 loss = 1.0426(1.0426)
2023/11/01 08:55:29 - INFO - root -   Epoch: [247/300][20/53], lr: 0.00000241 	 loss = 0.8207(0.3600)
2023/11/01 08:56:34 - INFO - root -   Epoch: [247/300][40/53], lr: 0.00000241 	 loss = 0.5907(0.3832)
2023/11/01 08:56:57 - INFO - root -   Epoch: [247/300] 	 loss = 0.3975
2023/11/01 08:56:57 - INFO - root -   train_accuracy = 0.8019
2023/11/01 08:57:19 - INFO - root -   Epoch: [248/300][0/53], lr: 0.00000242 	 loss = 0.3199(0.3199)
2023/11/01 08:58:31 - INFO - root -   Epoch: [248/300][20/53], lr: 0.00000242 	 loss = 0.8624(0.3726)
2023/11/01 08:59:35 - INFO - root -   Epoch: [248/300][40/53], lr: 0.00000242 	 loss = 0.0539(0.3803)
2023/11/01 08:59:56 - INFO - root -   Epoch: [248/300] 	 loss = 0.4131
2023/11/01 08:59:56 - INFO - root -   train_accuracy = 0.8019
2023/11/01 09:00:27 - INFO - root -   Epoch: [249/300][0/53], lr: 0.00000243 	 loss = 0.3053(0.3053)
2023/11/01 09:01:34 - INFO - root -   Epoch: [249/300][20/53], lr: 0.00000243 	 loss = 0.5766(0.3018)
2023/11/01 09:02:50 - INFO - root -   Epoch: [249/300][40/53], lr: 0.00000243 	 loss = 0.2395(0.3330)
2023/11/01 09:03:06 - INFO - root -   Epoch: [249/300] 	 loss = 0.3196
2023/11/01 09:03:43 - INFO - root -   precision = 0.5556
2023/11/01 09:03:43 - INFO - root -   eval_loss = 1.0267
2023/11/01 09:03:43 - INFO - root -   eval_acc = 0.5556
2023/11/01 09:03:44 - INFO - root -   train_accuracy = 0.8962
2023/11/01 09:04:14 - INFO - root -   Epoch: [250/300][0/53], lr: 0.00000243 	 loss = 0.9240(0.9240)
2023/11/01 09:05:30 - INFO - root -   Epoch: [250/300][20/53], lr: 0.00000243 	 loss = 0.7558(0.5595)
2023/11/01 09:06:37 - INFO - root -   Epoch: [250/300][40/53], lr: 0.00000243 	 loss = 0.0574(0.4689)
2023/11/01 09:06:49 - INFO - root -   Epoch: [250/300] 	 loss = 0.4680
2023/11/01 09:06:49 - INFO - root -   train_accuracy = 0.7925
2023/11/01 09:07:26 - INFO - root -   Epoch: [251/300][0/53], lr: 0.00000244 	 loss = 0.3127(0.3127)
2023/11/01 09:08:24 - INFO - root -   Epoch: [251/300][20/53], lr: 0.00000244 	 loss = 2.2351(0.4974)
2023/11/01 09:09:35 - INFO - root -   Epoch: [251/300][40/53], lr: 0.00000244 	 loss = 0.9060(0.4575)
2023/11/01 09:09:51 - INFO - root -   Epoch: [251/300] 	 loss = 0.4415
2023/11/01 09:09:51 - INFO - root -   train_accuracy = 0.7925
2023/11/01 09:10:21 - INFO - root -   Epoch: [252/300][0/53], lr: 0.00000245 	 loss = 0.2411(0.2411)
2023/11/01 09:11:32 - INFO - root -   Epoch: [252/300][20/53], lr: 0.00000245 	 loss = 0.4044(0.3807)
2023/11/01 09:12:30 - INFO - root -   Epoch: [252/300][40/53], lr: 0.00000245 	 loss = 0.1272(0.3662)
2023/11/01 09:12:57 - INFO - root -   Epoch: [252/300] 	 loss = 0.4196
2023/11/01 09:12:57 - INFO - root -   train_accuracy = 0.8302
2023/11/01 09:13:20 - INFO - root -   Epoch: [253/300][0/53], lr: 0.00000246 	 loss = 0.4429(0.4429)
2023/11/01 09:14:27 - INFO - root -   Epoch: [253/300][20/53], lr: 0.00000246 	 loss = 0.7149(0.3313)
2023/11/01 09:15:35 - INFO - root -   Epoch: [253/300][40/53], lr: 0.00000246 	 loss = 0.1958(0.4037)
2023/11/01 09:15:53 - INFO - root -   Epoch: [253/300] 	 loss = 0.4111
2023/11/01 09:15:53 - INFO - root -   train_accuracy = 0.8113
2023/11/01 09:16:16 - INFO - root -   Epoch: [254/300][0/53], lr: 0.00000247 	 loss = 0.0780(0.0780)
2023/11/01 09:17:30 - INFO - root -   Epoch: [254/300][20/53], lr: 0.00000247 	 loss = 0.9277(0.3264)
2023/11/01 09:18:30 - INFO - root -   Epoch: [254/300][40/53], lr: 0.00000247 	 loss = 0.1224(0.3492)
2023/11/01 09:18:54 - INFO - root -   Epoch: [254/300] 	 loss = 0.3945
2023/11/01 09:19:31 - INFO - root -   precision = 0.5926
2023/11/01 09:19:31 - INFO - root -   eval_loss = 1.0404
2023/11/01 09:19:31 - INFO - root -   eval_acc = 0.5926
2023/11/01 09:19:32 - INFO - root -   train_accuracy = 0.8396
2023/11/01 09:19:55 - INFO - root -   Epoch: [255/300][0/53], lr: 0.00000248 	 loss = 0.5389(0.5389)
2023/11/01 09:21:09 - INFO - root -   Epoch: [255/300][20/53], lr: 0.00000248 	 loss = 0.5889(0.5023)
2023/11/01 09:22:13 - INFO - root -   Epoch: [255/300][40/53], lr: 0.00000248 	 loss = 0.6553(0.5100)
2023/11/01 09:22:35 - INFO - root -   Epoch: [255/300] 	 loss = 0.5659
2023/11/01 09:22:35 - INFO - root -   train_accuracy = 0.7075
2023/11/01 09:22:58 - INFO - root -   Epoch: [256/300][0/53], lr: 0.00000249 	 loss = 0.0621(0.0621)
2023/11/01 09:23:59 - INFO - root -   Epoch: [256/300][20/53], lr: 0.00000249 	 loss = 0.4834(0.2981)
2023/11/01 09:25:14 - INFO - root -   Epoch: [256/300][40/53], lr: 0.00000249 	 loss = 0.4700(0.3623)
2023/11/01 09:25:31 - INFO - root -   Epoch: [256/300] 	 loss = 0.3554
2023/11/01 09:25:31 - INFO - root -   train_accuracy = 0.8302
2023/11/01 09:25:54 - INFO - root -   Epoch: [257/300][0/53], lr: 0.00000250 	 loss = 0.3881(0.3881)
2023/11/01 09:27:17 - INFO - root -   Epoch: [257/300][20/53], lr: 0.00000250 	 loss = 0.6894(0.5152)
2023/11/01 09:28:17 - INFO - root -   Epoch: [257/300][40/53], lr: 0.00000250 	 loss = 0.1193(0.5022)
2023/11/01 09:28:35 - INFO - root -   Epoch: [257/300] 	 loss = 0.4787
2023/11/01 09:28:35 - INFO - root -   train_accuracy = 0.7547
2023/11/01 09:29:00 - INFO - root -   Epoch: [258/300][0/53], lr: 0.00000251 	 loss = 0.3944(0.3944)
2023/11/01 09:30:08 - INFO - root -   Epoch: [258/300][20/53], lr: 0.00000251 	 loss = 1.5321(0.3549)
2023/11/01 09:31:09 - INFO - root -   Epoch: [258/300][40/53], lr: 0.00000251 	 loss = 0.6245(0.4615)
2023/11/01 09:31:28 - INFO - root -   Epoch: [258/300] 	 loss = 0.4107
2023/11/01 09:31:28 - INFO - root -   train_accuracy = 0.8491
2023/11/01 09:31:59 - INFO - root -   Epoch: [259/300][0/53], lr: 0.00000252 	 loss = 0.1033(0.1033)
2023/11/01 09:32:49 - INFO - root -   Epoch: [259/300][20/53], lr: 0.00000252 	 loss = 1.0366(0.4082)
2023/11/01 09:34:01 - INFO - root -   Epoch: [259/300][40/53], lr: 0.00000252 	 loss = 1.0690(0.3815)
2023/11/01 09:34:27 - INFO - root -   Epoch: [259/300] 	 loss = 0.3683
2023/11/01 09:35:05 - INFO - root -   precision = 0.5926
2023/11/01 09:35:05 - INFO - root -   eval_loss = 0.8712
2023/11/01 09:35:05 - INFO - root -   eval_acc = 0.5926
2023/11/01 09:35:07 - INFO - root -   train_accuracy = 0.8208
2023/11/01 09:35:32 - INFO - root -   Epoch: [260/300][0/53], lr: 0.00000253 	 loss = 0.0612(0.0612)
2023/11/01 09:36:38 - INFO - root -   Epoch: [260/300][20/53], lr: 0.00000253 	 loss = 0.2101(0.3206)
2023/11/01 09:37:42 - INFO - root -   Epoch: [260/300][40/53], lr: 0.00000253 	 loss = 0.2501(0.3879)
2023/11/01 09:38:06 - INFO - root -   Epoch: [260/300] 	 loss = 0.4026
2023/11/01 09:38:06 - INFO - root -   train_accuracy = 0.8113
2023/11/01 09:38:44 - INFO - root -   Epoch: [261/300][0/53], lr: 0.00000254 	 loss = 0.1704(0.1704)
2023/11/01 09:39:36 - INFO - root -   Epoch: [261/300][20/53], lr: 0.00000254 	 loss = 0.3122(0.2166)
2023/11/01 09:40:47 - INFO - root -   Epoch: [261/300][40/53], lr: 0.00000254 	 loss = 0.4015(0.3366)
2023/11/01 09:41:03 - INFO - root -   Epoch: [261/300] 	 loss = 0.3424
2023/11/01 09:41:03 - INFO - root -   train_accuracy = 0.8679
2023/11/01 09:41:28 - INFO - root -   Epoch: [262/300][0/53], lr: 0.00000255 	 loss = 0.0558(0.0558)
2023/11/01 09:42:33 - INFO - root -   Epoch: [262/300][20/53], lr: 0.00000255 	 loss = 1.0783(0.4250)
2023/11/01 09:43:39 - INFO - root -   Epoch: [262/300][40/53], lr: 0.00000255 	 loss = 0.1190(0.3440)
2023/11/01 09:44:05 - INFO - root -   Epoch: [262/300] 	 loss = 0.3847
2023/11/01 09:44:05 - INFO - root -   train_accuracy = 0.8302
2023/11/01 09:44:27 - INFO - root -   Epoch: [263/300][0/53], lr: 0.00000256 	 loss = 0.0540(0.0540)
2023/11/01 09:45:35 - INFO - root -   Epoch: [263/300][20/53], lr: 0.00000256 	 loss = 0.5905(0.4776)
2023/11/01 09:46:50 - INFO - root -   Epoch: [263/300][40/53], lr: 0.00000256 	 loss = 0.3262(0.4410)
2023/11/01 09:47:08 - INFO - root -   Epoch: [263/300] 	 loss = 0.4263
2023/11/01 09:47:08 - INFO - root -   train_accuracy = 0.8113
2023/11/01 09:47:31 - INFO - root -   Epoch: [264/300][0/53], lr: 0.00000257 	 loss = 0.1497(0.1497)
2023/11/01 09:48:51 - INFO - root -   Epoch: [264/300][20/53], lr: 0.00000257 	 loss = 0.1754(0.3897)
2023/11/01 09:49:44 - INFO - root -   Epoch: [264/300][40/53], lr: 0.00000257 	 loss = 1.2921(0.4192)
2023/11/01 09:50:06 - INFO - root -   Epoch: [264/300] 	 loss = 0.3994
2023/11/01 09:50:45 - INFO - root -   precision = 0.7407
2023/11/01 09:50:45 - INFO - root -   eval_loss = 0.9375
2023/11/01 09:50:45 - INFO - root -   eval_acc = 0.7407
2023/11/01 09:50:46 - INFO - root -   train_accuracy = 0.8396
2023/11/01 09:51:24 - INFO - root -   Epoch: [265/300][0/53], lr: 0.00000258 	 loss = 0.4188(0.4188)
2023/11/01 09:52:24 - INFO - root -   Epoch: [265/300][20/53], lr: 0.00000258 	 loss = 2.1845(0.6163)
2023/11/01 09:53:24 - INFO - root -   Epoch: [265/300][40/53], lr: 0.00000258 	 loss = 0.0959(0.4787)
2023/11/01 09:53:49 - INFO - root -   Epoch: [265/300] 	 loss = 0.4569
2023/11/01 09:53:49 - INFO - root -   train_accuracy = 0.7830
2023/11/01 09:54:11 - INFO - root -   Epoch: [266/300][0/53], lr: 0.00000258 	 loss = 0.1032(0.1032)
2023/11/01 09:55:13 - INFO - root -   Epoch: [266/300][20/53], lr: 0.00000258 	 loss = 1.9106(0.4190)
2023/11/01 09:56:38 - INFO - root -   Epoch: [266/300][40/53], lr: 0.00000258 	 loss = 0.6317(0.4145)
2023/11/01 09:56:51 - INFO - root -   Epoch: [266/300] 	 loss = 0.4197
2023/11/01 09:56:51 - INFO - root -   train_accuracy = 0.7925
2023/11/01 09:57:11 - INFO - root -   Epoch: [267/300][0/53], lr: 0.00000259 	 loss = 0.2083(0.2083)
2023/11/01 09:58:24 - INFO - root -   Epoch: [267/300][20/53], lr: 0.00000259 	 loss = 0.2964(0.2977)
2023/11/01 09:59:29 - INFO - root -   Epoch: [267/300][40/53], lr: 0.00000259 	 loss = 0.8631(0.2674)
2023/11/01 09:59:48 - INFO - root -   Epoch: [267/300] 	 loss = 0.2860
2023/11/01 09:59:48 - INFO - root -   train_accuracy = 0.8679
2023/11/01 10:00:19 - INFO - root -   Epoch: [268/300][0/53], lr: 0.00000260 	 loss = 0.0800(0.0800)
2023/11/01 10:01:29 - INFO - root -   Epoch: [268/300][20/53], lr: 0.00000260 	 loss = 0.5330(0.3683)
2023/11/01 10:02:23 - INFO - root -   Epoch: [268/300][40/53], lr: 0.00000260 	 loss = 0.0204(0.3320)
2023/11/01 10:02:46 - INFO - root -   Epoch: [268/300] 	 loss = 0.3054
2023/11/01 10:02:46 - INFO - root -   train_accuracy = 0.8679
2023/11/01 10:03:19 - INFO - root -   Epoch: [269/300][0/53], lr: 0.00000261 	 loss = 0.5513(0.5513)
2023/11/01 10:04:24 - INFO - root -   Epoch: [269/300][20/53], lr: 0.00000261 	 loss = 0.8299(0.3757)
2023/11/01 10:05:28 - INFO - root -   Epoch: [269/300][40/53], lr: 0.00000261 	 loss = 0.0409(0.3963)
2023/11/01 10:05:41 - INFO - root -   Epoch: [269/300] 	 loss = 0.4027
2023/11/01 10:06:20 - INFO - root -   precision = 0.5926
2023/11/01 10:06:20 - INFO - root -   eval_loss = 0.8778
2023/11/01 10:06:20 - INFO - root -   eval_acc = 0.5926
2023/11/01 10:06:25 - INFO - root -   train_accuracy = 0.8302
2023/11/01 10:06:55 - INFO - root -   Epoch: [270/300][0/53], lr: 0.00000262 	 loss = 0.4019(0.4019)
2023/11/01 10:07:51 - INFO - root -   Epoch: [270/300][20/53], lr: 0.00000262 	 loss = 0.5290(0.3589)
2023/11/01 10:09:02 - INFO - root -   Epoch: [270/300][40/53], lr: 0.00000262 	 loss = 0.0183(0.3529)
2023/11/01 10:09:30 - INFO - root -   Epoch: [270/300] 	 loss = 0.4132
2023/11/01 10:09:30 - INFO - root -   train_accuracy = 0.7830
2023/11/01 10:09:53 - INFO - root -   Epoch: [271/300][0/53], lr: 0.00000263 	 loss = 0.0725(0.0725)
2023/11/01 10:11:01 - INFO - root -   Epoch: [271/300][20/53], lr: 0.00000263 	 loss = 0.4708(0.3828)
2023/11/01 10:12:17 - INFO - root -   Epoch: [271/300][40/53], lr: 0.00000263 	 loss = 0.1832(0.3852)
2023/11/01 10:12:31 - INFO - root -   Epoch: [271/300] 	 loss = 0.3675
2023/11/01 10:12:31 - INFO - root -   train_accuracy = 0.7736
2023/11/01 10:13:00 - INFO - root -   Epoch: [272/300][0/53], lr: 0.00000264 	 loss = 0.2979(0.2979)
2023/11/01 10:13:54 - INFO - root -   Epoch: [272/300][20/53], lr: 0.00000264 	 loss = 0.3772(0.2901)
2023/11/01 10:15:09 - INFO - root -   Epoch: [272/300][40/53], lr: 0.00000264 	 loss = 0.0275(0.2950)
2023/11/01 10:15:34 - INFO - root -   Epoch: [272/300] 	 loss = 0.3027
2023/11/01 10:15:34 - INFO - root -   train_accuracy = 0.8679
2023/11/01 10:15:57 - INFO - root -   Epoch: [273/300][0/53], lr: 0.00000265 	 loss = 0.0874(0.0874)
2023/11/01 10:17:04 - INFO - root -   Epoch: [273/300][20/53], lr: 0.00000265 	 loss = 1.6132(0.2838)
2023/11/01 10:18:05 - INFO - root -   Epoch: [273/300][40/53], lr: 0.00000265 	 loss = 0.0171(0.2591)
2023/11/01 10:18:26 - INFO - root -   Epoch: [273/300] 	 loss = 0.2730
2023/11/01 10:18:26 - INFO - root -   train_accuracy = 0.8774
2023/11/01 10:18:49 - INFO - root -   Epoch: [274/300][0/53], lr: 0.00000266 	 loss = 0.3503(0.3503)
2023/11/01 10:19:52 - INFO - root -   Epoch: [274/300][20/53], lr: 0.00000266 	 loss = 0.1524(0.2589)
2023/11/01 10:21:12 - INFO - root -   Epoch: [274/300][40/53], lr: 0.00000266 	 loss = 0.0528(0.2691)
2023/11/01 10:21:30 - INFO - root -   Epoch: [274/300] 	 loss = 0.2819
2023/11/01 10:22:08 - INFO - root -   precision = 0.5926
2023/11/01 10:22:08 - INFO - root -   eval_loss = 1.0220
2023/11/01 10:22:08 - INFO - root -   eval_acc = 0.5926
2023/11/01 10:22:09 - INFO - root -   train_accuracy = 0.8962
2023/11/01 10:22:39 - INFO - root -   Epoch: [275/300][0/53], lr: 0.00000267 	 loss = 0.0779(0.0779)
2023/11/01 10:23:49 - INFO - root -   Epoch: [275/300][20/53], lr: 0.00000267 	 loss = 0.1900(0.3445)
2023/11/01 10:24:42 - INFO - root -   Epoch: [275/300][40/53], lr: 0.00000267 	 loss = 0.1638(0.3486)
2023/11/01 10:25:07 - INFO - root -   Epoch: [275/300] 	 loss = 0.3655
2023/11/01 10:25:07 - INFO - root -   train_accuracy = 0.7925
2023/11/01 10:25:30 - INFO - root -   Epoch: [276/300][0/53], lr: 0.00000268 	 loss = 0.1687(0.1687)
2023/11/01 10:26:39 - INFO - root -   Epoch: [276/300][20/53], lr: 0.00000268 	 loss = 1.2072(0.3489)
2023/11/01 10:27:42 - INFO - root -   Epoch: [276/300][40/53], lr: 0.00000268 	 loss = 0.5487(0.3671)
2023/11/01 10:28:04 - INFO - root -   Epoch: [276/300] 	 loss = 0.3373
2023/11/01 10:28:04 - INFO - root -   train_accuracy = 0.8491
2023/11/01 10:28:34 - INFO - root -   Epoch: [277/300][0/53], lr: 0.00000269 	 loss = 0.0367(0.0367)
2023/11/01 10:29:52 - INFO - root -   Epoch: [277/300][20/53], lr: 0.00000269 	 loss = 0.3616(0.5031)
2023/11/01 10:31:17 - INFO - root -   Epoch: [277/300][40/53], lr: 0.00000269 	 loss = 0.0976(0.3635)
2023/11/01 10:31:27 - INFO - root -   Epoch: [277/300] 	 loss = 0.3825
2023/11/01 10:31:27 - INFO - root -   train_accuracy = 0.8302
2023/11/01 10:31:57 - INFO - root -   Epoch: [278/300][0/53], lr: 0.00000270 	 loss = 1.2872(1.2872)
2023/11/01 10:33:03 - INFO - root -   Epoch: [278/300][20/53], lr: 0.00000270 	 loss = 1.2114(0.6225)
2023/11/01 10:34:11 - INFO - root -   Epoch: [278/300][40/53], lr: 0.00000270 	 loss = 0.9229(0.4741)
2023/11/01 10:34:26 - INFO - root -   Epoch: [278/300] 	 loss = 0.4488
2023/11/01 10:34:26 - INFO - root -   train_accuracy = 0.8019
2023/11/01 10:34:50 - INFO - root -   Epoch: [279/300][0/53], lr: 0.00000271 	 loss = 1.1138(1.1138)
2023/11/01 10:36:10 - INFO - root -   Epoch: [279/300][20/53], lr: 0.00000271 	 loss = 2.3460(0.5291)
2023/11/01 10:37:15 - INFO - root -   Epoch: [279/300][40/53], lr: 0.00000271 	 loss = 0.0221(0.5759)
2023/11/01 10:37:31 - INFO - root -   Epoch: [279/300] 	 loss = 0.5518
2023/11/01 10:38:08 - INFO - root -   precision = 0.6667
2023/11/01 10:38:08 - INFO - root -   eval_loss = 1.1995
2023/11/01 10:38:08 - INFO - root -   eval_acc = 0.6667
2023/11/01 10:38:10 - INFO - root -   train_accuracy = 0.7170
2023/11/01 10:38:32 - INFO - root -   Epoch: [280/300][0/53], lr: 0.00000272 	 loss = 0.0023(0.0023)
2023/11/01 10:39:37 - INFO - root -   Epoch: [280/300][20/53], lr: 0.00000272 	 loss = 0.7664(0.3536)
2023/11/01 10:40:47 - INFO - root -   Epoch: [280/300][40/53], lr: 0.00000272 	 loss = 0.7855(0.3267)
2023/11/01 10:41:04 - INFO - root -   Epoch: [280/300] 	 loss = 0.3714
2023/11/01 10:41:04 - INFO - root -   train_accuracy = 0.8302
2023/11/01 10:41:35 - INFO - root -   Epoch: [281/300][0/53], lr: 0.00000272 	 loss = 0.3687(0.3687)
2023/11/01 10:42:35 - INFO - root -   Epoch: [281/300][20/53], lr: 0.00000272 	 loss = 0.4505(0.4682)
2023/11/01 10:43:41 - INFO - root -   Epoch: [281/300][40/53], lr: 0.00000272 	 loss = 0.0875(0.4198)
2023/11/01 10:44:08 - INFO - root -   Epoch: [281/300] 	 loss = 0.4339
2023/11/01 10:44:08 - INFO - root -   train_accuracy = 0.7736
2023/11/01 10:44:30 - INFO - root -   Epoch: [282/300][0/53], lr: 0.00000273 	 loss = 0.0183(0.0183)
2023/11/01 10:45:47 - INFO - root -   Epoch: [282/300][20/53], lr: 0.00000273 	 loss = 1.6445(0.3812)
2023/11/01 10:46:54 - INFO - root -   Epoch: [282/300][40/53], lr: 0.00000273 	 loss = 0.2381(0.3785)
2023/11/01 10:47:07 - INFO - root -   Epoch: [282/300] 	 loss = 0.3544
2023/11/01 10:47:07 - INFO - root -   train_accuracy = 0.8774
2023/11/01 10:47:31 - INFO - root -   Epoch: [283/300][0/53], lr: 0.00000274 	 loss = 0.0825(0.0825)
2023/11/01 10:48:45 - INFO - root -   Epoch: [283/300][20/53], lr: 0.00000274 	 loss = 0.9912(0.3412)
2023/11/01 10:50:05 - INFO - root -   Epoch: [283/300][40/53], lr: 0.00000274 	 loss = 0.2294(0.3338)
2023/11/01 10:50:20 - INFO - root -   Epoch: [283/300] 	 loss = 0.3473
2023/11/01 10:50:20 - INFO - root -   train_accuracy = 0.8396
2023/11/01 10:50:59 - INFO - root -   Epoch: [284/300][0/53], lr: 0.00000275 	 loss = 0.1712(0.1712)
2023/11/01 10:51:49 - INFO - root -   Epoch: [284/300][20/53], lr: 0.00000275 	 loss = 0.4083(0.2257)
2023/11/01 10:53:11 - INFO - root -   Epoch: [284/300][40/53], lr: 0.00000275 	 loss = 0.4422(0.3370)
2023/11/01 10:53:26 - INFO - root -   Epoch: [284/300] 	 loss = 0.3134
2023/11/01 10:54:03 - INFO - root -   precision = 0.6296
2023/11/01 10:54:03 - INFO - root -   eval_loss = 0.8777
2023/11/01 10:54:03 - INFO - root -   eval_acc = 0.6296
2023/11/01 10:54:04 - INFO - root -   train_accuracy = 0.8962
2023/11/01 10:54:26 - INFO - root -   Epoch: [285/300][0/53], lr: 0.00000276 	 loss = 0.0273(0.0273)
2023/11/01 10:55:34 - INFO - root -   Epoch: [285/300][20/53], lr: 0.00000276 	 loss = 0.5263(0.2741)
2023/11/01 10:56:51 - INFO - root -   Epoch: [285/300][40/53], lr: 0.00000276 	 loss = 0.6262(0.3299)
2023/11/01 10:57:15 - INFO - root -   Epoch: [285/300] 	 loss = 0.3630
2023/11/01 10:57:15 - INFO - root -   train_accuracy = 0.8491
2023/11/01 10:57:37 - INFO - root -   Epoch: [286/300][0/53], lr: 0.00000277 	 loss = 0.0015(0.0015)
2023/11/01 10:58:45 - INFO - root -   Epoch: [286/300][20/53], lr: 0.00000277 	 loss = 0.6077(0.3156)
2023/11/01 10:59:58 - INFO - root -   Epoch: [286/300][40/53], lr: 0.00000277 	 loss = 0.0748(0.3639)
2023/11/01 11:00:15 - INFO - root -   Epoch: [286/300] 	 loss = 0.3892
2023/11/01 11:00:15 - INFO - root -   train_accuracy = 0.7925
2023/11/01 11:00:52 - INFO - root -   Epoch: [287/300][0/53], lr: 0.00000278 	 loss = 0.5283(0.5283)
2023/11/01 11:01:54 - INFO - root -   Epoch: [287/300][20/53], lr: 0.00000278 	 loss = 0.6713(0.5056)
2023/11/01 11:03:11 - INFO - root -   Epoch: [287/300][40/53], lr: 0.00000278 	 loss = 0.9205(0.4379)
2023/11/01 11:03:26 - INFO - root -   Epoch: [287/300] 	 loss = 0.4494
2023/11/01 11:03:26 - INFO - root -   train_accuracy = 0.8019
2023/11/01 11:03:58 - INFO - root -   Epoch: [288/300][0/53], lr: 0.00000279 	 loss = 0.1992(0.1992)
2023/11/01 11:04:58 - INFO - root -   Epoch: [288/300][20/53], lr: 0.00000279 	 loss = 1.1928(0.4102)
2023/11/01 11:06:00 - INFO - root -   Epoch: [288/300][40/53], lr: 0.00000279 	 loss = 0.0262(0.4027)
2023/11/01 11:06:24 - INFO - root -   Epoch: [288/300] 	 loss = 0.3979
2023/11/01 11:06:24 - INFO - root -   train_accuracy = 0.8019
2023/11/01 11:06:48 - INFO - root -   Epoch: [289/300][0/53], lr: 0.00000280 	 loss = 0.4959(0.4959)
2023/11/01 11:08:01 - INFO - root -   Epoch: [289/300][20/53], lr: 0.00000280 	 loss = 0.4467(0.3659)
2023/11/01 11:09:12 - INFO - root -   Epoch: [289/300][40/53], lr: 0.00000280 	 loss = 0.1322(0.3023)
2023/11/01 11:09:27 - INFO - root -   Epoch: [289/300] 	 loss = 0.3235
2023/11/01 11:10:05 - INFO - root -   precision = 0.5926
2023/11/01 11:10:09 - INFO - root -   eval_loss = 0.9312
2023/11/01 11:10:09 - INFO - root -   eval_acc = 0.5926
2023/11/01 11:10:10 - INFO - root -   train_accuracy = 0.8774
2023/11/01 11:10:39 - INFO - root -   Epoch: [290/300][0/53], lr: 0.00000281 	 loss = 0.6950(0.6950)
2023/11/01 11:12:11 - INFO - root -   Epoch: [290/300][20/53], lr: 0.00000281 	 loss = 0.3675(0.3707)
2023/11/01 11:13:12 - INFO - root -   Epoch: [290/300][40/53], lr: 0.00000281 	 loss = 0.8580(0.3301)
2023/11/01 11:13:28 - INFO - root -   Epoch: [290/300] 	 loss = 0.3172
2023/11/01 11:13:28 - INFO - root -   train_accuracy = 0.8774
2023/11/01 11:13:51 - INFO - root -   Epoch: [291/300][0/53], lr: 0.00000282 	 loss = 0.0647(0.0647)
2023/11/01 11:15:11 - INFO - root -   Epoch: [291/300][20/53], lr: 0.00000282 	 loss = 0.5200(0.3247)
2023/11/01 11:16:19 - INFO - root -   Epoch: [291/300][40/53], lr: 0.00000282 	 loss = 0.6813(0.3970)
2023/11/01 11:16:39 - INFO - root -   Epoch: [291/300] 	 loss = 0.3537
2023/11/01 11:16:39 - INFO - root -   train_accuracy = 0.8396
2023/11/01 11:17:11 - INFO - root -   Epoch: [292/300][0/53], lr: 0.00000283 	 loss = 0.0948(0.0948)
2023/11/01 11:18:05 - INFO - root -   Epoch: [292/300][20/53], lr: 0.00000283 	 loss = 1.6002(0.5529)
2023/11/01 11:19:20 - INFO - root -   Epoch: [292/300][40/53], lr: 0.00000283 	 loss = 0.0317(0.4655)
2023/11/01 11:19:43 - INFO - root -   Epoch: [292/300] 	 loss = 0.4274
2023/11/01 11:19:43 - INFO - root -   train_accuracy = 0.8302
2023/11/01 11:20:13 - INFO - root -   Epoch: [293/300][0/53], lr: 0.00000284 	 loss = 0.3421(0.3421)
2023/11/01 11:21:12 - INFO - root -   Epoch: [293/300][20/53], lr: 0.00000284 	 loss = 0.7841(0.2463)
2023/11/01 11:22:20 - INFO - root -   Epoch: [293/300][40/53], lr: 0.00000284 	 loss = 0.1303(0.3224)
2023/11/01 11:22:44 - INFO - root -   Epoch: [293/300] 	 loss = 0.3260
2023/11/01 11:22:44 - INFO - root -   train_accuracy = 0.8491
2023/11/01 11:23:07 - INFO - root -   Epoch: [294/300][0/53], lr: 0.00000285 	 loss = 0.0223(0.0223)
2023/11/01 11:24:29 - INFO - root -   Epoch: [294/300][20/53], lr: 0.00000285 	 loss = 0.8450(0.3468)
2023/11/01 11:25:34 - INFO - root -   Epoch: [294/300][40/53], lr: 0.00000285 	 loss = 1.0594(0.3992)
2023/11/01 11:25:51 - INFO - root -   Epoch: [294/300] 	 loss = 0.3505
2023/11/01 11:26:30 - INFO - root -   precision = 0.6667
2023/11/01 11:26:30 - INFO - root -   eval_loss = 0.9625
2023/11/01 11:26:30 - INFO - root -   eval_acc = 0.6667
2023/11/01 11:26:31 - INFO - root -   train_accuracy = 0.8396
2023/11/01 11:26:53 - INFO - root -   Epoch: [295/300][0/53], lr: 0.00000286 	 loss = 0.0211(0.0211)
2023/11/01 11:28:16 - INFO - root -   Epoch: [295/300][20/53], lr: 0.00000286 	 loss = 1.2817(0.2922)
2023/11/01 11:29:13 - INFO - root -   Epoch: [295/300][40/53], lr: 0.00000286 	 loss = 0.0996(0.3099)
2023/11/01 11:29:40 - INFO - root -   Epoch: [295/300] 	 loss = 0.3441
2023/11/01 11:29:40 - INFO - root -   train_accuracy = 0.8396
2023/11/01 11:30:03 - INFO - root -   Epoch: [296/300][0/53], lr: 0.00000286 	 loss = 0.0119(0.0119)
2023/11/01 11:31:33 - INFO - root -   Epoch: [296/300][20/53], lr: 0.00000286 	 loss = 1.0613(0.5754)
2023/11/01 11:32:25 - INFO - root -   Epoch: [296/300][40/53], lr: 0.00000286 	 loss = 0.0185(0.4575)
2023/11/01 11:32:45 - INFO - root -   Epoch: [296/300] 	 loss = 0.4068
2023/11/01 11:32:45 - INFO - root -   train_accuracy = 0.8208
2023/11/01 11:33:26 - INFO - root -   Epoch: [297/300][0/53], lr: 0.00000287 	 loss = 0.3161(0.3161)
2023/11/01 11:34:21 - INFO - root -   Epoch: [297/300][20/53], lr: 0.00000287 	 loss = 0.3013(0.3858)
2023/11/01 11:35:22 - INFO - root -   Epoch: [297/300][40/53], lr: 0.00000287 	 loss = 0.0048(0.4003)
2023/11/01 11:35:43 - INFO - root -   Epoch: [297/300] 	 loss = 0.3988
2023/11/01 11:35:43 - INFO - root -   train_accuracy = 0.8302
2023/11/01 11:36:13 - INFO - root -   Epoch: [298/300][0/53], lr: 0.00000288 	 loss = 0.0583(0.0583)
2023/11/01 11:37:25 - INFO - root -   Epoch: [298/300][20/53], lr: 0.00000288 	 loss = 2.2871(0.4617)
2023/11/01 11:38:22 - INFO - root -   Epoch: [298/300][40/53], lr: 0.00000288 	 loss = 0.0120(0.4012)
2023/11/01 11:38:51 - INFO - root -   Epoch: [298/300] 	 loss = 0.4098
2023/11/01 11:38:51 - INFO - root -   train_accuracy = 0.8208
2023/11/01 11:39:23 - INFO - root -   Epoch: [299/300][0/53], lr: 0.00000289 	 loss = 0.1362(0.1362)
2023/11/01 11:40:24 - INFO - root -   Epoch: [299/300][20/53], lr: 0.00000289 	 loss = 1.0248(0.3777)
2023/11/01 11:41:38 - INFO - root -   Epoch: [299/300][40/53], lr: 0.00000289 	 loss = 0.3087(0.3437)
2023/11/01 11:41:52 - INFO - root -   Epoch: [299/300] 	 loss = 0.3900
2023/11/01 11:42:31 - INFO - root -   precision = 0.5926
2023/11/01 11:42:31 - INFO - root -   eval_loss = 1.0720
2023/11/01 11:42:31 - INFO - root -   eval_acc = 0.5926
2023/11/01 11:42:32 - INFO - root -   train_accuracy = 0.8585
