2023/09/16 12:52:48 - INFO - root -   Num train examples = 693
2023/09/16 12:52:48 - INFO - root -   Num val examples = 174
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.0181818176060915
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.036363635212183
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.05454545468091965
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.072727270424366
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.09090908616781235
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.10909091681241989
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.12727272510528564
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.1454545557498932
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Drop path rate: 0.16363637149333954
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:48 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Drop path rate: 0.1818181872367859
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Drop path rate: 0.20000000298023224
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   No L_MHRA: True
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Double L_MHRA: True
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Use checkpoint: False
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Checkpoint number: [0]
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Drop path rate: 0.0
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Drop path rate: 0.13333334028720856
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Drop path rate: 0.2666666507720947
2023/09/16 12:52:49 - INFO - models.uniformerv2_model -   Drop path rate: 0.4000000059604645
2023/09/16 12:52:49 - INFO - root -   backend = nccl
2023/09/16 12:52:49 - INFO - root -   batch_size = 2
2023/09/16 12:52:49 - INFO - root -   dropout = 0.5
2023/09/16 12:52:49 - INFO - root -   epochs = 400
2023/09/16 12:52:49 - INFO - root -   eval_freq = 5
2023/09/16 12:52:49 - INFO - root -   focal_loss = False
2023/09/16 12:52:49 - INFO - root -   input_size = 224
2023/09/16 12:52:49 - INFO - root -   is_pretrained = False
2023/09/16 12:52:49 - INFO - root -   label_smooth = False
2023/09/16 12:52:49 - INFO - root -   local_rank = -1
2023/09/16 12:52:49 - INFO - root -   lr = 1e-05
2023/09/16 12:52:49 - INFO - root -   lr_decay_rate = 0.1
2023/09/16 12:52:49 - INFO - root -   lr_steps = [50, 100]
2023/09/16 12:52:49 - INFO - root -   lr_type = cosine
2023/09/16 12:52:49 - INFO - root -   model_depth = 34
2023/09/16 12:52:49 - INFO - root -   model_name = resnet50
2023/09/16 12:52:49 - INFO - root -   momentum = 0.9
2023/09/16 12:52:49 - INFO - root -   num_classes = 2
2023/09/16 12:52:49 - INFO - root -   output = ./all_roi_cls2_outputs
2023/09/16 12:52:49 - INFO - root -   print_freq = 20
2023/09/16 12:52:49 - INFO - root -   resume = 
2023/09/16 12:52:49 - INFO - root -   start_epoch = 0
2023/09/16 12:52:49 - INFO - root -   train_list = /media/spgou/DATA/ZYJ/Glioma_easy/dataset/train_patients.txt
2023/09/16 12:52:49 - INFO - root -   tune_from = 
2023/09/16 12:52:49 - INFO - root -   val_list = /media/spgou/DATA/ZYJ/Glioma_easy/dataset/test_patients.txt
2023/09/16 12:52:49 - INFO - root -   warmup_epoch = 20
2023/09/16 12:52:49 - INFO - root -   warmup_multiplier = 100
2023/09/16 12:52:49 - INFO - root -   weight_decay = 0.0005
2023/09/16 12:52:49 - INFO - root -   workers = 8
2023/09/16 12:53:12 - INFO - root -   Epoch: [0/400][0/346], lr: 0.00000010 	 loss = 0.3144(0.3144)
2023/09/16 12:53:54 - INFO - root -   Epoch: [0/400][20/346], lr: 0.00000010 	 loss = 0.3498(0.7738)
2023/09/16 12:54:56 - INFO - root -   Epoch: [0/400][40/346], lr: 0.00000010 	 loss = 0.5206(0.7418)
2023/09/16 12:55:40 - INFO - root -   Epoch: [0/400][60/346], lr: 0.00000010 	 loss = 0.6798(0.7871)
2023/09/16 12:56:39 - INFO - root -   Epoch: [0/400][80/346], lr: 0.00000010 	 loss = 0.5139(0.7694)
2023/09/16 12:57:23 - INFO - root -   Epoch: [0/400][100/346], lr: 0.00000010 	 loss = 0.5356(0.7611)
2023/09/16 12:58:21 - INFO - root -   Epoch: [0/400][120/346], lr: 0.00000010 	 loss = 0.5891(0.7832)
2023/09/16 12:59:07 - INFO - root -   Epoch: [0/400][140/346], lr: 0.00000010 	 loss = 0.7076(0.7864)
2023/09/16 13:00:05 - INFO - root -   Epoch: [0/400][160/346], lr: 0.00000010 	 loss = 1.0879(0.7896)
2023/09/16 13:00:51 - INFO - root -   Epoch: [0/400][180/346], lr: 0.00000010 	 loss = 0.7943(0.7810)
2023/09/16 13:01:49 - INFO - root -   Epoch: [0/400][200/346], lr: 0.00000010 	 loss = 0.5886(0.7674)
2023/09/16 13:02:35 - INFO - root -   Epoch: [0/400][220/346], lr: 0.00000010 	 loss = 0.3320(0.7690)
2023/09/16 13:03:33 - INFO - root -   Epoch: [0/400][240/346], lr: 0.00000010 	 loss = 0.4684(0.7650)
2023/09/16 13:04:19 - INFO - root -   Epoch: [0/400][260/346], lr: 0.00000010 	 loss = 0.9751(0.7748)
2023/09/16 13:05:16 - INFO - root -   Epoch: [0/400][280/346], lr: 0.00000010 	 loss = 0.8109(0.7716)
2023/09/16 13:06:04 - INFO - root -   Epoch: [0/400][300/346], lr: 0.00000010 	 loss = 0.6660(0.7724)
2023/09/16 13:06:59 - INFO - root -   Epoch: [0/400][320/346], lr: 0.00000010 	 loss = 0.5744(0.7728)
2023/09/16 13:07:45 - INFO - root -   Epoch: [0/400][340/346], lr: 0.00000010 	 loss = 0.9604(0.7750)
2023/09/16 13:07:48 - INFO - root -   Epoch: [0/400] 	 loss = 0.7755
2023/09/16 13:07:48 - INFO - root -   train_accuracy = 0.4986
2023/09/16 13:08:10 - INFO - root -   Epoch: [1/400][0/346], lr: 0.00000010 	 loss = 0.8037(0.8037)
2023/09/16 13:08:53 - INFO - root -   Epoch: [1/400][20/346], lr: 0.00000010 	 loss = 0.5960(0.8214)
2023/09/16 13:09:53 - INFO - root -   Epoch: [1/400][40/346], lr: 0.00000010 	 loss = 0.1436(0.7670)
2023/09/16 13:10:36 - INFO - root -   Epoch: [1/400][60/346], lr: 0.00000010 	 loss = 1.3986(0.7562)
2023/09/16 13:11:37 - INFO - root -   Epoch: [1/400][80/346], lr: 0.00000010 	 loss = 1.1785(0.7508)
2023/09/16 13:12:21 - INFO - root -   Epoch: [1/400][100/346], lr: 0.00000010 	 loss = 0.2860(0.7468)
2023/09/16 13:13:21 - INFO - root -   Epoch: [1/400][120/346], lr: 0.00000010 	 loss = 0.3679(0.7445)
2023/09/16 13:14:04 - INFO - root -   Epoch: [1/400][140/346], lr: 0.00000010 	 loss = 0.6635(0.7546)
2023/09/16 13:15:05 - INFO - root -   Epoch: [1/400][160/346], lr: 0.00000010 	 loss = 0.9892(0.7529)
2023/09/16 13:15:47 - INFO - root -   Epoch: [1/400][180/346], lr: 0.00000010 	 loss = 0.8181(0.7555)
2023/09/16 13:16:47 - INFO - root -   Epoch: [1/400][200/346], lr: 0.00000010 	 loss = 0.3907(0.7453)
2023/09/16 13:17:30 - INFO - root -   Epoch: [1/400][220/346], lr: 0.00000010 	 loss = 0.8879(0.7501)
2023/09/16 13:18:31 - INFO - root -   Epoch: [1/400][240/346], lr: 0.00000010 	 loss = 1.3219(0.7503)
2023/09/16 13:19:13 - INFO - root -   Epoch: [1/400][260/346], lr: 0.00000010 	 loss = 0.4233(0.7624)
2023/09/16 13:20:14 - INFO - root -   Epoch: [1/400][280/346], lr: 0.00000010 	 loss = 0.3391(0.7646)
2023/09/16 13:20:57 - INFO - root -   Epoch: [1/400][300/346], lr: 0.00000010 	 loss = 0.6580(0.7591)
2023/09/16 13:21:57 - INFO - root -   Epoch: [1/400][320/346], lr: 0.00000010 	 loss = 0.6047(0.7618)
2023/09/16 13:22:39 - INFO - root -   Epoch: [1/400][340/346], lr: 0.00000010 	 loss = 0.9454(0.7604)
2023/09/16 13:22:43 - INFO - root -   Epoch: [1/400] 	 loss = 0.7614
2023/09/16 13:22:43 - INFO - root -   train_accuracy = 0.5029
2023/09/16 13:23:05 - INFO - root -   Epoch: [2/400][0/346], lr: 0.00000010 	 loss = 0.6093(0.6093)
2023/09/16 13:23:48 - INFO - root -   Epoch: [2/400][20/346], lr: 0.00000010 	 loss = 0.7523(0.8134)
2023/09/16 13:24:48 - INFO - root -   Epoch: [2/400][40/346], lr: 0.00000010 	 loss = 0.5590(0.7596)
2023/09/16 13:25:32 - INFO - root -   Epoch: [2/400][60/346], lr: 0.00000010 	 loss = 0.5374(0.7413)
2023/09/16 13:26:32 - INFO - root -   Epoch: [2/400][80/346], lr: 0.00000010 	 loss = 0.8452(0.7360)
2023/09/16 13:27:15 - INFO - root -   Epoch: [2/400][100/346], lr: 0.00000010 	 loss = 0.8937(0.7250)
2023/09/16 13:28:16 - INFO - root -   Epoch: [2/400][120/346], lr: 0.00000010 	 loss = 1.4054(0.7314)
2023/09/16 13:28:59 - INFO - root -   Epoch: [2/400][140/346], lr: 0.00000010 	 loss = 0.7954(0.7407)
2023/09/16 13:30:00 - INFO - root -   Epoch: [2/400][160/346], lr: 0.00000010 	 loss = 0.3945(0.7447)
2023/09/16 13:30:43 - INFO - root -   Epoch: [2/400][180/346], lr: 0.00000010 	 loss = 0.8454(0.7399)
2023/09/16 13:31:43 - INFO - root -   Epoch: [2/400][200/346], lr: 0.00000010 	 loss = 0.3477(0.7286)
2023/09/16 13:32:26 - INFO - root -   Epoch: [2/400][220/346], lr: 0.00000010 	 loss = 0.5892(0.7266)
2023/09/16 13:33:27 - INFO - root -   Epoch: [2/400][240/346], lr: 0.00000010 	 loss = 1.0278(0.7278)
2023/09/16 13:34:10 - INFO - root -   Epoch: [2/400][260/346], lr: 0.00000010 	 loss = 1.2682(0.7364)
2023/09/16 13:35:11 - INFO - root -   Epoch: [2/400][280/346], lr: 0.00000010 	 loss = 0.9115(0.7387)
2023/09/16 13:35:54 - INFO - root -   Epoch: [2/400][300/346], lr: 0.00000010 	 loss = 0.5476(0.7354)
2023/09/16 13:36:54 - INFO - root -   Epoch: [2/400][320/346], lr: 0.00000010 	 loss = 0.5613(0.7292)
2023/09/16 13:37:36 - INFO - root -   Epoch: [2/400][340/346], lr: 0.00000010 	 loss = 0.7142(0.7286)
2023/09/16 13:37:41 - INFO - root -   Epoch: [2/400] 	 loss = 0.7334
2023/09/16 13:37:41 - INFO - root -   train_accuracy = 0.5462
2023/09/16 13:38:03 - INFO - root -   Epoch: [3/400][0/346], lr: 0.00000010 	 loss = 0.6711(0.6711)
2023/09/16 13:38:46 - INFO - root -   Epoch: [3/400][20/346], lr: 0.00000010 	 loss = 0.9694(0.7759)
2023/09/16 13:39:47 - INFO - root -   Epoch: [3/400][40/346], lr: 0.00000010 	 loss = 0.4134(0.7210)
2023/09/16 13:40:31 - INFO - root -   Epoch: [3/400][60/346], lr: 0.00000010 	 loss = 0.2338(0.7195)
2023/09/16 13:41:32 - INFO - root -   Epoch: [3/400][80/346], lr: 0.00000010 	 loss = 0.7545(0.7333)
2023/09/16 13:42:15 - INFO - root -   Epoch: [3/400][100/346], lr: 0.00000010 	 loss = 1.0049(0.7243)
2023/09/16 13:43:16 - INFO - root -   Epoch: [3/400][120/346], lr: 0.00000010 	 loss = 0.3592(0.7350)
2023/09/16 13:44:00 - INFO - root -   Epoch: [3/400][140/346], lr: 0.00000010 	 loss = 0.7356(0.7317)
2023/09/16 13:45:00 - INFO - root -   Epoch: [3/400][160/346], lr: 0.00000010 	 loss = 0.1567(0.7315)
2023/09/16 13:45:43 - INFO - root -   Epoch: [3/400][180/346], lr: 0.00000010 	 loss = 0.4454(0.7249)
2023/09/16 13:46:44 - INFO - root -   Epoch: [3/400][200/346], lr: 0.00000010 	 loss = 0.3086(0.7245)
2023/09/16 13:47:27 - INFO - root -   Epoch: [3/400][220/346], lr: 0.00000010 	 loss = 0.9020(0.7194)
2023/09/16 13:48:29 - INFO - root -   Epoch: [3/400][240/346], lr: 0.00000010 	 loss = 0.7237(0.7159)
2023/09/16 13:49:12 - INFO - root -   Epoch: [3/400][260/346], lr: 0.00000010 	 loss = 1.2121(0.7213)
2023/09/16 13:50:13 - INFO - root -   Epoch: [3/400][280/346], lr: 0.00000010 	 loss = 0.3611(0.7196)
2023/09/16 13:50:56 - INFO - root -   Epoch: [3/400][300/346], lr: 0.00000010 	 loss = 0.4119(0.7236)
2023/09/16 13:51:57 - INFO - root -   Epoch: [3/400][320/346], lr: 0.00000010 	 loss = 0.3655(0.7235)
2023/09/16 13:52:39 - INFO - root -   Epoch: [3/400][340/346], lr: 0.00000010 	 loss = 1.0756(0.7255)
2023/09/16 13:52:43 - INFO - root -   Epoch: [3/400] 	 loss = 0.7250
2023/09/16 13:52:43 - INFO - root -   train_accuracy = 0.5390
2023/09/16 13:53:05 - INFO - root -   Epoch: [4/400][0/346], lr: 0.00000011 	 loss = 0.4138(0.4138)
2023/09/16 13:53:48 - INFO - root -   Epoch: [4/400][20/346], lr: 0.00000011 	 loss = 0.9768(0.7039)
2023/09/16 13:54:48 - INFO - root -   Epoch: [4/400][40/346], lr: 0.00000011 	 loss = 0.4927(0.6859)
2023/09/16 13:55:31 - INFO - root -   Epoch: [4/400][60/346], lr: 0.00000011 	 loss = 0.2895(0.6988)
2023/09/16 13:56:32 - INFO - root -   Epoch: [4/400][80/346], lr: 0.00000011 	 loss = 0.9744(0.6814)
2023/09/16 13:57:15 - INFO - root -   Epoch: [4/400][100/346], lr: 0.00000011 	 loss = 0.6947(0.6790)
2023/09/16 13:58:16 - INFO - root -   Epoch: [4/400][120/346], lr: 0.00000011 	 loss = 0.6575(0.6950)
2023/09/16 13:58:59 - INFO - root -   Epoch: [4/400][140/346], lr: 0.00000011 	 loss = 0.3605(0.6930)
2023/09/16 14:00:00 - INFO - root -   Epoch: [4/400][160/346], lr: 0.00000011 	 loss = 0.5729(0.7030)
2023/09/16 14:00:43 - INFO - root -   Epoch: [4/400][180/346], lr: 0.00000011 	 loss = 0.4976(0.7068)
2023/09/16 14:01:44 - INFO - root -   Epoch: [4/400][200/346], lr: 0.00000011 	 loss = 0.3889(0.7078)
2023/09/16 14:02:27 - INFO - root -   Epoch: [4/400][220/346], lr: 0.00000011 	 loss = 0.2752(0.7019)
2023/09/16 14:03:28 - INFO - root -   Epoch: [4/400][240/346], lr: 0.00000011 	 loss = 0.7735(0.7011)
2023/09/16 14:04:11 - INFO - root -   Epoch: [4/400][260/346], lr: 0.00000011 	 loss = 0.8453(0.7034)
2023/09/16 14:05:12 - INFO - root -   Epoch: [4/400][280/346], lr: 0.00000011 	 loss = 0.3261(0.7139)
2023/09/16 14:05:55 - INFO - root -   Epoch: [4/400][300/346], lr: 0.00000011 	 loss = 0.8400(0.7089)
2023/09/16 14:06:55 - INFO - root -   Epoch: [4/400][320/346], lr: 0.00000011 	 loss = 0.1816(0.7049)
2023/09/16 14:07:36 - INFO - root -   Epoch: [4/400][340/346], lr: 0.00000011 	 loss = 0.8837(0.7030)
2023/09/16 14:07:40 - INFO - root -   Epoch: [4/400] 	 loss = 0.7027
2023/09/16 14:11:27 - INFO - root -   precision = 0.6379
2023/09/16 14:11:27 - INFO - root -   eval_loss = 0.6420
2023/09/16 14:11:29 - INFO - root -   train_accuracy = 0.5592
2023/09/16 14:11:50 - INFO - root -   Epoch: [5/400][0/346], lr: 0.00000011 	 loss = 0.4499(0.4499)
2023/09/16 14:12:33 - INFO - root -   Epoch: [5/400][20/346], lr: 0.00000011 	 loss = 0.7844(0.6389)
2023/09/16 14:13:34 - INFO - root -   Epoch: [5/400][40/346], lr: 0.00000011 	 loss = 0.1356(0.5967)
2023/09/16 14:14:17 - INFO - root -   Epoch: [5/400][60/346], lr: 0.00000011 	 loss = 0.8247(0.6056)
2023/09/16 14:15:17 - INFO - root -   Epoch: [5/400][80/346], lr: 0.00000011 	 loss = 0.6802(0.6366)
2023/09/16 14:16:01 - INFO - root -   Epoch: [5/400][100/346], lr: 0.00000011 	 loss = 0.4872(0.6662)
2023/09/16 14:17:01 - INFO - root -   Epoch: [5/400][120/346], lr: 0.00000011 	 loss = 0.3473(0.6811)
2023/09/16 14:17:44 - INFO - root -   Epoch: [5/400][140/346], lr: 0.00000011 	 loss = 0.6127(0.6696)
2023/09/16 14:18:44 - INFO - root -   Epoch: [5/400][160/346], lr: 0.00000011 	 loss = 0.3255(0.6838)
2023/09/16 14:19:27 - INFO - root -   Epoch: [5/400][180/346], lr: 0.00000011 	 loss = 0.8560(0.6808)
2023/09/16 14:20:27 - INFO - root -   Epoch: [5/400][200/346], lr: 0.00000011 	 loss = 0.4097(0.6917)
2023/09/16 14:21:10 - INFO - root -   Epoch: [5/400][220/346], lr: 0.00000011 	 loss = 0.4068(0.6971)
2023/09/16 14:22:11 - INFO - root -   Epoch: [5/400][240/346], lr: 0.00000011 	 loss = 0.6566(0.6952)
2023/09/16 14:22:54 - INFO - root -   Epoch: [5/400][260/346], lr: 0.00000011 	 loss = 0.7652(0.6990)
2023/09/16 14:23:54 - INFO - root -   Epoch: [5/400][280/346], lr: 0.00000011 	 loss = 0.2129(0.7000)
2023/09/16 14:24:37 - INFO - root -   Epoch: [5/400][300/346], lr: 0.00000011 	 loss = 0.8285(0.7023)
2023/09/16 14:25:37 - INFO - root -   Epoch: [5/400][320/346], lr: 0.00000011 	 loss = 0.2422(0.7019)
2023/09/16 14:26:19 - INFO - root -   Epoch: [5/400][340/346], lr: 0.00000011 	 loss = 1.0592(0.6952)
2023/09/16 14:26:23 - INFO - root -   Epoch: [5/400] 	 loss = 0.6924
2023/09/16 14:26:23 - INFO - root -   train_accuracy = 0.5925
2023/09/16 14:26:45 - INFO - root -   Epoch: [6/400][0/346], lr: 0.00000011 	 loss = 0.1445(0.1445)
2023/09/16 14:27:28 - INFO - root -   Epoch: [6/400][20/346], lr: 0.00000011 	 loss = 0.9307(0.6347)
2023/09/16 14:28:28 - INFO - root -   Epoch: [6/400][40/346], lr: 0.00000011 	 loss = 0.5602(0.6433)
2023/09/16 14:29:11 - INFO - root -   Epoch: [6/400][60/346], lr: 0.00000011 	 loss = 0.5613(0.6588)
2023/09/16 14:30:12 - INFO - root -   Epoch: [6/400][80/346], lr: 0.00000011 	 loss = 1.4154(0.6662)
2023/09/16 14:30:55 - INFO - root -   Epoch: [6/400][100/346], lr: 0.00000011 	 loss = 0.4186(0.6561)
2023/09/16 14:31:55 - INFO - root -   Epoch: [6/400][120/346], lr: 0.00000011 	 loss = 0.6302(0.6731)
2023/09/16 14:32:38 - INFO - root -   Epoch: [6/400][140/346], lr: 0.00000011 	 loss = 0.7833(0.6616)
2023/09/16 14:33:38 - INFO - root -   Epoch: [6/400][160/346], lr: 0.00000011 	 loss = 0.4385(0.6602)
2023/09/16 14:34:21 - INFO - root -   Epoch: [6/400][180/346], lr: 0.00000011 	 loss = 0.4554(0.6583)
2023/09/16 14:35:21 - INFO - root -   Epoch: [6/400][200/346], lr: 0.00000011 	 loss = 0.2059(0.6575)
2023/09/16 14:36:04 - INFO - root -   Epoch: [6/400][220/346], lr: 0.00000011 	 loss = 0.4654(0.6600)
2023/09/16 14:37:05 - INFO - root -   Epoch: [6/400][240/346], lr: 0.00000011 	 loss = 0.4585(0.6611)
2023/09/16 14:37:47 - INFO - root -   Epoch: [6/400][260/346], lr: 0.00000011 	 loss = 0.7451(0.6700)
2023/09/16 14:38:48 - INFO - root -   Epoch: [6/400][280/346], lr: 0.00000011 	 loss = 0.8522(0.6756)
2023/09/16 14:39:31 - INFO - root -   Epoch: [6/400][300/346], lr: 0.00000011 	 loss = 0.8557(0.6911)
2023/09/16 14:40:31 - INFO - root -   Epoch: [6/400][320/346], lr: 0.00000011 	 loss = 0.2719(0.6890)
2023/09/16 14:41:12 - INFO - root -   Epoch: [6/400][340/346], lr: 0.00000011 	 loss = 1.1592(0.6900)
2023/09/16 14:41:16 - INFO - root -   Epoch: [6/400] 	 loss = 0.6868
2023/09/16 14:41:16 - INFO - root -   train_accuracy = 0.5939
2023/09/16 14:41:38 - INFO - root -   Epoch: [7/400][0/346], lr: 0.00000011 	 loss = 0.2933(0.2933)
2023/09/16 14:42:21 - INFO - root -   Epoch: [7/400][20/346], lr: 0.00000011 	 loss = 0.6487(0.5882)
2023/09/16 14:43:21 - INFO - root -   Epoch: [7/400][40/346], lr: 0.00000011 	 loss = 0.7548(0.6534)
2023/09/16 14:44:05 - INFO - root -   Epoch: [7/400][60/346], lr: 0.00000011 	 loss = 0.8734(0.6910)
2023/09/16 14:45:05 - INFO - root -   Epoch: [7/400][80/346], lr: 0.00000011 	 loss = 0.9446(0.7001)
2023/09/16 14:45:48 - INFO - root -   Epoch: [7/400][100/346], lr: 0.00000011 	 loss = 0.5422(0.7020)
2023/09/16 14:46:49 - INFO - root -   Epoch: [7/400][120/346], lr: 0.00000011 	 loss = 0.5900(0.7066)
2023/09/16 14:47:32 - INFO - root -   Epoch: [7/400][140/346], lr: 0.00000011 	 loss = 0.5032(0.6869)
2023/09/16 14:48:32 - INFO - root -   Epoch: [7/400][160/346], lr: 0.00000011 	 loss = 0.6161(0.7021)
2023/09/16 14:49:15 - INFO - root -   Epoch: [7/400][180/346], lr: 0.00000011 	 loss = 1.0270(0.7043)
2023/09/16 14:50:15 - INFO - root -   Epoch: [7/400][200/346], lr: 0.00000011 	 loss = 0.3597(0.6932)
2023/09/16 14:50:59 - INFO - root -   Epoch: [7/400][220/346], lr: 0.00000011 	 loss = 0.3534(0.6946)
2023/09/16 14:51:59 - INFO - root -   Epoch: [7/400][240/346], lr: 0.00000011 	 loss = 0.8765(0.6881)
2023/09/16 14:52:42 - INFO - root -   Epoch: [7/400][260/346], lr: 0.00000011 	 loss = 0.9468(0.6869)
2023/09/16 14:53:43 - INFO - root -   Epoch: [7/400][280/346], lr: 0.00000011 	 loss = 0.7297(0.6965)
2023/09/16 14:54:26 - INFO - root -   Epoch: [7/400][300/346], lr: 0.00000011 	 loss = 0.5790(0.6949)
2023/09/16 14:55:26 - INFO - root -   Epoch: [7/400][320/346], lr: 0.00000011 	 loss = 0.7373(0.6919)
2023/09/16 14:56:09 - INFO - root -   Epoch: [7/400][340/346], lr: 0.00000011 	 loss = 0.6319(0.6860)
2023/09/16 14:56:13 - INFO - root -   Epoch: [7/400] 	 loss = 0.6880
2023/09/16 14:56:13 - INFO - root -   train_accuracy = 0.6142
2023/09/16 14:56:35 - INFO - root -   Epoch: [8/400][0/346], lr: 0.00000011 	 loss = 0.6693(0.6693)
2023/09/16 14:57:17 - INFO - root -   Epoch: [8/400][20/346], lr: 0.00000011 	 loss = 0.2414(0.6515)
2023/09/16 14:58:18 - INFO - root -   Epoch: [8/400][40/346], lr: 0.00000011 	 loss = 0.4975(0.6769)
2023/09/16 14:59:01 - INFO - root -   Epoch: [8/400][60/346], lr: 0.00000011 	 loss = 0.5436(0.6393)
2023/09/16 15:00:01 - INFO - root -   Epoch: [8/400][80/346], lr: 0.00000011 	 loss = 0.6636(0.6263)
2023/09/16 15:00:44 - INFO - root -   Epoch: [8/400][100/346], lr: 0.00000011 	 loss = 0.3403(0.6334)
2023/09/16 15:01:45 - INFO - root -   Epoch: [8/400][120/346], lr: 0.00000011 	 loss = 0.4610(0.6670)
2023/09/16 15:02:28 - INFO - root -   Epoch: [8/400][140/346], lr: 0.00000011 	 loss = 0.6107(0.6537)
2023/09/16 15:03:28 - INFO - root -   Epoch: [8/400][160/346], lr: 0.00000011 	 loss = 0.4988(0.6602)
2023/09/16 15:04:11 - INFO - root -   Epoch: [8/400][180/346], lr: 0.00000011 	 loss = 0.8066(0.6756)
2023/09/16 15:05:11 - INFO - root -   Epoch: [8/400][200/346], lr: 0.00000011 	 loss = 0.2043(0.6805)
2023/09/16 15:05:55 - INFO - root -   Epoch: [8/400][220/346], lr: 0.00000011 	 loss = 0.3429(0.6914)
2023/09/16 15:06:54 - INFO - root -   Epoch: [8/400][240/346], lr: 0.00000011 	 loss = 0.5340(0.6892)
2023/09/16 15:07:38 - INFO - root -   Epoch: [8/400][260/346], lr: 0.00000011 	 loss = 0.6541(0.7006)
2023/09/16 15:08:37 - INFO - root -   Epoch: [8/400][280/346], lr: 0.00000011 	 loss = 0.6713(0.7079)
2023/09/16 15:09:21 - INFO - root -   Epoch: [8/400][300/346], lr: 0.00000011 	 loss = 0.5638(0.7049)
2023/09/16 15:10:20 - INFO - root -   Epoch: [8/400][320/346], lr: 0.00000011 	 loss = 0.5872(0.7047)
2023/09/16 15:11:03 - INFO - root -   Epoch: [8/400][340/346], lr: 0.00000011 	 loss = 0.6581(0.7017)
2023/09/16 15:11:07 - INFO - root -   Epoch: [8/400] 	 loss = 0.6989
2023/09/16 15:11:07 - INFO - root -   train_accuracy = 0.6098
2023/09/16 15:11:28 - INFO - root -   Epoch: [9/400][0/346], lr: 0.00000011 	 loss = 0.2463(0.2463)
2023/09/16 15:12:11 - INFO - root -   Epoch: [9/400][20/346], lr: 0.00000011 	 loss = 0.4094(0.5407)
2023/09/16 15:13:12 - INFO - root -   Epoch: [9/400][40/346], lr: 0.00000011 	 loss = 0.2608(0.5882)
2023/09/16 15:13:55 - INFO - root -   Epoch: [9/400][60/346], lr: 0.00000011 	 loss = 0.6535(0.5695)
2023/09/16 15:14:56 - INFO - root -   Epoch: [9/400][80/346], lr: 0.00000011 	 loss = 0.4558(0.5679)
2023/09/16 15:15:39 - INFO - root -   Epoch: [9/400][100/346], lr: 0.00000011 	 loss = 0.4766(0.6116)
2023/09/16 15:16:40 - INFO - root -   Epoch: [9/400][120/346], lr: 0.00000011 	 loss = 1.1757(0.6459)
2023/09/16 15:17:23 - INFO - root -   Epoch: [9/400][140/346], lr: 0.00000011 	 loss = 0.6768(0.6427)
2023/09/16 15:18:24 - INFO - root -   Epoch: [9/400][160/346], lr: 0.00000011 	 loss = 0.1269(0.6505)
2023/09/16 15:19:07 - INFO - root -   Epoch: [9/400][180/346], lr: 0.00000011 	 loss = 0.5556(0.6445)
2023/09/16 15:20:08 - INFO - root -   Epoch: [9/400][200/346], lr: 0.00000011 	 loss = 0.4659(0.6469)
2023/09/16 15:20:51 - INFO - root -   Epoch: [9/400][220/346], lr: 0.00000011 	 loss = 0.3325(0.6533)
2023/09/16 15:21:51 - INFO - root -   Epoch: [9/400][240/346], lr: 0.00000011 	 loss = 0.7228(0.6622)
2023/09/16 15:22:34 - INFO - root -   Epoch: [9/400][260/346], lr: 0.00000011 	 loss = 0.8083(0.6678)
2023/09/16 15:23:35 - INFO - root -   Epoch: [9/400][280/346], lr: 0.00000011 	 loss = 0.1899(0.6729)
2023/09/16 15:24:18 - INFO - root -   Epoch: [9/400][300/346], lr: 0.00000011 	 loss = 0.3345(0.6751)
2023/09/16 15:25:19 - INFO - root -   Epoch: [9/400][320/346], lr: 0.00000011 	 loss = 0.3963(0.6774)
2023/09/16 15:26:00 - INFO - root -   Epoch: [9/400][340/346], lr: 0.00000011 	 loss = 1.1552(0.6779)
2023/09/16 15:26:04 - INFO - root -   Epoch: [9/400] 	 loss = 0.6821
2023/09/16 15:29:52 - INFO - root -   precision = 0.6609
2023/09/16 15:29:52 - INFO - root -   eval_loss = 0.6405
2023/09/16 15:29:53 - INFO - root -   train_accuracy = 0.5896
2023/09/16 15:30:15 - INFO - root -   Epoch: [10/400][0/346], lr: 0.00000011 	 loss = 0.4621(0.4621)
2023/09/16 15:30:58 - INFO - root -   Epoch: [10/400][20/346], lr: 0.00000011 	 loss = 0.3380(0.6747)
2023/09/16 15:31:58 - INFO - root -   Epoch: [10/400][40/346], lr: 0.00000011 	 loss = 0.7659(0.7018)
2023/09/16 15:32:41 - INFO - root -   Epoch: [10/400][60/346], lr: 0.00000011 	 loss = 0.7975(0.6603)
2023/09/16 15:33:41 - INFO - root -   Epoch: [10/400][80/346], lr: 0.00000011 	 loss = 0.9802(0.6618)
2023/09/16 15:34:24 - INFO - root -   Epoch: [10/400][100/346], lr: 0.00000011 	 loss = 0.4810(0.6620)
2023/09/16 15:35:25 - INFO - root -   Epoch: [10/400][120/346], lr: 0.00000011 	 loss = 0.3298(0.6504)
2023/09/16 15:36:08 - INFO - root -   Epoch: [10/400][140/346], lr: 0.00000011 	 loss = 0.9084(0.6429)
2023/09/16 15:37:08 - INFO - root -   Epoch: [10/400][160/346], lr: 0.00000011 	 loss = 0.4987(0.6539)
2023/09/16 15:37:51 - INFO - root -   Epoch: [10/400][180/346], lr: 0.00000011 	 loss = 1.0483(0.6476)
2023/09/16 15:38:51 - INFO - root -   Epoch: [10/400][200/346], lr: 0.00000011 	 loss = 0.3214(0.6485)
2023/09/16 15:39:35 - INFO - root -   Epoch: [10/400][220/346], lr: 0.00000011 	 loss = 0.2744(0.6487)
2023/09/16 15:40:34 - INFO - root -   Epoch: [10/400][240/346], lr: 0.00000011 	 loss = 0.8902(0.6573)
2023/09/16 15:41:18 - INFO - root -   Epoch: [10/400][260/346], lr: 0.00000011 	 loss = 0.7146(0.6651)
2023/09/16 15:42:17 - INFO - root -   Epoch: [10/400][280/346], lr: 0.00000011 	 loss = 0.8132(0.6766)
2023/09/16 15:43:01 - INFO - root -   Epoch: [10/400][300/346], lr: 0.00000011 	 loss = 0.3707(0.6731)
2023/09/16 15:44:00 - INFO - root -   Epoch: [10/400][320/346], lr: 0.00000011 	 loss = 0.6731(0.6732)
2023/09/16 15:44:43 - INFO - root -   Epoch: [10/400][340/346], lr: 0.00000011 	 loss = 0.6973(0.6740)
2023/09/16 15:44:47 - INFO - root -   Epoch: [10/400] 	 loss = 0.6769
2023/09/16 15:44:47 - INFO - root -   train_accuracy = 0.5968
2023/09/16 15:45:09 - INFO - root -   Epoch: [11/400][0/346], lr: 0.00000012 	 loss = 0.3660(0.3660)
2023/09/16 15:45:52 - INFO - root -   Epoch: [11/400][20/346], lr: 0.00000012 	 loss = 0.7300(0.6172)
2023/09/16 15:46:52 - INFO - root -   Epoch: [11/400][40/346], lr: 0.00000012 	 loss = 0.4896(0.6897)
2023/09/16 15:47:35 - INFO - root -   Epoch: [11/400][60/346], lr: 0.00000012 	 loss = 0.7356(0.6745)
2023/09/16 15:48:35 - INFO - root -   Epoch: [11/400][80/346], lr: 0.00000012 	 loss = 1.0944(0.6780)
2023/09/16 15:49:18 - INFO - root -   Epoch: [11/400][100/346], lr: 0.00000012 	 loss = 0.2134(0.6537)
2023/09/16 15:50:19 - INFO - root -   Epoch: [11/400][120/346], lr: 0.00000012 	 loss = 0.7450(0.6628)
2023/09/16 15:51:02 - INFO - root -   Epoch: [11/400][140/346], lr: 0.00000012 	 loss = 0.9213(0.6594)
2023/09/16 15:52:02 - INFO - root -   Epoch: [11/400][160/346], lr: 0.00000012 	 loss = 0.4156(0.6763)
2023/09/16 15:52:45 - INFO - root -   Epoch: [11/400][180/346], lr: 0.00000012 	 loss = 0.6824(0.6836)
2023/09/16 15:53:45 - INFO - root -   Epoch: [11/400][200/346], lr: 0.00000012 	 loss = 0.3798(0.6846)
2023/09/16 15:54:29 - INFO - root -   Epoch: [11/400][220/346], lr: 0.00000012 	 loss = 0.3739(0.6820)
2023/09/16 15:55:28 - INFO - root -   Epoch: [11/400][240/346], lr: 0.00000012 	 loss = 0.4225(0.6858)
2023/09/16 15:56:12 - INFO - root -   Epoch: [11/400][260/346], lr: 0.00000012 	 loss = 0.6661(0.6823)
2023/09/16 15:57:11 - INFO - root -   Epoch: [11/400][280/346], lr: 0.00000012 	 loss = 0.2176(0.6820)
2023/09/16 15:57:55 - INFO - root -   Epoch: [11/400][300/346], lr: 0.00000012 	 loss = 0.3751(0.6790)
2023/09/16 15:58:55 - INFO - root -   Epoch: [11/400][320/346], lr: 0.00000012 	 loss = 0.5504(0.6762)
2023/09/16 15:59:38 - INFO - root -   Epoch: [11/400][340/346], lr: 0.00000012 	 loss = 0.6557(0.6835)
2023/09/16 15:59:42 - INFO - root -   Epoch: [11/400] 	 loss = 0.6796
2023/09/16 15:59:42 - INFO - root -   train_accuracy = 0.5939
2023/09/16 16:00:04 - INFO - root -   Epoch: [12/400][0/346], lr: 0.00000012 	 loss = 0.2979(0.2979)
2023/09/16 16:00:47 - INFO - root -   Epoch: [12/400][20/346], lr: 0.00000012 	 loss = 0.3603(0.5840)
2023/09/16 16:01:48 - INFO - root -   Epoch: [12/400][40/346], lr: 0.00000012 	 loss = 0.5429(0.6346)
2023/09/16 16:02:31 - INFO - root -   Epoch: [12/400][60/346], lr: 0.00000012 	 loss = 0.9761(0.6015)
2023/09/16 16:03:32 - INFO - root -   Epoch: [12/400][80/346], lr: 0.00000012 	 loss = 0.5279(0.6217)
2023/09/16 16:04:15 - INFO - root -   Epoch: [12/400][100/346], lr: 0.00000012 	 loss = 0.5940(0.6425)
2023/09/16 16:05:16 - INFO - root -   Epoch: [12/400][120/346], lr: 0.00000012 	 loss = 0.2970(0.6769)
2023/09/16 16:05:59 - INFO - root -   Epoch: [12/400][140/346], lr: 0.00000012 	 loss = 0.7812(0.6708)
2023/09/16 16:07:00 - INFO - root -   Epoch: [12/400][160/346], lr: 0.00000012 	 loss = 0.2567(0.6691)
2023/09/16 16:07:43 - INFO - root -   Epoch: [12/400][180/346], lr: 0.00000012 	 loss = 1.4434(0.6646)
2023/09/16 16:08:43 - INFO - root -   Epoch: [12/400][200/346], lr: 0.00000012 	 loss = 0.3495(0.6637)
2023/09/16 16:09:26 - INFO - root -   Epoch: [12/400][220/346], lr: 0.00000012 	 loss = 0.5013(0.6672)
2023/09/16 16:10:27 - INFO - root -   Epoch: [12/400][240/346], lr: 0.00000012 	 loss = 0.3400(0.6739)
2023/09/16 16:11:10 - INFO - root -   Epoch: [12/400][260/346], lr: 0.00000012 	 loss = 0.9372(0.6818)
2023/09/16 16:12:10 - INFO - root -   Epoch: [12/400][280/346], lr: 0.00000012 	 loss = 0.5969(0.6883)
2023/09/16 16:12:54 - INFO - root -   Epoch: [12/400][300/346], lr: 0.00000012 	 loss = 0.5501(0.6826)
2023/09/16 16:13:54 - INFO - root -   Epoch: [12/400][320/346], lr: 0.00000012 	 loss = 0.8331(0.6866)
2023/09/16 16:14:36 - INFO - root -   Epoch: [12/400][340/346], lr: 0.00000012 	 loss = 0.7624(0.6824)
2023/09/16 16:14:40 - INFO - root -   Epoch: [12/400] 	 loss = 0.6837
2023/09/16 16:14:40 - INFO - root -   train_accuracy = 0.5983
2023/09/16 16:15:02 - INFO - root -   Epoch: [13/400][0/346], lr: 0.00000012 	 loss = 0.3716(0.3716)
2023/09/16 16:15:45 - INFO - root -   Epoch: [13/400][20/346], lr: 0.00000012 	 loss = 0.6116(0.5726)
2023/09/16 16:16:46 - INFO - root -   Epoch: [13/400][40/346], lr: 0.00000012 	 loss = 0.3923(0.6129)
2023/09/16 16:17:29 - INFO - root -   Epoch: [13/400][60/346], lr: 0.00000012 	 loss = 0.3875(0.5819)
2023/09/16 16:18:30 - INFO - root -   Epoch: [13/400][80/346], lr: 0.00000012 	 loss = 1.2339(0.5955)
2023/09/16 16:19:14 - INFO - root -   Epoch: [13/400][100/346], lr: 0.00000012 	 loss = 0.3563(0.6020)
2023/09/16 16:20:14 - INFO - root -   Epoch: [13/400][120/346], lr: 0.00000012 	 loss = 0.5731(0.6344)
2023/09/16 16:20:58 - INFO - root -   Epoch: [13/400][140/346], lr: 0.00000012 	 loss = 1.1138(0.6382)
2023/09/16 16:21:58 - INFO - root -   Epoch: [13/400][160/346], lr: 0.00000012 	 loss = 0.6511(0.6501)
2023/09/16 16:22:42 - INFO - root -   Epoch: [13/400][180/346], lr: 0.00000012 	 loss = 0.4914(0.6500)
2023/09/16 16:23:42 - INFO - root -   Epoch: [13/400][200/346], lr: 0.00000012 	 loss = 0.3645(0.6458)
2023/09/16 16:24:25 - INFO - root -   Epoch: [13/400][220/346], lr: 0.00000012 	 loss = 0.5987(0.6557)
2023/09/16 16:25:27 - INFO - root -   Epoch: [13/400][240/346], lr: 0.00000012 	 loss = 0.3366(0.6602)
2023/09/16 16:26:10 - INFO - root -   Epoch: [13/400][260/346], lr: 0.00000012 	 loss = 1.0486(0.6656)
2023/09/16 16:27:11 - INFO - root -   Epoch: [13/400][280/346], lr: 0.00000012 	 loss = 0.4005(0.6714)
2023/09/16 16:27:54 - INFO - root -   Epoch: [13/400][300/346], lr: 0.00000012 	 loss = 0.4084(0.6745)
2023/09/16 16:28:55 - INFO - root -   Epoch: [13/400][320/346], lr: 0.00000012 	 loss = 0.3130(0.6716)
2023/09/16 16:29:36 - INFO - root -   Epoch: [13/400][340/346], lr: 0.00000012 	 loss = 0.7626(0.6701)
2023/09/16 16:29:40 - INFO - root -   Epoch: [13/400] 	 loss = 0.6712
2023/09/16 16:29:40 - INFO - root -   train_accuracy = 0.6301
2023/09/16 16:30:02 - INFO - root -   Epoch: [14/400][0/346], lr: 0.00000012 	 loss = 0.3732(0.3732)
2023/09/16 16:30:45 - INFO - root -   Epoch: [14/400][20/346], lr: 0.00000012 	 loss = 0.5245(0.5838)
2023/09/16 16:31:46 - INFO - root -   Epoch: [14/400][40/346], lr: 0.00000012 	 loss = 0.8653(0.6250)
2023/09/16 16:32:29 - INFO - root -   Epoch: [14/400][60/346], lr: 0.00000012 	 loss = 0.9087(0.6123)
2023/09/16 16:33:30 - INFO - root -   Epoch: [14/400][80/346], lr: 0.00000012 	 loss = 0.7475(0.6314)
2023/09/16 16:34:13 - INFO - root -   Epoch: [14/400][100/346], lr: 0.00000012 	 loss = 0.8232(0.6294)
2023/09/16 16:35:13 - INFO - root -   Epoch: [14/400][120/346], lr: 0.00000012 	 loss = 0.8454(0.6757)
2023/09/16 16:35:56 - INFO - root -   Epoch: [14/400][140/346], lr: 0.00000012 	 loss = 0.4583(0.6600)
2023/09/16 16:36:57 - INFO - root -   Epoch: [14/400][160/346], lr: 0.00000012 	 loss = 0.1379(0.6645)
2023/09/16 16:37:40 - INFO - root -   Epoch: [14/400][180/346], lr: 0.00000012 	 loss = 1.1611(0.6670)
2023/09/16 16:38:40 - INFO - root -   Epoch: [14/400][200/346], lr: 0.00000012 	 loss = 0.3167(0.6653)
2023/09/16 16:39:23 - INFO - root -   Epoch: [14/400][220/346], lr: 0.00000012 	 loss = 0.3611(0.6666)
2023/09/16 16:40:24 - INFO - root -   Epoch: [14/400][240/346], lr: 0.00000012 	 loss = 0.6173(0.6684)
2023/09/16 16:41:06 - INFO - root -   Epoch: [14/400][260/346], lr: 0.00000012 	 loss = 0.7417(0.6716)
2023/09/16 16:42:07 - INFO - root -   Epoch: [14/400][280/346], lr: 0.00000012 	 loss = 0.9044(0.6831)
2023/09/16 16:42:50 - INFO - root -   Epoch: [14/400][300/346], lr: 0.00000012 	 loss = 0.2948(0.6858)
2023/09/16 16:43:50 - INFO - root -   Epoch: [14/400][320/346], lr: 0.00000012 	 loss = 0.3177(0.6848)
2023/09/16 16:44:32 - INFO - root -   Epoch: [14/400][340/346], lr: 0.00000012 	 loss = 0.8566(0.6840)
2023/09/16 16:44:36 - INFO - root -   Epoch: [14/400] 	 loss = 0.6819
2023/09/16 16:48:23 - INFO - root -   precision = 0.6782
2023/09/16 16:48:23 - INFO - root -   eval_loss = 0.6319
2023/09/16 16:48:24 - INFO - root -   train_accuracy = 0.5809
2023/09/16 16:48:45 - INFO - root -   Epoch: [15/400][0/346], lr: 0.00000012 	 loss = 0.2363(0.2363)
2023/09/16 16:49:28 - INFO - root -   Epoch: [15/400][20/346], lr: 0.00000012 	 loss = 0.9859(0.7147)
2023/09/16 16:50:29 - INFO - root -   Epoch: [15/400][40/346], lr: 0.00000012 	 loss = 0.5439(0.6925)
2023/09/16 16:51:12 - INFO - root -   Epoch: [15/400][60/346], lr: 0.00000012 	 loss = 0.5010(0.6401)
2023/09/16 16:52:13 - INFO - root -   Epoch: [15/400][80/346], lr: 0.00000012 	 loss = 1.1340(0.6820)
2023/09/16 16:52:56 - INFO - root -   Epoch: [15/400][100/346], lr: 0.00000012 	 loss = 0.4938(0.6856)
2023/09/16 16:53:57 - INFO - root -   Epoch: [15/400][120/346], lr: 0.00000012 	 loss = 0.8224(0.7187)
2023/09/16 16:54:39 - INFO - root -   Epoch: [15/400][140/346], lr: 0.00000012 	 loss = 0.6050(0.7046)
2023/09/16 16:55:40 - INFO - root -   Epoch: [15/400][160/346], lr: 0.00000012 	 loss = 0.2217(0.6982)
2023/09/16 16:56:23 - INFO - root -   Epoch: [15/400][180/346], lr: 0.00000012 	 loss = 0.8108(0.7079)
2023/09/16 16:57:23 - INFO - root -   Epoch: [15/400][200/346], lr: 0.00000012 	 loss = 0.3474(0.7056)
2023/09/16 16:58:06 - INFO - root -   Epoch: [15/400][220/346], lr: 0.00000012 	 loss = 0.5099(0.6979)
2023/09/16 16:59:07 - INFO - root -   Epoch: [15/400][240/346], lr: 0.00000012 	 loss = 0.2491(0.7049)
2023/09/16 16:59:50 - INFO - root -   Epoch: [15/400][260/346], lr: 0.00000012 	 loss = 1.3989(0.7020)
2023/09/16 17:00:50 - INFO - root -   Epoch: [15/400][280/346], lr: 0.00000012 	 loss = 0.5618(0.7095)
2023/09/16 17:01:34 - INFO - root -   Epoch: [15/400][300/346], lr: 0.00000012 	 loss = 0.4234(0.7061)
2023/09/16 17:02:33 - INFO - root -   Epoch: [15/400][320/346], lr: 0.00000012 	 loss = 1.1344(0.7073)
2023/09/16 17:03:15 - INFO - root -   Epoch: [15/400][340/346], lr: 0.00000012 	 loss = 0.7466(0.7018)
2023/09/16 17:03:19 - INFO - root -   Epoch: [15/400] 	 loss = 0.6983
2023/09/16 17:03:19 - INFO - root -   train_accuracy = 0.5882
2023/09/16 17:03:41 - INFO - root -   Epoch: [16/400][0/346], lr: 0.00000012 	 loss = 0.3990(0.3990)
2023/09/16 17:04:24 - INFO - root -   Epoch: [16/400][20/346], lr: 0.00000012 	 loss = 0.3741(0.5927)
2023/09/16 17:05:25 - INFO - root -   Epoch: [16/400][40/346], lr: 0.00000012 	 loss = 0.8283(0.6288)
2023/09/16 17:06:08 - INFO - root -   Epoch: [16/400][60/346], lr: 0.00000012 	 loss = 1.0172(0.6134)
2023/09/16 17:07:09 - INFO - root -   Epoch: [16/400][80/346], lr: 0.00000012 	 loss = 0.7735(0.6278)
2023/09/16 17:07:53 - INFO - root -   Epoch: [16/400][100/346], lr: 0.00000012 	 loss = 0.6902(0.6416)
2023/09/16 17:08:54 - INFO - root -   Epoch: [16/400][120/346], lr: 0.00000012 	 loss = 0.7139(0.6761)
2023/09/16 17:09:37 - INFO - root -   Epoch: [16/400][140/346], lr: 0.00000012 	 loss = 1.1004(0.6604)
2023/09/16 17:10:38 - INFO - root -   Epoch: [16/400][160/346], lr: 0.00000012 	 loss = 0.5229(0.6650)
2023/09/16 17:11:22 - INFO - root -   Epoch: [16/400][180/346], lr: 0.00000012 	 loss = 1.0218(0.6688)
2023/09/16 17:12:22 - INFO - root -   Epoch: [16/400][200/346], lr: 0.00000012 	 loss = 0.3428(0.6670)
2023/09/16 17:13:06 - INFO - root -   Epoch: [16/400][220/346], lr: 0.00000012 	 loss = 0.3920(0.6769)
2023/09/16 17:14:07 - INFO - root -   Epoch: [16/400][240/346], lr: 0.00000012 	 loss = 0.5013(0.6821)
2023/09/16 17:14:50 - INFO - root -   Epoch: [16/400][260/346], lr: 0.00000012 	 loss = 0.7755(0.6921)
2023/09/16 17:15:51 - INFO - root -   Epoch: [16/400][280/346], lr: 0.00000012 	 loss = 0.3858(0.7002)
2023/09/16 17:16:35 - INFO - root -   Epoch: [16/400][300/346], lr: 0.00000012 	 loss = 0.7721(0.6987)
2023/09/16 17:17:36 - INFO - root -   Epoch: [16/400][320/346], lr: 0.00000012 	 loss = 0.5648(0.6949)
2023/09/16 17:18:18 - INFO - root -   Epoch: [16/400][340/346], lr: 0.00000012 	 loss = 0.7402(0.7024)
2023/09/16 17:18:22 - INFO - root -   Epoch: [16/400] 	 loss = 0.7037
2023/09/16 17:18:22 - INFO - root -   train_accuracy = 0.5650
2023/09/16 17:18:43 - INFO - root -   Epoch: [17/400][0/346], lr: 0.00000012 	 loss = 0.3404(0.3404)
2023/09/16 17:19:27 - INFO - root -   Epoch: [17/400][20/346], lr: 0.00000012 	 loss = 0.5361(0.6762)
2023/09/16 17:20:28 - INFO - root -   Epoch: [17/400][40/346], lr: 0.00000012 	 loss = 1.0596(0.6863)
2023/09/16 17:21:11 - INFO - root -   Epoch: [17/400][60/346], lr: 0.00000012 	 loss = 0.8672(0.6407)
2023/09/16 17:22:12 - INFO - root -   Epoch: [17/400][80/346], lr: 0.00000012 	 loss = 0.5356(0.6465)
2023/09/16 17:22:56 - INFO - root -   Epoch: [17/400][100/346], lr: 0.00000012 	 loss = 0.4197(0.6559)
2023/09/16 17:23:57 - INFO - root -   Epoch: [17/400][120/346], lr: 0.00000012 	 loss = 0.5778(0.6703)
2023/09/16 17:24:41 - INFO - root -   Epoch: [17/400][140/346], lr: 0.00000012 	 loss = 0.3446(0.6745)
2023/09/16 17:25:41 - INFO - root -   Epoch: [17/400][160/346], lr: 0.00000012 	 loss = 0.2646(0.6762)
2023/09/16 17:26:25 - INFO - root -   Epoch: [17/400][180/346], lr: 0.00000012 	 loss = 0.6932(0.6829)
2023/09/16 17:27:26 - INFO - root -   Epoch: [17/400][200/346], lr: 0.00000012 	 loss = 0.2550(0.6733)
2023/09/16 17:28:10 - INFO - root -   Epoch: [17/400][220/346], lr: 0.00000012 	 loss = 0.2235(0.6702)
2023/09/16 17:29:10 - INFO - root -   Epoch: [17/400][240/346], lr: 0.00000012 	 loss = 0.6180(0.6741)
2023/09/16 17:29:55 - INFO - root -   Epoch: [17/400][260/346], lr: 0.00000012 	 loss = 0.9724(0.6755)
2023/09/16 17:30:55 - INFO - root -   Epoch: [17/400][280/346], lr: 0.00000012 	 loss = 0.4142(0.6768)
2023/09/16 17:31:39 - INFO - root -   Epoch: [17/400][300/346], lr: 0.00000012 	 loss = 0.5243(0.6778)
2023/09/16 17:32:39 - INFO - root -   Epoch: [17/400][320/346], lr: 0.00000012 	 loss = 0.1179(0.6734)
2023/09/16 17:33:22 - INFO - root -   Epoch: [17/400][340/346], lr: 0.00000012 	 loss = 0.6715(0.6729)
2023/09/16 17:33:26 - INFO - root -   Epoch: [17/400] 	 loss = 0.6714
2023/09/16 17:33:26 - INFO - root -   train_accuracy = 0.6127
2023/09/16 17:33:47 - INFO - root -   Epoch: [18/400][0/346], lr: 0.00000013 	 loss = 0.4097(0.4097)
2023/09/16 17:34:30 - INFO - root -   Epoch: [18/400][20/346], lr: 0.00000013 	 loss = 0.9183(0.4845)
2023/09/16 17:35:32 - INFO - root -   Epoch: [18/400][40/346], lr: 0.00000013 	 loss = 0.6714(0.5570)
2023/09/16 17:36:15 - INFO - root -   Epoch: [18/400][60/346], lr: 0.00000013 	 loss = 0.3957(0.5689)
2023/09/16 17:37:16 - INFO - root -   Epoch: [18/400][80/346], lr: 0.00000013 	 loss = 0.4828(0.5928)
2023/09/16 17:38:00 - INFO - root -   Epoch: [18/400][100/346], lr: 0.00000013 	 loss = 0.6216(0.6011)
2023/09/16 17:39:01 - INFO - root -   Epoch: [18/400][120/346], lr: 0.00000013 	 loss = 0.5580(0.6136)
2023/09/16 17:39:45 - INFO - root -   Epoch: [18/400][140/346], lr: 0.00000013 	 loss = 0.7165(0.6120)
2023/09/16 17:40:46 - INFO - root -   Epoch: [18/400][160/346], lr: 0.00000013 	 loss = 0.2117(0.6246)
2023/09/16 17:41:30 - INFO - root -   Epoch: [18/400][180/346], lr: 0.00000013 	 loss = 0.4438(0.6222)
2023/09/16 17:42:31 - INFO - root -   Epoch: [18/400][200/346], lr: 0.00000013 	 loss = 0.2270(0.6280)
2023/09/16 17:43:15 - INFO - root -   Epoch: [18/400][220/346], lr: 0.00000013 	 loss = 0.2790(0.6251)
2023/09/16 17:44:16 - INFO - root -   Epoch: [18/400][240/346], lr: 0.00000013 	 loss = 0.8973(0.6255)
2023/09/16 17:44:59 - INFO - root -   Epoch: [18/400][260/346], lr: 0.00000013 	 loss = 0.7273(0.6267)
2023/09/16 17:46:00 - INFO - root -   Epoch: [18/400][280/346], lr: 0.00000013 	 loss = 0.4967(0.6323)
2023/09/16 17:46:44 - INFO - root -   Epoch: [18/400][300/346], lr: 0.00000013 	 loss = 0.8811(0.6426)
2023/09/16 17:47:45 - INFO - root -   Epoch: [18/400][320/346], lr: 0.00000013 	 loss = 0.4552(0.6437)
2023/09/16 17:48:28 - INFO - root -   Epoch: [18/400][340/346], lr: 0.00000013 	 loss = 0.8944(0.6423)
2023/09/16 17:48:32 - INFO - root -   Epoch: [18/400] 	 loss = 0.6436
2023/09/16 17:48:32 - INFO - root -   train_accuracy = 0.6402
2023/09/16 17:48:53 - INFO - root -   Epoch: [19/400][0/346], lr: 0.00000013 	 loss = 0.6492(0.6492)
2023/09/16 17:49:36 - INFO - root -   Epoch: [19/400][20/346], lr: 0.00000013 	 loss = 0.4730(0.5206)
2023/09/16 17:50:37 - INFO - root -   Epoch: [19/400][40/346], lr: 0.00000013 	 loss = 0.7018(0.6036)
2023/09/16 17:51:20 - INFO - root -   Epoch: [19/400][60/346], lr: 0.00000013 	 loss = 0.9118(0.6068)
2023/09/16 17:52:21 - INFO - root -   Epoch: [19/400][80/346], lr: 0.00000013 	 loss = 0.3823(0.6184)
2023/09/16 17:53:04 - INFO - root -   Epoch: [19/400][100/346], lr: 0.00000013 	 loss = 0.6069(0.6264)
2023/09/16 17:54:05 - INFO - root -   Epoch: [19/400][120/346], lr: 0.00000013 	 loss = 0.4554(0.6587)
2023/09/16 17:54:48 - INFO - root -   Epoch: [19/400][140/346], lr: 0.00000013 	 loss = 0.4083(0.6543)
2023/09/16 17:55:48 - INFO - root -   Epoch: [19/400][160/346], lr: 0.00000013 	 loss = 0.3042(0.6663)
2023/09/16 17:56:32 - INFO - root -   Epoch: [19/400][180/346], lr: 0.00000013 	 loss = 0.6376(0.6720)
2023/09/16 17:57:32 - INFO - root -   Epoch: [19/400][200/346], lr: 0.00000013 	 loss = 0.2244(0.6703)
2023/09/16 17:58:16 - INFO - root -   Epoch: [19/400][220/346], lr: 0.00000013 	 loss = 0.4082(0.6693)
2023/09/16 17:59:15 - INFO - root -   Epoch: [19/400][240/346], lr: 0.00000013 	 loss = 0.7980(0.6707)
2023/09/16 18:00:00 - INFO - root -   Epoch: [19/400][260/346], lr: 0.00000013 	 loss = 0.8977(0.6718)
2023/09/16 18:00:59 - INFO - root -   Epoch: [19/400][280/346], lr: 0.00000013 	 loss = 0.4011(0.6730)
2023/09/16 18:01:43 - INFO - root -   Epoch: [19/400][300/346], lr: 0.00000013 	 loss = 0.3972(0.6783)
2023/09/16 18:02:42 - INFO - root -   Epoch: [19/400][320/346], lr: 0.00000013 	 loss = 0.4958(0.6760)
2023/09/16 18:03:25 - INFO - root -   Epoch: [19/400][340/346], lr: 0.00000013 	 loss = 1.0336(0.6744)
2023/09/16 18:03:29 - INFO - root -   Epoch: [19/400] 	 loss = 0.6733
2023/09/16 18:07:17 - INFO - root -   precision = 0.6609
2023/09/16 18:07:17 - INFO - root -   eval_loss = 0.6266
2023/09/16 18:07:18 - INFO - root -   train_accuracy = 0.6012
2023/09/16 18:07:40 - INFO - root -   Epoch: [20/400][0/346], lr: 0.00000013 	 loss = 0.2390(0.2390)
2023/09/16 18:08:22 - INFO - root -   Epoch: [20/400][20/346], lr: 0.00000013 	 loss = 0.5229(0.6142)
2023/09/16 18:09:23 - INFO - root -   Epoch: [20/400][40/346], lr: 0.00000013 	 loss = 0.6037(0.6173)
2023/09/16 18:10:06 - INFO - root -   Epoch: [20/400][60/346], lr: 0.00000013 	 loss = 0.6474(0.6039)
2023/09/16 18:11:06 - INFO - root -   Epoch: [20/400][80/346], lr: 0.00000013 	 loss = 1.0118(0.6274)
2023/09/16 18:11:49 - INFO - root -   Epoch: [20/400][100/346], lr: 0.00000013 	 loss = 0.2276(0.6281)
2023/09/16 18:12:50 - INFO - root -   Epoch: [20/400][120/346], lr: 0.00000013 	 loss = 0.5946(0.6628)
2023/09/16 18:13:33 - INFO - root -   Epoch: [20/400][140/346], lr: 0.00000013 	 loss = 0.6539(0.6505)
2023/09/16 18:14:33 - INFO - root -   Epoch: [20/400][160/346], lr: 0.00000013 	 loss = 0.1926(0.6662)
2023/09/16 18:15:16 - INFO - root -   Epoch: [20/400][180/346], lr: 0.00000013 	 loss = 0.5922(0.6770)
2023/09/16 18:16:16 - INFO - root -   Epoch: [20/400][200/346], lr: 0.00000013 	 loss = 0.5066(0.6809)
2023/09/16 18:16:59 - INFO - root -   Epoch: [20/400][220/346], lr: 0.00000013 	 loss = 0.4627(0.6812)
2023/09/16 18:17:59 - INFO - root -   Epoch: [20/400][240/346], lr: 0.00000013 	 loss = 0.6794(0.6808)
2023/09/16 18:18:42 - INFO - root -   Epoch: [20/400][260/346], lr: 0.00000013 	 loss = 0.9833(0.6784)
2023/09/16 18:19:42 - INFO - root -   Epoch: [20/400][280/346], lr: 0.00000013 	 loss = 0.5248(0.6797)
2023/09/16 18:20:26 - INFO - root -   Epoch: [20/400][300/346], lr: 0.00000013 	 loss = 0.3970(0.6746)
2023/09/16 18:21:25 - INFO - root -   Epoch: [20/400][320/346], lr: 0.00000013 	 loss = 0.3984(0.6669)
2023/09/16 18:22:07 - INFO - root -   Epoch: [20/400][340/346], lr: 0.00000013 	 loss = 0.6871(0.6672)
2023/09/16 18:22:11 - INFO - root -   Epoch: [20/400] 	 loss = 0.6654
2023/09/16 18:22:11 - INFO - root -   train_accuracy = 0.6084
2023/09/16 18:22:33 - INFO - root -   Epoch: [21/400][0/346], lr: 0.00000013 	 loss = 0.1390(0.1390)
2023/09/16 18:23:15 - INFO - root -   Epoch: [21/400][20/346], lr: 0.00000013 	 loss = 0.5635(0.5371)
2023/09/16 18:24:16 - INFO - root -   Epoch: [21/400][40/346], lr: 0.00000013 	 loss = 0.4840(0.5604)
2023/09/16 18:24:59 - INFO - root -   Epoch: [21/400][60/346], lr: 0.00000013 	 loss = 0.6106(0.5668)
2023/09/16 18:26:00 - INFO - root -   Epoch: [21/400][80/346], lr: 0.00000013 	 loss = 1.1104(0.5956)
2023/09/16 18:26:43 - INFO - root -   Epoch: [21/400][100/346], lr: 0.00000013 	 loss = 0.2427(0.5872)
2023/09/16 18:27:43 - INFO - root -   Epoch: [21/400][120/346], lr: 0.00000013 	 loss = 0.4924(0.6077)
2023/09/16 18:28:26 - INFO - root -   Epoch: [21/400][140/346], lr: 0.00000013 	 loss = 0.9501(0.6034)
2023/09/16 18:29:26 - INFO - root -   Epoch: [21/400][160/346], lr: 0.00000013 	 loss = 0.1983(0.6310)
2023/09/16 18:30:10 - INFO - root -   Epoch: [21/400][180/346], lr: 0.00000013 	 loss = 0.6632(0.6379)
2023/09/16 18:31:10 - INFO - root -   Epoch: [21/400][200/346], lr: 0.00000013 	 loss = 0.3449(0.6371)
2023/09/16 18:31:53 - INFO - root -   Epoch: [21/400][220/346], lr: 0.00000013 	 loss = 0.2515(0.6399)
2023/09/16 18:32:53 - INFO - root -   Epoch: [21/400][240/346], lr: 0.00000013 	 loss = 0.3204(0.6411)
2023/09/16 18:33:36 - INFO - root -   Epoch: [21/400][260/346], lr: 0.00000013 	 loss = 0.4900(0.6331)
2023/09/16 18:34:37 - INFO - root -   Epoch: [21/400][280/346], lr: 0.00000013 	 loss = 0.2345(0.6484)
2023/09/16 18:35:20 - INFO - root -   Epoch: [21/400][300/346], lr: 0.00000013 	 loss = 0.6390(0.6547)
2023/09/16 18:36:20 - INFO - root -   Epoch: [21/400][320/346], lr: 0.00000013 	 loss = 0.5131(0.6488)
2023/09/16 18:37:03 - INFO - root -   Epoch: [21/400][340/346], lr: 0.00000013 	 loss = 0.9888(0.6522)
2023/09/16 18:37:07 - INFO - root -   Epoch: [21/400] 	 loss = 0.6521
2023/09/16 18:37:07 - INFO - root -   train_accuracy = 0.6474
2023/09/16 18:37:28 - INFO - root -   Epoch: [22/400][0/346], lr: 0.00000013 	 loss = 0.5090(0.5090)
2023/09/16 18:38:12 - INFO - root -   Epoch: [22/400][20/346], lr: 0.00000013 	 loss = 0.6825(0.6490)
2023/09/16 18:39:12 - INFO - root -   Epoch: [22/400][40/346], lr: 0.00000013 	 loss = 0.2918(0.6329)
2023/09/16 18:39:55 - INFO - root -   Epoch: [22/400][60/346], lr: 0.00000013 	 loss = 0.8264(0.6075)
2023/09/16 18:40:56 - INFO - root -   Epoch: [22/400][80/346], lr: 0.00000013 	 loss = 0.8685(0.6205)
2023/09/16 18:41:39 - INFO - root -   Epoch: [22/400][100/346], lr: 0.00000013 	 loss = 0.6315(0.6271)
2023/09/16 18:42:40 - INFO - root -   Epoch: [22/400][120/346], lr: 0.00000013 	 loss = 0.8599(0.6321)
2023/09/16 18:43:23 - INFO - root -   Epoch: [22/400][140/346], lr: 0.00000013 	 loss = 0.4095(0.6214)
2023/09/16 18:44:24 - INFO - root -   Epoch: [22/400][160/346], lr: 0.00000013 	 loss = 0.3676(0.6338)
2023/09/16 18:45:07 - INFO - root -   Epoch: [22/400][180/346], lr: 0.00000013 	 loss = 0.7370(0.6353)
2023/09/16 18:46:08 - INFO - root -   Epoch: [22/400][200/346], lr: 0.00000013 	 loss = 0.1853(0.6404)
2023/09/16 18:46:51 - INFO - root -   Epoch: [22/400][220/346], lr: 0.00000013 	 loss = 0.5572(0.6429)
2023/09/16 18:47:51 - INFO - root -   Epoch: [22/400][240/346], lr: 0.00000013 	 loss = 0.4689(0.6432)
2023/09/16 18:48:35 - INFO - root -   Epoch: [22/400][260/346], lr: 0.00000013 	 loss = 0.3281(0.6430)
2023/09/16 18:49:35 - INFO - root -   Epoch: [22/400][280/346], lr: 0.00000013 	 loss = 0.4192(0.6548)
2023/09/16 18:50:19 - INFO - root -   Epoch: [22/400][300/346], lr: 0.00000013 	 loss = 0.2469(0.6553)
2023/09/16 18:51:18 - INFO - root -   Epoch: [22/400][320/346], lr: 0.00000013 	 loss = 0.2898(0.6561)
2023/09/16 18:52:00 - INFO - root -   Epoch: [22/400][340/346], lr: 0.00000013 	 loss = 0.9647(0.6528)
2023/09/16 18:52:05 - INFO - root -   Epoch: [22/400] 	 loss = 0.6516
2023/09/16 18:52:05 - INFO - root -   train_accuracy = 0.6329
2023/09/16 18:52:26 - INFO - root -   Epoch: [23/400][0/346], lr: 0.00000013 	 loss = 0.3118(0.3118)
2023/09/16 18:53:09 - INFO - root -   Epoch: [23/400][20/346], lr: 0.00000013 	 loss = 1.0713(0.4737)
2023/09/16 18:54:11 - INFO - root -   Epoch: [23/400][40/346], lr: 0.00000013 	 loss = 0.3611(0.5127)
2023/09/16 18:54:54 - INFO - root -   Epoch: [23/400][60/346], lr: 0.00000013 	 loss = 0.7979(0.5366)
2023/09/16 18:55:55 - INFO - root -   Epoch: [23/400][80/346], lr: 0.00000013 	 loss = 0.9623(0.5663)
2023/09/16 18:56:39 - INFO - root -   Epoch: [23/400][100/346], lr: 0.00000013 	 loss = 0.6958(0.6162)
2023/09/16 18:57:40 - INFO - root -   Epoch: [23/400][120/346], lr: 0.00000013 	 loss = 0.5667(0.6437)
2023/09/16 18:58:24 - INFO - root -   Epoch: [23/400][140/346], lr: 0.00000013 	 loss = 0.7759(0.6271)
2023/09/16 18:59:25 - INFO - root -   Epoch: [23/400][160/346], lr: 0.00000013 	 loss = 0.3302(0.6341)
2023/09/16 19:00:08 - INFO - root -   Epoch: [23/400][180/346], lr: 0.00000013 	 loss = 0.5613(0.6317)
2023/09/16 19:01:10 - INFO - root -   Epoch: [23/400][200/346], lr: 0.00000013 	 loss = 0.1156(0.6406)
2023/09/16 19:01:53 - INFO - root -   Epoch: [23/400][220/346], lr: 0.00000013 	 loss = 0.1262(0.6441)
2023/09/16 19:02:54 - INFO - root -   Epoch: [23/400][240/346], lr: 0.00000013 	 loss = 0.6334(0.6392)
2023/09/16 19:03:38 - INFO - root -   Epoch: [23/400][260/346], lr: 0.00000013 	 loss = 0.7210(0.6401)
2023/09/16 19:04:39 - INFO - root -   Epoch: [23/400][280/346], lr: 0.00000013 	 loss = 0.2532(0.6519)
2023/09/16 19:05:22 - INFO - root -   Epoch: [23/400][300/346], lr: 0.00000013 	 loss = 0.2752(0.6546)
2023/09/16 19:06:23 - INFO - root -   Epoch: [23/400][320/346], lr: 0.00000013 	 loss = 0.8175(0.6532)
2023/09/16 19:07:05 - INFO - root -   Epoch: [23/400][340/346], lr: 0.00000013 	 loss = 1.0908(0.6543)
2023/09/16 19:07:09 - INFO - root -   Epoch: [23/400] 	 loss = 0.6539
2023/09/16 19:07:09 - INFO - root -   train_accuracy = 0.6402
2023/09/16 19:07:31 - INFO - root -   Epoch: [24/400][0/346], lr: 0.00000013 	 loss = 0.2676(0.2676)
2023/09/16 19:08:14 - INFO - root -   Epoch: [24/400][20/346], lr: 0.00000013 	 loss = 0.3007(0.5465)
2023/09/16 19:09:14 - INFO - root -   Epoch: [24/400][40/346], lr: 0.00000013 	 loss = 0.3704(0.5969)
2023/09/16 19:09:58 - INFO - root -   Epoch: [24/400][60/346], lr: 0.00000013 	 loss = 0.5019(0.6066)
2023/09/16 19:10:59 - INFO - root -   Epoch: [24/400][80/346], lr: 0.00000013 	 loss = 0.6320(0.6166)
2023/09/16 19:11:42 - INFO - root -   Epoch: [24/400][100/346], lr: 0.00000013 	 loss = 0.4210(0.6118)
2023/09/16 19:12:43 - INFO - root -   Epoch: [24/400][120/346], lr: 0.00000013 	 loss = 0.6178(0.6242)
2023/09/16 19:13:26 - INFO - root -   Epoch: [24/400][140/346], lr: 0.00000013 	 loss = 0.6567(0.6280)
2023/09/16 19:14:26 - INFO - root -   Epoch: [24/400][160/346], lr: 0.00000013 	 loss = 0.2910(0.6388)
2023/09/16 19:15:10 - INFO - root -   Epoch: [24/400][180/346], lr: 0.00000013 	 loss = 0.4792(0.6468)
2023/09/16 19:16:10 - INFO - root -   Epoch: [24/400][200/346], lr: 0.00000013 	 loss = 0.1231(0.6442)
2023/09/16 19:16:54 - INFO - root -   Epoch: [24/400][220/346], lr: 0.00000013 	 loss = 0.2153(0.6460)
2023/09/16 19:17:55 - INFO - root -   Epoch: [24/400][240/346], lr: 0.00000013 	 loss = 0.4481(0.6491)
2023/09/16 19:18:38 - INFO - root -   Epoch: [24/400][260/346], lr: 0.00000013 	 loss = 0.8131(0.6499)
2023/09/16 19:19:38 - INFO - root -   Epoch: [24/400][280/346], lr: 0.00000013 	 loss = 0.2216(0.6572)
2023/09/16 19:20:21 - INFO - root -   Epoch: [24/400][300/346], lr: 0.00000013 	 loss = 0.2168(0.6567)
2023/09/16 19:21:22 - INFO - root -   Epoch: [24/400][320/346], lr: 0.00000013 	 loss = 0.2706(0.6603)
2023/09/16 19:22:04 - INFO - root -   Epoch: [24/400][340/346], lr: 0.00000013 	 loss = 1.2855(0.6617)
2023/09/16 19:22:09 - INFO - root -   Epoch: [24/400] 	 loss = 0.6614
2023/09/16 19:25:56 - INFO - root -   precision = 0.6494
2023/09/16 19:25:56 - INFO - root -   eval_loss = 0.6197
2023/09/16 19:25:57 - INFO - root -   train_accuracy = 0.6257
2023/09/16 19:26:19 - INFO - root -   Epoch: [25/400][0/346], lr: 0.00000014 	 loss = 0.2291(0.2291)
2023/09/16 19:27:02 - INFO - root -   Epoch: [25/400][20/346], lr: 0.00000014 	 loss = 0.7888(0.5018)
2023/09/16 19:28:03 - INFO - root -   Epoch: [25/400][40/346], lr: 0.00000014 	 loss = 0.4430(0.5344)
2023/09/16 19:28:47 - INFO - root -   Epoch: [25/400][60/346], lr: 0.00000014 	 loss = 1.0630(0.5404)
2023/09/16 19:29:48 - INFO - root -   Epoch: [25/400][80/346], lr: 0.00000014 	 loss = 0.3814(0.5665)
2023/09/16 19:30:31 - INFO - root -   Epoch: [25/400][100/346], lr: 0.00000014 	 loss = 0.5609(0.5824)
2023/09/16 19:31:32 - INFO - root -   Epoch: [25/400][120/346], lr: 0.00000014 	 loss = 0.3991(0.6081)
2023/09/16 19:32:15 - INFO - root -   Epoch: [25/400][140/346], lr: 0.00000014 	 loss = 0.8750(0.6021)
2023/09/16 19:33:16 - INFO - root -   Epoch: [25/400][160/346], lr: 0.00000014 	 loss = 0.2182(0.6206)
2023/09/16 19:34:00 - INFO - root -   Epoch: [25/400][180/346], lr: 0.00000014 	 loss = 1.0929(0.6179)
2023/09/16 19:35:01 - INFO - root -   Epoch: [25/400][200/346], lr: 0.00000014 	 loss = 0.4140(0.6155)
2023/09/16 19:35:44 - INFO - root -   Epoch: [25/400][220/346], lr: 0.00000014 	 loss = 0.2766(0.6110)
2023/09/16 19:36:45 - INFO - root -   Epoch: [25/400][240/346], lr: 0.00000014 	 loss = 0.3718(0.6101)
2023/09/16 19:37:28 - INFO - root -   Epoch: [25/400][260/346], lr: 0.00000014 	 loss = 0.5874(0.6057)
2023/09/16 19:38:29 - INFO - root -   Epoch: [25/400][280/346], lr: 0.00000014 	 loss = 0.2314(0.6148)
2023/09/16 19:39:12 - INFO - root -   Epoch: [25/400][300/346], lr: 0.00000014 	 loss = 0.2554(0.6208)
2023/09/16 19:40:13 - INFO - root -   Epoch: [25/400][320/346], lr: 0.00000014 	 loss = 0.3671(0.6138)
2023/09/16 19:40:55 - INFO - root -   Epoch: [25/400][340/346], lr: 0.00000014 	 loss = 1.2352(0.6138)
2023/09/16 19:40:59 - INFO - root -   Epoch: [25/400] 	 loss = 0.6136
2023/09/16 19:40:59 - INFO - root -   train_accuracy = 0.6763
2023/09/16 19:41:21 - INFO - root -   Epoch: [26/400][0/346], lr: 0.00000014 	 loss = 0.2651(0.2651)
2023/09/16 19:42:04 - INFO - root -   Epoch: [26/400][20/346], lr: 0.00000014 	 loss = 0.9689(0.4900)
2023/09/16 19:43:05 - INFO - root -   Epoch: [26/400][40/346], lr: 0.00000014 	 loss = 0.3777(0.5234)
2023/09/16 19:43:48 - INFO - root -   Epoch: [26/400][60/346], lr: 0.00000014 	 loss = 0.8001(0.5334)
2023/09/16 19:44:48 - INFO - root -   Epoch: [26/400][80/346], lr: 0.00000014 	 loss = 0.7605(0.5568)
2023/09/16 19:45:32 - INFO - root -   Epoch: [26/400][100/346], lr: 0.00000014 	 loss = 0.4759(0.5730)
2023/09/16 19:46:32 - INFO - root -   Epoch: [26/400][120/346], lr: 0.00000014 	 loss = 0.2997(0.6024)
2023/09/16 19:47:15 - INFO - root -   Epoch: [26/400][140/346], lr: 0.00000014 	 loss = 0.4661(0.5919)
2023/09/16 19:48:16 - INFO - root -   Epoch: [26/400][160/346], lr: 0.00000014 	 loss = 0.3114(0.6155)
2023/09/16 19:48:59 - INFO - root -   Epoch: [26/400][180/346], lr: 0.00000014 	 loss = 0.4921(0.6192)
2023/09/16 19:49:59 - INFO - root -   Epoch: [26/400][200/346], lr: 0.00000014 	 loss = 0.2540(0.6161)
2023/09/16 19:50:42 - INFO - root -   Epoch: [26/400][220/346], lr: 0.00000014 	 loss = 0.3892(0.6170)
2023/09/16 19:51:43 - INFO - root -   Epoch: [26/400][240/346], lr: 0.00000014 	 loss = 0.4987(0.6188)
2023/09/16 19:52:26 - INFO - root -   Epoch: [26/400][260/346], lr: 0.00000014 	 loss = 0.5633(0.6173)
2023/09/16 19:53:26 - INFO - root -   Epoch: [26/400][280/346], lr: 0.00000014 	 loss = 0.2236(0.6239)
2023/09/16 19:54:10 - INFO - root -   Epoch: [26/400][300/346], lr: 0.00000014 	 loss = 0.5157(0.6273)
2023/09/16 19:55:10 - INFO - root -   Epoch: [26/400][320/346], lr: 0.00000014 	 loss = 0.3732(0.6285)
2023/09/16 19:55:52 - INFO - root -   Epoch: [26/400][340/346], lr: 0.00000014 	 loss = 0.9299(0.6293)
2023/09/16 19:55:57 - INFO - root -   Epoch: [26/400] 	 loss = 0.6288
2023/09/16 19:55:57 - INFO - root -   train_accuracy = 0.6691
2023/09/16 19:56:18 - INFO - root -   Epoch: [27/400][0/346], lr: 0.00000014 	 loss = 0.2739(0.2739)
2023/09/16 19:57:01 - INFO - root -   Epoch: [27/400][20/346], lr: 0.00000014 	 loss = 0.7442(0.5026)
2023/09/16 19:58:01 - INFO - root -   Epoch: [27/400][40/346], lr: 0.00000014 	 loss = 0.2749(0.5812)
2023/09/16 19:58:44 - INFO - root -   Epoch: [27/400][60/346], lr: 0.00000014 	 loss = 1.0693(0.5591)
2023/09/16 19:59:45 - INFO - root -   Epoch: [27/400][80/346], lr: 0.00000014 	 loss = 0.5248(0.5798)
2023/09/16 20:00:28 - INFO - root -   Epoch: [27/400][100/346], lr: 0.00000014 	 loss = 0.3386(0.5836)
2023/09/16 20:01:28 - INFO - root -   Epoch: [27/400][120/346], lr: 0.00000014 	 loss = 0.7681(0.6085)
2023/09/16 20:02:11 - INFO - root -   Epoch: [27/400][140/346], lr: 0.00000014 	 loss = 1.4877(0.6098)
2023/09/16 20:03:12 - INFO - root -   Epoch: [27/400][160/346], lr: 0.00000014 	 loss = 0.2476(0.6227)
2023/09/16 20:03:54 - INFO - root -   Epoch: [27/400][180/346], lr: 0.00000014 	 loss = 0.9301(0.6362)
2023/09/16 20:04:55 - INFO - root -   Epoch: [27/400][200/346], lr: 0.00000014 	 loss = 0.1680(0.6310)
2023/09/16 20:05:38 - INFO - root -   Epoch: [27/400][220/346], lr: 0.00000014 	 loss = 0.1189(0.6339)
2023/09/16 20:06:38 - INFO - root -   Epoch: [27/400][240/346], lr: 0.00000014 	 loss = 0.2683(0.6373)
2023/09/16 20:07:21 - INFO - root -   Epoch: [27/400][260/346], lr: 0.00000014 	 loss = 0.9656(0.6371)
2023/09/16 20:08:21 - INFO - root -   Epoch: [27/400][280/346], lr: 0.00000014 	 loss = 0.3920(0.6433)
2023/09/16 20:09:04 - INFO - root -   Epoch: [27/400][300/346], lr: 0.00000014 	 loss = 0.5736(0.6503)
2023/09/16 20:10:04 - INFO - root -   Epoch: [27/400][320/346], lr: 0.00000014 	 loss = 0.4422(0.6595)
2023/09/16 20:10:46 - INFO - root -   Epoch: [27/400][340/346], lr: 0.00000014 	 loss = 0.8164(0.6564)
2023/09/16 20:10:50 - INFO - root -   Epoch: [27/400] 	 loss = 0.6578
2023/09/16 20:10:50 - INFO - root -   train_accuracy = 0.6488
2023/09/16 20:11:12 - INFO - root -   Epoch: [28/400][0/346], lr: 0.00000014 	 loss = 0.1927(0.1927)
2023/09/16 20:11:55 - INFO - root -   Epoch: [28/400][20/346], lr: 0.00000014 	 loss = 0.6315(0.5162)
2023/09/16 20:12:55 - INFO - root -   Epoch: [28/400][40/346], lr: 0.00000014 	 loss = 0.3660(0.5808)
2023/09/16 20:13:38 - INFO - root -   Epoch: [28/400][60/346], lr: 0.00000014 	 loss = 1.1919(0.5770)
2023/09/16 20:14:39 - INFO - root -   Epoch: [28/400][80/346], lr: 0.00000014 	 loss = 0.6469(0.5994)
2023/09/16 20:15:22 - INFO - root -   Epoch: [28/400][100/346], lr: 0.00000014 	 loss = 0.5972(0.6291)
2023/09/16 20:16:22 - INFO - root -   Epoch: [28/400][120/346], lr: 0.00000014 	 loss = 0.4373(0.6404)
2023/09/16 20:17:05 - INFO - root -   Epoch: [28/400][140/346], lr: 0.00000014 	 loss = 0.6150(0.6387)
2023/09/16 20:18:06 - INFO - root -   Epoch: [28/400][160/346], lr: 0.00000014 	 loss = 0.3183(0.6515)
2023/09/16 20:18:49 - INFO - root -   Epoch: [28/400][180/346], lr: 0.00000014 	 loss = 0.8326(0.6525)
2023/09/16 20:19:49 - INFO - root -   Epoch: [28/400][200/346], lr: 0.00000014 	 loss = 0.1088(0.6434)
2023/09/16 20:20:32 - INFO - root -   Epoch: [28/400][220/346], lr: 0.00000014 	 loss = 0.3805(0.6428)
2023/09/16 20:21:33 - INFO - root -   Epoch: [28/400][240/346], lr: 0.00000014 	 loss = 0.4170(0.6468)
2023/09/16 20:22:16 - INFO - root -   Epoch: [28/400][260/346], lr: 0.00000014 	 loss = 0.9536(0.6477)
2023/09/16 20:23:16 - INFO - root -   Epoch: [28/400][280/346], lr: 0.00000014 	 loss = 0.4060(0.6608)
2023/09/16 20:23:59 - INFO - root -   Epoch: [28/400][300/346], lr: 0.00000014 	 loss = 0.4952(0.6585)
2023/09/16 20:24:59 - INFO - root -   Epoch: [28/400][320/346], lr: 0.00000014 	 loss = 0.6192(0.6634)
2023/09/16 20:25:41 - INFO - root -   Epoch: [28/400][340/346], lr: 0.00000014 	 loss = 0.9633(0.6622)
2023/09/16 20:25:45 - INFO - root -   Epoch: [28/400] 	 loss = 0.6588
2023/09/16 20:25:45 - INFO - root -   train_accuracy = 0.6113
2023/09/16 20:26:07 - INFO - root -   Epoch: [29/400][0/346], lr: 0.00000014 	 loss = 0.2613(0.2613)
2023/09/16 20:26:50 - INFO - root -   Epoch: [29/400][20/346], lr: 0.00000014 	 loss = 0.2192(0.4847)
2023/09/16 20:27:51 - INFO - root -   Epoch: [29/400][40/346], lr: 0.00000014 	 loss = 0.5377(0.5898)
2023/09/16 20:28:35 - INFO - root -   Epoch: [29/400][60/346], lr: 0.00000014 	 loss = 0.5264(0.5712)
2023/09/16 20:29:35 - INFO - root -   Epoch: [29/400][80/346], lr: 0.00000014 	 loss = 0.4186(0.5822)
2023/09/16 20:30:18 - INFO - root -   Epoch: [29/400][100/346], lr: 0.00000014 	 loss = 0.4827(0.6047)
2023/09/16 20:31:19 - INFO - root -   Epoch: [29/400][120/346], lr: 0.00000014 	 loss = 0.6769(0.6427)
2023/09/16 20:32:02 - INFO - root -   Epoch: [29/400][140/346], lr: 0.00000014 	 loss = 0.7192(0.6279)
2023/09/16 20:33:03 - INFO - root -   Epoch: [29/400][160/346], lr: 0.00000014 	 loss = 0.2558(0.6451)
2023/09/16 20:33:45 - INFO - root -   Epoch: [29/400][180/346], lr: 0.00000014 	 loss = 0.7441(0.6468)
2023/09/16 20:34:46 - INFO - root -   Epoch: [29/400][200/346], lr: 0.00000014 	 loss = 0.1521(0.6467)
2023/09/16 20:35:29 - INFO - root -   Epoch: [29/400][220/346], lr: 0.00000014 	 loss = 0.2155(0.6487)
2023/09/16 20:36:29 - INFO - root -   Epoch: [29/400][240/346], lr: 0.00000014 	 loss = 0.5764(0.6540)
2023/09/16 20:37:13 - INFO - root -   Epoch: [29/400][260/346], lr: 0.00000014 	 loss = 1.0247(0.6488)
2023/09/16 20:38:13 - INFO - root -   Epoch: [29/400][280/346], lr: 0.00000014 	 loss = 0.4468(0.6596)
2023/09/16 20:38:56 - INFO - root -   Epoch: [29/400][300/346], lr: 0.00000014 	 loss = 0.3070(0.6645)
2023/09/16 20:39:57 - INFO - root -   Epoch: [29/400][320/346], lr: 0.00000014 	 loss = 0.2051(0.6570)
2023/09/16 20:40:39 - INFO - root -   Epoch: [29/400][340/346], lr: 0.00000014 	 loss = 1.1086(0.6530)
2023/09/16 20:40:43 - INFO - root -   Epoch: [29/400] 	 loss = 0.6507
2023/09/16 20:44:31 - INFO - root -   precision = 0.6724
2023/09/16 20:44:31 - INFO - root -   eval_loss = 0.6293
2023/09/16 20:44:32 - INFO - root -   train_accuracy = 0.6387
2023/09/16 20:44:54 - INFO - root -   Epoch: [30/400][0/346], lr: 0.00000014 	 loss = 0.3057(0.3057)
2023/09/16 20:45:37 - INFO - root -   Epoch: [30/400][20/346], lr: 0.00000014 	 loss = 0.5064(0.4429)
2023/09/16 20:46:38 - INFO - root -   Epoch: [30/400][40/346], lr: 0.00000014 	 loss = 0.7555(0.5614)
2023/09/16 20:47:21 - INFO - root -   Epoch: [30/400][60/346], lr: 0.00000014 	 loss = 0.5691(0.5340)
2023/09/16 20:48:21 - INFO - root -   Epoch: [30/400][80/346], lr: 0.00000014 	 loss = 0.2906(0.5788)
2023/09/16 20:49:04 - INFO - root -   Epoch: [30/400][100/346], lr: 0.00000014 	 loss = 0.3451(0.5909)
2023/09/16 20:50:05 - INFO - root -   Epoch: [30/400][120/346], lr: 0.00000014 	 loss = 0.3971(0.6333)
2023/09/16 20:50:48 - INFO - root -   Epoch: [30/400][140/346], lr: 0.00000014 	 loss = 0.6524(0.6223)
2023/09/16 20:51:48 - INFO - root -   Epoch: [30/400][160/346], lr: 0.00000014 	 loss = 0.3258(0.6299)
2023/09/16 20:52:31 - INFO - root -   Epoch: [30/400][180/346], lr: 0.00000014 	 loss = 0.6791(0.6429)
2023/09/16 20:53:31 - INFO - root -   Epoch: [30/400][200/346], lr: 0.00000014 	 loss = 0.2677(0.6489)
2023/09/16 20:54:15 - INFO - root -   Epoch: [30/400][220/346], lr: 0.00000014 	 loss = 0.3294(0.6437)
2023/09/16 20:55:15 - INFO - root -   Epoch: [30/400][240/346], lr: 0.00000014 	 loss = 0.2731(0.6438)
2023/09/16 20:55:58 - INFO - root -   Epoch: [30/400][260/346], lr: 0.00000014 	 loss = 1.2535(0.6465)
2023/09/16 20:56:58 - INFO - root -   Epoch: [30/400][280/346], lr: 0.00000014 	 loss = 0.3293(0.6558)
2023/09/16 20:57:42 - INFO - root -   Epoch: [30/400][300/346], lr: 0.00000014 	 loss = 0.4793(0.6559)
2023/09/16 20:58:41 - INFO - root -   Epoch: [30/400][320/346], lr: 0.00000014 	 loss = 0.5391(0.6499)
2023/09/16 20:59:24 - INFO - root -   Epoch: [30/400][340/346], lr: 0.00000014 	 loss = 1.3092(0.6481)
2023/09/16 20:59:28 - INFO - root -   Epoch: [30/400] 	 loss = 0.6439
2023/09/16 20:59:28 - INFO - root -   train_accuracy = 0.6358
2023/09/16 20:59:49 - INFO - root -   Epoch: [31/400][0/346], lr: 0.00000014 	 loss = 0.3126(0.3126)
2023/09/16 21:00:33 - INFO - root -   Epoch: [31/400][20/346], lr: 0.00000014 	 loss = 0.4474(0.5515)
2023/09/16 21:01:33 - INFO - root -   Epoch: [31/400][40/346], lr: 0.00000014 	 loss = 0.4690(0.6090)
2023/09/16 21:02:16 - INFO - root -   Epoch: [31/400][60/346], lr: 0.00000014 	 loss = 0.3801(0.5860)
2023/09/16 21:03:17 - INFO - root -   Epoch: [31/400][80/346], lr: 0.00000014 	 loss = 0.3390(0.5933)
2023/09/16 21:04:00 - INFO - root -   Epoch: [31/400][100/346], lr: 0.00000014 	 loss = 0.2153(0.6112)
2023/09/16 21:05:01 - INFO - root -   Epoch: [31/400][120/346], lr: 0.00000014 	 loss = 0.6294(0.6191)
2023/09/16 21:05:44 - INFO - root -   Epoch: [31/400][140/346], lr: 0.00000014 	 loss = 0.5724(0.6173)
2023/09/16 21:06:45 - INFO - root -   Epoch: [31/400][160/346], lr: 0.00000014 	 loss = 0.2538(0.6219)
2023/09/16 21:07:28 - INFO - root -   Epoch: [31/400][180/346], lr: 0.00000014 	 loss = 0.9006(0.6262)
2023/09/16 21:08:29 - INFO - root -   Epoch: [31/400][200/346], lr: 0.00000014 	 loss = 0.3855(0.6254)
2023/09/16 21:09:12 - INFO - root -   Epoch: [31/400][220/346], lr: 0.00000014 	 loss = 0.3045(0.6289)
2023/09/16 21:10:12 - INFO - root -   Epoch: [31/400][240/346], lr: 0.00000014 	 loss = 0.6926(0.6340)
2023/09/16 21:10:55 - INFO - root -   Epoch: [31/400][260/346], lr: 0.00000014 	 loss = 1.1366(0.6337)
2023/09/16 21:11:56 - INFO - root -   Epoch: [31/400][280/346], lr: 0.00000014 	 loss = 0.3523(0.6387)
2023/09/16 21:12:39 - INFO - root -   Epoch: [31/400][300/346], lr: 0.00000014 	 loss = 0.2282(0.6358)
2023/09/16 21:13:40 - INFO - root -   Epoch: [31/400][320/346], lr: 0.00000014 	 loss = 0.2669(0.6325)
2023/09/16 21:14:21 - INFO - root -   Epoch: [31/400][340/346], lr: 0.00000014 	 loss = 0.8519(0.6301)
2023/09/16 21:14:25 - INFO - root -   Epoch: [31/400] 	 loss = 0.6283
2023/09/16 21:14:25 - INFO - root -   train_accuracy = 0.6373
2023/09/16 21:14:47 - INFO - root -   Epoch: [32/400][0/346], lr: 0.00000015 	 loss = 0.1347(0.1347)
2023/09/16 21:15:30 - INFO - root -   Epoch: [32/400][20/346], lr: 0.00000015 	 loss = 0.5738(0.4578)
2023/09/16 21:16:31 - INFO - root -   Epoch: [32/400][40/346], lr: 0.00000015 	 loss = 0.8575(0.5337)
2023/09/16 21:17:15 - INFO - root -   Epoch: [32/400][60/346], lr: 0.00000015 	 loss = 0.6624(0.5432)
2023/09/16 21:18:16 - INFO - root -   Epoch: [32/400][80/346], lr: 0.00000015 	 loss = 0.3665(0.5785)
2023/09/16 21:18:59 - INFO - root -   Epoch: [32/400][100/346], lr: 0.00000015 	 loss = 0.7162(0.6158)
2023/09/16 21:20:00 - INFO - root -   Epoch: [32/400][120/346], lr: 0.00000015 	 loss = 0.3970(0.6428)
2023/09/16 21:20:44 - INFO - root -   Epoch: [32/400][140/346], lr: 0.00000015 	 loss = 0.4360(0.6396)
2023/09/16 21:21:44 - INFO - root -   Epoch: [32/400][160/346], lr: 0.00000015 	 loss = 0.7496(0.6496)
2023/09/16 21:22:28 - INFO - root -   Epoch: [32/400][180/346], lr: 0.00000015 	 loss = 0.5101(0.6445)
2023/09/16 21:23:29 - INFO - root -   Epoch: [32/400][200/346], lr: 0.00000015 	 loss = 0.2292(0.6450)
2023/09/16 21:24:12 - INFO - root -   Epoch: [32/400][220/346], lr: 0.00000015 	 loss = 0.2174(0.6540)
2023/09/16 21:25:13 - INFO - root -   Epoch: [32/400][240/346], lr: 0.00000015 	 loss = 0.4962(0.6560)
2023/09/16 21:25:56 - INFO - root -   Epoch: [32/400][260/346], lr: 0.00000015 	 loss = 0.6918(0.6541)
2023/09/16 21:26:57 - INFO - root -   Epoch: [32/400][280/346], lr: 0.00000015 	 loss = 0.3295(0.6627)
2023/09/16 21:27:40 - INFO - root -   Epoch: [32/400][300/346], lr: 0.00000015 	 loss = 0.2761(0.6644)
2023/09/16 21:28:41 - INFO - root -   Epoch: [32/400][320/346], lr: 0.00000015 	 loss = 0.4734(0.6638)
2023/09/16 21:29:23 - INFO - root -   Epoch: [32/400][340/346], lr: 0.00000015 	 loss = 0.9379(0.6665)
2023/09/16 21:29:27 - INFO - root -   Epoch: [32/400] 	 loss = 0.6660
2023/09/16 21:29:27 - INFO - root -   train_accuracy = 0.6358
2023/09/16 21:29:49 - INFO - root -   Epoch: [33/400][0/346], lr: 0.00000015 	 loss = 0.6650(0.6650)
2023/09/16 21:30:32 - INFO - root -   Epoch: [33/400][20/346], lr: 0.00000015 	 loss = 0.5924(0.5533)
2023/09/16 21:31:33 - INFO - root -   Epoch: [33/400][40/346], lr: 0.00000015 	 loss = 0.4025(0.6327)
2023/09/16 21:32:16 - INFO - root -   Epoch: [33/400][60/346], lr: 0.00000015 	 loss = 0.7185(0.6024)
2023/09/16 21:33:17 - INFO - root -   Epoch: [33/400][80/346], lr: 0.00000015 	 loss = 0.5346(0.6039)
2023/09/16 21:34:01 - INFO - root -   Epoch: [33/400][100/346], lr: 0.00000015 	 loss = 0.4785(0.6126)
2023/09/16 21:35:02 - INFO - root -   Epoch: [33/400][120/346], lr: 0.00000015 	 loss = 0.6923(0.6356)
2023/09/16 21:35:45 - INFO - root -   Epoch: [33/400][140/346], lr: 0.00000015 	 loss = 0.8175(0.6389)
2023/09/16 21:36:46 - INFO - root -   Epoch: [33/400][160/346], lr: 0.00000015 	 loss = 0.2430(0.6400)
2023/09/16 21:37:29 - INFO - root -   Epoch: [33/400][180/346], lr: 0.00000015 	 loss = 0.9729(0.6412)
2023/09/16 21:38:30 - INFO - root -   Epoch: [33/400][200/346], lr: 0.00000015 	 loss = 0.1079(0.6318)
2023/09/16 21:39:13 - INFO - root -   Epoch: [33/400][220/346], lr: 0.00000015 	 loss = 0.2875(0.6330)
2023/09/16 21:40:14 - INFO - root -   Epoch: [33/400][240/346], lr: 0.00000015 	 loss = 0.3860(0.6320)
2023/09/16 21:40:58 - INFO - root -   Epoch: [33/400][260/346], lr: 0.00000015 	 loss = 0.8944(0.6284)
2023/09/16 21:41:58 - INFO - root -   Epoch: [33/400][280/346], lr: 0.00000015 	 loss = 0.4629(0.6455)
2023/09/16 21:42:42 - INFO - root -   Epoch: [33/400][300/346], lr: 0.00000015 	 loss = 0.4735(0.6455)
2023/09/16 21:43:42 - INFO - root -   Epoch: [33/400][320/346], lr: 0.00000015 	 loss = 0.7483(0.6507)
2023/09/16 21:44:24 - INFO - root -   Epoch: [33/400][340/346], lr: 0.00000015 	 loss = 1.0466(0.6528)
2023/09/16 21:44:28 - INFO - root -   Epoch: [33/400] 	 loss = 0.6509
2023/09/16 21:44:28 - INFO - root -   train_accuracy = 0.6431
2023/09/16 21:44:50 - INFO - root -   Epoch: [34/400][0/346], lr: 0.00000015 	 loss = 0.1532(0.1532)
2023/09/16 21:45:33 - INFO - root -   Epoch: [34/400][20/346], lr: 0.00000015 	 loss = 0.9041(0.5570)
2023/09/16 21:46:34 - INFO - root -   Epoch: [34/400][40/346], lr: 0.00000015 	 loss = 0.6623(0.5786)
2023/09/16 21:47:18 - INFO - root -   Epoch: [34/400][60/346], lr: 0.00000015 	 loss = 0.7231(0.5818)
2023/09/16 21:48:19 - INFO - root -   Epoch: [34/400][80/346], lr: 0.00000015 	 loss = 0.4877(0.6034)
2023/09/16 21:49:03 - INFO - root -   Epoch: [34/400][100/346], lr: 0.00000015 	 loss = 0.5970(0.6005)
2023/09/16 21:50:04 - INFO - root -   Epoch: [34/400][120/346], lr: 0.00000015 	 loss = 0.3621(0.6223)
2023/09/16 21:50:48 - INFO - root -   Epoch: [34/400][140/346], lr: 0.00000015 	 loss = 0.4685(0.6121)
2023/09/16 21:51:49 - INFO - root -   Epoch: [34/400][160/346], lr: 0.00000015 	 loss = 0.3566(0.6154)
2023/09/16 21:52:33 - INFO - root -   Epoch: [34/400][180/346], lr: 0.00000015 	 loss = 0.5200(0.6143)
2023/09/16 21:53:34 - INFO - root -   Epoch: [34/400][200/346], lr: 0.00000015 	 loss = 0.1765(0.6103)
2023/09/16 21:54:18 - INFO - root -   Epoch: [34/400][220/346], lr: 0.00000015 	 loss = 0.6785(0.6166)
2023/09/16 21:55:19 - INFO - root -   Epoch: [34/400][240/346], lr: 0.00000015 	 loss = 0.5740(0.6272)
2023/09/16 21:56:02 - INFO - root -   Epoch: [34/400][260/346], lr: 0.00000015 	 loss = 1.1222(0.6318)
2023/09/16 21:57:03 - INFO - root -   Epoch: [34/400][280/346], lr: 0.00000015 	 loss = 0.6836(0.6455)
2023/09/16 21:57:47 - INFO - root -   Epoch: [34/400][300/346], lr: 0.00000015 	 loss = 0.4560(0.6509)
2023/09/16 21:58:48 - INFO - root -   Epoch: [34/400][320/346], lr: 0.00000015 	 loss = 0.2600(0.6411)
2023/09/16 21:59:30 - INFO - root -   Epoch: [34/400][340/346], lr: 0.00000015 	 loss = 1.2297(0.6416)
2023/09/16 21:59:34 - INFO - root -   Epoch: [34/400] 	 loss = 0.6412
2023/09/16 22:03:23 - INFO - root -   precision = 0.6437
2023/09/16 22:03:23 - INFO - root -   eval_loss = 0.6214
2023/09/16 22:03:24 - INFO - root -   train_accuracy = 0.6329
2023/09/16 22:03:45 - INFO - root -   Epoch: [35/400][0/346], lr: 0.00000015 	 loss = 0.4878(0.4878)
2023/09/16 22:04:28 - INFO - root -   Epoch: [35/400][20/346], lr: 0.00000015 	 loss = 0.6834(0.5605)
2023/09/16 22:05:29 - INFO - root -   Epoch: [35/400][40/346], lr: 0.00000015 	 loss = 0.7516(0.6157)
2023/09/16 22:06:12 - INFO - root -   Epoch: [35/400][60/346], lr: 0.00000015 	 loss = 0.8428(0.5665)
2023/09/16 22:07:12 - INFO - root -   Epoch: [35/400][80/346], lr: 0.00000015 	 loss = 0.5796(0.5762)
2023/09/16 22:07:55 - INFO - root -   Epoch: [35/400][100/346], lr: 0.00000015 	 loss = 0.4892(0.5978)
2023/09/16 22:08:55 - INFO - root -   Epoch: [35/400][120/346], lr: 0.00000015 	 loss = 0.3164(0.6126)
2023/09/16 22:09:38 - INFO - root -   Epoch: [35/400][140/346], lr: 0.00000015 	 loss = 1.0112(0.6001)
2023/09/16 22:10:38 - INFO - root -   Epoch: [35/400][160/346], lr: 0.00000015 	 loss = 0.1655(0.6134)
2023/09/16 22:11:22 - INFO - root -   Epoch: [35/400][180/346], lr: 0.00000015 	 loss = 0.5370(0.6031)
2023/09/16 22:12:21 - INFO - root -   Epoch: [35/400][200/346], lr: 0.00000015 	 loss = 0.1734(0.5920)
2023/09/16 22:13:05 - INFO - root -   Epoch: [35/400][220/346], lr: 0.00000015 	 loss = 0.2747(0.5873)
2023/09/16 22:14:04 - INFO - root -   Epoch: [35/400][240/346], lr: 0.00000015 	 loss = 0.2933(0.5958)
2023/09/16 22:14:48 - INFO - root -   Epoch: [35/400][260/346], lr: 0.00000015 	 loss = 0.4665(0.5991)
2023/09/16 22:15:47 - INFO - root -   Epoch: [35/400][280/346], lr: 0.00000015 	 loss = 0.2838(0.6239)
2023/09/16 22:16:31 - INFO - root -   Epoch: [35/400][300/346], lr: 0.00000015 	 loss = 0.4103(0.6263)
2023/09/16 22:17:30 - INFO - root -   Epoch: [35/400][320/346], lr: 0.00000015 	 loss = 0.5651(0.6213)
2023/09/16 22:18:13 - INFO - root -   Epoch: [35/400][340/346], lr: 0.00000015 	 loss = 0.6576(0.6283)
2023/09/16 22:18:17 - INFO - root -   Epoch: [35/400] 	 loss = 0.6287
2023/09/16 22:18:17 - INFO - root -   train_accuracy = 0.6561
2023/09/16 22:18:39 - INFO - root -   Epoch: [36/400][0/346], lr: 0.00000015 	 loss = 0.2463(0.2463)
2023/09/16 22:19:22 - INFO - root -   Epoch: [36/400][20/346], lr: 0.00000015 	 loss = 0.8210(0.5892)
2023/09/16 22:20:23 - INFO - root -   Epoch: [36/400][40/346], lr: 0.00000015 	 loss = 0.6026(0.6415)
2023/09/16 22:21:06 - INFO - root -   Epoch: [36/400][60/346], lr: 0.00000015 	 loss = 0.6656(0.6070)
2023/09/16 22:22:07 - INFO - root -   Epoch: [36/400][80/346], lr: 0.00000015 	 loss = 0.3427(0.6078)
2023/09/16 22:22:49 - INFO - root -   Epoch: [36/400][100/346], lr: 0.00000015 	 loss = 0.3132(0.6202)
2023/09/16 22:23:50 - INFO - root -   Epoch: [36/400][120/346], lr: 0.00000015 	 loss = 0.2940(0.6258)
2023/09/16 22:24:33 - INFO - root -   Epoch: [36/400][140/346], lr: 0.00000015 	 loss = 0.4754(0.6344)
2023/09/16 22:25:33 - INFO - root -   Epoch: [36/400][160/346], lr: 0.00000015 	 loss = 0.1839(0.6503)
2023/09/16 22:26:16 - INFO - root -   Epoch: [36/400][180/346], lr: 0.00000015 	 loss = 0.8692(0.6445)
2023/09/16 22:27:17 - INFO - root -   Epoch: [36/400][200/346], lr: 0.00000015 	 loss = 0.2247(0.6414)
2023/09/16 22:28:00 - INFO - root -   Epoch: [36/400][220/346], lr: 0.00000015 	 loss = 0.5851(0.6386)
2023/09/16 22:29:01 - INFO - root -   Epoch: [36/400][240/346], lr: 0.00000015 	 loss = 0.7547(0.6363)
2023/09/16 22:29:44 - INFO - root -   Epoch: [36/400][260/346], lr: 0.00000015 	 loss = 0.9514(0.6298)
2023/09/16 22:30:44 - INFO - root -   Epoch: [36/400][280/346], lr: 0.00000015 	 loss = 0.4189(0.6355)
2023/09/16 22:31:27 - INFO - root -   Epoch: [36/400][300/346], lr: 0.00000015 	 loss = 0.4222(0.6423)
2023/09/16 22:32:28 - INFO - root -   Epoch: [36/400][320/346], lr: 0.00000015 	 loss = 0.6871(0.6441)
2023/09/16 22:33:09 - INFO - root -   Epoch: [36/400][340/346], lr: 0.00000015 	 loss = 1.7056(0.6422)
2023/09/16 22:33:13 - INFO - root -   Epoch: [36/400] 	 loss = 0.6390
2023/09/16 22:33:13 - INFO - root -   train_accuracy = 0.6460
2023/09/16 22:33:35 - INFO - root -   Epoch: [37/400][0/346], lr: 0.00000015 	 loss = 0.3647(0.3647)
2023/09/16 22:34:17 - INFO - root -   Epoch: [37/400][20/346], lr: 0.00000015 	 loss = 0.6630(0.5233)
2023/09/16 22:35:18 - INFO - root -   Epoch: [37/400][40/346], lr: 0.00000015 	 loss = 0.1753(0.5789)
2023/09/16 22:36:01 - INFO - root -   Epoch: [37/400][60/346], lr: 0.00000015 	 loss = 0.6054(0.5593)
2023/09/16 22:37:02 - INFO - root -   Epoch: [37/400][80/346], lr: 0.00000015 	 loss = 0.3325(0.5836)
2023/09/16 22:37:45 - INFO - root -   Epoch: [37/400][100/346], lr: 0.00000015 	 loss = 0.4403(0.5799)
2023/09/16 22:38:46 - INFO - root -   Epoch: [37/400][120/346], lr: 0.00000015 	 loss = 0.7238(0.6196)
2023/09/16 22:39:29 - INFO - root -   Epoch: [37/400][140/346], lr: 0.00000015 	 loss = 0.9307(0.6094)
2023/09/16 22:40:29 - INFO - root -   Epoch: [37/400][160/346], lr: 0.00000015 	 loss = 0.3150(0.6251)
2023/09/16 22:41:12 - INFO - root -   Epoch: [37/400][180/346], lr: 0.00000015 	 loss = 0.3264(0.6228)
2023/09/16 22:42:12 - INFO - root -   Epoch: [37/400][200/346], lr: 0.00000015 	 loss = 0.1782(0.6172)
2023/09/16 22:42:55 - INFO - root -   Epoch: [37/400][220/346], lr: 0.00000015 	 loss = 0.2102(0.6204)
2023/09/16 22:43:56 - INFO - root -   Epoch: [37/400][240/346], lr: 0.00000015 	 loss = 0.3776(0.6141)
2023/09/16 22:44:39 - INFO - root -   Epoch: [37/400][260/346], lr: 0.00000015 	 loss = 0.5390(0.6119)
2023/09/16 22:45:39 - INFO - root -   Epoch: [37/400][280/346], lr: 0.00000015 	 loss = 0.1436(0.6248)
2023/09/16 22:46:22 - INFO - root -   Epoch: [37/400][300/346], lr: 0.00000015 	 loss = 0.7216(0.6200)
2023/09/16 22:47:22 - INFO - root -   Epoch: [37/400][320/346], lr: 0.00000015 	 loss = 0.3220(0.6181)
2023/09/16 22:48:05 - INFO - root -   Epoch: [37/400][340/346], lr: 0.00000015 	 loss = 1.3909(0.6136)
2023/09/16 22:48:09 - INFO - root -   Epoch: [37/400] 	 loss = 0.6120
2023/09/16 22:48:09 - INFO - root -   train_accuracy = 0.6749
2023/09/16 22:48:31 - INFO - root -   Epoch: [38/400][0/346], lr: 0.00000015 	 loss = 0.5559(0.5559)
2023/09/16 22:49:15 - INFO - root -   Epoch: [38/400][20/346], lr: 0.00000015 	 loss = 0.3937(0.5508)
2023/09/16 22:50:17 - INFO - root -   Epoch: [38/400][40/346], lr: 0.00000015 	 loss = 0.6882(0.6391)
2023/09/16 22:51:01 - INFO - root -   Epoch: [38/400][60/346], lr: 0.00000015 	 loss = 0.9893(0.6047)
2023/09/16 22:52:02 - INFO - root -   Epoch: [38/400][80/346], lr: 0.00000015 	 loss = 0.7294(0.5898)
2023/09/16 22:52:46 - INFO - root -   Epoch: [38/400][100/346], lr: 0.00000015 	 loss = 0.2765(0.6132)
2023/09/16 22:53:48 - INFO - root -   Epoch: [38/400][120/346], lr: 0.00000015 	 loss = 0.3543(0.6295)
2023/09/16 22:54:31 - INFO - root -   Epoch: [38/400][140/346], lr: 0.00000015 	 loss = 0.8257(0.6184)
2023/09/16 22:55:33 - INFO - root -   Epoch: [38/400][160/346], lr: 0.00000015 	 loss = 0.3997(0.6233)
2023/09/16 22:56:17 - INFO - root -   Epoch: [38/400][180/346], lr: 0.00000015 	 loss = 0.6815(0.6297)
2023/09/16 22:57:19 - INFO - root -   Epoch: [38/400][200/346], lr: 0.00000015 	 loss = 0.2659(0.6226)
2023/09/16 22:58:02 - INFO - root -   Epoch: [38/400][220/346], lr: 0.00000015 	 loss = 0.3318(0.6187)
2023/09/16 22:59:04 - INFO - root -   Epoch: [38/400][240/346], lr: 0.00000015 	 loss = 0.4580(0.6200)
2023/09/16 22:59:48 - INFO - root -   Epoch: [38/400][260/346], lr: 0.00000015 	 loss = 1.0577(0.6224)
2023/09/16 23:00:49 - INFO - root -   Epoch: [38/400][280/346], lr: 0.00000015 	 loss = 0.4418(0.6411)
2023/09/16 23:01:33 - INFO - root -   Epoch: [38/400][300/346], lr: 0.00000015 	 loss = 0.5307(0.6445)
2023/09/16 23:02:34 - INFO - root -   Epoch: [38/400][320/346], lr: 0.00000015 	 loss = 0.2824(0.6426)
2023/09/16 23:03:14 - INFO - root -   Epoch: [38/400][340/346], lr: 0.00000015 	 loss = 0.9526(0.6389)
2023/09/16 23:03:19 - INFO - root -   Epoch: [38/400] 	 loss = 0.6367
2023/09/16 23:03:19 - INFO - root -   train_accuracy = 0.6344
2023/09/16 23:03:40 - INFO - root -   Epoch: [39/400][0/346], lr: 0.00000016 	 loss = 0.2955(0.2955)
2023/09/16 23:04:23 - INFO - root -   Epoch: [39/400][20/346], lr: 0.00000016 	 loss = 0.3331(0.5261)
2023/09/16 23:05:24 - INFO - root -   Epoch: [39/400][40/346], lr: 0.00000016 	 loss = 0.4233(0.5599)
2023/09/16 23:06:07 - INFO - root -   Epoch: [39/400][60/346], lr: 0.00000016 	 loss = 0.7571(0.5467)
2023/09/16 23:07:08 - INFO - root -   Epoch: [39/400][80/346], lr: 0.00000016 	 loss = 0.5503(0.5746)
2023/09/16 23:07:51 - INFO - root -   Epoch: [39/400][100/346], lr: 0.00000016 	 loss = 0.5047(0.5726)
2023/09/16 23:08:51 - INFO - root -   Epoch: [39/400][120/346], lr: 0.00000016 	 loss = 0.3899(0.6191)
2023/09/16 23:09:34 - INFO - root -   Epoch: [39/400][140/346], lr: 0.00000016 	 loss = 0.5765(0.6209)
2023/09/16 23:10:35 - INFO - root -   Epoch: [39/400][160/346], lr: 0.00000016 	 loss = 0.2808(0.6277)
2023/09/16 23:11:17 - INFO - root -   Epoch: [39/400][180/346], lr: 0.00000016 	 loss = 0.7525(0.6257)
2023/09/16 23:12:18 - INFO - root -   Epoch: [39/400][200/346], lr: 0.00000016 	 loss = 0.2524(0.6235)
2023/09/16 23:13:01 - INFO - root -   Epoch: [39/400][220/346], lr: 0.00000016 	 loss = 0.4302(0.6308)
2023/09/16 23:14:01 - INFO - root -   Epoch: [39/400][240/346], lr: 0.00000016 	 loss = 0.4011(0.6338)
2023/09/16 23:14:44 - INFO - root -   Epoch: [39/400][260/346], lr: 0.00000016 	 loss = 0.5330(0.6284)
2023/09/16 23:15:44 - INFO - root -   Epoch: [39/400][280/346], lr: 0.00000016 	 loss = 0.1681(0.6397)
2023/09/16 23:16:28 - INFO - root -   Epoch: [39/400][300/346], lr: 0.00000016 	 loss = 0.2489(0.6370)
2023/09/16 23:17:28 - INFO - root -   Epoch: [39/400][320/346], lr: 0.00000016 	 loss = 0.2839(0.6329)
2023/09/16 23:18:10 - INFO - root -   Epoch: [39/400][340/346], lr: 0.00000016 	 loss = 1.1384(0.6349)
2023/09/16 23:18:14 - INFO - root -   Epoch: [39/400] 	 loss = 0.6325
2023/09/16 23:22:00 - INFO - root -   precision = 0.6552
2023/09/16 23:22:00 - INFO - root -   eval_loss = 0.6159
2023/09/16 23:22:02 - INFO - root -   train_accuracy = 0.6647
2023/09/16 23:22:24 - INFO - root -   Epoch: [40/400][0/346], lr: 0.00000016 	 loss = 0.1986(0.1986)
2023/09/16 23:23:07 - INFO - root -   Epoch: [40/400][20/346], lr: 0.00000016 	 loss = 0.3546(0.5439)
2023/09/16 23:24:08 - INFO - root -   Epoch: [40/400][40/346], lr: 0.00000016 	 loss = 0.1684(0.5621)
2023/09/16 23:24:51 - INFO - root -   Epoch: [40/400][60/346], lr: 0.00000016 	 loss = 0.8184(0.5367)
2023/09/16 23:25:52 - INFO - root -   Epoch: [40/400][80/346], lr: 0.00000016 	 loss = 0.4972(0.5584)
2023/09/16 23:26:35 - INFO - root -   Epoch: [40/400][100/346], lr: 0.00000016 	 loss = 0.7143(0.5842)
2023/09/16 23:27:35 - INFO - root -   Epoch: [40/400][120/346], lr: 0.00000016 	 loss = 0.5599(0.6192)
2023/09/16 23:28:18 - INFO - root -   Epoch: [40/400][140/346], lr: 0.00000016 	 loss = 0.5643(0.6167)
2023/09/16 23:29:19 - INFO - root -   Epoch: [40/400][160/346], lr: 0.00000016 	 loss = 0.3574(0.6260)
2023/09/16 23:30:01 - INFO - root -   Epoch: [40/400][180/346], lr: 0.00000016 	 loss = 0.8247(0.6364)
2023/09/16 23:31:02 - INFO - root -   Epoch: [40/400][200/346], lr: 0.00000016 	 loss = 0.1551(0.6217)
2023/09/16 23:31:45 - INFO - root -   Epoch: [40/400][220/346], lr: 0.00000016 	 loss = 0.4555(0.6231)
2023/09/16 23:32:46 - INFO - root -   Epoch: [40/400][240/346], lr: 0.00000016 	 loss = 0.4919(0.6150)
2023/09/16 23:33:29 - INFO - root -   Epoch: [40/400][260/346], lr: 0.00000016 	 loss = 0.6341(0.6090)
2023/09/16 23:34:30 - INFO - root -   Epoch: [40/400][280/346], lr: 0.00000016 	 loss = 0.5814(0.6198)
2023/09/16 23:35:13 - INFO - root -   Epoch: [40/400][300/346], lr: 0.00000016 	 loss = 0.3520(0.6210)
2023/09/16 23:36:13 - INFO - root -   Epoch: [40/400][320/346], lr: 0.00000016 	 loss = 0.3967(0.6239)
2023/09/16 23:36:55 - INFO - root -   Epoch: [40/400][340/346], lr: 0.00000016 	 loss = 0.9457(0.6247)
2023/09/16 23:36:59 - INFO - root -   Epoch: [40/400] 	 loss = 0.6231
2023/09/16 23:36:59 - INFO - root -   train_accuracy = 0.6590
2023/09/16 23:37:21 - INFO - root -   Epoch: [41/400][0/346], lr: 0.00000016 	 loss = 0.3094(0.3094)
2023/09/16 23:38:04 - INFO - root -   Epoch: [41/400][20/346], lr: 0.00000016 	 loss = 0.4479(0.4978)
2023/09/16 23:39:05 - INFO - root -   Epoch: [41/400][40/346], lr: 0.00000016 	 loss = 0.3115(0.5273)
2023/09/16 23:39:48 - INFO - root -   Epoch: [41/400][60/346], lr: 0.00000016 	 loss = 0.4298(0.5023)
2023/09/16 23:40:48 - INFO - root -   Epoch: [41/400][80/346], lr: 0.00000016 	 loss = 1.2295(0.5341)
2023/09/16 23:41:31 - INFO - root -   Epoch: [41/400][100/346], lr: 0.00000016 	 loss = 0.4048(0.5393)
2023/09/16 23:42:32 - INFO - root -   Epoch: [41/400][120/346], lr: 0.00000016 	 loss = 0.3724(0.5838)
2023/09/16 23:43:15 - INFO - root -   Epoch: [41/400][140/346], lr: 0.00000016 	 loss = 0.5794(0.5783)
2023/09/16 23:44:16 - INFO - root -   Epoch: [41/400][160/346], lr: 0.00000016 	 loss = 0.2806(0.5965)
2023/09/16 23:44:59 - INFO - root -   Epoch: [41/400][180/346], lr: 0.00000016 	 loss = 0.4518(0.6083)
2023/09/16 23:45:59 - INFO - root -   Epoch: [41/400][200/346], lr: 0.00000016 	 loss = 0.2856(0.5980)
2023/09/16 23:46:42 - INFO - root -   Epoch: [41/400][220/346], lr: 0.00000016 	 loss = 0.5001(0.5968)
2023/09/16 23:47:43 - INFO - root -   Epoch: [41/400][240/346], lr: 0.00000016 	 loss = 0.3330(0.6007)
2023/09/16 23:48:26 - INFO - root -   Epoch: [41/400][260/346], lr: 0.00000016 	 loss = 0.6579(0.5991)
2023/09/16 23:49:27 - INFO - root -   Epoch: [41/400][280/346], lr: 0.00000016 	 loss = 0.3886(0.6125)
2023/09/16 23:50:10 - INFO - root -   Epoch: [41/400][300/346], lr: 0.00000016 	 loss = 0.3649(0.6148)
2023/09/16 23:51:10 - INFO - root -   Epoch: [41/400][320/346], lr: 0.00000016 	 loss = 0.2998(0.6175)
2023/09/16 23:51:52 - INFO - root -   Epoch: [41/400][340/346], lr: 0.00000016 	 loss = 1.0574(0.6167)
2023/09/16 23:51:56 - INFO - root -   Epoch: [41/400] 	 loss = 0.6145
2023/09/16 23:51:56 - INFO - root -   train_accuracy = 0.6806
2023/09/16 23:52:18 - INFO - root -   Epoch: [42/400][0/346], lr: 0.00000016 	 loss = 0.0982(0.0982)
2023/09/16 23:53:01 - INFO - root -   Epoch: [42/400][20/346], lr: 0.00000016 	 loss = 0.6261(0.4578)
2023/09/16 23:54:01 - INFO - root -   Epoch: [42/400][40/346], lr: 0.00000016 	 loss = 0.6352(0.5474)
2023/09/16 23:54:44 - INFO - root -   Epoch: [42/400][60/346], lr: 0.00000016 	 loss = 0.7337(0.5435)
2023/09/16 23:55:45 - INFO - root -   Epoch: [42/400][80/346], lr: 0.00000016 	 loss = 0.4685(0.5740)
2023/09/16 23:56:28 - INFO - root -   Epoch: [42/400][100/346], lr: 0.00000016 	 loss = 0.5336(0.5662)
2023/09/16 23:57:28 - INFO - root -   Epoch: [42/400][120/346], lr: 0.00000016 	 loss = 0.4013(0.5888)
2023/09/16 23:58:11 - INFO - root -   Epoch: [42/400][140/346], lr: 0.00000016 	 loss = 0.7376(0.5883)
2023/09/16 23:59:11 - INFO - root -   Epoch: [42/400][160/346], lr: 0.00000016 	 loss = 0.4984(0.6037)
2023/09/16 23:59:55 - INFO - root -   Epoch: [42/400][180/346], lr: 0.00000016 	 loss = 0.9332(0.6079)
2023/09/17 00:00:55 - INFO - root -   Epoch: [42/400][200/346], lr: 0.00000016 	 loss = 0.2692(0.5996)
2023/09/17 00:01:38 - INFO - root -   Epoch: [42/400][220/346], lr: 0.00000016 	 loss = 0.3399(0.6044)
2023/09/17 00:02:38 - INFO - root -   Epoch: [42/400][240/346], lr: 0.00000016 	 loss = 0.4463(0.6054)
2023/09/17 00:03:21 - INFO - root -   Epoch: [42/400][260/346], lr: 0.00000016 	 loss = 1.1154(0.6134)
2023/09/17 00:04:21 - INFO - root -   Epoch: [42/400][280/346], lr: 0.00000016 	 loss = 0.7593(0.6310)
2023/09/17 00:05:05 - INFO - root -   Epoch: [42/400][300/346], lr: 0.00000016 	 loss = 0.2694(0.6296)
2023/09/17 00:06:04 - INFO - root -   Epoch: [42/400][320/346], lr: 0.00000016 	 loss = 0.6219(0.6356)
2023/09/17 00:06:47 - INFO - root -   Epoch: [42/400][340/346], lr: 0.00000016 	 loss = 1.1506(0.6373)
2023/09/17 00:06:51 - INFO - root -   Epoch: [42/400] 	 loss = 0.6361
2023/09/17 00:06:51 - INFO - root -   train_accuracy = 0.6445
2023/09/17 00:07:12 - INFO - root -   Epoch: [43/400][0/346], lr: 0.00000016 	 loss = 0.3089(0.3089)
2023/09/17 00:07:55 - INFO - root -   Epoch: [43/400][20/346], lr: 0.00000016 	 loss = 0.5872(0.5335)
2023/09/17 00:08:56 - INFO - root -   Epoch: [43/400][40/346], lr: 0.00000016 	 loss = 0.4624(0.5760)
2023/09/17 00:09:39 - INFO - root -   Epoch: [43/400][60/346], lr: 0.00000016 	 loss = 1.0535(0.5966)
2023/09/17 00:10:40 - INFO - root -   Epoch: [43/400][80/346], lr: 0.00000016 	 loss = 0.4393(0.6101)
2023/09/17 00:11:23 - INFO - root -   Epoch: [43/400][100/346], lr: 0.00000016 	 loss = 0.5946(0.6274)
2023/09/17 00:12:24 - INFO - root -   Epoch: [43/400][120/346], lr: 0.00000016 	 loss = 0.3759(0.6530)
2023/09/17 00:13:07 - INFO - root -   Epoch: [43/400][140/346], lr: 0.00000016 	 loss = 0.7666(0.6365)
2023/09/17 00:14:07 - INFO - root -   Epoch: [43/400][160/346], lr: 0.00000016 	 loss = 0.1879(0.6295)
2023/09/17 00:14:50 - INFO - root -   Epoch: [43/400][180/346], lr: 0.00000016 	 loss = 0.7921(0.6241)
2023/09/17 00:15:51 - INFO - root -   Epoch: [43/400][200/346], lr: 0.00000016 	 loss = 0.4081(0.6196)
2023/09/17 00:16:34 - INFO - root -   Epoch: [43/400][220/346], lr: 0.00000016 	 loss = 0.5018(0.6202)
2023/09/17 00:17:34 - INFO - root -   Epoch: [43/400][240/346], lr: 0.00000016 	 loss = 0.2518(0.6181)
2023/09/17 00:18:18 - INFO - root -   Epoch: [43/400][260/346], lr: 0.00000016 	 loss = 0.4469(0.6167)
2023/09/17 00:19:18 - INFO - root -   Epoch: [43/400][280/346], lr: 0.00000016 	 loss = 0.3307(0.6319)
2023/09/17 00:20:02 - INFO - root -   Epoch: [43/400][300/346], lr: 0.00000016 	 loss = 0.3662(0.6340)
2023/09/17 00:21:01 - INFO - root -   Epoch: [43/400][320/346], lr: 0.00000016 	 loss = 0.2820(0.6305)
2023/09/17 00:21:44 - INFO - root -   Epoch: [43/400][340/346], lr: 0.00000016 	 loss = 0.6375(0.6324)
2023/09/17 00:21:48 - INFO - root -   Epoch: [43/400] 	 loss = 0.6297
2023/09/17 00:21:48 - INFO - root -   train_accuracy = 0.6329
2023/09/17 00:22:10 - INFO - root -   Epoch: [44/400][0/346], lr: 0.00000016 	 loss = 0.2292(0.2292)
2023/09/17 00:22:53 - INFO - root -   Epoch: [44/400][20/346], lr: 0.00000016 	 loss = 0.3562(0.4701)
2023/09/17 00:23:54 - INFO - root -   Epoch: [44/400][40/346], lr: 0.00000016 	 loss = 0.6052(0.5209)
2023/09/17 00:24:37 - INFO - root -   Epoch: [44/400][60/346], lr: 0.00000016 	 loss = 0.7055(0.5211)
2023/09/17 00:25:38 - INFO - root -   Epoch: [44/400][80/346], lr: 0.00000016 	 loss = 0.8006(0.5642)
2023/09/17 00:26:21 - INFO - root -   Epoch: [44/400][100/346], lr: 0.00000016 	 loss = 0.3055(0.5678)
2023/09/17 00:27:22 - INFO - root -   Epoch: [44/400][120/346], lr: 0.00000016 	 loss = 0.2822(0.5975)
2023/09/17 00:28:06 - INFO - root -   Epoch: [44/400][140/346], lr: 0.00000016 	 loss = 0.4632(0.5934)
2023/09/17 00:29:07 - INFO - root -   Epoch: [44/400][160/346], lr: 0.00000016 	 loss = 0.2979(0.6001)
2023/09/17 00:29:50 - INFO - root -   Epoch: [44/400][180/346], lr: 0.00000016 	 loss = 0.7174(0.6044)
2023/09/17 00:30:51 - INFO - root -   Epoch: [44/400][200/346], lr: 0.00000016 	 loss = 0.3121(0.5936)
2023/09/17 00:31:34 - INFO - root -   Epoch: [44/400][220/346], lr: 0.00000016 	 loss = 0.2434(0.5990)
2023/09/17 00:32:35 - INFO - root -   Epoch: [44/400][240/346], lr: 0.00000016 	 loss = 0.5668(0.6002)
2023/09/17 00:33:18 - INFO - root -   Epoch: [44/400][260/346], lr: 0.00000016 	 loss = 0.8746(0.6019)
2023/09/17 00:34:19 - INFO - root -   Epoch: [44/400][280/346], lr: 0.00000016 	 loss = 0.3950(0.6184)
2023/09/17 00:35:03 - INFO - root -   Epoch: [44/400][300/346], lr: 0.00000016 	 loss = 0.3975(0.6136)
2023/09/17 00:36:04 - INFO - root -   Epoch: [44/400][320/346], lr: 0.00000016 	 loss = 0.3550(0.6179)
2023/09/17 00:36:45 - INFO - root -   Epoch: [44/400][340/346], lr: 0.00000016 	 loss = 0.7268(0.6179)
2023/09/17 00:36:49 - INFO - root -   Epoch: [44/400] 	 loss = 0.6164
2023/09/17 00:40:36 - INFO - root -   precision = 0.6609
2023/09/17 00:40:36 - INFO - root -   eval_loss = 0.6122
2023/09/17 00:40:37 - INFO - root -   train_accuracy = 0.6850
2023/09/17 00:40:58 - INFO - root -   Epoch: [45/400][0/346], lr: 0.00000016 	 loss = 0.3404(0.3404)
2023/09/17 00:41:41 - INFO - root -   Epoch: [45/400][20/346], lr: 0.00000016 	 loss = 0.5636(0.5224)
2023/09/17 00:42:41 - INFO - root -   Epoch: [45/400][40/346], lr: 0.00000016 	 loss = 0.3334(0.5569)
2023/09/17 00:43:24 - INFO - root -   Epoch: [45/400][60/346], lr: 0.00000016 	 loss = 0.6421(0.5568)
2023/09/17 00:44:25 - INFO - root -   Epoch: [45/400][80/346], lr: 0.00000016 	 loss = 0.3908(0.5497)
2023/09/17 00:45:08 - INFO - root -   Epoch: [45/400][100/346], lr: 0.00000016 	 loss = 0.5415(0.5715)
2023/09/17 00:46:08 - INFO - root -   Epoch: [45/400][120/346], lr: 0.00000016 	 loss = 0.2939(0.6031)
2023/09/17 00:46:51 - INFO - root -   Epoch: [45/400][140/346], lr: 0.00000016 	 loss = 0.5600(0.6030)
2023/09/17 00:47:51 - INFO - root -   Epoch: [45/400][160/346], lr: 0.00000016 	 loss = 0.2211(0.6184)
2023/09/17 00:48:34 - INFO - root -   Epoch: [45/400][180/346], lr: 0.00000016 	 loss = 0.4241(0.6140)
2023/09/17 00:49:34 - INFO - root -   Epoch: [45/400][200/346], lr: 0.00000016 	 loss = 0.1465(0.6062)
2023/09/17 00:50:17 - INFO - root -   Epoch: [45/400][220/346], lr: 0.00000016 	 loss = 0.2488(0.6122)
2023/09/17 00:51:17 - INFO - root -   Epoch: [45/400][240/346], lr: 0.00000016 	 loss = 0.5202(0.6131)
2023/09/17 00:52:00 - INFO - root -   Epoch: [45/400][260/346], lr: 0.00000016 	 loss = 0.8511(0.6136)
2023/09/17 00:53:01 - INFO - root -   Epoch: [45/400][280/346], lr: 0.00000016 	 loss = 0.6776(0.6266)
2023/09/17 00:53:44 - INFO - root -   Epoch: [45/400][300/346], lr: 0.00000016 	 loss = 0.2549(0.6284)
2023/09/17 00:54:44 - INFO - root -   Epoch: [45/400][320/346], lr: 0.00000016 	 loss = 0.3182(0.6276)
2023/09/17 00:55:26 - INFO - root -   Epoch: [45/400][340/346], lr: 0.00000016 	 loss = 1.4400(0.6270)
2023/09/17 00:55:30 - INFO - root -   Epoch: [45/400] 	 loss = 0.6254
2023/09/17 00:55:30 - INFO - root -   train_accuracy = 0.6460
2023/09/17 00:55:51 - INFO - root -   Epoch: [46/400][0/346], lr: 0.00000017 	 loss = 0.3034(0.3034)
2023/09/17 00:56:34 - INFO - root -   Epoch: [46/400][20/346], lr: 0.00000017 	 loss = 0.4077(0.5111)
2023/09/17 00:57:35 - INFO - root -   Epoch: [46/400][40/346], lr: 0.00000017 	 loss = 0.3314(0.5266)
2023/09/17 00:58:18 - INFO - root -   Epoch: [46/400][60/346], lr: 0.00000017 	 loss = 0.4726(0.4892)
2023/09/17 00:59:19 - INFO - root -   Epoch: [46/400][80/346], lr: 0.00000017 	 loss = 0.3321(0.5294)
2023/09/17 01:00:02 - INFO - root -   Epoch: [46/400][100/346], lr: 0.00000017 	 loss = 0.3956(0.5370)
2023/09/17 01:01:02 - INFO - root -   Epoch: [46/400][120/346], lr: 0.00000017 	 loss = 0.3605(0.5751)
2023/09/17 01:01:46 - INFO - root -   Epoch: [46/400][140/346], lr: 0.00000017 	 loss = 0.5381(0.5701)
2023/09/17 01:02:46 - INFO - root -   Epoch: [46/400][160/346], lr: 0.00000017 	 loss = 0.1602(0.5838)
2023/09/17 01:03:30 - INFO - root -   Epoch: [46/400][180/346], lr: 0.00000017 	 loss = 0.6857(0.5892)
2023/09/17 01:04:29 - INFO - root -   Epoch: [46/400][200/346], lr: 0.00000017 	 loss = 0.1107(0.5805)
2023/09/17 01:05:13 - INFO - root -   Epoch: [46/400][220/346], lr: 0.00000017 	 loss = 0.2089(0.5808)
2023/09/17 01:06:13 - INFO - root -   Epoch: [46/400][240/346], lr: 0.00000017 	 loss = 0.1465(0.5817)
2023/09/17 01:06:57 - INFO - root -   Epoch: [46/400][260/346], lr: 0.00000017 	 loss = 0.9948(0.5817)
2023/09/17 01:07:56 - INFO - root -   Epoch: [46/400][280/346], lr: 0.00000017 	 loss = 0.4438(0.5882)
2023/09/17 01:08:41 - INFO - root -   Epoch: [46/400][300/346], lr: 0.00000017 	 loss = 0.3710(0.5906)
2023/09/17 01:09:39 - INFO - root -   Epoch: [46/400][320/346], lr: 0.00000017 	 loss = 0.4072(0.5854)
2023/09/17 01:10:23 - INFO - root -   Epoch: [46/400][340/346], lr: 0.00000017 	 loss = 1.3076(0.5902)
2023/09/17 01:10:27 - INFO - root -   Epoch: [46/400] 	 loss = 0.5873
2023/09/17 01:10:27 - INFO - root -   train_accuracy = 0.6951
2023/09/17 01:10:49 - INFO - root -   Epoch: [47/400][0/346], lr: 0.00000017 	 loss = 0.1591(0.1591)
2023/09/17 01:11:31 - INFO - root -   Epoch: [47/400][20/346], lr: 0.00000017 	 loss = 0.4060(0.4650)
2023/09/17 01:12:32 - INFO - root -   Epoch: [47/400][40/346], lr: 0.00000017 	 loss = 0.4035(0.5433)
2023/09/17 01:13:15 - INFO - root -   Epoch: [47/400][60/346], lr: 0.00000017 	 loss = 0.5063(0.5280)
2023/09/17 01:14:15 - INFO - root -   Epoch: [47/400][80/346], lr: 0.00000017 	 loss = 0.4857(0.5203)
2023/09/17 01:14:58 - INFO - root -   Epoch: [47/400][100/346], lr: 0.00000017 	 loss = 0.6865(0.5342)
2023/09/17 01:15:59 - INFO - root -   Epoch: [47/400][120/346], lr: 0.00000017 	 loss = 0.2154(0.5582)
2023/09/17 01:16:42 - INFO - root -   Epoch: [47/400][140/346], lr: 0.00000017 	 loss = 0.6440(0.5496)
2023/09/17 01:17:42 - INFO - root -   Epoch: [47/400][160/346], lr: 0.00000017 	 loss = 0.2670(0.5674)
2023/09/17 01:18:25 - INFO - root -   Epoch: [47/400][180/346], lr: 0.00000017 	 loss = 0.5590(0.5769)
2023/09/17 01:19:25 - INFO - root -   Epoch: [47/400][200/346], lr: 0.00000017 	 loss = 0.2336(0.5810)
2023/09/17 01:20:08 - INFO - root -   Epoch: [47/400][220/346], lr: 0.00000017 	 loss = 0.6203(0.5885)
2023/09/17 01:21:09 - INFO - root -   Epoch: [47/400][240/346], lr: 0.00000017 	 loss = 0.1430(0.5858)
2023/09/17 01:21:51 - INFO - root -   Epoch: [47/400][260/346], lr: 0.00000017 	 loss = 0.7882(0.5842)
2023/09/17 01:22:52 - INFO - root -   Epoch: [47/400][280/346], lr: 0.00000017 	 loss = 0.2581(0.5952)
2023/09/17 01:23:35 - INFO - root -   Epoch: [47/400][300/346], lr: 0.00000017 	 loss = 0.2259(0.5982)
2023/09/17 01:24:35 - INFO - root -   Epoch: [47/400][320/346], lr: 0.00000017 	 loss = 0.5103(0.5944)
2023/09/17 01:25:17 - INFO - root -   Epoch: [47/400][340/346], lr: 0.00000017 	 loss = 1.5351(0.5964)
2023/09/17 01:25:21 - INFO - root -   Epoch: [47/400] 	 loss = 0.5959
2023/09/17 01:25:21 - INFO - root -   train_accuracy = 0.6936
2023/09/17 01:25:43 - INFO - root -   Epoch: [48/400][0/346], lr: 0.00000017 	 loss = 0.3371(0.3371)
2023/09/17 01:26:26 - INFO - root -   Epoch: [48/400][20/346], lr: 0.00000017 	 loss = 0.9058(0.5309)
2023/09/17 01:27:27 - INFO - root -   Epoch: [48/400][40/346], lr: 0.00000017 	 loss = 0.2435(0.5580)
2023/09/17 01:28:10 - INFO - root -   Epoch: [48/400][60/346], lr: 0.00000017 	 loss = 0.8953(0.5516)
2023/09/17 01:29:10 - INFO - root -   Epoch: [48/400][80/346], lr: 0.00000017 	 loss = 0.3792(0.5467)
2023/09/17 01:29:53 - INFO - root -   Epoch: [48/400][100/346], lr: 0.00000017 	 loss = 0.6835(0.5714)
2023/09/17 01:30:54 - INFO - root -   Epoch: [48/400][120/346], lr: 0.00000017 	 loss = 0.3576(0.5911)
2023/09/17 01:31:37 - INFO - root -   Epoch: [48/400][140/346], lr: 0.00000017 	 loss = 0.6845(0.5880)
2023/09/17 01:32:37 - INFO - root -   Epoch: [48/400][160/346], lr: 0.00000017 	 loss = 0.2088(0.5848)
2023/09/17 01:33:20 - INFO - root -   Epoch: [48/400][180/346], lr: 0.00000017 	 loss = 1.1303(0.5845)
2023/09/17 01:34:20 - INFO - root -   Epoch: [48/400][200/346], lr: 0.00000017 	 loss = 0.3224(0.5850)
2023/09/17 01:35:03 - INFO - root -   Epoch: [48/400][220/346], lr: 0.00000017 	 loss = 0.2453(0.5917)
2023/09/17 01:36:04 - INFO - root -   Epoch: [48/400][240/346], lr: 0.00000017 	 loss = 0.9193(0.5935)
2023/09/17 01:36:47 - INFO - root -   Epoch: [48/400][260/346], lr: 0.00000017 	 loss = 0.5474(0.5868)
2023/09/17 01:37:47 - INFO - root -   Epoch: [48/400][280/346], lr: 0.00000017 	 loss = 0.2435(0.5964)
2023/09/17 01:38:30 - INFO - root -   Epoch: [48/400][300/346], lr: 0.00000017 	 loss = 0.2504(0.5940)
2023/09/17 01:39:30 - INFO - root -   Epoch: [48/400][320/346], lr: 0.00000017 	 loss = 0.2332(0.5995)
2023/09/17 01:40:12 - INFO - root -   Epoch: [48/400][340/346], lr: 0.00000017 	 loss = 1.2470(0.5967)
2023/09/17 01:40:16 - INFO - root -   Epoch: [48/400] 	 loss = 0.5967
2023/09/17 01:40:16 - INFO - root -   train_accuracy = 0.6720
2023/09/17 01:40:38 - INFO - root -   Epoch: [49/400][0/346], lr: 0.00000017 	 loss = 0.2215(0.2215)
2023/09/17 01:41:21 - INFO - root -   Epoch: [49/400][20/346], lr: 0.00000017 	 loss = 0.8649(0.5325)
2023/09/17 01:42:22 - INFO - root -   Epoch: [49/400][40/346], lr: 0.00000017 	 loss = 0.6359(0.5461)
2023/09/17 01:43:05 - INFO - root -   Epoch: [49/400][60/346], lr: 0.00000017 	 loss = 1.1065(0.5123)
2023/09/17 01:44:06 - INFO - root -   Epoch: [49/400][80/346], lr: 0.00000017 	 loss = 0.5087(0.5311)
2023/09/17 01:44:49 - INFO - root -   Epoch: [49/400][100/346], lr: 0.00000017 	 loss = 0.3323(0.5601)
2023/09/17 01:45:50 - INFO - root -   Epoch: [49/400][120/346], lr: 0.00000017 	 loss = 0.3426(0.5852)
2023/09/17 01:46:33 - INFO - root -   Epoch: [49/400][140/346], lr: 0.00000017 	 loss = 0.5767(0.5781)
2023/09/17 01:47:33 - INFO - root -   Epoch: [49/400][160/346], lr: 0.00000017 	 loss = 0.2756(0.5801)
2023/09/17 01:48:16 - INFO - root -   Epoch: [49/400][180/346], lr: 0.00000017 	 loss = 0.4528(0.5889)
2023/09/17 01:49:17 - INFO - root -   Epoch: [49/400][200/346], lr: 0.00000017 	 loss = 0.1898(0.5761)
2023/09/17 01:50:00 - INFO - root -   Epoch: [49/400][220/346], lr: 0.00000017 	 loss = 0.2862(0.5771)
2023/09/17 01:51:01 - INFO - root -   Epoch: [49/400][240/346], lr: 0.00000017 	 loss = 0.2042(0.5835)
2023/09/17 01:51:44 - INFO - root -   Epoch: [49/400][260/346], lr: 0.00000017 	 loss = 1.1410(0.5817)
2023/09/17 01:52:45 - INFO - root -   Epoch: [49/400][280/346], lr: 0.00000017 	 loss = 0.3595(0.5954)
2023/09/17 01:53:28 - INFO - root -   Epoch: [49/400][300/346], lr: 0.00000017 	 loss = 0.2781(0.5959)
2023/09/17 01:54:28 - INFO - root -   Epoch: [49/400][320/346], lr: 0.00000017 	 loss = 0.4406(0.5972)
2023/09/17 01:55:11 - INFO - root -   Epoch: [49/400][340/346], lr: 0.00000017 	 loss = 0.7396(0.5908)
2023/09/17 01:55:15 - INFO - root -   Epoch: [49/400] 	 loss = 0.5900
2023/09/17 01:59:03 - INFO - root -   precision = 0.6897
2023/09/17 01:59:03 - INFO - root -   eval_loss = 0.6123
2023/09/17 01:59:04 - INFO - root -   train_accuracy = 0.6951
2023/09/17 01:59:25 - INFO - root -   Epoch: [50/400][0/346], lr: 0.00000017 	 loss = 0.2759(0.2759)
2023/09/17 02:00:08 - INFO - root -   Epoch: [50/400][20/346], lr: 0.00000017 	 loss = 0.5625(0.5329)
2023/09/17 02:01:08 - INFO - root -   Epoch: [50/400][40/346], lr: 0.00000017 	 loss = 0.3703(0.5553)
2023/09/17 02:01:51 - INFO - root -   Epoch: [50/400][60/346], lr: 0.00000017 	 loss = 0.8010(0.5531)
2023/09/17 02:02:52 - INFO - root -   Epoch: [50/400][80/346], lr: 0.00000017 	 loss = 0.4942(0.5492)
2023/09/17 02:03:35 - INFO - root -   Epoch: [50/400][100/346], lr: 0.00000017 	 loss = 0.3943(0.5638)
2023/09/17 02:04:35 - INFO - root -   Epoch: [50/400][120/346], lr: 0.00000017 	 loss = 0.7124(0.6086)
2023/09/17 02:05:18 - INFO - root -   Epoch: [50/400][140/346], lr: 0.00000017 	 loss = 0.1860(0.5958)
2023/09/17 02:06:19 - INFO - root -   Epoch: [50/400][160/346], lr: 0.00000017 	 loss = 0.3323(0.6131)
2023/09/17 02:07:02 - INFO - root -   Epoch: [50/400][180/346], lr: 0.00000017 	 loss = 0.6667(0.6166)
2023/09/17 02:08:02 - INFO - root -   Epoch: [50/400][200/346], lr: 0.00000017 	 loss = 0.2885(0.6005)
2023/09/17 02:08:45 - INFO - root -   Epoch: [50/400][220/346], lr: 0.00000017 	 loss = 0.4467(0.6023)
2023/09/17 02:09:45 - INFO - root -   Epoch: [50/400][240/346], lr: 0.00000017 	 loss = 0.4659(0.5982)
2023/09/17 02:10:29 - INFO - root -   Epoch: [50/400][260/346], lr: 0.00000017 	 loss = 0.5841(0.5924)
2023/09/17 02:11:28 - INFO - root -   Epoch: [50/400][280/346], lr: 0.00000017 	 loss = 0.3391(0.5971)
2023/09/17 02:12:12 - INFO - root -   Epoch: [50/400][300/346], lr: 0.00000017 	 loss = 0.3505(0.5990)
2023/09/17 02:13:12 - INFO - root -   Epoch: [50/400][320/346], lr: 0.00000017 	 loss = 0.3605(0.5990)
2023/09/17 02:13:55 - INFO - root -   Epoch: [50/400][340/346], lr: 0.00000017 	 loss = 1.2362(0.6009)
2023/09/17 02:13:59 - INFO - root -   Epoch: [50/400] 	 loss = 0.6013
2023/09/17 02:13:59 - INFO - root -   train_accuracy = 0.6777
2023/09/17 02:14:20 - INFO - root -   Epoch: [51/400][0/346], lr: 0.00000017 	 loss = 0.0644(0.0644)
2023/09/17 02:15:03 - INFO - root -   Epoch: [51/400][20/346], lr: 0.00000017 	 loss = 0.7431(0.5243)
2023/09/17 02:16:04 - INFO - root -   Epoch: [51/400][40/346], lr: 0.00000017 	 loss = 0.3666(0.5885)
2023/09/17 02:16:48 - INFO - root -   Epoch: [51/400][60/346], lr: 0.00000017 	 loss = 0.7696(0.5345)
2023/09/17 02:17:49 - INFO - root -   Epoch: [51/400][80/346], lr: 0.00000017 	 loss = 0.3513(0.5393)
2023/09/17 02:18:32 - INFO - root -   Epoch: [51/400][100/346], lr: 0.00000017 	 loss = 0.6324(0.5484)
2023/09/17 02:19:33 - INFO - root -   Epoch: [51/400][120/346], lr: 0.00000017 	 loss = 0.3044(0.5668)
2023/09/17 02:20:16 - INFO - root -   Epoch: [51/400][140/346], lr: 0.00000017 	 loss = 0.6349(0.5660)
2023/09/17 02:21:17 - INFO - root -   Epoch: [51/400][160/346], lr: 0.00000017 	 loss = 0.2225(0.5787)
2023/09/17 02:22:00 - INFO - root -   Epoch: [51/400][180/346], lr: 0.00000017 	 loss = 0.4252(0.5812)
2023/09/17 02:23:01 - INFO - root -   Epoch: [51/400][200/346], lr: 0.00000017 	 loss = 0.1194(0.5823)
2023/09/17 02:23:44 - INFO - root -   Epoch: [51/400][220/346], lr: 0.00000017 	 loss = 0.2114(0.5912)
2023/09/17 02:24:44 - INFO - root -   Epoch: [51/400][240/346], lr: 0.00000017 	 loss = 0.2359(0.5935)
2023/09/17 02:25:28 - INFO - root -   Epoch: [51/400][260/346], lr: 0.00000017 	 loss = 0.5955(0.6029)
2023/09/17 02:26:28 - INFO - root -   Epoch: [51/400][280/346], lr: 0.00000017 	 loss = 0.1766(0.6170)
2023/09/17 02:27:11 - INFO - root -   Epoch: [51/400][300/346], lr: 0.00000017 	 loss = 0.4249(0.6218)
2023/09/17 02:28:12 - INFO - root -   Epoch: [51/400][320/346], lr: 0.00000017 	 loss = 0.2721(0.6217)
2023/09/17 02:28:54 - INFO - root -   Epoch: [51/400][340/346], lr: 0.00000017 	 loss = 1.3309(0.6224)
2023/09/17 02:28:58 - INFO - root -   Epoch: [51/400] 	 loss = 0.6215
2023/09/17 02:28:58 - INFO - root -   train_accuracy = 0.6373
2023/09/17 02:29:20 - INFO - root -   Epoch: [52/400][0/346], lr: 0.00000017 	 loss = 0.3119(0.3119)
2023/09/17 02:30:03 - INFO - root -   Epoch: [52/400][20/346], lr: 0.00000017 	 loss = 0.4417(0.5948)
2023/09/17 02:31:04 - INFO - root -   Epoch: [52/400][40/346], lr: 0.00000017 	 loss = 0.6553(0.5942)
2023/09/17 02:31:47 - INFO - root -   Epoch: [52/400][60/346], lr: 0.00000017 	 loss = 0.6872(0.5875)
2023/09/17 02:32:48 - INFO - root -   Epoch: [52/400][80/346], lr: 0.00000017 	 loss = 0.9944(0.5970)
2023/09/17 02:33:31 - INFO - root -   Epoch: [52/400][100/346], lr: 0.00000017 	 loss = 0.3327(0.5886)
2023/09/17 02:34:31 - INFO - root -   Epoch: [52/400][120/346], lr: 0.00000017 	 loss = 0.6795(0.5984)
2023/09/17 02:35:15 - INFO - root -   Epoch: [52/400][140/346], lr: 0.00000017 	 loss = 1.1327(0.5891)
2023/09/17 02:36:15 - INFO - root -   Epoch: [52/400][160/346], lr: 0.00000017 	 loss = 0.4735(0.5905)
2023/09/17 02:36:58 - INFO - root -   Epoch: [52/400][180/346], lr: 0.00000017 	 loss = 0.4405(0.5914)
2023/09/17 02:37:59 - INFO - root -   Epoch: [52/400][200/346], lr: 0.00000017 	 loss = 0.1216(0.5860)
2023/09/17 02:38:42 - INFO - root -   Epoch: [52/400][220/346], lr: 0.00000017 	 loss = 0.2008(0.5876)
2023/09/17 02:39:42 - INFO - root -   Epoch: [52/400][240/346], lr: 0.00000017 	 loss = 0.3015(0.5896)
2023/09/17 02:40:25 - INFO - root -   Epoch: [52/400][260/346], lr: 0.00000017 	 loss = 1.0165(0.5890)
2023/09/17 02:41:26 - INFO - root -   Epoch: [52/400][280/346], lr: 0.00000017 	 loss = 0.3448(0.6049)
2023/09/17 02:42:09 - INFO - root -   Epoch: [52/400][300/346], lr: 0.00000017 	 loss = 0.4221(0.6043)
2023/09/17 02:43:09 - INFO - root -   Epoch: [52/400][320/346], lr: 0.00000017 	 loss = 0.6381(0.6012)
2023/09/17 02:43:51 - INFO - root -   Epoch: [52/400][340/346], lr: 0.00000017 	 loss = 1.0297(0.5962)
2023/09/17 02:43:55 - INFO - root -   Epoch: [52/400] 	 loss = 0.5952
2023/09/17 02:43:55 - INFO - root -   train_accuracy = 0.6575
2023/09/17 02:44:17 - INFO - root -   Epoch: [53/400][0/346], lr: 0.00000018 	 loss = 0.1720(0.1720)
2023/09/17 02:45:01 - INFO - root -   Epoch: [53/400][20/346], lr: 0.00000018 	 loss = 0.5920(0.5139)
2023/09/17 02:46:02 - INFO - root -   Epoch: [53/400][40/346], lr: 0.00000018 	 loss = 0.4447(0.5450)
2023/09/17 02:46:46 - INFO - root -   Epoch: [53/400][60/346], lr: 0.00000018 	 loss = 0.6624(0.5074)
2023/09/17 02:47:47 - INFO - root -   Epoch: [53/400][80/346], lr: 0.00000018 	 loss = 0.3127(0.5311)
2023/09/17 02:48:30 - INFO - root -   Epoch: [53/400][100/346], lr: 0.00000018 	 loss = 0.6282(0.5416)
2023/09/17 02:49:31 - INFO - root -   Epoch: [53/400][120/346], lr: 0.00000018 	 loss = 0.1708(0.5815)
2023/09/17 02:50:14 - INFO - root -   Epoch: [53/400][140/346], lr: 0.00000018 	 loss = 0.8463(0.5671)
2023/09/17 02:51:15 - INFO - root -   Epoch: [53/400][160/346], lr: 0.00000018 	 loss = 0.1547(0.5709)
2023/09/17 02:51:58 - INFO - root -   Epoch: [53/400][180/346], lr: 0.00000018 	 loss = 0.7877(0.5768)
2023/09/17 02:52:59 - INFO - root -   Epoch: [53/400][200/346], lr: 0.00000018 	 loss = 0.2219(0.5697)
2023/09/17 02:53:43 - INFO - root -   Epoch: [53/400][220/346], lr: 0.00000018 	 loss = 0.3307(0.5761)
2023/09/17 02:54:43 - INFO - root -   Epoch: [53/400][240/346], lr: 0.00000018 	 loss = 0.3878(0.5760)
2023/09/17 02:55:27 - INFO - root -   Epoch: [53/400][260/346], lr: 0.00000018 	 loss = 1.0194(0.5704)
2023/09/17 02:56:27 - INFO - root -   Epoch: [53/400][280/346], lr: 0.00000018 	 loss = 0.3668(0.5947)
2023/09/17 02:57:11 - INFO - root -   Epoch: [53/400][300/346], lr: 0.00000018 	 loss = 0.2854(0.5979)
2023/09/17 02:58:11 - INFO - root -   Epoch: [53/400][320/346], lr: 0.00000018 	 loss = 0.1728(0.5950)
2023/09/17 02:58:53 - INFO - root -   Epoch: [53/400][340/346], lr: 0.00000018 	 loss = 1.4875(0.5945)
2023/09/17 02:58:58 - INFO - root -   Epoch: [53/400] 	 loss = 0.5944
2023/09/17 02:58:58 - INFO - root -   train_accuracy = 0.6850
2023/09/17 02:59:19 - INFO - root -   Epoch: [54/400][0/346], lr: 0.00000018 	 loss = 0.3850(0.3850)
2023/09/17 03:00:02 - INFO - root -   Epoch: [54/400][20/346], lr: 0.00000018 	 loss = 0.4343(0.4810)
2023/09/17 03:01:03 - INFO - root -   Epoch: [54/400][40/346], lr: 0.00000018 	 loss = 0.5753(0.5590)
2023/09/17 03:01:46 - INFO - root -   Epoch: [54/400][60/346], lr: 0.00000018 	 loss = 0.6138(0.5192)
2023/09/17 03:02:47 - INFO - root -   Epoch: [54/400][80/346], lr: 0.00000018 	 loss = 0.6137(0.5347)
2023/09/17 03:03:30 - INFO - root -   Epoch: [54/400][100/346], lr: 0.00000018 	 loss = 0.6281(0.5607)
2023/09/17 03:04:31 - INFO - root -   Epoch: [54/400][120/346], lr: 0.00000018 	 loss = 0.3360(0.5779)
2023/09/17 03:05:14 - INFO - root -   Epoch: [54/400][140/346], lr: 0.00000018 	 loss = 0.5413(0.5813)
2023/09/17 03:06:14 - INFO - root -   Epoch: [54/400][160/346], lr: 0.00000018 	 loss = 0.2589(0.5853)
2023/09/17 03:06:57 - INFO - root -   Epoch: [54/400][180/346], lr: 0.00000018 	 loss = 0.4673(0.5825)
2023/09/17 03:07:58 - INFO - root -   Epoch: [54/400][200/346], lr: 0.00000018 	 loss = 0.1745(0.5717)
2023/09/17 03:08:41 - INFO - root -   Epoch: [54/400][220/346], lr: 0.00000018 	 loss = 0.3813(0.5724)
2023/09/17 03:09:41 - INFO - root -   Epoch: [54/400][240/346], lr: 0.00000018 	 loss = 0.1576(0.5721)
2023/09/17 03:10:24 - INFO - root -   Epoch: [54/400][260/346], lr: 0.00000018 	 loss = 0.4479(0.5627)
2023/09/17 03:11:25 - INFO - root -   Epoch: [54/400][280/346], lr: 0.00000018 	 loss = 0.4673(0.5823)
2023/09/17 03:12:08 - INFO - root -   Epoch: [54/400][300/346], lr: 0.00000018 	 loss = 0.1393(0.5848)
2023/09/17 03:13:08 - INFO - root -   Epoch: [54/400][320/346], lr: 0.00000018 	 loss = 0.3266(0.5840)
2023/09/17 03:13:50 - INFO - root -   Epoch: [54/400][340/346], lr: 0.00000018 	 loss = 1.1348(0.5835)
2023/09/17 03:13:54 - INFO - root -   Epoch: [54/400] 	 loss = 0.5832
2023/09/17 03:17:45 - INFO - root -   precision = 0.6724
2023/09/17 03:17:45 - INFO - root -   eval_loss = 0.6135
2023/09/17 03:17:46 - INFO - root -   train_accuracy = 0.7023
2023/09/17 03:18:08 - INFO - root -   Epoch: [55/400][0/346], lr: 0.00000018 	 loss = 0.3213(0.3213)
2023/09/17 03:18:51 - INFO - root -   Epoch: [55/400][20/346], lr: 0.00000018 	 loss = 0.4465(0.4509)
2023/09/17 03:19:51 - INFO - root -   Epoch: [55/400][40/346], lr: 0.00000018 	 loss = 0.3240(0.5719)
2023/09/17 03:20:34 - INFO - root -   Epoch: [55/400][60/346], lr: 0.00000018 	 loss = 0.5931(0.5225)
2023/09/17 03:21:35 - INFO - root -   Epoch: [55/400][80/346], lr: 0.00000018 	 loss = 0.3402(0.5614)
2023/09/17 03:22:18 - INFO - root -   Epoch: [55/400][100/346], lr: 0.00000018 	 loss = 0.4183(0.5731)
2023/09/17 03:23:18 - INFO - root -   Epoch: [55/400][120/346], lr: 0.00000018 	 loss = 0.3211(0.5997)
2023/09/17 03:24:02 - INFO - root -   Epoch: [55/400][140/346], lr: 0.00000018 	 loss = 0.4396(0.5935)
2023/09/17 03:25:02 - INFO - root -   Epoch: [55/400][160/346], lr: 0.00000018 	 loss = 0.1322(0.5998)
2023/09/17 03:25:44 - INFO - root -   Epoch: [55/400][180/346], lr: 0.00000018 	 loss = 0.2980(0.6089)
2023/09/17 03:26:45 - INFO - root -   Epoch: [55/400][200/346], lr: 0.00000018 	 loss = 0.1622(0.6039)
2023/09/17 03:27:27 - INFO - root -   Epoch: [55/400][220/346], lr: 0.00000018 	 loss = 0.3047(0.6027)
2023/09/17 03:28:28 - INFO - root -   Epoch: [55/400][240/346], lr: 0.00000018 	 loss = 0.6402(0.5999)
2023/09/17 03:29:11 - INFO - root -   Epoch: [55/400][260/346], lr: 0.00000018 	 loss = 0.3901(0.5910)
2023/09/17 03:30:11 - INFO - root -   Epoch: [55/400][280/346], lr: 0.00000018 	 loss = 0.2079(0.5994)
2023/09/17 03:30:53 - INFO - root -   Epoch: [55/400][300/346], lr: 0.00000018 	 loss = 0.2443(0.5962)
2023/09/17 03:31:53 - INFO - root -   Epoch: [55/400][320/346], lr: 0.00000018 	 loss = 0.7228(0.6048)
2023/09/17 03:32:35 - INFO - root -   Epoch: [55/400][340/346], lr: 0.00000018 	 loss = 0.8900(0.6039)
2023/09/17 03:32:40 - INFO - root -   Epoch: [55/400] 	 loss = 0.6043
2023/09/17 03:32:40 - INFO - root -   train_accuracy = 0.6908
2023/09/17 03:33:01 - INFO - root -   Epoch: [56/400][0/346], lr: 0.00000018 	 loss = 0.5391(0.5391)
2023/09/17 03:33:45 - INFO - root -   Epoch: [56/400][20/346], lr: 0.00000018 	 loss = 0.4340(0.3965)
2023/09/17 03:34:46 - INFO - root -   Epoch: [56/400][40/346], lr: 0.00000018 	 loss = 0.4927(0.4837)
2023/09/17 03:35:29 - INFO - root -   Epoch: [56/400][60/346], lr: 0.00000018 	 loss = 0.4969(0.4732)
2023/09/17 03:36:30 - INFO - root -   Epoch: [56/400][80/346], lr: 0.00000018 	 loss = 0.7229(0.4937)
2023/09/17 03:37:14 - INFO - root -   Epoch: [56/400][100/346], lr: 0.00000018 	 loss = 0.3994(0.5112)
2023/09/17 03:38:15 - INFO - root -   Epoch: [56/400][120/346], lr: 0.00000018 	 loss = 0.3713(0.5459)
2023/09/17 03:38:58 - INFO - root -   Epoch: [56/400][140/346], lr: 0.00000018 	 loss = 0.3127(0.5389)
2023/09/17 03:39:59 - INFO - root -   Epoch: [56/400][160/346], lr: 0.00000018 	 loss = 0.0687(0.5442)
2023/09/17 03:40:42 - INFO - root -   Epoch: [56/400][180/346], lr: 0.00000018 	 loss = 0.5992(0.5498)
2023/09/17 03:41:43 - INFO - root -   Epoch: [56/400][200/346], lr: 0.00000018 	 loss = 0.2621(0.5547)
2023/09/17 03:42:26 - INFO - root -   Epoch: [56/400][220/346], lr: 0.00000018 	 loss = 0.3115(0.5585)
2023/09/17 03:43:27 - INFO - root -   Epoch: [56/400][240/346], lr: 0.00000018 	 loss = 0.3625(0.5627)
2023/09/17 03:44:10 - INFO - root -   Epoch: [56/400][260/346], lr: 0.00000018 	 loss = 0.8012(0.5559)
2023/09/17 03:45:11 - INFO - root -   Epoch: [56/400][280/346], lr: 0.00000018 	 loss = 0.2798(0.5668)
2023/09/17 03:45:55 - INFO - root -   Epoch: [56/400][300/346], lr: 0.00000018 	 loss = 0.2570(0.5706)
2023/09/17 03:46:56 - INFO - root -   Epoch: [56/400][320/346], lr: 0.00000018 	 loss = 0.4633(0.5695)
2023/09/17 03:47:38 - INFO - root -   Epoch: [56/400][340/346], lr: 0.00000018 	 loss = 1.3007(0.5740)
2023/09/17 03:47:42 - INFO - root -   Epoch: [56/400] 	 loss = 0.5738
2023/09/17 03:47:42 - INFO - root -   train_accuracy = 0.7110
2023/09/17 03:48:04 - INFO - root -   Epoch: [57/400][0/346], lr: 0.00000018 	 loss = 0.3532(0.3532)
2023/09/17 03:48:47 - INFO - root -   Epoch: [57/400][20/346], lr: 0.00000018 	 loss = 0.4032(0.4676)
2023/09/17 03:49:48 - INFO - root -   Epoch: [57/400][40/346], lr: 0.00000018 	 loss = 0.5346(0.5264)
2023/09/17 03:50:32 - INFO - root -   Epoch: [57/400][60/346], lr: 0.00000018 	 loss = 0.6254(0.4847)
2023/09/17 03:51:33 - INFO - root -   Epoch: [57/400][80/346], lr: 0.00000018 	 loss = 0.6800(0.4919)
2023/09/17 03:52:17 - INFO - root -   Epoch: [57/400][100/346], lr: 0.00000018 	 loss = 0.4547(0.5038)
2023/09/17 03:53:18 - INFO - root -   Epoch: [57/400][120/346], lr: 0.00000018 	 loss = 0.2610(0.5396)
2023/09/17 03:54:01 - INFO - root -   Epoch: [57/400][140/346], lr: 0.00000018 	 loss = 0.6899(0.5380)
2023/09/17 03:55:02 - INFO - root -   Epoch: [57/400][160/346], lr: 0.00000018 	 loss = 0.1026(0.5440)
2023/09/17 03:55:46 - INFO - root -   Epoch: [57/400][180/346], lr: 0.00000018 	 loss = 0.9055(0.5497)
2023/09/17 03:56:47 - INFO - root -   Epoch: [57/400][200/346], lr: 0.00000018 	 loss = 0.2068(0.5480)
2023/09/17 03:57:30 - INFO - root -   Epoch: [57/400][220/346], lr: 0.00000018 	 loss = 0.4658(0.5500)
2023/09/17 03:58:32 - INFO - root -   Epoch: [57/400][240/346], lr: 0.00000018 	 loss = 0.2798(0.5522)
2023/09/17 03:59:15 - INFO - root -   Epoch: [57/400][260/346], lr: 0.00000018 	 loss = 0.8462(0.5487)
2023/09/17 04:00:17 - INFO - root -   Epoch: [57/400][280/346], lr: 0.00000018 	 loss = 0.1313(0.5648)
2023/09/17 04:01:01 - INFO - root -   Epoch: [57/400][300/346], lr: 0.00000018 	 loss = 0.1284(0.5667)
2023/09/17 04:02:02 - INFO - root -   Epoch: [57/400][320/346], lr: 0.00000018 	 loss = 0.3678(0.5649)
2023/09/17 04:02:45 - INFO - root -   Epoch: [57/400][340/346], lr: 0.00000018 	 loss = 1.1171(0.5674)
2023/09/17 04:02:49 - INFO - root -   Epoch: [57/400] 	 loss = 0.5665
2023/09/17 04:02:49 - INFO - root -   train_accuracy = 0.7110
2023/09/17 04:03:11 - INFO - root -   Epoch: [58/400][0/346], lr: 0.00000018 	 loss = 0.2813(0.2813)
2023/09/17 04:03:54 - INFO - root -   Epoch: [58/400][20/346], lr: 0.00000018 	 loss = 0.5636(0.4367)
2023/09/17 04:04:54 - INFO - root -   Epoch: [58/400][40/346], lr: 0.00000018 	 loss = 0.7231(0.5256)
2023/09/17 04:05:37 - INFO - root -   Epoch: [58/400][60/346], lr: 0.00000018 	 loss = 0.7363(0.4983)
2023/09/17 04:06:38 - INFO - root -   Epoch: [58/400][80/346], lr: 0.00000018 	 loss = 0.9976(0.5419)
2023/09/17 04:07:21 - INFO - root -   Epoch: [58/400][100/346], lr: 0.00000018 	 loss = 0.2818(0.5461)
2023/09/17 04:08:22 - INFO - root -   Epoch: [58/400][120/346], lr: 0.00000018 	 loss = 0.3328(0.5658)
2023/09/17 04:09:05 - INFO - root -   Epoch: [58/400][140/346], lr: 0.00000018 	 loss = 0.5269(0.5466)
2023/09/17 04:10:06 - INFO - root -   Epoch: [58/400][160/346], lr: 0.00000018 	 loss = 0.3774(0.5509)
2023/09/17 04:10:49 - INFO - root -   Epoch: [58/400][180/346], lr: 0.00000018 	 loss = 0.4961(0.5513)
2023/09/17 04:11:49 - INFO - root -   Epoch: [58/400][200/346], lr: 0.00000018 	 loss = 0.0598(0.5466)
2023/09/17 04:12:33 - INFO - root -   Epoch: [58/400][220/346], lr: 0.00000018 	 loss = 0.5349(0.5583)
2023/09/17 04:13:33 - INFO - root -   Epoch: [58/400][240/346], lr: 0.00000018 	 loss = 0.4560(0.5594)
2023/09/17 04:14:16 - INFO - root -   Epoch: [58/400][260/346], lr: 0.00000018 	 loss = 0.5122(0.5542)
2023/09/17 04:15:17 - INFO - root -   Epoch: [58/400][280/346], lr: 0.00000018 	 loss = 0.2845(0.5751)
2023/09/17 04:16:00 - INFO - root -   Epoch: [58/400][300/346], lr: 0.00000018 	 loss = 0.2447(0.5766)
2023/09/17 04:17:01 - INFO - root -   Epoch: [58/400][320/346], lr: 0.00000018 	 loss = 0.3344(0.5727)
2023/09/17 04:17:43 - INFO - root -   Epoch: [58/400][340/346], lr: 0.00000018 	 loss = 1.5318(0.5740)
2023/09/17 04:17:47 - INFO - root -   Epoch: [58/400] 	 loss = 0.5729
2023/09/17 04:17:47 - INFO - root -   train_accuracy = 0.6980
2023/09/17 04:18:08 - INFO - root -   Epoch: [59/400][0/346], lr: 0.00000018 	 loss = 0.2217(0.2217)
2023/09/17 04:18:52 - INFO - root -   Epoch: [59/400][20/346], lr: 0.00000018 	 loss = 0.4450(0.4487)
2023/09/17 04:19:53 - INFO - root -   Epoch: [59/400][40/346], lr: 0.00000018 	 loss = 0.6546(0.5140)
2023/09/17 04:20:36 - INFO - root -   Epoch: [59/400][60/346], lr: 0.00000018 	 loss = 0.8298(0.4835)
2023/09/17 04:21:37 - INFO - root -   Epoch: [59/400][80/346], lr: 0.00000018 	 loss = 0.4353(0.5024)
2023/09/17 04:22:21 - INFO - root -   Epoch: [59/400][100/346], lr: 0.00000018 	 loss = 0.4561(0.5110)
2023/09/17 04:23:21 - INFO - root -   Epoch: [59/400][120/346], lr: 0.00000018 	 loss = 0.2626(0.5393)
2023/09/17 04:24:06 - INFO - root -   Epoch: [59/400][140/346], lr: 0.00000018 	 loss = 0.6808(0.5389)
2023/09/17 04:25:06 - INFO - root -   Epoch: [59/400][160/346], lr: 0.00000018 	 loss = 0.1117(0.5472)
2023/09/17 04:25:50 - INFO - root -   Epoch: [59/400][180/346], lr: 0.00000018 	 loss = 0.7780(0.5578)
2023/09/17 04:26:50 - INFO - root -   Epoch: [59/400][200/346], lr: 0.00000018 	 loss = 0.1046(0.5530)
2023/09/17 04:27:35 - INFO - root -   Epoch: [59/400][220/346], lr: 0.00000018 	 loss = 0.2221(0.5589)
2023/09/17 04:28:34 - INFO - root -   Epoch: [59/400][240/346], lr: 0.00000018 	 loss = 0.2784(0.5518)
2023/09/17 04:29:19 - INFO - root -   Epoch: [59/400][260/346], lr: 0.00000018 	 loss = 0.6045(0.5447)
2023/09/17 04:30:18 - INFO - root -   Epoch: [59/400][280/346], lr: 0.00000018 	 loss = 0.2157(0.5649)
2023/09/17 04:31:03 - INFO - root -   Epoch: [59/400][300/346], lr: 0.00000018 	 loss = 0.3337(0.5683)
2023/09/17 04:32:02 - INFO - root -   Epoch: [59/400][320/346], lr: 0.00000018 	 loss = 0.2152(0.5683)
2023/09/17 04:32:46 - INFO - root -   Epoch: [59/400][340/346], lr: 0.00000018 	 loss = 1.3357(0.5716)
2023/09/17 04:32:50 - INFO - root -   Epoch: [59/400] 	 loss = 0.5715
2023/09/17 04:36:39 - INFO - root -   precision = 0.6839
2023/09/17 04:36:39 - INFO - root -   eval_loss = 0.6112
2023/09/17 04:36:40 - INFO - root -   train_accuracy = 0.7052
2023/09/17 04:37:03 - INFO - root -   Epoch: [60/400][0/346], lr: 0.00000019 	 loss = 0.1677(0.1677)
2023/09/17 04:37:46 - INFO - root -   Epoch: [60/400][20/346], lr: 0.00000019 	 loss = 0.4330(0.4054)
2023/09/17 04:38:46 - INFO - root -   Epoch: [60/400][40/346], lr: 0.00000019 	 loss = 0.3683(0.5270)
2023/09/17 04:39:30 - INFO - root -   Epoch: [60/400][60/346], lr: 0.00000019 	 loss = 0.5736(0.4940)
2023/09/17 04:40:31 - INFO - root -   Epoch: [60/400][80/346], lr: 0.00000019 	 loss = 0.2942(0.4929)
2023/09/17 04:41:14 - INFO - root -   Epoch: [60/400][100/346], lr: 0.00000019 	 loss = 0.3163(0.5047)
2023/09/17 04:42:15 - INFO - root -   Epoch: [60/400][120/346], lr: 0.00000019 	 loss = 0.3022(0.5402)
2023/09/17 04:42:58 - INFO - root -   Epoch: [60/400][140/346], lr: 0.00000019 	 loss = 0.5773(0.5430)
2023/09/17 04:43:59 - INFO - root -   Epoch: [60/400][160/346], lr: 0.00000019 	 loss = 0.0959(0.5534)
2023/09/17 04:44:42 - INFO - root -   Epoch: [60/400][180/346], lr: 0.00000019 	 loss = 0.9352(0.5546)
2023/09/17 04:45:43 - INFO - root -   Epoch: [60/400][200/346], lr: 0.00000019 	 loss = 0.1679(0.5511)
2023/09/17 04:46:26 - INFO - root -   Epoch: [60/400][220/346], lr: 0.00000019 	 loss = 0.4040(0.5620)
2023/09/17 04:47:27 - INFO - root -   Epoch: [60/400][240/346], lr: 0.00000019 	 loss = 0.2509(0.5557)
2023/09/17 04:48:10 - INFO - root -   Epoch: [60/400][260/346], lr: 0.00000019 	 loss = 0.4713(0.5454)
2023/09/17 04:49:11 - INFO - root -   Epoch: [60/400][280/346], lr: 0.00000019 	 loss = 0.3851(0.5643)
2023/09/17 04:49:54 - INFO - root -   Epoch: [60/400][300/346], lr: 0.00000019 	 loss = 0.1919(0.5699)
2023/09/17 04:50:54 - INFO - root -   Epoch: [60/400][320/346], lr: 0.00000019 	 loss = 0.2344(0.5720)
2023/09/17 04:51:36 - INFO - root -   Epoch: [60/400][340/346], lr: 0.00000019 	 loss = 0.9799(0.5756)
2023/09/17 04:51:40 - INFO - root -   Epoch: [60/400] 	 loss = 0.5738
2023/09/17 04:51:40 - INFO - root -   train_accuracy = 0.7023
2023/09/17 04:52:02 - INFO - root -   Epoch: [61/400][0/346], lr: 0.00000019 	 loss = 0.1331(0.1331)
2023/09/17 04:52:44 - INFO - root -   Epoch: [61/400][20/346], lr: 0.00000019 	 loss = 0.3988(0.4074)
2023/09/17 04:53:45 - INFO - root -   Epoch: [61/400][40/346], lr: 0.00000019 	 loss = 0.3603(0.5124)
2023/09/17 04:54:28 - INFO - root -   Epoch: [61/400][60/346], lr: 0.00000019 	 loss = 0.6075(0.4925)
2023/09/17 04:55:29 - INFO - root -   Epoch: [61/400][80/346], lr: 0.00000019 	 loss = 0.2639(0.5026)
2023/09/17 04:56:12 - INFO - root -   Epoch: [61/400][100/346], lr: 0.00000019 	 loss = 0.4216(0.5047)
2023/09/17 04:57:13 - INFO - root -   Epoch: [61/400][120/346], lr: 0.00000019 	 loss = 0.3100(0.5351)
2023/09/17 04:57:56 - INFO - root -   Epoch: [61/400][140/346], lr: 0.00000019 	 loss = 0.5854(0.5253)
2023/09/17 04:58:56 - INFO - root -   Epoch: [61/400][160/346], lr: 0.00000019 	 loss = 0.1626(0.5425)
2023/09/17 04:59:39 - INFO - root -   Epoch: [61/400][180/346], lr: 0.00000019 	 loss = 0.2976(0.5446)
2023/09/17 05:00:40 - INFO - root -   Epoch: [61/400][200/346], lr: 0.00000019 	 loss = 0.3045(0.5455)
2023/09/17 05:01:23 - INFO - root -   Epoch: [61/400][220/346], lr: 0.00000019 	 loss = 0.3503(0.5490)
2023/09/17 05:02:24 - INFO - root -   Epoch: [61/400][240/346], lr: 0.00000019 	 loss = 0.2033(0.5435)
2023/09/17 05:03:07 - INFO - root -   Epoch: [61/400][260/346], lr: 0.00000019 	 loss = 0.9369(0.5418)
2023/09/17 05:04:07 - INFO - root -   Epoch: [61/400][280/346], lr: 0.00000019 	 loss = 0.1835(0.5549)
2023/09/17 05:04:50 - INFO - root -   Epoch: [61/400][300/346], lr: 0.00000019 	 loss = 0.3058(0.5645)
2023/09/17 05:05:51 - INFO - root -   Epoch: [61/400][320/346], lr: 0.00000019 	 loss = 0.4466(0.5656)
2023/09/17 05:06:33 - INFO - root -   Epoch: [61/400][340/346], lr: 0.00000019 	 loss = 1.5695(0.5681)
2023/09/17 05:06:37 - INFO - root -   Epoch: [61/400] 	 loss = 0.5668
2023/09/17 05:06:37 - INFO - root -   train_accuracy = 0.7283
2023/09/17 05:06:58 - INFO - root -   Epoch: [62/400][0/346], lr: 0.00000019 	 loss = 0.4193(0.4193)
2023/09/17 05:07:42 - INFO - root -   Epoch: [62/400][20/346], lr: 0.00000019 	 loss = 0.3025(0.4373)
2023/09/17 05:08:42 - INFO - root -   Epoch: [62/400][40/346], lr: 0.00000019 	 loss = 0.5645(0.5154)
2023/09/17 05:09:25 - INFO - root -   Epoch: [62/400][60/346], lr: 0.00000019 	 loss = 0.5562(0.4794)
2023/09/17 05:10:26 - INFO - root -   Epoch: [62/400][80/346], lr: 0.00000019 	 loss = 0.5105(0.5039)
2023/09/17 05:11:09 - INFO - root -   Epoch: [62/400][100/346], lr: 0.00000019 	 loss = 0.3441(0.5174)
2023/09/17 05:12:10 - INFO - root -   Epoch: [62/400][120/346], lr: 0.00000019 	 loss = 0.2590(0.5427)
2023/09/17 05:12:53 - INFO - root -   Epoch: [62/400][140/346], lr: 0.00000019 	 loss = 0.7650(0.5375)
2023/09/17 05:13:54 - INFO - root -   Epoch: [62/400][160/346], lr: 0.00000019 	 loss = 0.1537(0.5393)
2023/09/17 05:14:37 - INFO - root -   Epoch: [62/400][180/346], lr: 0.00000019 	 loss = 0.4950(0.5444)
2023/09/17 05:15:37 - INFO - root -   Epoch: [62/400][200/346], lr: 0.00000019 	 loss = 0.3549(0.5398)
2023/09/17 05:16:20 - INFO - root -   Epoch: [62/400][220/346], lr: 0.00000019 	 loss = 0.3309(0.5474)
2023/09/17 05:17:21 - INFO - root -   Epoch: [62/400][240/346], lr: 0.00000019 	 loss = 0.2408(0.5463)
2023/09/17 05:18:04 - INFO - root -   Epoch: [62/400][260/346], lr: 0.00000019 	 loss = 0.6868(0.5404)
2023/09/17 05:19:04 - INFO - root -   Epoch: [62/400][280/346], lr: 0.00000019 	 loss = 0.2399(0.5596)
2023/09/17 05:19:47 - INFO - root -   Epoch: [62/400][300/346], lr: 0.00000019 	 loss = 0.4584(0.5668)
2023/09/17 05:20:48 - INFO - root -   Epoch: [62/400][320/346], lr: 0.00000019 	 loss = 0.4133(0.5652)
2023/09/17 05:21:31 - INFO - root -   Epoch: [62/400][340/346], lr: 0.00000019 	 loss = 1.7888(0.5642)
2023/09/17 05:21:35 - INFO - root -   Epoch: [62/400] 	 loss = 0.5652
2023/09/17 05:21:35 - INFO - root -   train_accuracy = 0.7370
2023/09/17 05:21:56 - INFO - root -   Epoch: [63/400][0/346], lr: 0.00000019 	 loss = 0.1081(0.1081)
2023/09/17 05:22:39 - INFO - root -   Epoch: [63/400][20/346], lr: 0.00000019 	 loss = 0.4240(0.4035)
2023/09/17 05:23:40 - INFO - root -   Epoch: [63/400][40/346], lr: 0.00000019 	 loss = 0.4141(0.4655)
2023/09/17 05:24:23 - INFO - root -   Epoch: [63/400][60/346], lr: 0.00000019 	 loss = 0.8501(0.4362)
2023/09/17 05:25:23 - INFO - root -   Epoch: [63/400][80/346], lr: 0.00000019 	 loss = 0.4664(0.4978)
2023/09/17 05:26:06 - INFO - root -   Epoch: [63/400][100/346], lr: 0.00000019 	 loss = 0.3644(0.5122)
2023/09/17 05:27:07 - INFO - root -   Epoch: [63/400][120/346], lr: 0.00000019 	 loss = 0.2123(0.5342)
2023/09/17 05:27:50 - INFO - root -   Epoch: [63/400][140/346], lr: 0.00000019 	 loss = 0.6190(0.5365)
2023/09/17 05:28:51 - INFO - root -   Epoch: [63/400][160/346], lr: 0.00000019 	 loss = 0.2712(0.5463)
2023/09/17 05:29:34 - INFO - root -   Epoch: [63/400][180/346], lr: 0.00000019 	 loss = 0.7763(0.5488)
2023/09/17 05:30:34 - INFO - root -   Epoch: [63/400][200/346], lr: 0.00000019 	 loss = 0.1541(0.5427)
2023/09/17 05:31:17 - INFO - root -   Epoch: [63/400][220/346], lr: 0.00000019 	 loss = 0.1883(0.5460)
2023/09/17 05:32:18 - INFO - root -   Epoch: [63/400][240/346], lr: 0.00000019 	 loss = 0.2289(0.5526)
2023/09/17 05:33:01 - INFO - root -   Epoch: [63/400][260/346], lr: 0.00000019 	 loss = 0.7939(0.5449)
2023/09/17 05:34:02 - INFO - root -   Epoch: [63/400][280/346], lr: 0.00000019 	 loss = 0.1455(0.5618)
2023/09/17 05:34:45 - INFO - root -   Epoch: [63/400][300/346], lr: 0.00000019 	 loss = 0.4642(0.5706)
2023/09/17 05:35:45 - INFO - root -   Epoch: [63/400][320/346], lr: 0.00000019 	 loss = 0.2168(0.5645)
2023/09/17 05:36:27 - INFO - root -   Epoch: [63/400][340/346], lr: 0.00000019 	 loss = 1.0120(0.5641)
2023/09/17 05:36:31 - INFO - root -   Epoch: [63/400] 	 loss = 0.5652
2023/09/17 05:36:31 - INFO - root -   train_accuracy = 0.6922
2023/09/17 05:36:53 - INFO - root -   Epoch: [64/400][0/346], lr: 0.00000019 	 loss = 0.1793(0.1793)
2023/09/17 05:37:36 - INFO - root -   Epoch: [64/400][20/346], lr: 0.00000019 	 loss = 0.3845(0.4617)
2023/09/17 05:38:37 - INFO - root -   Epoch: [64/400][40/346], lr: 0.00000019 	 loss = 0.5097(0.5255)
2023/09/17 05:39:20 - INFO - root -   Epoch: [64/400][60/346], lr: 0.00000019 	 loss = 0.4515(0.4890)
2023/09/17 05:40:22 - INFO - root -   Epoch: [64/400][80/346], lr: 0.00000019 	 loss = 0.5209(0.5120)
2023/09/17 05:41:05 - INFO - root -   Epoch: [64/400][100/346], lr: 0.00000019 	 loss = 0.2544(0.5129)
2023/09/17 05:42:06 - INFO - root -   Epoch: [64/400][120/346], lr: 0.00000019 	 loss = 0.4065(0.5456)
2023/09/17 05:42:50 - INFO - root -   Epoch: [64/400][140/346], lr: 0.00000019 	 loss = 0.6689(0.5484)
2023/09/17 05:43:51 - INFO - root -   Epoch: [64/400][160/346], lr: 0.00000019 	 loss = 0.3681(0.5545)
2023/09/17 05:44:34 - INFO - root -   Epoch: [64/400][180/346], lr: 0.00000019 	 loss = 0.8449(0.5676)
2023/09/17 05:45:35 - INFO - root -   Epoch: [64/400][200/346], lr: 0.00000019 	 loss = 0.1982(0.5623)
2023/09/17 05:46:19 - INFO - root -   Epoch: [64/400][220/346], lr: 0.00000019 	 loss = 0.4025(0.5680)
2023/09/17 05:47:20 - INFO - root -   Epoch: [64/400][240/346], lr: 0.00000019 	 loss = 0.3142(0.5662)
2023/09/17 05:48:03 - INFO - root -   Epoch: [64/400][260/346], lr: 0.00000019 	 loss = 0.5035(0.5605)
2023/09/17 05:49:04 - INFO - root -   Epoch: [64/400][280/346], lr: 0.00000019 	 loss = 0.2447(0.5723)
2023/09/17 05:49:47 - INFO - root -   Epoch: [64/400][300/346], lr: 0.00000019 	 loss = 0.7061(0.5737)
2023/09/17 05:50:48 - INFO - root -   Epoch: [64/400][320/346], lr: 0.00000019 	 loss = 0.4122(0.5782)
2023/09/17 05:51:30 - INFO - root -   Epoch: [64/400][340/346], lr: 0.00000019 	 loss = 0.9120(0.5791)
2023/09/17 05:51:35 - INFO - root -   Epoch: [64/400] 	 loss = 0.5784
2023/09/17 05:55:21 - INFO - root -   precision = 0.6379
2023/09/17 05:55:21 - INFO - root -   eval_loss = 0.6198
2023/09/17 05:55:22 - INFO - root -   train_accuracy = 0.6994
2023/09/17 05:55:44 - INFO - root -   Epoch: [65/400][0/346], lr: 0.00000019 	 loss = 0.2148(0.2148)
2023/09/17 05:56:27 - INFO - root -   Epoch: [65/400][20/346], lr: 0.00000019 	 loss = 0.5430(0.4569)
2023/09/17 05:57:28 - INFO - root -   Epoch: [65/400][40/346], lr: 0.00000019 	 loss = 0.6526(0.5461)
2023/09/17 05:58:11 - INFO - root -   Epoch: [65/400][60/346], lr: 0.00000019 	 loss = 0.3330(0.5061)
2023/09/17 05:59:12 - INFO - root -   Epoch: [65/400][80/346], lr: 0.00000019 	 loss = 0.2214(0.4989)
2023/09/17 05:59:55 - INFO - root -   Epoch: [65/400][100/346], lr: 0.00000019 	 loss = 0.3283(0.5029)
2023/09/17 06:00:55 - INFO - root -   Epoch: [65/400][120/346], lr: 0.00000019 	 loss = 0.1577(0.5400)
2023/09/17 06:01:38 - INFO - root -   Epoch: [65/400][140/346], lr: 0.00000019 	 loss = 1.0902(0.5443)
2023/09/17 06:02:38 - INFO - root -   Epoch: [65/400][160/346], lr: 0.00000019 	 loss = 0.1941(0.5530)
2023/09/17 06:03:21 - INFO - root -   Epoch: [65/400][180/346], lr: 0.00000019 	 loss = 0.3699(0.5542)
2023/09/17 06:04:22 - INFO - root -   Epoch: [65/400][200/346], lr: 0.00000019 	 loss = 0.1534(0.5482)
2023/09/17 06:05:04 - INFO - root -   Epoch: [65/400][220/346], lr: 0.00000019 	 loss = 0.3216(0.5481)
2023/09/17 06:06:05 - INFO - root -   Epoch: [65/400][240/346], lr: 0.00000019 	 loss = 0.1940(0.5422)
2023/09/17 06:06:48 - INFO - root -   Epoch: [65/400][260/346], lr: 0.00000019 	 loss = 0.5171(0.5348)
2023/09/17 06:07:48 - INFO - root -   Epoch: [65/400][280/346], lr: 0.00000019 	 loss = 0.1518(0.5516)
2023/09/17 06:08:31 - INFO - root -   Epoch: [65/400][300/346], lr: 0.00000019 	 loss = 0.2642(0.5544)
2023/09/17 06:09:32 - INFO - root -   Epoch: [65/400][320/346], lr: 0.00000019 	 loss = 0.3192(0.5573)
2023/09/17 06:10:14 - INFO - root -   Epoch: [65/400][340/346], lr: 0.00000019 	 loss = 1.4512(0.5592)
2023/09/17 06:10:18 - INFO - root -   Epoch: [65/400] 	 loss = 0.5592
2023/09/17 06:10:18 - INFO - root -   train_accuracy = 0.7254
2023/09/17 06:10:39 - INFO - root -   Epoch: [66/400][0/346], lr: 0.00000019 	 loss = 0.1062(0.1062)
2023/09/17 06:11:22 - INFO - root -   Epoch: [66/400][20/346], lr: 0.00000019 	 loss = 0.1707(0.4474)
2023/09/17 06:12:23 - INFO - root -   Epoch: [66/400][40/346], lr: 0.00000019 	 loss = 0.2537(0.5062)
2023/09/17 06:13:07 - INFO - root -   Epoch: [66/400][60/346], lr: 0.00000019 	 loss = 0.4480(0.4952)
2023/09/17 06:14:07 - INFO - root -   Epoch: [66/400][80/346], lr: 0.00000019 	 loss = 0.5028(0.5021)
2023/09/17 06:14:51 - INFO - root -   Epoch: [66/400][100/346], lr: 0.00000019 	 loss = 0.4371(0.5200)
2023/09/17 06:15:51 - INFO - root -   Epoch: [66/400][120/346], lr: 0.00000019 	 loss = 0.7533(0.5515)
2023/09/17 06:16:34 - INFO - root -   Epoch: [66/400][140/346], lr: 0.00000019 	 loss = 1.0074(0.5460)
2023/09/17 06:17:35 - INFO - root -   Epoch: [66/400][160/346], lr: 0.00000019 	 loss = 0.1435(0.5595)
2023/09/17 06:18:18 - INFO - root -   Epoch: [66/400][180/346], lr: 0.00000019 	 loss = 0.6578(0.5528)
2023/09/17 06:19:19 - INFO - root -   Epoch: [66/400][200/346], lr: 0.00000019 	 loss = 0.1856(0.5484)
2023/09/17 06:20:02 - INFO - root -   Epoch: [66/400][220/346], lr: 0.00000019 	 loss = 0.3099(0.5583)
2023/09/17 06:21:03 - INFO - root -   Epoch: [66/400][240/346], lr: 0.00000019 	 loss = 0.4063(0.5635)
2023/09/17 06:21:46 - INFO - root -   Epoch: [66/400][260/346], lr: 0.00000019 	 loss = 0.9785(0.5583)
2023/09/17 06:22:46 - INFO - root -   Epoch: [66/400][280/346], lr: 0.00000019 	 loss = 0.2621(0.5757)
2023/09/17 06:23:30 - INFO - root -   Epoch: [66/400][300/346], lr: 0.00000019 	 loss = 0.3350(0.5774)
2023/09/17 06:24:30 - INFO - root -   Epoch: [66/400][320/346], lr: 0.00000019 	 loss = 0.2572(0.5761)
2023/09/17 06:25:12 - INFO - root -   Epoch: [66/400][340/346], lr: 0.00000019 	 loss = 1.5678(0.5746)
2023/09/17 06:25:16 - INFO - root -   Epoch: [66/400] 	 loss = 0.5743
2023/09/17 06:25:16 - INFO - root -   train_accuracy = 0.7095
2023/09/17 06:25:38 - INFO - root -   Epoch: [67/400][0/346], lr: 0.00000020 	 loss = 0.1505(0.1505)
2023/09/17 06:26:21 - INFO - root -   Epoch: [67/400][20/346], lr: 0.00000020 	 loss = 0.5648(0.4628)
2023/09/17 06:27:22 - INFO - root -   Epoch: [67/400][40/346], lr: 0.00000020 	 loss = 0.3235(0.5449)
2023/09/17 06:28:06 - INFO - root -   Epoch: [67/400][60/346], lr: 0.00000020 	 loss = 0.3911(0.5329)
2023/09/17 06:29:07 - INFO - root -   Epoch: [67/400][80/346], lr: 0.00000020 	 loss = 0.4329(0.5459)
2023/09/17 06:29:50 - INFO - root -   Epoch: [67/400][100/346], lr: 0.00000020 	 loss = 0.6139(0.5548)
2023/09/17 06:30:51 - INFO - root -   Epoch: [67/400][120/346], lr: 0.00000020 	 loss = 0.2309(0.5856)
2023/09/17 06:31:34 - INFO - root -   Epoch: [67/400][140/346], lr: 0.00000020 	 loss = 0.8353(0.5790)
2023/09/17 06:32:35 - INFO - root -   Epoch: [67/400][160/346], lr: 0.00000020 	 loss = 0.2486(0.5838)
2023/09/17 06:33:18 - INFO - root -   Epoch: [67/400][180/346], lr: 0.00000020 	 loss = 0.9011(0.5812)
2023/09/17 06:34:19 - INFO - root -   Epoch: [67/400][200/346], lr: 0.00000020 	 loss = 0.2081(0.5722)
2023/09/17 06:35:02 - INFO - root -   Epoch: [67/400][220/346], lr: 0.00000020 	 loss = 0.4182(0.5730)
2023/09/17 06:36:03 - INFO - root -   Epoch: [67/400][240/346], lr: 0.00000020 	 loss = 0.1621(0.5686)
2023/09/17 06:36:47 - INFO - root -   Epoch: [67/400][260/346], lr: 0.00000020 	 loss = 0.3014(0.5642)
2023/09/17 06:37:48 - INFO - root -   Epoch: [67/400][280/346], lr: 0.00000020 	 loss = 0.1971(0.5833)
2023/09/17 06:38:31 - INFO - root -   Epoch: [67/400][300/346], lr: 0.00000020 	 loss = 0.3116(0.5849)
2023/09/17 06:39:32 - INFO - root -   Epoch: [67/400][320/346], lr: 0.00000020 	 loss = 0.5152(0.5833)
2023/09/17 06:40:14 - INFO - root -   Epoch: [67/400][340/346], lr: 0.00000020 	 loss = 1.2880(0.5839)
2023/09/17 06:40:18 - INFO - root -   Epoch: [67/400] 	 loss = 0.5828
2023/09/17 06:40:18 - INFO - root -   train_accuracy = 0.6922
2023/09/17 06:40:40 - INFO - root -   Epoch: [68/400][0/346], lr: 0.00000020 	 loss = 0.6769(0.6769)
2023/09/17 06:41:24 - INFO - root -   Epoch: [68/400][20/346], lr: 0.00000020 	 loss = 0.3863(0.5080)
2023/09/17 06:42:26 - INFO - root -   Epoch: [68/400][40/346], lr: 0.00000020 	 loss = 0.5037(0.5847)
2023/09/17 06:43:09 - INFO - root -   Epoch: [68/400][60/346], lr: 0.00000020 	 loss = 0.5931(0.5165)
2023/09/17 06:44:10 - INFO - root -   Epoch: [68/400][80/346], lr: 0.00000020 	 loss = 0.3041(0.5260)
2023/09/17 06:44:54 - INFO - root -   Epoch: [68/400][100/346], lr: 0.00000020 	 loss = 0.3393(0.5168)
2023/09/17 06:45:55 - INFO - root -   Epoch: [68/400][120/346], lr: 0.00000020 	 loss = 0.1822(0.5433)
2023/09/17 06:46:38 - INFO - root -   Epoch: [68/400][140/346], lr: 0.00000020 	 loss = 0.6814(0.5396)
2023/09/17 06:47:38 - INFO - root -   Epoch: [68/400][160/346], lr: 0.00000020 	 loss = 0.1850(0.5452)
2023/09/17 06:48:21 - INFO - root -   Epoch: [68/400][180/346], lr: 0.00000020 	 loss = 0.5198(0.5566)
2023/09/17 06:49:22 - INFO - root -   Epoch: [68/400][200/346], lr: 0.00000020 	 loss = 0.2117(0.5439)
2023/09/17 06:50:05 - INFO - root -   Epoch: [68/400][220/346], lr: 0.00000020 	 loss = 0.3049(0.5469)
2023/09/17 06:51:06 - INFO - root -   Epoch: [68/400][240/346], lr: 0.00000020 	 loss = 0.1906(0.5404)
2023/09/17 06:51:49 - INFO - root -   Epoch: [68/400][260/346], lr: 0.00000020 	 loss = 0.3511(0.5331)
2023/09/17 06:52:50 - INFO - root -   Epoch: [68/400][280/346], lr: 0.00000020 	 loss = 0.3627(0.5444)
2023/09/17 06:53:33 - INFO - root -   Epoch: [68/400][300/346], lr: 0.00000020 	 loss = 0.1751(0.5479)
2023/09/17 06:54:33 - INFO - root -   Epoch: [68/400][320/346], lr: 0.00000020 	 loss = 0.2682(0.5470)
2023/09/17 06:55:15 - INFO - root -   Epoch: [68/400][340/346], lr: 0.00000020 	 loss = 1.2617(0.5518)
2023/09/17 06:55:19 - INFO - root -   Epoch: [68/400] 	 loss = 0.5507
2023/09/17 06:55:19 - INFO - root -   train_accuracy = 0.7038
2023/09/17 06:55:41 - INFO - root -   Epoch: [69/400][0/346], lr: 0.00000020 	 loss = 0.4819(0.4819)
2023/09/17 06:56:24 - INFO - root -   Epoch: [69/400][20/346], lr: 0.00000020 	 loss = 0.1053(0.4893)
2023/09/17 06:57:24 - INFO - root -   Epoch: [69/400][40/346], lr: 0.00000020 	 loss = 0.3797(0.5154)
2023/09/17 06:58:08 - INFO - root -   Epoch: [69/400][60/346], lr: 0.00000020 	 loss = 0.6371(0.4861)
2023/09/17 06:59:08 - INFO - root -   Epoch: [69/400][80/346], lr: 0.00000020 	 loss = 0.2911(0.5047)
2023/09/17 06:59:51 - INFO - root -   Epoch: [69/400][100/346], lr: 0.00000020 	 loss = 0.4851(0.5286)
2023/09/17 07:00:52 - INFO - root -   Epoch: [69/400][120/346], lr: 0.00000020 	 loss = 0.2183(0.5465)
2023/09/17 07:01:35 - INFO - root -   Epoch: [69/400][140/346], lr: 0.00000020 	 loss = 0.6042(0.5345)
2023/09/17 07:02:36 - INFO - root -   Epoch: [69/400][160/346], lr: 0.00000020 	 loss = 0.1806(0.5422)
2023/09/17 07:03:19 - INFO - root -   Epoch: [69/400][180/346], lr: 0.00000020 	 loss = 0.5179(0.5513)
2023/09/17 07:04:19 - INFO - root -   Epoch: [69/400][200/346], lr: 0.00000020 	 loss = 0.1157(0.5417)
2023/09/17 07:05:02 - INFO - root -   Epoch: [69/400][220/346], lr: 0.00000020 	 loss = 0.3498(0.5445)
2023/09/17 07:06:03 - INFO - root -   Epoch: [69/400][240/346], lr: 0.00000020 	 loss = 0.6035(0.5419)
2023/09/17 07:06:46 - INFO - root -   Epoch: [69/400][260/346], lr: 0.00000020 	 loss = 0.5599(0.5344)
2023/09/17 07:07:46 - INFO - root -   Epoch: [69/400][280/346], lr: 0.00000020 	 loss = 0.3034(0.5499)
2023/09/17 07:08:30 - INFO - root -   Epoch: [69/400][300/346], lr: 0.00000020 	 loss = 0.1858(0.5534)
2023/09/17 07:09:29 - INFO - root -   Epoch: [69/400][320/346], lr: 0.00000020 	 loss = 0.2188(0.5560)
2023/09/17 07:10:11 - INFO - root -   Epoch: [69/400][340/346], lr: 0.00000020 	 loss = 1.1739(0.5554)
2023/09/17 07:10:16 - INFO - root -   Epoch: [69/400] 	 loss = 0.5546
2023/09/17 07:14:03 - INFO - root -   precision = 0.6839
2023/09/17 07:14:03 - INFO - root -   eval_loss = 0.6197
2023/09/17 07:14:04 - INFO - root -   train_accuracy = 0.7095
2023/09/17 07:14:26 - INFO - root -   Epoch: [70/400][0/346], lr: 0.00000020 	 loss = 0.3256(0.3256)
2023/09/17 07:15:09 - INFO - root -   Epoch: [70/400][20/346], lr: 0.00000020 	 loss = 0.3886(0.4084)
2023/09/17 07:16:10 - INFO - root -   Epoch: [70/400][40/346], lr: 0.00000020 	 loss = 0.3146(0.4534)
2023/09/17 07:16:52 - INFO - root -   Epoch: [70/400][60/346], lr: 0.00000020 	 loss = 0.7529(0.4392)
2023/09/17 07:17:53 - INFO - root -   Epoch: [70/400][80/346], lr: 0.00000020 	 loss = 0.2844(0.4826)
2023/09/17 07:18:36 - INFO - root -   Epoch: [70/400][100/346], lr: 0.00000020 	 loss = 0.4761(0.4967)
2023/09/17 07:19:36 - INFO - root -   Epoch: [70/400][120/346], lr: 0.00000020 	 loss = 0.4498(0.5320)
2023/09/17 07:20:20 - INFO - root -   Epoch: [70/400][140/346], lr: 0.00000020 	 loss = 0.4565(0.5344)
2023/09/17 07:21:20 - INFO - root -   Epoch: [70/400][160/346], lr: 0.00000020 	 loss = 0.1669(0.5505)
2023/09/17 07:22:03 - INFO - root -   Epoch: [70/400][180/346], lr: 0.00000020 	 loss = 0.7202(0.5574)
2023/09/17 07:23:04 - INFO - root -   Epoch: [70/400][200/346], lr: 0.00000020 	 loss = 0.0992(0.5507)
2023/09/17 07:23:47 - INFO - root -   Epoch: [70/400][220/346], lr: 0.00000020 	 loss = 0.3135(0.5540)
2023/09/17 07:24:47 - INFO - root -   Epoch: [70/400][240/346], lr: 0.00000020 	 loss = 0.1939(0.5503)
2023/09/17 07:25:30 - INFO - root -   Epoch: [70/400][260/346], lr: 0.00000020 	 loss = 1.3049(0.5532)
2023/09/17 07:26:31 - INFO - root -   Epoch: [70/400][280/346], lr: 0.00000020 	 loss = 0.2232(0.5680)
2023/09/17 07:27:14 - INFO - root -   Epoch: [70/400][300/346], lr: 0.00000020 	 loss = 0.3265(0.5697)
2023/09/17 07:28:14 - INFO - root -   Epoch: [70/400][320/346], lr: 0.00000020 	 loss = 0.3721(0.5718)
2023/09/17 07:28:56 - INFO - root -   Epoch: [70/400][340/346], lr: 0.00000020 	 loss = 0.8729(0.5699)
2023/09/17 07:29:00 - INFO - root -   Epoch: [70/400] 	 loss = 0.5703
2023/09/17 07:29:00 - INFO - root -   train_accuracy = 0.6965
2023/09/17 07:29:22 - INFO - root -   Epoch: [71/400][0/346], lr: 0.00000020 	 loss = 0.0952(0.0952)
2023/09/17 07:30:05 - INFO - root -   Epoch: [71/400][20/346], lr: 0.00000020 	 loss = 0.4255(0.4515)
2023/09/17 07:31:05 - INFO - root -   Epoch: [71/400][40/346], lr: 0.00000020 	 loss = 0.4931(0.5129)
2023/09/17 07:31:49 - INFO - root -   Epoch: [71/400][60/346], lr: 0.00000020 	 loss = 0.5841(0.4638)
2023/09/17 07:32:50 - INFO - root -   Epoch: [71/400][80/346], lr: 0.00000020 	 loss = 0.3505(0.4908)
2023/09/17 07:33:33 - INFO - root -   Epoch: [71/400][100/346], lr: 0.00000020 	 loss = 0.7966(0.4988)
2023/09/17 07:34:33 - INFO - root -   Epoch: [71/400][120/346], lr: 0.00000020 	 loss = 0.2270(0.5276)
2023/09/17 07:35:16 - INFO - root -   Epoch: [71/400][140/346], lr: 0.00000020 	 loss = 0.4232(0.5172)
2023/09/17 07:36:17 - INFO - root -   Epoch: [71/400][160/346], lr: 0.00000020 	 loss = 0.0953(0.5235)
2023/09/17 07:37:00 - INFO - root -   Epoch: [71/400][180/346], lr: 0.00000020 	 loss = 0.8188(0.5376)
2023/09/17 07:38:00 - INFO - root -   Epoch: [71/400][200/346], lr: 0.00000020 	 loss = 0.1427(0.5318)
2023/09/17 07:38:43 - INFO - root -   Epoch: [71/400][220/346], lr: 0.00000020 	 loss = 0.3397(0.5379)
2023/09/17 07:39:44 - INFO - root -   Epoch: [71/400][240/346], lr: 0.00000020 	 loss = 0.1066(0.5363)
2023/09/17 07:40:27 - INFO - root -   Epoch: [71/400][260/346], lr: 0.00000020 	 loss = 0.5585(0.5467)
2023/09/17 07:41:27 - INFO - root -   Epoch: [71/400][280/346], lr: 0.00000020 	 loss = 0.5966(0.5643)
2023/09/17 07:42:11 - INFO - root -   Epoch: [71/400][300/346], lr: 0.00000020 	 loss = 0.2310(0.5620)
2023/09/17 07:43:10 - INFO - root -   Epoch: [71/400][320/346], lr: 0.00000020 	 loss = 0.3972(0.5656)
2023/09/17 07:43:53 - INFO - root -   Epoch: [71/400][340/346], lr: 0.00000020 	 loss = 0.6825(0.5629)
2023/09/17 07:43:57 - INFO - root -   Epoch: [71/400] 	 loss = 0.5637
2023/09/17 07:43:57 - INFO - root -   train_accuracy = 0.7038
2023/09/17 07:44:18 - INFO - root -   Epoch: [72/400][0/346], lr: 0.00000020 	 loss = 0.3357(0.3357)
2023/09/17 07:45:01 - INFO - root -   Epoch: [72/400][20/346], lr: 0.00000020 	 loss = 0.2447(0.3715)
2023/09/17 07:46:02 - INFO - root -   Epoch: [72/400][40/346], lr: 0.00000020 	 loss = 0.3381(0.4531)
2023/09/17 07:46:45 - INFO - root -   Epoch: [72/400][60/346], lr: 0.00000020 	 loss = 0.5908(0.4299)
2023/09/17 07:47:46 - INFO - root -   Epoch: [72/400][80/346], lr: 0.00000020 	 loss = 0.5441(0.4711)
2023/09/17 07:48:29 - INFO - root -   Epoch: [72/400][100/346], lr: 0.00000020 	 loss = 0.4364(0.4851)
2023/09/17 07:49:30 - INFO - root -   Epoch: [72/400][120/346], lr: 0.00000020 	 loss = 0.3461(0.5135)
2023/09/17 07:50:13 - INFO - root -   Epoch: [72/400][140/346], lr: 0.00000020 	 loss = 0.4825(0.5081)
2023/09/17 07:51:13 - INFO - root -   Epoch: [72/400][160/346], lr: 0.00000020 	 loss = 0.1352(0.5102)
2023/09/17 07:51:56 - INFO - root -   Epoch: [72/400][180/346], lr: 0.00000020 	 loss = 0.7859(0.5276)
2023/09/17 07:52:57 - INFO - root -   Epoch: [72/400][200/346], lr: 0.00000020 	 loss = 0.1586(0.5259)
2023/09/17 07:53:40 - INFO - root -   Epoch: [72/400][220/346], lr: 0.00000020 	 loss = 0.3299(0.5359)
2023/09/17 07:54:40 - INFO - root -   Epoch: [72/400][240/346], lr: 0.00000020 	 loss = 0.3705(0.5486)
2023/09/17 07:55:23 - INFO - root -   Epoch: [72/400][260/346], lr: 0.00000020 	 loss = 1.1120(0.5572)
2023/09/17 07:56:23 - INFO - root -   Epoch: [72/400][280/346], lr: 0.00000020 	 loss = 0.2494(0.5715)
2023/09/17 07:57:07 - INFO - root -   Epoch: [72/400][300/346], lr: 0.00000020 	 loss = 0.3944(0.5808)
2023/09/17 07:58:07 - INFO - root -   Epoch: [72/400][320/346], lr: 0.00000020 	 loss = 0.6973(0.5854)
2023/09/17 07:58:49 - INFO - root -   Epoch: [72/400][340/346], lr: 0.00000020 	 loss = 0.8204(0.5813)
2023/09/17 07:58:53 - INFO - root -   Epoch: [72/400] 	 loss = 0.5827
2023/09/17 07:58:53 - INFO - root -   train_accuracy = 0.6994
2023/09/17 07:59:15 - INFO - root -   Epoch: [73/400][0/346], lr: 0.00000020 	 loss = 0.2585(0.2585)
2023/09/17 07:59:58 - INFO - root -   Epoch: [73/400][20/346], lr: 0.00000020 	 loss = 0.2490(0.5725)
2023/09/17 08:00:59 - INFO - root -   Epoch: [73/400][40/346], lr: 0.00000020 	 loss = 0.4605(0.6240)
2023/09/17 08:01:42 - INFO - root -   Epoch: [73/400][60/346], lr: 0.00000020 	 loss = 0.7720(0.6000)
2023/09/17 08:02:43 - INFO - root -   Epoch: [73/400][80/346], lr: 0.00000020 	 loss = 0.4837(0.6082)
2023/09/17 08:03:26 - INFO - root -   Epoch: [73/400][100/346], lr: 0.00000020 	 loss = 0.6587(0.6235)
2023/09/17 08:04:26 - INFO - root -   Epoch: [73/400][120/346], lr: 0.00000020 	 loss = 0.4489(0.6516)
2023/09/17 08:05:09 - INFO - root -   Epoch: [73/400][140/346], lr: 0.00000020 	 loss = 0.8019(0.6439)
2023/09/17 08:06:09 - INFO - root -   Epoch: [73/400][160/346], lr: 0.00000020 	 loss = 0.1779(0.6361)
2023/09/17 08:06:52 - INFO - root -   Epoch: [73/400][180/346], lr: 0.00000020 	 loss = 0.5396(0.6350)
2023/09/17 08:07:53 - INFO - root -   Epoch: [73/400][200/346], lr: 0.00000020 	 loss = 0.1026(0.6249)
2023/09/17 08:08:36 - INFO - root -   Epoch: [73/400][220/346], lr: 0.00000020 	 loss = 0.3352(0.6188)
2023/09/17 08:09:36 - INFO - root -   Epoch: [73/400][240/346], lr: 0.00000020 	 loss = 0.3022(0.6170)
2023/09/17 08:10:19 - INFO - root -   Epoch: [73/400][260/346], lr: 0.00000020 	 loss = 1.3188(0.6211)
2023/09/17 08:11:20 - INFO - root -   Epoch: [73/400][280/346], lr: 0.00000020 	 loss = 0.3508(0.6343)
2023/09/17 08:12:03 - INFO - root -   Epoch: [73/400][300/346], lr: 0.00000020 	 loss = 0.4512(0.6343)
2023/09/17 08:13:03 - INFO - root -   Epoch: [73/400][320/346], lr: 0.00000020 	 loss = 0.5216(0.6338)
2023/09/17 08:13:45 - INFO - root -   Epoch: [73/400][340/346], lr: 0.00000020 	 loss = 1.1027(0.6310)
2023/09/17 08:13:49 - INFO - root -   Epoch: [73/400] 	 loss = 0.6308
2023/09/17 08:13:49 - INFO - root -   train_accuracy = 0.6387
2023/09/17 08:14:11 - INFO - root -   Epoch: [74/400][0/346], lr: 0.00000021 	 loss = 0.4040(0.4040)
2023/09/17 08:14:53 - INFO - root -   Epoch: [74/400][20/346], lr: 0.00000021 	 loss = 0.4216(0.5665)
2023/09/17 08:15:54 - INFO - root -   Epoch: [74/400][40/346], lr: 0.00000021 	 loss = 0.4286(0.5824)
2023/09/17 08:16:37 - INFO - root -   Epoch: [74/400][60/346], lr: 0.00000021 	 loss = 0.6896(0.5710)
2023/09/17 08:17:37 - INFO - root -   Epoch: [74/400][80/346], lr: 0.00000021 	 loss = 0.6475(0.5762)
2023/09/17 08:18:20 - INFO - root -   Epoch: [74/400][100/346], lr: 0.00000021 	 loss = 0.7195(0.5847)
2023/09/17 08:19:20 - INFO - root -   Epoch: [74/400][120/346], lr: 0.00000021 	 loss = 0.2459(0.6064)
2023/09/17 08:20:03 - INFO - root -   Epoch: [74/400][140/346], lr: 0.00000021 	 loss = 0.4594(0.5983)
2023/09/17 08:21:04 - INFO - root -   Epoch: [74/400][160/346], lr: 0.00000021 	 loss = 0.2795(0.5990)
2023/09/17 08:21:46 - INFO - root -   Epoch: [74/400][180/346], lr: 0.00000021 	 loss = 0.6703(0.6009)
2023/09/17 08:22:47 - INFO - root -   Epoch: [74/400][200/346], lr: 0.00000021 	 loss = 0.3043(0.5962)
2023/09/17 08:23:30 - INFO - root -   Epoch: [74/400][220/346], lr: 0.00000021 	 loss = 0.1588(0.5943)
2023/09/17 08:24:30 - INFO - root -   Epoch: [74/400][240/346], lr: 0.00000021 	 loss = 0.1921(0.5999)
2023/09/17 08:25:13 - INFO - root -   Epoch: [74/400][260/346], lr: 0.00000021 	 loss = 0.6497(0.6066)
2023/09/17 08:26:13 - INFO - root -   Epoch: [74/400][280/346], lr: 0.00000021 	 loss = 0.3848(0.6170)
2023/09/17 08:26:56 - INFO - root -   Epoch: [74/400][300/346], lr: 0.00000021 	 loss = 0.2056(0.6163)
2023/09/17 08:27:56 - INFO - root -   Epoch: [74/400][320/346], lr: 0.00000021 	 loss = 0.3995(0.6174)
2023/09/17 08:28:38 - INFO - root -   Epoch: [74/400][340/346], lr: 0.00000021 	 loss = 1.1901(0.6166)
2023/09/17 08:28:42 - INFO - root -   Epoch: [74/400] 	 loss = 0.6156
2023/09/17 08:32:30 - INFO - root -   precision = 0.6609
2023/09/17 08:32:30 - INFO - root -   eval_loss = 0.6174
2023/09/17 08:32:31 - INFO - root -   train_accuracy = 0.6633
2023/09/17 08:32:52 - INFO - root -   Epoch: [75/400][0/346], lr: 0.00000021 	 loss = 0.2808(0.2808)
2023/09/17 08:33:35 - INFO - root -   Epoch: [75/400][20/346], lr: 0.00000021 	 loss = 0.2953(0.5060)
2023/09/17 08:34:36 - INFO - root -   Epoch: [75/400][40/346], lr: 0.00000021 	 loss = 0.4553(0.5542)
2023/09/17 08:35:19 - INFO - root -   Epoch: [75/400][60/346], lr: 0.00000021 	 loss = 0.5692(0.5545)
2023/09/17 08:36:20 - INFO - root -   Epoch: [75/400][80/346], lr: 0.00000021 	 loss = 0.3485(0.5737)
2023/09/17 08:37:03 - INFO - root -   Epoch: [75/400][100/346], lr: 0.00000021 	 loss = 0.7568(0.5896)
2023/09/17 08:38:03 - INFO - root -   Epoch: [75/400][120/346], lr: 0.00000021 	 loss = 0.4907(0.6228)
2023/09/17 08:38:46 - INFO - root -   Epoch: [75/400][140/346], lr: 0.00000021 	 loss = 0.9274(0.6072)
2023/09/17 08:39:47 - INFO - root -   Epoch: [75/400][160/346], lr: 0.00000021 	 loss = 0.1894(0.6022)
2023/09/17 08:40:30 - INFO - root -   Epoch: [75/400][180/346], lr: 0.00000021 	 loss = 0.6063(0.6000)
2023/09/17 08:41:30 - INFO - root -   Epoch: [75/400][200/346], lr: 0.00000021 	 loss = 0.1254(0.5874)
2023/09/17 08:42:14 - INFO - root -   Epoch: [75/400][220/346], lr: 0.00000021 	 loss = 0.4239(0.5896)
2023/09/17 08:43:14 - INFO - root -   Epoch: [75/400][240/346], lr: 0.00000021 	 loss = 0.2511(0.5902)
2023/09/17 08:43:57 - INFO - root -   Epoch: [75/400][260/346], lr: 0.00000021 	 loss = 0.6741(0.5893)
2023/09/17 08:44:57 - INFO - root -   Epoch: [75/400][280/346], lr: 0.00000021 	 loss = 0.5042(0.5986)
2023/09/17 08:45:40 - INFO - root -   Epoch: [75/400][300/346], lr: 0.00000021 	 loss = 0.4216(0.6035)
2023/09/17 08:46:41 - INFO - root -   Epoch: [75/400][320/346], lr: 0.00000021 	 loss = 0.4001(0.6025)
2023/09/17 08:47:23 - INFO - root -   Epoch: [75/400][340/346], lr: 0.00000021 	 loss = 1.1545(0.6003)
2023/09/17 08:47:27 - INFO - root -   Epoch: [75/400] 	 loss = 0.5998
2023/09/17 08:47:27 - INFO - root -   train_accuracy = 0.6633
2023/09/17 08:47:49 - INFO - root -   Epoch: [76/400][0/346], lr: 0.00000021 	 loss = 0.3925(0.3925)
2023/09/17 08:48:32 - INFO - root -   Epoch: [76/400][20/346], lr: 0.00000021 	 loss = 0.2133(0.4981)
2023/09/17 08:49:32 - INFO - root -   Epoch: [76/400][40/346], lr: 0.00000021 	 loss = 0.4901(0.5651)
2023/09/17 08:50:15 - INFO - root -   Epoch: [76/400][60/346], lr: 0.00000021 	 loss = 0.4105(0.5398)
2023/09/17 08:51:16 - INFO - root -   Epoch: [76/400][80/346], lr: 0.00000021 	 loss = 0.3299(0.5487)
2023/09/17 08:51:59 - INFO - root -   Epoch: [76/400][100/346], lr: 0.00000021 	 loss = 0.8341(0.5478)
2023/09/17 08:53:00 - INFO - root -   Epoch: [76/400][120/346], lr: 0.00000021 	 loss = 0.5036(0.5836)
2023/09/17 08:53:43 - INFO - root -   Epoch: [76/400][140/346], lr: 0.00000021 	 loss = 0.7305(0.5703)
2023/09/17 08:54:43 - INFO - root -   Epoch: [76/400][160/346], lr: 0.00000021 	 loss = 0.1086(0.5728)
2023/09/17 08:55:26 - INFO - root -   Epoch: [76/400][180/346], lr: 0.00000021 	 loss = 0.5040(0.5798)
2023/09/17 08:56:27 - INFO - root -   Epoch: [76/400][200/346], lr: 0.00000021 	 loss = 0.1627(0.5675)
2023/09/17 08:57:10 - INFO - root -   Epoch: [76/400][220/346], lr: 0.00000021 	 loss = 0.2515(0.5693)
2023/09/17 08:58:10 - INFO - root -   Epoch: [76/400][240/346], lr: 0.00000021 	 loss = 0.2130(0.5729)
2023/09/17 08:58:53 - INFO - root -   Epoch: [76/400][260/346], lr: 0.00000021 	 loss = 0.9066(0.5682)
2023/09/17 08:59:53 - INFO - root -   Epoch: [76/400][280/346], lr: 0.00000021 	 loss = 0.3755(0.5754)
2023/09/17 09:00:37 - INFO - root -   Epoch: [76/400][300/346], lr: 0.00000021 	 loss = 0.3413(0.5802)
2023/09/17 09:01:37 - INFO - root -   Epoch: [76/400][320/346], lr: 0.00000021 	 loss = 0.3354(0.5795)
2023/09/17 09:02:20 - INFO - root -   Epoch: [76/400][340/346], lr: 0.00000021 	 loss = 1.0560(0.5805)
2023/09/17 09:02:24 - INFO - root -   Epoch: [76/400] 	 loss = 0.5793
2023/09/17 09:02:24 - INFO - root -   train_accuracy = 0.6965
2023/09/17 09:02:46 - INFO - root -   Epoch: [77/400][0/346], lr: 0.00000021 	 loss = 0.2618(0.2618)
2023/09/17 09:03:29 - INFO - root -   Epoch: [77/400][20/346], lr: 0.00000021 	 loss = 0.3870(0.4803)
2023/09/17 09:04:30 - INFO - root -   Epoch: [77/400][40/346], lr: 0.00000021 	 loss = 0.4416(0.5297)
2023/09/17 09:05:14 - INFO - root -   Epoch: [77/400][60/346], lr: 0.00000021 	 loss = 0.9238(0.5264)
2023/09/17 09:06:15 - INFO - root -   Epoch: [77/400][80/346], lr: 0.00000021 	 loss = 0.4481(0.5279)
2023/09/17 09:06:58 - INFO - root -   Epoch: [77/400][100/346], lr: 0.00000021 	 loss = 0.4928(0.5288)
2023/09/17 09:07:59 - INFO - root -   Epoch: [77/400][120/346], lr: 0.00000021 	 loss = 0.1837(0.5721)
2023/09/17 09:08:42 - INFO - root -   Epoch: [77/400][140/346], lr: 0.00000021 	 loss = 0.4848(0.5697)
2023/09/17 09:09:43 - INFO - root -   Epoch: [77/400][160/346], lr: 0.00000021 	 loss = 0.2226(0.5798)
2023/09/17 09:10:26 - INFO - root -   Epoch: [77/400][180/346], lr: 0.00000021 	 loss = 0.9561(0.5789)
2023/09/17 09:11:27 - INFO - root -   Epoch: [77/400][200/346], lr: 0.00000021 	 loss = 0.2424(0.5654)
2023/09/17 09:12:10 - INFO - root -   Epoch: [77/400][220/346], lr: 0.00000021 	 loss = 0.1964(0.5691)
2023/09/17 09:13:11 - INFO - root -   Epoch: [77/400][240/346], lr: 0.00000021 	 loss = 0.1341(0.5650)
2023/09/17 09:13:54 - INFO - root -   Epoch: [77/400][260/346], lr: 0.00000021 	 loss = 0.7353(0.5617)
2023/09/17 09:14:55 - INFO - root -   Epoch: [77/400][280/346], lr: 0.00000021 	 loss = 0.3397(0.5750)
2023/09/17 09:15:38 - INFO - root -   Epoch: [77/400][300/346], lr: 0.00000021 	 loss = 0.4239(0.5757)
2023/09/17 09:16:39 - INFO - root -   Epoch: [77/400][320/346], lr: 0.00000021 	 loss = 0.2911(0.5736)
2023/09/17 09:17:20 - INFO - root -   Epoch: [77/400][340/346], lr: 0.00000021 	 loss = 1.0825(0.5725)
2023/09/17 09:17:25 - INFO - root -   Epoch: [77/400] 	 loss = 0.5716
2023/09/17 09:17:25 - INFO - root -   train_accuracy = 0.6994
2023/09/17 09:17:46 - INFO - root -   Epoch: [78/400][0/346], lr: 0.00000021 	 loss = 0.2028(0.2028)
2023/09/17 09:18:29 - INFO - root -   Epoch: [78/400][20/346], lr: 0.00000021 	 loss = 0.3722(0.4275)
2023/09/17 09:19:31 - INFO - root -   Epoch: [78/400][40/346], lr: 0.00000021 	 loss = 0.4773(0.5291)
2023/09/17 09:20:14 - INFO - root -   Epoch: [78/400][60/346], lr: 0.00000021 	 loss = 0.3558(0.4863)
2023/09/17 09:21:15 - INFO - root -   Epoch: [78/400][80/346], lr: 0.00000021 	 loss = 0.3615(0.4856)
2023/09/17 09:21:58 - INFO - root -   Epoch: [78/400][100/346], lr: 0.00000021 	 loss = 0.2285(0.4929)
2023/09/17 09:22:59 - INFO - root -   Epoch: [78/400][120/346], lr: 0.00000021 	 loss = 0.4426(0.5273)
2023/09/17 09:23:43 - INFO - root -   Epoch: [78/400][140/346], lr: 0.00000021 	 loss = 0.9485(0.5224)
2023/09/17 09:24:44 - INFO - root -   Epoch: [78/400][160/346], lr: 0.00000021 	 loss = 0.1454(0.5249)
2023/09/17 09:25:27 - INFO - root -   Epoch: [78/400][180/346], lr: 0.00000021 	 loss = 0.3962(0.5312)
2023/09/17 09:26:28 - INFO - root -   Epoch: [78/400][200/346], lr: 0.00000021 	 loss = 0.2356(0.5288)
2023/09/17 09:27:11 - INFO - root -   Epoch: [78/400][220/346], lr: 0.00000021 	 loss = 0.2215(0.5358)
2023/09/17 09:28:12 - INFO - root -   Epoch: [78/400][240/346], lr: 0.00000021 	 loss = 0.2602(0.5299)
2023/09/17 09:28:56 - INFO - root -   Epoch: [78/400][260/346], lr: 0.00000021 	 loss = 0.9595(0.5293)
2023/09/17 09:29:56 - INFO - root -   Epoch: [78/400][280/346], lr: 0.00000021 	 loss = 0.4016(0.5475)
2023/09/17 09:30:40 - INFO - root -   Epoch: [78/400][300/346], lr: 0.00000021 	 loss = 0.3133(0.5546)
2023/09/17 09:31:40 - INFO - root -   Epoch: [78/400][320/346], lr: 0.00000021 	 loss = 0.3744(0.5530)
2023/09/17 09:32:23 - INFO - root -   Epoch: [78/400][340/346], lr: 0.00000021 	 loss = 1.4584(0.5569)
2023/09/17 09:32:28 - INFO - root -   Epoch: [78/400] 	 loss = 0.5625
2023/09/17 09:32:28 - INFO - root -   train_accuracy = 0.7168
2023/09/17 09:32:49 - INFO - root -   Epoch: [79/400][0/346], lr: 0.00000021 	 loss = 0.2842(0.2842)
2023/09/17 09:33:32 - INFO - root -   Epoch: [79/400][20/346], lr: 0.00000021 	 loss = 1.1846(0.4933)
2023/09/17 09:34:34 - INFO - root -   Epoch: [79/400][40/346], lr: 0.00000021 	 loss = 0.4242(0.5258)
2023/09/17 09:35:17 - INFO - root -   Epoch: [79/400][60/346], lr: 0.00000021 	 loss = 0.9691(0.4950)
2023/09/17 09:36:18 - INFO - root -   Epoch: [79/400][80/346], lr: 0.00000021 	 loss = 0.1921(0.5207)
2023/09/17 09:37:01 - INFO - root -   Epoch: [79/400][100/346], lr: 0.00000021 	 loss = 0.7935(0.5353)
2023/09/17 09:38:02 - INFO - root -   Epoch: [79/400][120/346], lr: 0.00000021 	 loss = 0.4079(0.5531)
2023/09/17 09:38:45 - INFO - root -   Epoch: [79/400][140/346], lr: 0.00000021 	 loss = 0.6949(0.5512)
2023/09/17 09:39:46 - INFO - root -   Epoch: [79/400][160/346], lr: 0.00000021 	 loss = 0.1445(0.5535)
2023/09/17 09:40:29 - INFO - root -   Epoch: [79/400][180/346], lr: 0.00000021 	 loss = 0.6695(0.5630)
2023/09/17 09:41:30 - INFO - root -   Epoch: [79/400][200/346], lr: 0.00000021 	 loss = 0.2533(0.5519)
2023/09/17 09:42:13 - INFO - root -   Epoch: [79/400][220/346], lr: 0.00000021 	 loss = 0.1479(0.5610)
2023/09/17 09:43:14 - INFO - root -   Epoch: [79/400][240/346], lr: 0.00000021 	 loss = 0.2649(0.5568)
2023/09/17 09:43:57 - INFO - root -   Epoch: [79/400][260/346], lr: 0.00000021 	 loss = 0.8056(0.5511)
2023/09/17 09:44:58 - INFO - root -   Epoch: [79/400][280/346], lr: 0.00000021 	 loss = 0.2789(0.5677)
2023/09/17 09:45:42 - INFO - root -   Epoch: [79/400][300/346], lr: 0.00000021 	 loss = 0.2574(0.5681)
2023/09/17 09:46:42 - INFO - root -   Epoch: [79/400][320/346], lr: 0.00000021 	 loss = 0.5205(0.5690)
2023/09/17 09:47:24 - INFO - root -   Epoch: [79/400][340/346], lr: 0.00000021 	 loss = 1.7016(0.5684)
2023/09/17 09:47:28 - INFO - root -   Epoch: [79/400] 	 loss = 0.5694
2023/09/17 09:51:15 - INFO - root -   precision = 0.7011
2023/09/17 09:51:15 - INFO - root -   eval_loss = 0.6089
2023/09/17 09:51:16 - INFO - root -   train_accuracy = 0.7110
2023/09/17 09:51:37 - INFO - root -   Epoch: [80/400][0/346], lr: 0.00000021 	 loss = 0.4239(0.4239)
2023/09/17 09:52:20 - INFO - root -   Epoch: [80/400][20/346], lr: 0.00000021 	 loss = 0.1500(0.4094)
2023/09/17 09:53:20 - INFO - root -   Epoch: [80/400][40/346], lr: 0.00000021 	 loss = 0.2085(0.4636)
2023/09/17 09:54:03 - INFO - root -   Epoch: [80/400][60/346], lr: 0.00000021 	 loss = 0.8253(0.4412)
2023/09/17 09:55:04 - INFO - root -   Epoch: [80/400][80/346], lr: 0.00000021 	 loss = 0.4349(0.4768)
2023/09/17 09:55:47 - INFO - root -   Epoch: [80/400][100/346], lr: 0.00000021 	 loss = 0.8572(0.4894)
2023/09/17 09:56:47 - INFO - root -   Epoch: [80/400][120/346], lr: 0.00000021 	 loss = 0.4492(0.5339)
2023/09/17 09:57:30 - INFO - root -   Epoch: [80/400][140/346], lr: 0.00000021 	 loss = 0.3622(0.5273)
2023/09/17 09:58:30 - INFO - root -   Epoch: [80/400][160/346], lr: 0.00000021 	 loss = 0.1348(0.5367)
2023/09/17 09:59:13 - INFO - root -   Epoch: [80/400][180/346], lr: 0.00000021 	 loss = 0.4070(0.5437)
2023/09/17 10:00:13 - INFO - root -   Epoch: [80/400][200/346], lr: 0.00000021 	 loss = 0.1159(0.5447)
2023/09/17 10:00:56 - INFO - root -   Epoch: [80/400][220/346], lr: 0.00000021 	 loss = 0.1426(0.5509)
2023/09/17 10:01:56 - INFO - root -   Epoch: [80/400][240/346], lr: 0.00000021 	 loss = 0.2966(0.5446)
2023/09/17 10:02:39 - INFO - root -   Epoch: [80/400][260/346], lr: 0.00000021 	 loss = 0.6846(0.5412)
2023/09/17 10:03:39 - INFO - root -   Epoch: [80/400][280/346], lr: 0.00000021 	 loss = 0.2105(0.5587)
2023/09/17 10:04:22 - INFO - root -   Epoch: [80/400][300/346], lr: 0.00000021 	 loss = 0.3074(0.5661)
2023/09/17 10:05:21 - INFO - root -   Epoch: [80/400][320/346], lr: 0.00000021 	 loss = 0.3119(0.5587)
2023/09/17 10:06:04 - INFO - root -   Epoch: [80/400][340/346], lr: 0.00000021 	 loss = 1.2350(0.5576)
2023/09/17 10:06:08 - INFO - root -   Epoch: [80/400] 	 loss = 0.5573
2023/09/17 10:06:08 - INFO - root -   train_accuracy = 0.7081
2023/09/17 10:06:29 - INFO - root -   Epoch: [81/400][0/346], lr: 0.00000022 	 loss = 0.2211(0.2211)
2023/09/17 10:07:12 - INFO - root -   Epoch: [81/400][20/346], lr: 0.00000022 	 loss = 0.3570(0.4571)
2023/09/17 10:08:13 - INFO - root -   Epoch: [81/400][40/346], lr: 0.00000022 	 loss = 0.3462(0.5149)
2023/09/17 10:08:56 - INFO - root -   Epoch: [81/400][60/346], lr: 0.00000022 	 loss = 0.9444(0.4504)
2023/09/17 10:09:56 - INFO - root -   Epoch: [81/400][80/346], lr: 0.00000022 	 loss = 0.4109(0.4805)
2023/09/17 10:10:39 - INFO - root -   Epoch: [81/400][100/346], lr: 0.00000022 	 loss = 0.3546(0.5035)
2023/09/17 10:11:40 - INFO - root -   Epoch: [81/400][120/346], lr: 0.00000022 	 loss = 0.4714(0.5376)
2023/09/17 10:12:23 - INFO - root -   Epoch: [81/400][140/346], lr: 0.00000022 	 loss = 0.5278(0.5381)
2023/09/17 10:13:23 - INFO - root -   Epoch: [81/400][160/346], lr: 0.00000022 	 loss = 0.1520(0.5471)
2023/09/17 10:14:07 - INFO - root -   Epoch: [81/400][180/346], lr: 0.00000022 	 loss = 0.4497(0.5531)
2023/09/17 10:15:07 - INFO - root -   Epoch: [81/400][200/346], lr: 0.00000022 	 loss = 0.1013(0.5457)
2023/09/17 10:15:51 - INFO - root -   Epoch: [81/400][220/346], lr: 0.00000022 	 loss = 0.4303(0.5470)
2023/09/17 10:16:50 - INFO - root -   Epoch: [81/400][240/346], lr: 0.00000022 	 loss = 0.1183(0.5409)
2023/09/17 10:17:34 - INFO - root -   Epoch: [81/400][260/346], lr: 0.00000022 	 loss = 0.3542(0.5299)
2023/09/17 10:18:33 - INFO - root -   Epoch: [81/400][280/346], lr: 0.00000022 	 loss = 0.2867(0.5507)
2023/09/17 10:19:18 - INFO - root -   Epoch: [81/400][300/346], lr: 0.00000022 	 loss = 0.1067(0.5499)
2023/09/17 10:20:16 - INFO - root -   Epoch: [81/400][320/346], lr: 0.00000022 	 loss = 0.3310(0.5519)
2023/09/17 10:21:00 - INFO - root -   Epoch: [81/400][340/346], lr: 0.00000022 	 loss = 0.5147(0.5525)
2023/09/17 10:21:04 - INFO - root -   Epoch: [81/400] 	 loss = 0.5556
2023/09/17 10:21:04 - INFO - root -   train_accuracy = 0.7384
2023/09/17 10:21:26 - INFO - root -   Epoch: [82/400][0/346], lr: 0.00000022 	 loss = 0.2140(0.2140)
2023/09/17 10:22:09 - INFO - root -   Epoch: [82/400][20/346], lr: 0.00000022 	 loss = 0.1718(0.4526)
2023/09/17 10:23:09 - INFO - root -   Epoch: [82/400][40/346], lr: 0.00000022 	 loss = 0.4152(0.4945)
2023/09/17 10:23:52 - INFO - root -   Epoch: [82/400][60/346], lr: 0.00000022 	 loss = 0.8618(0.4733)
2023/09/17 10:24:53 - INFO - root -   Epoch: [82/400][80/346], lr: 0.00000022 	 loss = 0.3785(0.5015)
2023/09/17 10:25:36 - INFO - root -   Epoch: [82/400][100/346], lr: 0.00000022 	 loss = 0.4767(0.5094)
2023/09/17 10:26:36 - INFO - root -   Epoch: [82/400][120/346], lr: 0.00000022 	 loss = 0.2135(0.5274)
2023/09/17 10:27:20 - INFO - root -   Epoch: [82/400][140/346], lr: 0.00000022 	 loss = 0.6513(0.5166)
2023/09/17 10:28:20 - INFO - root -   Epoch: [82/400][160/346], lr: 0.00000022 	 loss = 0.0761(0.5303)
2023/09/17 10:29:03 - INFO - root -   Epoch: [82/400][180/346], lr: 0.00000022 	 loss = 0.7544(0.5394)
2023/09/17 10:30:03 - INFO - root -   Epoch: [82/400][200/346], lr: 0.00000022 	 loss = 0.1144(0.5294)
2023/09/17 10:30:46 - INFO - root -   Epoch: [82/400][220/346], lr: 0.00000022 	 loss = 0.1997(0.5373)
2023/09/17 10:31:47 - INFO - root -   Epoch: [82/400][240/346], lr: 0.00000022 	 loss = 0.1662(0.5313)
2023/09/17 10:32:29 - INFO - root -   Epoch: [82/400][260/346], lr: 0.00000022 	 loss = 0.4435(0.5216)
2023/09/17 10:33:30 - INFO - root -   Epoch: [82/400][280/346], lr: 0.00000022 	 loss = 0.4393(0.5439)
2023/09/17 10:34:13 - INFO - root -   Epoch: [82/400][300/346], lr: 0.00000022 	 loss = 0.1982(0.5456)
2023/09/17 10:35:13 - INFO - root -   Epoch: [82/400][320/346], lr: 0.00000022 	 loss = 0.2904(0.5417)
2023/09/17 10:35:56 - INFO - root -   Epoch: [82/400][340/346], lr: 0.00000022 	 loss = 0.7643(0.5442)
2023/09/17 10:36:00 - INFO - root -   Epoch: [82/400] 	 loss = 0.5447
2023/09/17 10:36:00 - INFO - root -   train_accuracy = 0.7254
2023/09/17 10:36:22 - INFO - root -   Epoch: [83/400][0/346], lr: 0.00000022 	 loss = 0.1871(0.1871)
2023/09/17 10:37:04 - INFO - root -   Epoch: [83/400][20/346], lr: 0.00000022 	 loss = 0.1615(0.4423)
2023/09/17 10:38:05 - INFO - root -   Epoch: [83/400][40/346], lr: 0.00000022 	 loss = 0.3865(0.4673)
2023/09/17 10:38:48 - INFO - root -   Epoch: [83/400][60/346], lr: 0.00000022 	 loss = 0.3865(0.4087)
2023/09/17 10:39:49 - INFO - root -   Epoch: [83/400][80/346], lr: 0.00000022 	 loss = 0.3138(0.4272)
2023/09/17 10:40:32 - INFO - root -   Epoch: [83/400][100/346], lr: 0.00000022 	 loss = 0.4274(0.4551)
2023/09/17 10:41:33 - INFO - root -   Epoch: [83/400][120/346], lr: 0.00000022 	 loss = 0.3063(0.4827)
2023/09/17 10:42:16 - INFO - root -   Epoch: [83/400][140/346], lr: 0.00000022 	 loss = 0.7529(0.4821)
2023/09/17 10:43:16 - INFO - root -   Epoch: [83/400][160/346], lr: 0.00000022 	 loss = 0.1719(0.4996)
2023/09/17 10:43:59 - INFO - root -   Epoch: [83/400][180/346], lr: 0.00000022 	 loss = 0.2473(0.5082)
2023/09/17 10:44:59 - INFO - root -   Epoch: [83/400][200/346], lr: 0.00000022 	 loss = 0.1081(0.5034)
2023/09/17 10:45:42 - INFO - root -   Epoch: [83/400][220/346], lr: 0.00000022 	 loss = 0.1482(0.5154)
2023/09/17 10:46:43 - INFO - root -   Epoch: [83/400][240/346], lr: 0.00000022 	 loss = 0.2051(0.5073)
2023/09/17 10:47:26 - INFO - root -   Epoch: [83/400][260/346], lr: 0.00000022 	 loss = 0.9625(0.5067)
2023/09/17 10:48:26 - INFO - root -   Epoch: [83/400][280/346], lr: 0.00000022 	 loss = 0.2316(0.5283)
2023/09/17 10:49:09 - INFO - root -   Epoch: [83/400][300/346], lr: 0.00000022 	 loss = 0.5639(0.5290)
2023/09/17 10:50:10 - INFO - root -   Epoch: [83/400][320/346], lr: 0.00000022 	 loss = 0.4898(0.5278)
2023/09/17 10:50:52 - INFO - root -   Epoch: [83/400][340/346], lr: 0.00000022 	 loss = 0.9977(0.5286)
2023/09/17 10:50:56 - INFO - root -   Epoch: [83/400] 	 loss = 0.5278
2023/09/17 10:50:56 - INFO - root -   train_accuracy = 0.7529
2023/09/17 10:51:17 - INFO - root -   Epoch: [84/400][0/346], lr: 0.00000022 	 loss = 0.4665(0.4665)
2023/09/17 10:52:00 - INFO - root -   Epoch: [84/400][20/346], lr: 0.00000022 	 loss = 0.2529(0.4128)
2023/09/17 10:53:01 - INFO - root -   Epoch: [84/400][40/346], lr: 0.00000022 	 loss = 0.4686(0.4523)
2023/09/17 10:53:44 - INFO - root -   Epoch: [84/400][60/346], lr: 0.00000022 	 loss = 0.5091(0.4096)
2023/09/17 10:54:45 - INFO - root -   Epoch: [84/400][80/346], lr: 0.00000022 	 loss = 0.2570(0.4506)
2023/09/17 10:55:28 - INFO - root -   Epoch: [84/400][100/346], lr: 0.00000022 	 loss = 0.2773(0.4578)
2023/09/17 10:56:29 - INFO - root -   Epoch: [84/400][120/346], lr: 0.00000022 	 loss = 0.1564(0.5098)
2023/09/17 10:57:12 - INFO - root -   Epoch: [84/400][140/346], lr: 0.00000022 	 loss = 0.7159(0.5107)
2023/09/17 10:58:13 - INFO - root -   Epoch: [84/400][160/346], lr: 0.00000022 	 loss = 0.1611(0.5275)
2023/09/17 10:58:56 - INFO - root -   Epoch: [84/400][180/346], lr: 0.00000022 	 loss = 0.3154(0.5350)
2023/09/17 10:59:56 - INFO - root -   Epoch: [84/400][200/346], lr: 0.00000022 	 loss = 0.1185(0.5188)
2023/09/17 11:00:40 - INFO - root -   Epoch: [84/400][220/346], lr: 0.00000022 	 loss = 0.4213(0.5255)
2023/09/17 11:01:40 - INFO - root -   Epoch: [84/400][240/346], lr: 0.00000022 	 loss = 0.2102(0.5260)
2023/09/17 11:02:24 - INFO - root -   Epoch: [84/400][260/346], lr: 0.00000022 	 loss = 0.6308(0.5179)
2023/09/17 11:03:24 - INFO - root -   Epoch: [84/400][280/346], lr: 0.00000022 	 loss = 0.2378(0.5308)
2023/09/17 11:04:07 - INFO - root -   Epoch: [84/400][300/346], lr: 0.00000022 	 loss = 0.2850(0.5345)
2023/09/17 11:05:07 - INFO - root -   Epoch: [84/400][320/346], lr: 0.00000022 	 loss = 0.1849(0.5314)
2023/09/17 11:05:51 - INFO - root -   Epoch: [84/400][340/346], lr: 0.00000022 	 loss = 1.0829(0.5316)
2023/09/17 11:05:55 - INFO - root -   Epoch: [84/400] 	 loss = 0.5310
2023/09/17 11:09:41 - INFO - root -   precision = 0.6839
2023/09/17 11:09:41 - INFO - root -   eval_loss = 0.6250
2023/09/17 11:09:42 - INFO - root -   train_accuracy = 0.7370
2023/09/17 11:10:04 - INFO - root -   Epoch: [85/400][0/346], lr: 0.00000022 	 loss = 0.2806(0.2806)
2023/09/17 11:10:47 - INFO - root -   Epoch: [85/400][20/346], lr: 0.00000022 	 loss = 0.1534(0.4403)
2023/09/17 11:11:48 - INFO - root -   Epoch: [85/400][40/346], lr: 0.00000022 	 loss = 0.3264(0.4879)
2023/09/17 11:12:32 - INFO - root -   Epoch: [85/400][60/346], lr: 0.00000022 	 loss = 0.6845(0.4505)
2023/09/17 11:13:33 - INFO - root -   Epoch: [85/400][80/346], lr: 0.00000022 	 loss = 0.4094(0.4706)
2023/09/17 11:14:16 - INFO - root -   Epoch: [85/400][100/346], lr: 0.00000022 	 loss = 0.2963(0.4793)
2023/09/17 11:15:17 - INFO - root -   Epoch: [85/400][120/346], lr: 0.00000022 	 loss = 0.2416(0.5138)
2023/09/17 11:16:00 - INFO - root -   Epoch: [85/400][140/346], lr: 0.00000022 	 loss = 0.5184(0.5041)
2023/09/17 11:17:01 - INFO - root -   Epoch: [85/400][160/346], lr: 0.00000022 	 loss = 0.2451(0.5096)
2023/09/17 11:17:44 - INFO - root -   Epoch: [85/400][180/346], lr: 0.00000022 	 loss = 0.3485(0.5142)
2023/09/17 11:18:45 - INFO - root -   Epoch: [85/400][200/346], lr: 0.00000022 	 loss = 0.1184(0.5077)
2023/09/17 11:19:28 - INFO - root -   Epoch: [85/400][220/346], lr: 0.00000022 	 loss = 0.3746(0.5082)
2023/09/17 11:20:29 - INFO - root -   Epoch: [85/400][240/346], lr: 0.00000022 	 loss = 0.1895(0.5089)
2023/09/17 11:21:12 - INFO - root -   Epoch: [85/400][260/346], lr: 0.00000022 	 loss = 0.3727(0.5084)
2023/09/17 11:22:13 - INFO - root -   Epoch: [85/400][280/346], lr: 0.00000022 	 loss = 0.1749(0.5273)
2023/09/17 11:22:56 - INFO - root -   Epoch: [85/400][300/346], lr: 0.00000022 	 loss = 0.1990(0.5277)
2023/09/17 11:23:57 - INFO - root -   Epoch: [85/400][320/346], lr: 0.00000022 	 loss = 0.3496(0.5266)
2023/09/17 11:24:39 - INFO - root -   Epoch: [85/400][340/346], lr: 0.00000022 	 loss = 2.0126(0.5349)
2023/09/17 11:24:43 - INFO - root -   Epoch: [85/400] 	 loss = 0.5355
2023/09/17 11:24:43 - INFO - root -   train_accuracy = 0.7486
2023/09/17 11:25:05 - INFO - root -   Epoch: [86/400][0/346], lr: 0.00000022 	 loss = 0.4084(0.4084)
2023/09/17 11:25:48 - INFO - root -   Epoch: [86/400][20/346], lr: 0.00000022 	 loss = 0.0971(0.5747)
2023/09/17 11:26:50 - INFO - root -   Epoch: [86/400][40/346], lr: 0.00000022 	 loss = 0.3631(0.5548)
2023/09/17 11:27:34 - INFO - root -   Epoch: [86/400][60/346], lr: 0.00000022 	 loss = 0.5163(0.4942)
2023/09/17 11:28:36 - INFO - root -   Epoch: [86/400][80/346], lr: 0.00000022 	 loss = 0.3357(0.5186)
2023/09/17 11:29:20 - INFO - root -   Epoch: [86/400][100/346], lr: 0.00000022 	 loss = 0.2702(0.5076)
2023/09/17 11:30:21 - INFO - root -   Epoch: [86/400][120/346], lr: 0.00000022 	 loss = 0.1270(0.5223)
2023/09/17 11:31:06 - INFO - root -   Epoch: [86/400][140/346], lr: 0.00000022 	 loss = 0.4045(0.5188)
2023/09/17 11:32:07 - INFO - root -   Epoch: [86/400][160/346], lr: 0.00000022 	 loss = 0.1665(0.5205)
2023/09/17 11:32:51 - INFO - root -   Epoch: [86/400][180/346], lr: 0.00000022 	 loss = 0.2613(0.5290)
2023/09/17 11:33:53 - INFO - root -   Epoch: [86/400][200/346], lr: 0.00000022 	 loss = 0.1372(0.5187)
2023/09/17 11:34:37 - INFO - root -   Epoch: [86/400][220/346], lr: 0.00000022 	 loss = 0.1744(0.5246)
2023/09/17 11:35:38 - INFO - root -   Epoch: [86/400][240/346], lr: 0.00000022 	 loss = 0.3835(0.5248)
2023/09/17 11:36:23 - INFO - root -   Epoch: [86/400][260/346], lr: 0.00000022 	 loss = 0.6031(0.5162)
2023/09/17 11:37:24 - INFO - root -   Epoch: [86/400][280/346], lr: 0.00000022 	 loss = 0.1863(0.5297)
2023/09/17 11:38:08 - INFO - root -   Epoch: [86/400][300/346], lr: 0.00000022 	 loss = 0.1705(0.5300)
2023/09/17 11:39:09 - INFO - root -   Epoch: [86/400][320/346], lr: 0.00000022 	 loss = 0.2413(0.5291)
2023/09/17 11:39:52 - INFO - root -   Epoch: [86/400][340/346], lr: 0.00000022 	 loss = 1.4265(0.5334)
2023/09/17 11:39:56 - INFO - root -   Epoch: [86/400] 	 loss = 0.5345
2023/09/17 11:39:56 - INFO - root -   train_accuracy = 0.7240
2023/09/17 11:40:17 - INFO - root -   Epoch: [87/400][0/346], lr: 0.00000022 	 loss = 0.3652(0.3652)
2023/09/17 11:41:00 - INFO - root -   Epoch: [87/400][20/346], lr: 0.00000022 	 loss = 0.1033(0.4292)
2023/09/17 11:42:01 - INFO - root -   Epoch: [87/400][40/346], lr: 0.00000022 	 loss = 0.3926(0.4903)
2023/09/17 11:42:44 - INFO - root -   Epoch: [87/400][60/346], lr: 0.00000022 	 loss = 0.4109(0.4614)
2023/09/17 11:43:45 - INFO - root -   Epoch: [87/400][80/346], lr: 0.00000022 	 loss = 0.4501(0.4742)
2023/09/17 11:44:28 - INFO - root -   Epoch: [87/400][100/346], lr: 0.00000022 	 loss = 0.4613(0.4928)
2023/09/17 11:45:28 - INFO - root -   Epoch: [87/400][120/346], lr: 0.00000022 	 loss = 0.2539(0.5394)
2023/09/17 11:46:11 - INFO - root -   Epoch: [87/400][140/346], lr: 0.00000022 	 loss = 0.7480(0.5340)
2023/09/17 11:47:12 - INFO - root -   Epoch: [87/400][160/346], lr: 0.00000022 	 loss = 0.0953(0.5326)
2023/09/17 11:47:55 - INFO - root -   Epoch: [87/400][180/346], lr: 0.00000022 	 loss = 0.4614(0.5309)
2023/09/17 11:48:55 - INFO - root -   Epoch: [87/400][200/346], lr: 0.00000022 	 loss = 0.1401(0.5192)
2023/09/17 11:49:38 - INFO - root -   Epoch: [87/400][220/346], lr: 0.00000022 	 loss = 0.3677(0.5217)
2023/09/17 11:50:38 - INFO - root -   Epoch: [87/400][240/346], lr: 0.00000022 	 loss = 0.1878(0.5189)
2023/09/17 11:51:22 - INFO - root -   Epoch: [87/400][260/346], lr: 0.00000022 	 loss = 0.9257(0.5130)
2023/09/17 11:52:22 - INFO - root -   Epoch: [87/400][280/346], lr: 0.00000022 	 loss = 0.1760(0.5358)
2023/09/17 11:53:06 - INFO - root -   Epoch: [87/400][300/346], lr: 0.00000022 	 loss = 0.2585(0.5359)
2023/09/17 11:54:05 - INFO - root -   Epoch: [87/400][320/346], lr: 0.00000022 	 loss = 0.3988(0.5351)
2023/09/17 11:54:47 - INFO - root -   Epoch: [87/400][340/346], lr: 0.00000022 	 loss = 0.8659(0.5326)
2023/09/17 11:54:51 - INFO - root -   Epoch: [87/400] 	 loss = 0.5344
2023/09/17 11:54:51 - INFO - root -   train_accuracy = 0.7442
2023/09/17 11:55:13 - INFO - root -   Epoch: [88/400][0/346], lr: 0.00000023 	 loss = 0.1861(0.1861)
2023/09/17 11:55:56 - INFO - root -   Epoch: [88/400][20/346], lr: 0.00000023 	 loss = 0.0587(0.4785)
2023/09/17 11:56:57 - INFO - root -   Epoch: [88/400][40/346], lr: 0.00000023 	 loss = 0.2721(0.4969)
2023/09/17 11:57:40 - INFO - root -   Epoch: [88/400][60/346], lr: 0.00000023 	 loss = 0.6802(0.4755)
2023/09/17 11:58:42 - INFO - root -   Epoch: [88/400][80/346], lr: 0.00000023 	 loss = 0.2582(0.4696)
2023/09/17 11:59:25 - INFO - root -   Epoch: [88/400][100/346], lr: 0.00000023 	 loss = 0.4030(0.4741)
2023/09/17 12:00:26 - INFO - root -   Epoch: [88/400][120/346], lr: 0.00000023 	 loss = 0.1237(0.5024)
2023/09/17 12:01:09 - INFO - root -   Epoch: [88/400][140/346], lr: 0.00000023 	 loss = 0.4239(0.4912)
2023/09/17 12:02:10 - INFO - root -   Epoch: [88/400][160/346], lr: 0.00000023 	 loss = 0.0697(0.4941)
2023/09/17 12:02:53 - INFO - root -   Epoch: [88/400][180/346], lr: 0.00000023 	 loss = 0.8110(0.4928)
2023/09/17 12:03:54 - INFO - root -   Epoch: [88/400][200/346], lr: 0.00000023 	 loss = 0.0635(0.4856)
2023/09/17 12:04:38 - INFO - root -   Epoch: [88/400][220/346], lr: 0.00000023 	 loss = 0.3818(0.4948)
2023/09/17 12:05:38 - INFO - root -   Epoch: [88/400][240/346], lr: 0.00000023 	 loss = 0.2102(0.4892)
2023/09/17 12:06:22 - INFO - root -   Epoch: [88/400][260/346], lr: 0.00000023 	 loss = 0.3952(0.4912)
2023/09/17 12:07:22 - INFO - root -   Epoch: [88/400][280/346], lr: 0.00000023 	 loss = 0.2838(0.5087)
2023/09/17 12:08:06 - INFO - root -   Epoch: [88/400][300/346], lr: 0.00000023 	 loss = 0.3700(0.5095)
2023/09/17 12:09:06 - INFO - root -   Epoch: [88/400][320/346], lr: 0.00000023 	 loss = 0.2652(0.5069)
2023/09/17 12:09:49 - INFO - root -   Epoch: [88/400][340/346], lr: 0.00000023 	 loss = 1.6734(0.5100)
2023/09/17 12:09:53 - INFO - root -   Epoch: [88/400] 	 loss = 0.5113
2023/09/17 12:09:53 - INFO - root -   train_accuracy = 0.7529
2023/09/17 12:10:14 - INFO - root -   Epoch: [89/400][0/346], lr: 0.00000023 	 loss = 0.3474(0.3474)
2023/09/17 12:10:57 - INFO - root -   Epoch: [89/400][20/346], lr: 0.00000023 	 loss = 0.2488(0.4996)
2023/09/17 12:11:58 - INFO - root -   Epoch: [89/400][40/346], lr: 0.00000023 	 loss = 0.3080(0.5036)
2023/09/17 12:12:42 - INFO - root -   Epoch: [89/400][60/346], lr: 0.00000023 	 loss = 0.5090(0.4691)
2023/09/17 12:13:43 - INFO - root -   Epoch: [89/400][80/346], lr: 0.00000023 	 loss = 0.2604(0.4950)
2023/09/17 12:14:26 - INFO - root -   Epoch: [89/400][100/346], lr: 0.00000023 	 loss = 0.4264(0.4949)
2023/09/17 12:15:26 - INFO - root -   Epoch: [89/400][120/346], lr: 0.00000023 	 loss = 0.2470(0.5251)
2023/09/17 12:16:10 - INFO - root -   Epoch: [89/400][140/346], lr: 0.00000023 	 loss = 0.5169(0.5113)
2023/09/17 12:17:10 - INFO - root -   Epoch: [89/400][160/346], lr: 0.00000023 	 loss = 0.1266(0.5190)
2023/09/17 12:17:54 - INFO - root -   Epoch: [89/400][180/346], lr: 0.00000023 	 loss = 0.2981(0.5203)
2023/09/17 12:18:54 - INFO - root -   Epoch: [89/400][200/346], lr: 0.00000023 	 loss = 0.1173(0.5067)
2023/09/17 12:19:38 - INFO - root -   Epoch: [89/400][220/346], lr: 0.00000023 	 loss = 0.3216(0.5127)
2023/09/17 12:20:38 - INFO - root -   Epoch: [89/400][240/346], lr: 0.00000023 	 loss = 0.1696(0.5109)
2023/09/17 12:21:22 - INFO - root -   Epoch: [89/400][260/346], lr: 0.00000023 	 loss = 1.0170(0.5062)
2023/09/17 12:22:22 - INFO - root -   Epoch: [89/400][280/346], lr: 0.00000023 	 loss = 0.2297(0.5265)
2023/09/17 12:23:06 - INFO - root -   Epoch: [89/400][300/346], lr: 0.00000023 	 loss = 0.3683(0.5316)
2023/09/17 12:24:06 - INFO - root -   Epoch: [89/400][320/346], lr: 0.00000023 	 loss = 0.2265(0.5250)
2023/09/17 12:24:47 - INFO - root -   Epoch: [89/400][340/346], lr: 0.00000023 	 loss = 1.0295(0.5283)
2023/09/17 12:24:51 - INFO - root -   Epoch: [89/400] 	 loss = 0.5285
2023/09/17 12:28:39 - INFO - root -   precision = 0.7011
2023/09/17 12:28:39 - INFO - root -   eval_loss = 0.5899
2023/09/17 12:28:40 - INFO - root -   train_accuracy = 0.7370
2023/09/17 12:29:02 - INFO - root -   Epoch: [90/400][0/346], lr: 0.00000023 	 loss = 0.5523(0.5523)
2023/09/17 12:29:45 - INFO - root -   Epoch: [90/400][20/346], lr: 0.00000023 	 loss = 0.1827(0.4233)
2023/09/17 12:30:45 - INFO - root -   Epoch: [90/400][40/346], lr: 0.00000023 	 loss = 0.4484(0.4637)
2023/09/17 12:31:28 - INFO - root -   Epoch: [90/400][60/346], lr: 0.00000023 	 loss = 0.4490(0.4195)
2023/09/17 12:32:29 - INFO - root -   Epoch: [90/400][80/346], lr: 0.00000023 	 loss = 0.4344(0.4623)
2023/09/17 12:33:12 - INFO - root -   Epoch: [90/400][100/346], lr: 0.00000023 	 loss = 0.2173(0.4744)
2023/09/17 12:34:13 - INFO - root -   Epoch: [90/400][120/346], lr: 0.00000023 	 loss = 0.1632(0.5012)
2023/09/17 12:34:56 - INFO - root -   Epoch: [90/400][140/346], lr: 0.00000023 	 loss = 0.3995(0.4975)
2023/09/17 12:35:56 - INFO - root -   Epoch: [90/400][160/346], lr: 0.00000023 	 loss = 0.0633(0.4978)
2023/09/17 12:36:39 - INFO - root -   Epoch: [90/400][180/346], lr: 0.00000023 	 loss = 0.1263(0.5003)
2023/09/17 12:37:39 - INFO - root -   Epoch: [90/400][200/346], lr: 0.00000023 	 loss = 0.0707(0.4903)
2023/09/17 12:38:23 - INFO - root -   Epoch: [90/400][220/346], lr: 0.00000023 	 loss = 0.3770(0.4984)
2023/09/17 12:39:22 - INFO - root -   Epoch: [90/400][240/346], lr: 0.00000023 	 loss = 0.2709(0.4958)
2023/09/17 12:40:06 - INFO - root -   Epoch: [90/400][260/346], lr: 0.00000023 	 loss = 0.7203(0.4930)
2023/09/17 12:41:06 - INFO - root -   Epoch: [90/400][280/346], lr: 0.00000023 	 loss = 0.2387(0.5067)
2023/09/17 12:41:50 - INFO - root -   Epoch: [90/400][300/346], lr: 0.00000023 	 loss = 0.1827(0.5099)
2023/09/17 12:42:49 - INFO - root -   Epoch: [90/400][320/346], lr: 0.00000023 	 loss = 0.2426(0.5078)
2023/09/17 12:43:32 - INFO - root -   Epoch: [90/400][340/346], lr: 0.00000023 	 loss = 0.9199(0.5104)
2023/09/17 12:43:37 - INFO - root -   Epoch: [90/400] 	 loss = 0.5106
2023/09/17 12:43:37 - INFO - root -   train_accuracy = 0.7514
2023/09/17 12:43:58 - INFO - root -   Epoch: [91/400][0/346], lr: 0.00000023 	 loss = 0.8244(0.8244)
2023/09/17 12:44:41 - INFO - root -   Epoch: [91/400][20/346], lr: 0.00000023 	 loss = 0.1519(0.4219)
2023/09/17 12:45:42 - INFO - root -   Epoch: [91/400][40/346], lr: 0.00000023 	 loss = 0.3060(0.4963)
2023/09/17 12:46:25 - INFO - root -   Epoch: [91/400][60/346], lr: 0.00000023 	 loss = 0.3065(0.4418)
2023/09/17 12:47:26 - INFO - root -   Epoch: [91/400][80/346], lr: 0.00000023 	 loss = 0.1352(0.4926)
2023/09/17 12:48:09 - INFO - root -   Epoch: [91/400][100/346], lr: 0.00000023 	 loss = 0.8071(0.5142)
2023/09/17 12:49:10 - INFO - root -   Epoch: [91/400][120/346], lr: 0.00000023 	 loss = 0.3513(0.5465)
2023/09/17 12:49:53 - INFO - root -   Epoch: [91/400][140/346], lr: 0.00000023 	 loss = 0.8521(0.5348)
2023/09/17 12:50:54 - INFO - root -   Epoch: [91/400][160/346], lr: 0.00000023 	 loss = 0.1711(0.5295)
2023/09/17 12:51:39 - INFO - root -   Epoch: [91/400][180/346], lr: 0.00000023 	 loss = 0.2083(0.5295)
2023/09/17 12:52:37 - INFO - root -   Epoch: [91/400][200/346], lr: 0.00000023 	 loss = 0.1604(0.5111)
2023/09/17 12:53:23 - INFO - root -   Epoch: [91/400][220/346], lr: 0.00000023 	 loss = 0.3225(0.5131)
2023/09/17 12:54:21 - INFO - root -   Epoch: [91/400][240/346], lr: 0.00000023 	 loss = 0.0799(0.5063)
2023/09/17 12:55:06 - INFO - root -   Epoch: [91/400][260/346], lr: 0.00000023 	 loss = 0.8121(0.5025)
2023/09/17 12:56:05 - INFO - root -   Epoch: [91/400][280/346], lr: 0.00000023 	 loss = 0.1301(0.5158)
2023/09/17 12:56:50 - INFO - root -   Epoch: [91/400][300/346], lr: 0.00000023 	 loss = 0.2938(0.5171)
2023/09/17 12:57:49 - INFO - root -   Epoch: [91/400][320/346], lr: 0.00000023 	 loss = 0.1437(0.5151)
2023/09/17 12:58:32 - INFO - root -   Epoch: [91/400][340/346], lr: 0.00000023 	 loss = 1.1629(0.5153)
2023/09/17 12:58:36 - INFO - root -   Epoch: [91/400] 	 loss = 0.5167
2023/09/17 12:58:36 - INFO - root -   train_accuracy = 0.7529
2023/09/17 12:58:57 - INFO - root -   Epoch: [92/400][0/346], lr: 0.00000023 	 loss = 0.4135(0.4135)
2023/09/17 12:59:40 - INFO - root -   Epoch: [92/400][20/346], lr: 0.00000023 	 loss = 0.1666(0.3850)
2023/09/17 13:00:41 - INFO - root -   Epoch: [92/400][40/346], lr: 0.00000023 	 loss = 0.2903(0.4810)
2023/09/17 13:01:24 - INFO - root -   Epoch: [92/400][60/346], lr: 0.00000023 	 loss = 0.6268(0.4177)
2023/09/17 13:02:25 - INFO - root -   Epoch: [92/400][80/346], lr: 0.00000023 	 loss = 0.3302(0.4542)
2023/09/17 13:03:09 - INFO - root -   Epoch: [92/400][100/346], lr: 0.00000023 	 loss = 0.4362(0.4660)
2023/09/17 13:04:10 - INFO - root -   Epoch: [92/400][120/346], lr: 0.00000023 	 loss = 0.1840(0.4933)
2023/09/17 13:04:53 - INFO - root -   Epoch: [92/400][140/346], lr: 0.00000023 	 loss = 0.8287(0.4986)
2023/09/17 13:05:54 - INFO - root -   Epoch: [92/400][160/346], lr: 0.00000023 	 loss = 0.0726(0.5117)
2023/09/17 13:06:37 - INFO - root -   Epoch: [92/400][180/346], lr: 0.00000023 	 loss = 0.1247(0.5091)
2023/09/17 13:07:37 - INFO - root -   Epoch: [92/400][200/346], lr: 0.00000023 	 loss = 0.0946(0.4977)
2023/09/17 13:08:22 - INFO - root -   Epoch: [92/400][220/346], lr: 0.00000023 	 loss = 0.4023(0.5075)
2023/09/17 13:09:21 - INFO - root -   Epoch: [92/400][240/346], lr: 0.00000023 	 loss = 0.1299(0.4990)
2023/09/17 13:10:06 - INFO - root -   Epoch: [92/400][260/346], lr: 0.00000023 	 loss = 0.6470(0.4882)
2023/09/17 13:11:05 - INFO - root -   Epoch: [92/400][280/346], lr: 0.00000023 	 loss = 0.1548(0.5081)
2023/09/17 13:11:50 - INFO - root -   Epoch: [92/400][300/346], lr: 0.00000023 	 loss = 0.1105(0.5052)
2023/09/17 13:12:49 - INFO - root -   Epoch: [92/400][320/346], lr: 0.00000023 	 loss = 0.1848(0.5027)
2023/09/17 13:13:33 - INFO - root -   Epoch: [92/400][340/346], lr: 0.00000023 	 loss = 0.9087(0.5082)
2023/09/17 13:13:37 - INFO - root -   Epoch: [92/400] 	 loss = 0.5098
2023/09/17 13:13:37 - INFO - root -   train_accuracy = 0.7500
2023/09/17 13:13:58 - INFO - root -   Epoch: [93/400][0/346], lr: 0.00000023 	 loss = 0.1272(0.1272)
2023/09/17 13:14:41 - INFO - root -   Epoch: [93/400][20/346], lr: 0.00000023 	 loss = 0.4228(0.4337)
2023/09/17 13:15:42 - INFO - root -   Epoch: [93/400][40/346], lr: 0.00000023 	 loss = 0.2675(0.4775)
2023/09/17 13:16:25 - INFO - root -   Epoch: [93/400][60/346], lr: 0.00000023 	 loss = 0.5503(0.4237)
2023/09/17 13:17:25 - INFO - root -   Epoch: [93/400][80/346], lr: 0.00000023 	 loss = 0.2408(0.4227)
2023/09/17 13:18:08 - INFO - root -   Epoch: [93/400][100/346], lr: 0.00000023 	 loss = 0.3669(0.4437)
2023/09/17 13:19:09 - INFO - root -   Epoch: [93/400][120/346], lr: 0.00000023 	 loss = 0.3635(0.4772)
2023/09/17 13:19:52 - INFO - root -   Epoch: [93/400][140/346], lr: 0.00000023 	 loss = 0.6218(0.4846)
2023/09/17 13:20:53 - INFO - root -   Epoch: [93/400][160/346], lr: 0.00000023 	 loss = 0.1405(0.4888)
2023/09/17 13:21:36 - INFO - root -   Epoch: [93/400][180/346], lr: 0.00000023 	 loss = 0.1590(0.4947)
2023/09/17 13:22:36 - INFO - root -   Epoch: [93/400][200/346], lr: 0.00000023 	 loss = 0.0427(0.4898)
2023/09/17 13:23:19 - INFO - root -   Epoch: [93/400][220/346], lr: 0.00000023 	 loss = 0.4230(0.4930)
2023/09/17 13:24:20 - INFO - root -   Epoch: [93/400][240/346], lr: 0.00000023 	 loss = 0.2300(0.4955)
2023/09/17 13:25:03 - INFO - root -   Epoch: [93/400][260/346], lr: 0.00000023 	 loss = 0.5338(0.4887)
2023/09/17 13:26:03 - INFO - root -   Epoch: [93/400][280/346], lr: 0.00000023 	 loss = 0.3122(0.5028)
2023/09/17 13:26:46 - INFO - root -   Epoch: [93/400][300/346], lr: 0.00000023 	 loss = 0.1192(0.4999)
2023/09/17 13:27:47 - INFO - root -   Epoch: [93/400][320/346], lr: 0.00000023 	 loss = 0.2608(0.5015)
2023/09/17 13:28:28 - INFO - root -   Epoch: [93/400][340/346], lr: 0.00000023 	 loss = 1.5181(0.5007)
2023/09/17 13:28:32 - INFO - root -   Epoch: [93/400] 	 loss = 0.5020
2023/09/17 13:28:32 - INFO - root -   train_accuracy = 0.7572
2023/09/17 13:28:54 - INFO - root -   Epoch: [94/400][0/346], lr: 0.00000023 	 loss = 0.2637(0.2637)
2023/09/17 13:29:37 - INFO - root -   Epoch: [94/400][20/346], lr: 0.00000023 	 loss = 0.0721(0.4232)
2023/09/17 13:30:38 - INFO - root -   Epoch: [94/400][40/346], lr: 0.00000023 	 loss = 0.3954(0.4546)
2023/09/17 13:31:21 - INFO - root -   Epoch: [94/400][60/346], lr: 0.00000023 	 loss = 0.5243(0.4055)
2023/09/17 13:32:22 - INFO - root -   Epoch: [94/400][80/346], lr: 0.00000023 	 loss = 0.3141(0.4511)
2023/09/17 13:33:05 - INFO - root -   Epoch: [94/400][100/346], lr: 0.00000023 	 loss = 0.5214(0.4627)
2023/09/17 13:34:06 - INFO - root -   Epoch: [94/400][120/346], lr: 0.00000023 	 loss = 0.3822(0.4919)
2023/09/17 13:34:49 - INFO - root -   Epoch: [94/400][140/346], lr: 0.00000023 	 loss = 0.4917(0.4851)
2023/09/17 13:35:50 - INFO - root -   Epoch: [94/400][160/346], lr: 0.00000023 	 loss = 0.0801(0.4889)
2023/09/17 13:36:33 - INFO - root -   Epoch: [94/400][180/346], lr: 0.00000023 	 loss = 0.5172(0.4966)
2023/09/17 13:37:34 - INFO - root -   Epoch: [94/400][200/346], lr: 0.00000023 	 loss = 0.1523(0.4921)
2023/09/17 13:38:17 - INFO - root -   Epoch: [94/400][220/346], lr: 0.00000023 	 loss = 0.5225(0.5057)
2023/09/17 13:39:18 - INFO - root -   Epoch: [94/400][240/346], lr: 0.00000023 	 loss = 0.1689(0.5025)
2023/09/17 13:40:01 - INFO - root -   Epoch: [94/400][260/346], lr: 0.00000023 	 loss = 0.4195(0.4940)
2023/09/17 13:41:02 - INFO - root -   Epoch: [94/400][280/346], lr: 0.00000023 	 loss = 0.1385(0.5070)
2023/09/17 13:41:45 - INFO - root -   Epoch: [94/400][300/346], lr: 0.00000023 	 loss = 0.2601(0.5091)
2023/09/17 13:42:46 - INFO - root -   Epoch: [94/400][320/346], lr: 0.00000023 	 loss = 0.3083(0.5047)
2023/09/17 13:43:27 - INFO - root -   Epoch: [94/400][340/346], lr: 0.00000023 	 loss = 1.3807(0.5080)
2023/09/17 13:43:31 - INFO - root -   Epoch: [94/400] 	 loss = 0.5086
2023/09/17 13:47:19 - INFO - root -   precision = 0.6839
2023/09/17 13:47:19 - INFO - root -   eval_loss = 0.6470
2023/09/17 13:47:20 - INFO - root -   train_accuracy = 0.7572
2023/09/17 13:47:41 - INFO - root -   Epoch: [95/400][0/346], lr: 0.00000024 	 loss = 0.5250(0.5250)
2023/09/17 13:48:25 - INFO - root -   Epoch: [95/400][20/346], lr: 0.00000024 	 loss = 0.0962(0.4346)
2023/09/17 13:49:25 - INFO - root -   Epoch: [95/400][40/346], lr: 0.00000024 	 loss = 0.2235(0.4724)
2023/09/17 13:50:08 - INFO - root -   Epoch: [95/400][60/346], lr: 0.00000024 	 loss = 0.3493(0.4372)
2023/09/17 13:51:09 - INFO - root -   Epoch: [95/400][80/346], lr: 0.00000024 	 loss = 0.2002(0.4648)
2023/09/17 13:51:52 - INFO - root -   Epoch: [95/400][100/346], lr: 0.00000024 	 loss = 0.3355(0.4762)
2023/09/17 13:52:52 - INFO - root -   Epoch: [95/400][120/346], lr: 0.00000024 	 loss = 0.2088(0.5067)
2023/09/17 13:53:36 - INFO - root -   Epoch: [95/400][140/346], lr: 0.00000024 	 loss = 0.5565(0.4960)
2023/09/17 13:54:36 - INFO - root -   Epoch: [95/400][160/346], lr: 0.00000024 	 loss = 0.1059(0.5079)
2023/09/17 13:55:20 - INFO - root -   Epoch: [95/400][180/346], lr: 0.00000024 	 loss = 1.0196(0.5233)
2023/09/17 13:56:19 - INFO - root -   Epoch: [95/400][200/346], lr: 0.00000024 	 loss = 0.0938(0.5180)
2023/09/17 13:57:03 - INFO - root -   Epoch: [95/400][220/346], lr: 0.00000024 	 loss = 0.4162(0.5237)
2023/09/17 13:58:03 - INFO - root -   Epoch: [95/400][240/346], lr: 0.00000024 	 loss = 0.0556(0.5161)
2023/09/17 13:58:47 - INFO - root -   Epoch: [95/400][260/346], lr: 0.00000024 	 loss = 0.5289(0.5085)
2023/09/17 13:59:46 - INFO - root -   Epoch: [95/400][280/346], lr: 0.00000024 	 loss = 0.2628(0.5263)
2023/09/17 14:00:30 - INFO - root -   Epoch: [95/400][300/346], lr: 0.00000024 	 loss = 0.1753(0.5252)
2023/09/17 14:01:30 - INFO - root -   Epoch: [95/400][320/346], lr: 0.00000024 	 loss = 0.2006(0.5234)
2023/09/17 14:02:13 - INFO - root -   Epoch: [95/400][340/346], lr: 0.00000024 	 loss = 0.9986(0.5244)
2023/09/17 14:02:17 - INFO - root -   Epoch: [95/400] 	 loss = 0.5245
2023/09/17 14:02:17 - INFO - root -   train_accuracy = 0.7486
2023/09/17 14:02:39 - INFO - root -   Epoch: [96/400][0/346], lr: 0.00000024 	 loss = 0.4332(0.4332)
2023/09/17 14:03:22 - INFO - root -   Epoch: [96/400][20/346], lr: 0.00000024 	 loss = 0.2508(0.4120)
2023/09/17 14:04:23 - INFO - root -   Epoch: [96/400][40/346], lr: 0.00000024 	 loss = 1.0072(0.4878)
2023/09/17 14:05:07 - INFO - root -   Epoch: [96/400][60/346], lr: 0.00000024 	 loss = 0.7364(0.4535)
2023/09/17 14:06:08 - INFO - root -   Epoch: [96/400][80/346], lr: 0.00000024 	 loss = 0.4356(0.4896)
2023/09/17 14:06:52 - INFO - root -   Epoch: [96/400][100/346], lr: 0.00000024 	 loss = 0.7090(0.5001)
2023/09/17 14:07:53 - INFO - root -   Epoch: [96/400][120/346], lr: 0.00000024 	 loss = 0.2805(0.5132)
2023/09/17 14:08:36 - INFO - root -   Epoch: [96/400][140/346], lr: 0.00000024 	 loss = 0.2692(0.4996)
2023/09/17 14:09:37 - INFO - root -   Epoch: [96/400][160/346], lr: 0.00000024 	 loss = 0.2649(0.5033)
2023/09/17 14:10:21 - INFO - root -   Epoch: [96/400][180/346], lr: 0.00000024 	 loss = 0.6329(0.5169)
2023/09/17 14:11:22 - INFO - root -   Epoch: [96/400][200/346], lr: 0.00000024 	 loss = 0.1462(0.5108)
2023/09/17 14:12:05 - INFO - root -   Epoch: [96/400][220/346], lr: 0.00000024 	 loss = 0.3215(0.5193)
2023/09/17 14:13:06 - INFO - root -   Epoch: [96/400][240/346], lr: 0.00000024 	 loss = 0.0963(0.5228)
2023/09/17 14:13:50 - INFO - root -   Epoch: [96/400][260/346], lr: 0.00000024 	 loss = 1.4847(0.5296)
2023/09/17 14:14:50 - INFO - root -   Epoch: [96/400][280/346], lr: 0.00000024 	 loss = 0.6455(0.5429)
2023/09/17 14:15:34 - INFO - root -   Epoch: [96/400][300/346], lr: 0.00000024 	 loss = 0.1907(0.5414)
2023/09/17 14:16:34 - INFO - root -   Epoch: [96/400][320/346], lr: 0.00000024 	 loss = 0.3609(0.5365)
2023/09/17 14:17:15 - INFO - root -   Epoch: [96/400][340/346], lr: 0.00000024 	 loss = 0.7783(0.5370)
2023/09/17 14:17:20 - INFO - root -   Epoch: [96/400] 	 loss = 0.5365
2023/09/17 14:17:20 - INFO - root -   train_accuracy = 0.7225
2023/09/17 14:17:41 - INFO - root -   Epoch: [97/400][0/346], lr: 0.00000024 	 loss = 0.5700(0.5700)
2023/09/17 14:18:25 - INFO - root -   Epoch: [97/400][20/346], lr: 0.00000024 	 loss = 0.1584(0.5072)
2023/09/17 14:19:25 - INFO - root -   Epoch: [97/400][40/346], lr: 0.00000024 	 loss = 0.3004(0.5199)
2023/09/17 14:20:08 - INFO - root -   Epoch: [97/400][60/346], lr: 0.00000024 	 loss = 0.3572(0.4640)
2023/09/17 14:21:09 - INFO - root -   Epoch: [97/400][80/346], lr: 0.00000024 	 loss = 0.2264(0.4674)
2023/09/17 14:21:53 - INFO - root -   Epoch: [97/400][100/346], lr: 0.00000024 	 loss = 0.4833(0.4786)
2023/09/17 14:22:52 - INFO - root -   Epoch: [97/400][120/346], lr: 0.00000024 	 loss = 0.0948(0.4856)
2023/09/17 14:23:37 - INFO - root -   Epoch: [97/400][140/346], lr: 0.00000024 	 loss = 0.3862(0.4887)
2023/09/17 14:24:36 - INFO - root -   Epoch: [97/400][160/346], lr: 0.00000024 	 loss = 0.1764(0.4951)
2023/09/17 14:25:21 - INFO - root -   Epoch: [97/400][180/346], lr: 0.00000024 	 loss = 0.3111(0.5013)
2023/09/17 14:26:19 - INFO - root -   Epoch: [97/400][200/346], lr: 0.00000024 	 loss = 0.2245(0.4942)
2023/09/17 14:27:05 - INFO - root -   Epoch: [97/400][220/346], lr: 0.00000024 	 loss = 0.1780(0.5009)
2023/09/17 14:28:03 - INFO - root -   Epoch: [97/400][240/346], lr: 0.00000024 	 loss = 0.2260(0.4983)
2023/09/17 14:28:49 - INFO - root -   Epoch: [97/400][260/346], lr: 0.00000024 	 loss = 0.5507(0.4889)
2023/09/17 14:29:46 - INFO - root -   Epoch: [97/400][280/346], lr: 0.00000024 	 loss = 0.4126(0.5042)
2023/09/17 14:30:33 - INFO - root -   Epoch: [97/400][300/346], lr: 0.00000024 	 loss = 0.1564(0.4992)
2023/09/17 14:31:30 - INFO - root -   Epoch: [97/400][320/346], lr: 0.00000024 	 loss = 0.1270(0.4954)
2023/09/17 14:32:14 - INFO - root -   Epoch: [97/400][340/346], lr: 0.00000024 	 loss = 0.6341(0.5008)
2023/09/17 14:32:18 - INFO - root -   Epoch: [97/400] 	 loss = 0.5037
2023/09/17 14:32:18 - INFO - root -   train_accuracy = 0.7486
2023/09/17 14:32:40 - INFO - root -   Epoch: [98/400][0/346], lr: 0.00000024 	 loss = 0.3450(0.3450)
2023/09/17 14:33:22 - INFO - root -   Epoch: [98/400][20/346], lr: 0.00000024 	 loss = 0.0936(0.3870)
2023/09/17 14:34:23 - INFO - root -   Epoch: [98/400][40/346], lr: 0.00000024 	 loss = 0.6948(0.4612)
2023/09/17 14:35:07 - INFO - root -   Epoch: [98/400][60/346], lr: 0.00000024 	 loss = 0.4638(0.4633)
2023/09/17 14:36:07 - INFO - root -   Epoch: [98/400][80/346], lr: 0.00000024 	 loss = 0.1672(0.4892)
2023/09/17 14:36:51 - INFO - root -   Epoch: [98/400][100/346], lr: 0.00000024 	 loss = 0.5428(0.4907)
2023/09/17 14:37:51 - INFO - root -   Epoch: [98/400][120/346], lr: 0.00000024 	 loss = 0.5014(0.5264)
2023/09/17 14:38:34 - INFO - root -   Epoch: [98/400][140/346], lr: 0.00000024 	 loss = 0.4980(0.5270)
2023/09/17 14:39:35 - INFO - root -   Epoch: [98/400][160/346], lr: 0.00000024 	 loss = 0.1217(0.5320)
2023/09/17 14:40:19 - INFO - root -   Epoch: [98/400][180/346], lr: 0.00000024 	 loss = 0.1164(0.5398)
2023/09/17 14:41:19 - INFO - root -   Epoch: [98/400][200/346], lr: 0.00000024 	 loss = 0.1072(0.5210)
2023/09/17 14:42:03 - INFO - root -   Epoch: [98/400][220/346], lr: 0.00000024 	 loss = 0.4993(0.5265)
2023/09/17 14:43:02 - INFO - root -   Epoch: [98/400][240/346], lr: 0.00000024 	 loss = 0.1608(0.5189)
2023/09/17 14:43:46 - INFO - root -   Epoch: [98/400][260/346], lr: 0.00000024 	 loss = 0.3089(0.5080)
2023/09/17 14:44:46 - INFO - root -   Epoch: [98/400][280/346], lr: 0.00000024 	 loss = 0.1676(0.5151)
2023/09/17 14:45:30 - INFO - root -   Epoch: [98/400][300/346], lr: 0.00000024 	 loss = 0.2559(0.5137)
2023/09/17 14:46:30 - INFO - root -   Epoch: [98/400][320/346], lr: 0.00000024 	 loss = 0.1254(0.5128)
2023/09/17 14:47:13 - INFO - root -   Epoch: [98/400][340/346], lr: 0.00000024 	 loss = 0.6826(0.5133)
2023/09/17 14:47:17 - INFO - root -   Epoch: [98/400] 	 loss = 0.5192
2023/09/17 14:47:17 - INFO - root -   train_accuracy = 0.7457
2023/09/17 14:47:39 - INFO - root -   Epoch: [99/400][0/346], lr: 0.00000024 	 loss = 0.2050(0.2050)
2023/09/17 14:48:22 - INFO - root -   Epoch: [99/400][20/346], lr: 0.00000024 	 loss = 0.0822(0.3780)
2023/09/17 14:49:22 - INFO - root -   Epoch: [99/400][40/346], lr: 0.00000024 	 loss = 0.2317(0.4215)
2023/09/17 14:50:06 - INFO - root -   Epoch: [99/400][60/346], lr: 0.00000024 	 loss = 0.6061(0.3754)
2023/09/17 14:51:06 - INFO - root -   Epoch: [99/400][80/346], lr: 0.00000024 	 loss = 0.4854(0.3874)
2023/09/17 14:51:49 - INFO - root -   Epoch: [99/400][100/346], lr: 0.00000024 	 loss = 0.3639(0.4020)
2023/09/17 14:52:50 - INFO - root -   Epoch: [99/400][120/346], lr: 0.00000024 	 loss = 0.0664(0.4296)
2023/09/17 14:53:33 - INFO - root -   Epoch: [99/400][140/346], lr: 0.00000024 	 loss = 0.6233(0.4396)
2023/09/17 14:54:33 - INFO - root -   Epoch: [99/400][160/346], lr: 0.00000024 	 loss = 0.1076(0.4606)
2023/09/17 14:55:16 - INFO - root -   Epoch: [99/400][180/346], lr: 0.00000024 	 loss = 0.2245(0.4742)
2023/09/17 14:56:17 - INFO - root -   Epoch: [99/400][200/346], lr: 0.00000024 	 loss = 0.1978(0.4623)
2023/09/17 14:57:00 - INFO - root -   Epoch: [99/400][220/346], lr: 0.00000024 	 loss = 0.3992(0.4737)
2023/09/17 14:58:00 - INFO - root -   Epoch: [99/400][240/346], lr: 0.00000024 	 loss = 0.1621(0.4710)
2023/09/17 14:58:44 - INFO - root -   Epoch: [99/400][260/346], lr: 0.00000024 	 loss = 1.1050(0.4711)
2023/09/17 14:59:43 - INFO - root -   Epoch: [99/400][280/346], lr: 0.00000024 	 loss = 0.2920(0.4820)
2023/09/17 15:00:27 - INFO - root -   Epoch: [99/400][300/346], lr: 0.00000024 	 loss = 0.3348(0.4843)
2023/09/17 15:01:27 - INFO - root -   Epoch: [99/400][320/346], lr: 0.00000024 	 loss = 0.2495(0.4810)
2023/09/17 15:02:10 - INFO - root -   Epoch: [99/400][340/346], lr: 0.00000024 	 loss = 0.7284(0.4788)
2023/09/17 15:02:14 - INFO - root -   Epoch: [99/400] 	 loss = 0.4796
2023/09/17 15:06:01 - INFO - root -   precision = 0.7011
2023/09/17 15:06:01 - INFO - root -   eval_loss = 0.6287
2023/09/17 15:06:02 - INFO - root -   train_accuracy = 0.7717
2023/09/17 15:06:24 - INFO - root -   Epoch: [100/400][0/346], lr: 0.00000024 	 loss = 0.3949(0.3949)
2023/09/17 15:07:07 - INFO - root -   Epoch: [100/400][20/346], lr: 0.00000024 	 loss = 0.1693(0.3759)
2023/09/17 15:08:09 - INFO - root -   Epoch: [100/400][40/346], lr: 0.00000024 	 loss = 0.3594(0.4859)
2023/09/17 15:08:52 - INFO - root -   Epoch: [100/400][60/346], lr: 0.00000024 	 loss = 0.6477(0.4820)
2023/09/17 15:09:53 - INFO - root -   Epoch: [100/400][80/346], lr: 0.00000024 	 loss = 0.4744(0.4958)
2023/09/17 15:10:37 - INFO - root -   Epoch: [100/400][100/346], lr: 0.00000024 	 loss = 0.7650(0.5094)
2023/09/17 15:11:38 - INFO - root -   Epoch: [100/400][120/346], lr: 0.00000024 	 loss = 0.2494(0.5357)
2023/09/17 15:12:21 - INFO - root -   Epoch: [100/400][140/346], lr: 0.00000024 	 loss = 0.4872(0.5311)
2023/09/17 15:13:22 - INFO - root -   Epoch: [100/400][160/346], lr: 0.00000024 	 loss = 0.1128(0.5230)
2023/09/17 15:14:06 - INFO - root -   Epoch: [100/400][180/346], lr: 0.00000024 	 loss = 0.1148(0.5249)
2023/09/17 15:15:07 - INFO - root -   Epoch: [100/400][200/346], lr: 0.00000024 	 loss = 0.1386(0.5073)
2023/09/17 15:15:50 - INFO - root -   Epoch: [100/400][220/346], lr: 0.00000024 	 loss = 0.1355(0.5119)
2023/09/17 15:16:51 - INFO - root -   Epoch: [100/400][240/346], lr: 0.00000024 	 loss = 0.0425(0.5064)
2023/09/17 15:17:35 - INFO - root -   Epoch: [100/400][260/346], lr: 0.00000024 	 loss = 0.6586(0.4948)
2023/09/17 15:18:35 - INFO - root -   Epoch: [100/400][280/346], lr: 0.00000024 	 loss = 0.1438(0.5144)
2023/09/17 15:19:19 - INFO - root -   Epoch: [100/400][300/346], lr: 0.00000024 	 loss = 0.1048(0.5097)
2023/09/17 15:20:19 - INFO - root -   Epoch: [100/400][320/346], lr: 0.00000024 	 loss = 0.2165(0.5052)
2023/09/17 15:21:01 - INFO - root -   Epoch: [100/400][340/346], lr: 0.00000024 	 loss = 1.2758(0.5019)
2023/09/17 15:21:05 - INFO - root -   Epoch: [100/400] 	 loss = 0.5026
2023/09/17 15:21:05 - INFO - root -   train_accuracy = 0.7572
2023/09/17 15:21:26 - INFO - root -   Epoch: [101/400][0/346], lr: 0.00000024 	 loss = 0.5133(0.5133)
2023/09/17 15:22:10 - INFO - root -   Epoch: [101/400][20/346], lr: 0.00000024 	 loss = 0.1545(0.4536)
2023/09/17 15:23:11 - INFO - root -   Epoch: [101/400][40/346], lr: 0.00000024 	 loss = 0.6948(0.5107)
2023/09/17 15:23:54 - INFO - root -   Epoch: [101/400][60/346], lr: 0.00000024 	 loss = 0.3929(0.4543)
2023/09/17 15:24:55 - INFO - root -   Epoch: [101/400][80/346], lr: 0.00000024 	 loss = 0.2193(0.4793)
2023/09/17 15:25:39 - INFO - root -   Epoch: [101/400][100/346], lr: 0.00000024 	 loss = 0.6429(0.4918)
2023/09/17 15:26:40 - INFO - root -   Epoch: [101/400][120/346], lr: 0.00000024 	 loss = 0.1089(0.5112)
2023/09/17 15:27:24 - INFO - root -   Epoch: [101/400][140/346], lr: 0.00000024 	 loss = 0.5846(0.5009)
2023/09/17 15:28:24 - INFO - root -   Epoch: [101/400][160/346], lr: 0.00000024 	 loss = 0.1022(0.4937)
2023/09/17 15:29:09 - INFO - root -   Epoch: [101/400][180/346], lr: 0.00000024 	 loss = 0.1184(0.4963)
2023/09/17 15:30:08 - INFO - root -   Epoch: [101/400][200/346], lr: 0.00000024 	 loss = 0.0829(0.4835)
2023/09/17 15:30:53 - INFO - root -   Epoch: [101/400][220/346], lr: 0.00000024 	 loss = 0.2222(0.4855)
2023/09/17 15:31:53 - INFO - root -   Epoch: [101/400][240/346], lr: 0.00000024 	 loss = 0.1352(0.4812)
2023/09/17 15:32:38 - INFO - root -   Epoch: [101/400][260/346], lr: 0.00000024 	 loss = 0.8305(0.4750)
2023/09/17 15:33:37 - INFO - root -   Epoch: [101/400][280/346], lr: 0.00000024 	 loss = 0.1067(0.4925)
2023/09/17 15:34:22 - INFO - root -   Epoch: [101/400][300/346], lr: 0.00000024 	 loss = 0.1508(0.4932)
2023/09/17 15:35:21 - INFO - root -   Epoch: [101/400][320/346], lr: 0.00000024 	 loss = 0.5237(0.4876)
2023/09/17 15:36:05 - INFO - root -   Epoch: [101/400][340/346], lr: 0.00000024 	 loss = 1.2468(0.4887)
2023/09/17 15:36:09 - INFO - root -   Epoch: [101/400] 	 loss = 0.4917
2023/09/17 15:36:09 - INFO - root -   train_accuracy = 0.7673
2023/09/17 15:36:30 - INFO - root -   Epoch: [102/400][0/346], lr: 0.00000025 	 loss = 0.2744(0.2744)
2023/09/17 15:37:14 - INFO - root -   Epoch: [102/400][20/346], lr: 0.00000025 	 loss = 0.1195(0.4459)
2023/09/17 15:38:15 - INFO - root -   Epoch: [102/400][40/346], lr: 0.00000025 	 loss = 0.2004(0.4619)
2023/09/17 15:38:58 - INFO - root -   Epoch: [102/400][60/346], lr: 0.00000025 	 loss = 0.5799(0.4317)
2023/09/17 15:39:59 - INFO - root -   Epoch: [102/400][80/346], lr: 0.00000025 	 loss = 0.3476(0.4541)
2023/09/17 15:40:42 - INFO - root -   Epoch: [102/400][100/346], lr: 0.00000025 	 loss = 0.2828(0.4847)
2023/09/17 15:41:43 - INFO - root -   Epoch: [102/400][120/346], lr: 0.00000025 	 loss = 0.1034(0.5034)
2023/09/17 15:42:26 - INFO - root -   Epoch: [102/400][140/346], lr: 0.00000025 	 loss = 0.5072(0.5010)
2023/09/17 15:43:27 - INFO - root -   Epoch: [102/400][160/346], lr: 0.00000025 	 loss = 0.0696(0.4951)
2023/09/17 15:44:11 - INFO - root -   Epoch: [102/400][180/346], lr: 0.00000025 	 loss = 0.4895(0.4987)
2023/09/17 15:45:11 - INFO - root -   Epoch: [102/400][200/346], lr: 0.00000025 	 loss = 0.0823(0.4890)
2023/09/17 15:45:55 - INFO - root -   Epoch: [102/400][220/346], lr: 0.00000025 	 loss = 0.2341(0.4977)
2023/09/17 15:46:55 - INFO - root -   Epoch: [102/400][240/346], lr: 0.00000025 	 loss = 0.2141(0.4899)
2023/09/17 15:47:38 - INFO - root -   Epoch: [102/400][260/346], lr: 0.00000025 	 loss = 1.2025(0.4868)
2023/09/17 15:48:39 - INFO - root -   Epoch: [102/400][280/346], lr: 0.00000025 	 loss = 0.3421(0.4967)
2023/09/17 15:49:23 - INFO - root -   Epoch: [102/400][300/346], lr: 0.00000025 	 loss = 0.2177(0.5002)
2023/09/17 15:50:22 - INFO - root -   Epoch: [102/400][320/346], lr: 0.00000025 	 loss = 0.1549(0.4974)
2023/09/17 15:51:05 - INFO - root -   Epoch: [102/400][340/346], lr: 0.00000025 	 loss = 1.1485(0.4978)
2023/09/17 15:51:09 - INFO - root -   Epoch: [102/400] 	 loss = 0.4992
2023/09/17 15:51:09 - INFO - root -   train_accuracy = 0.7500
2023/09/17 15:51:31 - INFO - root -   Epoch: [103/400][0/346], lr: 0.00000025 	 loss = 0.2223(0.2223)
2023/09/17 15:52:14 - INFO - root -   Epoch: [103/400][20/346], lr: 0.00000025 	 loss = 0.1482(0.4262)
2023/09/17 15:53:15 - INFO - root -   Epoch: [103/400][40/346], lr: 0.00000025 	 loss = 0.1437(0.4750)
2023/09/17 15:53:58 - INFO - root -   Epoch: [103/400][60/346], lr: 0.00000025 	 loss = 0.3927(0.4551)
2023/09/17 15:54:58 - INFO - root -   Epoch: [103/400][80/346], lr: 0.00000025 	 loss = 0.4539(0.4752)
2023/09/17 15:55:41 - INFO - root -   Epoch: [103/400][100/346], lr: 0.00000025 	 loss = 0.4260(0.4906)
2023/09/17 15:56:42 - INFO - root -   Epoch: [103/400][120/346], lr: 0.00000025 	 loss = 0.1569(0.5184)
2023/09/17 15:57:25 - INFO - root -   Epoch: [103/400][140/346], lr: 0.00000025 	 loss = 0.4156(0.5110)
2023/09/17 15:58:25 - INFO - root -   Epoch: [103/400][160/346], lr: 0.00000025 	 loss = 0.1556(0.5136)
2023/09/17 15:59:09 - INFO - root -   Epoch: [103/400][180/346], lr: 0.00000025 	 loss = 0.1960(0.5169)
2023/09/17 16:00:09 - INFO - root -   Epoch: [103/400][200/346], lr: 0.00000025 	 loss = 0.0939(0.5033)
2023/09/17 16:00:52 - INFO - root -   Epoch: [103/400][220/346], lr: 0.00000025 	 loss = 0.2007(0.5080)
2023/09/17 16:01:52 - INFO - root -   Epoch: [103/400][240/346], lr: 0.00000025 	 loss = 0.1136(0.4964)
2023/09/17 16:02:35 - INFO - root -   Epoch: [103/400][260/346], lr: 0.00000025 	 loss = 0.5063(0.4870)
2023/09/17 16:03:36 - INFO - root -   Epoch: [103/400][280/346], lr: 0.00000025 	 loss = 0.1629(0.4976)
2023/09/17 16:04:19 - INFO - root -   Epoch: [103/400][300/346], lr: 0.00000025 	 loss = 0.0854(0.4998)
2023/09/17 16:05:19 - INFO - root -   Epoch: [103/400][320/346], lr: 0.00000025 	 loss = 0.1858(0.4928)
2023/09/17 16:06:01 - INFO - root -   Epoch: [103/400][340/346], lr: 0.00000025 	 loss = 1.1658(0.5129)
2023/09/17 16:06:05 - INFO - root -   Epoch: [103/400] 	 loss = 0.5163
2023/09/17 16:06:05 - INFO - root -   train_accuracy = 0.7514
2023/09/17 16:06:27 - INFO - root -   Epoch: [104/400][0/346], lr: 0.00000025 	 loss = 0.2323(0.2323)
2023/09/17 16:07:10 - INFO - root -   Epoch: [104/400][20/346], lr: 0.00000025 	 loss = 0.3966(0.5753)
2023/09/17 16:08:10 - INFO - root -   Epoch: [104/400][40/346], lr: 0.00000025 	 loss = 0.2497(0.5852)
2023/09/17 16:08:53 - INFO - root -   Epoch: [104/400][60/346], lr: 0.00000025 	 loss = 0.3779(0.5107)
2023/09/17 16:09:54 - INFO - root -   Epoch: [104/400][80/346], lr: 0.00000025 	 loss = 0.1976(0.5496)
2023/09/17 16:10:37 - INFO - root -   Epoch: [104/400][100/346], lr: 0.00000025 	 loss = 0.3473(0.5450)
2023/09/17 16:11:38 - INFO - root -   Epoch: [104/400][120/346], lr: 0.00000025 	 loss = 0.1418(0.5537)
2023/09/17 16:12:21 - INFO - root -   Epoch: [104/400][140/346], lr: 0.00000025 	 loss = 0.7226(0.5406)
2023/09/17 16:13:21 - INFO - root -   Epoch: [104/400][160/346], lr: 0.00000025 	 loss = 0.1019(0.5343)
2023/09/17 16:14:04 - INFO - root -   Epoch: [104/400][180/346], lr: 0.00000025 	 loss = 0.3846(0.5400)
2023/09/17 16:15:04 - INFO - root -   Epoch: [104/400][200/346], lr: 0.00000025 	 loss = 0.2027(0.5210)
2023/09/17 16:15:47 - INFO - root -   Epoch: [104/400][220/346], lr: 0.00000025 	 loss = 0.2114(0.5173)
2023/09/17 16:16:47 - INFO - root -   Epoch: [104/400][240/346], lr: 0.00000025 	 loss = 0.0917(0.5083)
2023/09/17 16:17:30 - INFO - root -   Epoch: [104/400][260/346], lr: 0.00000025 	 loss = 0.5643(0.5022)
2023/09/17 16:18:31 - INFO - root -   Epoch: [104/400][280/346], lr: 0.00000025 	 loss = 0.2601(0.5165)
2023/09/17 16:19:14 - INFO - root -   Epoch: [104/400][300/346], lr: 0.00000025 	 loss = 0.1603(0.5150)
2023/09/17 16:20:14 - INFO - root -   Epoch: [104/400][320/346], lr: 0.00000025 	 loss = 0.1513(0.5129)
2023/09/17 16:20:56 - INFO - root -   Epoch: [104/400][340/346], lr: 0.00000025 	 loss = 0.7641(0.5095)
2023/09/17 16:21:00 - INFO - root -   Epoch: [104/400] 	 loss = 0.5093
2023/09/17 16:24:50 - INFO - root -   precision = 0.7126
2023/09/17 16:24:50 - INFO - root -   eval_loss = 0.6147
2023/09/17 16:24:51 - INFO - root -   train_accuracy = 0.7673
2023/09/17 16:25:12 - INFO - root -   Epoch: [105/400][0/346], lr: 0.00000025 	 loss = 0.3785(0.3785)
2023/09/17 16:25:55 - INFO - root -   Epoch: [105/400][20/346], lr: 0.00000025 	 loss = 0.0340(0.4201)
2023/09/17 16:26:56 - INFO - root -   Epoch: [105/400][40/346], lr: 0.00000025 	 loss = 0.3707(0.4506)
2023/09/17 16:27:39 - INFO - root -   Epoch: [105/400][60/346], lr: 0.00000025 	 loss = 0.6365(0.3962)
2023/09/17 16:28:40 - INFO - root -   Epoch: [105/400][80/346], lr: 0.00000025 	 loss = 0.1569(0.4268)
2023/09/17 16:29:23 - INFO - root -   Epoch: [105/400][100/346], lr: 0.00000025 	 loss = 0.3992(0.4351)
2023/09/17 16:30:24 - INFO - root -   Epoch: [105/400][120/346], lr: 0.00000025 	 loss = 0.1100(0.4641)
2023/09/17 16:31:07 - INFO - root -   Epoch: [105/400][140/346], lr: 0.00000025 	 loss = 0.7271(0.4503)
2023/09/17 16:32:08 - INFO - root -   Epoch: [105/400][160/346], lr: 0.00000025 	 loss = 0.1031(0.4609)
2023/09/17 16:32:51 - INFO - root -   Epoch: [105/400][180/346], lr: 0.00000025 	 loss = 0.0670(0.4605)
2023/09/17 16:33:51 - INFO - root -   Epoch: [105/400][200/346], lr: 0.00000025 	 loss = 0.0934(0.4531)
2023/09/17 16:34:35 - INFO - root -   Epoch: [105/400][220/346], lr: 0.00000025 	 loss = 0.3136(0.4603)
2023/09/17 16:35:35 - INFO - root -   Epoch: [105/400][240/346], lr: 0.00000025 	 loss = 0.0782(0.4563)
2023/09/17 16:36:18 - INFO - root -   Epoch: [105/400][260/346], lr: 0.00000025 	 loss = 0.4999(0.4515)
2023/09/17 16:37:19 - INFO - root -   Epoch: [105/400][280/346], lr: 0.00000025 	 loss = 0.3463(0.4630)
2023/09/17 16:38:02 - INFO - root -   Epoch: [105/400][300/346], lr: 0.00000025 	 loss = 0.1430(0.4679)
2023/09/17 16:39:03 - INFO - root -   Epoch: [105/400][320/346], lr: 0.00000025 	 loss = 0.2304(0.4659)
2023/09/17 16:39:44 - INFO - root -   Epoch: [105/400][340/346], lr: 0.00000025 	 loss = 0.8815(0.4653)
2023/09/17 16:39:49 - INFO - root -   Epoch: [105/400] 	 loss = 0.4678
2023/09/17 16:39:49 - INFO - root -   train_accuracy = 0.7688
2023/09/17 16:40:10 - INFO - root -   Epoch: [106/400][0/346], lr: 0.00000025 	 loss = 0.5836(0.5836)
2023/09/17 16:40:53 - INFO - root -   Epoch: [106/400][20/346], lr: 0.00000025 	 loss = 0.2255(0.3962)
2023/09/17 16:41:54 - INFO - root -   Epoch: [106/400][40/346], lr: 0.00000025 	 loss = 0.4125(0.4398)
2023/09/17 16:42:37 - INFO - root -   Epoch: [106/400][60/346], lr: 0.00000025 	 loss = 0.5108(0.3947)
2023/09/17 16:43:38 - INFO - root -   Epoch: [106/400][80/346], lr: 0.00000025 	 loss = 0.2538(0.4364)
2023/09/17 16:44:22 - INFO - root -   Epoch: [106/400][100/346], lr: 0.00000025 	 loss = 0.8392(0.4373)
2023/09/17 16:45:23 - INFO - root -   Epoch: [106/400][120/346], lr: 0.00000025 	 loss = 0.0948(0.4505)
2023/09/17 16:46:06 - INFO - root -   Epoch: [106/400][140/346], lr: 0.00000025 	 loss = 0.6360(0.4430)
2023/09/17 16:47:07 - INFO - root -   Epoch: [106/400][160/346], lr: 0.00000025 	 loss = 0.0708(0.4534)
2023/09/17 16:47:51 - INFO - root -   Epoch: [106/400][180/346], lr: 0.00000025 	 loss = 0.3978(0.4638)
2023/09/17 16:48:51 - INFO - root -   Epoch: [106/400][200/346], lr: 0.00000025 	 loss = 0.1251(0.4499)
2023/09/17 16:49:35 - INFO - root -   Epoch: [106/400][220/346], lr: 0.00000025 	 loss = 0.5330(0.4602)
2023/09/17 16:50:35 - INFO - root -   Epoch: [106/400][240/346], lr: 0.00000025 	 loss = 0.2598(0.4546)
2023/09/17 16:51:19 - INFO - root -   Epoch: [106/400][260/346], lr: 0.00000025 	 loss = 0.7146(0.4484)
2023/09/17 16:52:19 - INFO - root -   Epoch: [106/400][280/346], lr: 0.00000025 	 loss = 0.2454(0.4615)
2023/09/17 16:53:03 - INFO - root -   Epoch: [106/400][300/346], lr: 0.00000025 	 loss = 0.1244(0.4665)
2023/09/17 16:54:03 - INFO - root -   Epoch: [106/400][320/346], lr: 0.00000025 	 loss = 0.0407(0.4646)
2023/09/17 16:54:46 - INFO - root -   Epoch: [106/400][340/346], lr: 0.00000025 	 loss = 0.9643(0.4653)
2023/09/17 16:54:51 - INFO - root -   Epoch: [106/400] 	 loss = 0.4694
2023/09/17 16:54:51 - INFO - root -   train_accuracy = 0.7789
2023/09/17 16:55:13 - INFO - root -   Epoch: [107/400][0/346], lr: 0.00000025 	 loss = 0.4180(0.4180)
2023/09/17 16:55:57 - INFO - root -   Epoch: [107/400][20/346], lr: 0.00000025 	 loss = 0.0786(0.4008)
2023/09/17 16:56:59 - INFO - root -   Epoch: [107/400][40/346], lr: 0.00000025 	 loss = 0.2876(0.4296)
2023/09/17 16:57:42 - INFO - root -   Epoch: [107/400][60/346], lr: 0.00000025 	 loss = 0.2617(0.3795)
2023/09/17 16:58:44 - INFO - root -   Epoch: [107/400][80/346], lr: 0.00000025 	 loss = 0.1383(0.4039)
2023/09/17 16:59:27 - INFO - root -   Epoch: [107/400][100/346], lr: 0.00000025 	 loss = 0.3175(0.4100)
2023/09/17 17:00:29 - INFO - root -   Epoch: [107/400][120/346], lr: 0.00000025 	 loss = 0.2043(0.4464)
2023/09/17 17:01:12 - INFO - root -   Epoch: [107/400][140/346], lr: 0.00000025 	 loss = 0.4192(0.4439)
2023/09/17 17:02:13 - INFO - root -   Epoch: [107/400][160/346], lr: 0.00000025 	 loss = 0.1444(0.4636)
2023/09/17 17:02:56 - INFO - root -   Epoch: [107/400][180/346], lr: 0.00000025 	 loss = 0.2931(0.4785)
2023/09/17 17:03:58 - INFO - root -   Epoch: [107/400][200/346], lr: 0.00000025 	 loss = 0.0606(0.4620)
2023/09/17 17:04:41 - INFO - root -   Epoch: [107/400][220/346], lr: 0.00000025 	 loss = 0.2001(0.4662)
2023/09/17 17:05:42 - INFO - root -   Epoch: [107/400][240/346], lr: 0.00000025 	 loss = 0.0763(0.4610)
2023/09/17 17:06:25 - INFO - root -   Epoch: [107/400][260/346], lr: 0.00000025 	 loss = 0.7212(0.4572)
2023/09/17 17:07:26 - INFO - root -   Epoch: [107/400][280/346], lr: 0.00000025 	 loss = 0.1902(0.4717)
2023/09/17 17:08:10 - INFO - root -   Epoch: [107/400][300/346], lr: 0.00000025 	 loss = 0.3103(0.4712)
2023/09/17 17:09:11 - INFO - root -   Epoch: [107/400][320/346], lr: 0.00000025 	 loss = 0.3186(0.4665)
2023/09/17 17:09:53 - INFO - root -   Epoch: [107/400][340/346], lr: 0.00000025 	 loss = 0.8221(0.4709)
2023/09/17 17:09:57 - INFO - root -   Epoch: [107/400] 	 loss = 0.4730
2023/09/17 17:09:57 - INFO - root -   train_accuracy = 0.7789
2023/09/17 17:10:18 - INFO - root -   Epoch: [108/400][0/346], lr: 0.00000025 	 loss = 0.1679(0.1679)
2023/09/17 17:11:01 - INFO - root -   Epoch: [108/400][20/346], lr: 0.00000025 	 loss = 0.0691(0.4023)
2023/09/17 17:12:02 - INFO - root -   Epoch: [108/400][40/346], lr: 0.00000025 	 loss = 0.2315(0.4476)
2023/09/17 17:12:46 - INFO - root -   Epoch: [108/400][60/346], lr: 0.00000025 	 loss = 0.3416(0.4036)
2023/09/17 17:13:47 - INFO - root -   Epoch: [108/400][80/346], lr: 0.00000025 	 loss = 0.1584(0.4249)
2023/09/17 17:14:30 - INFO - root -   Epoch: [108/400][100/346], lr: 0.00000025 	 loss = 0.6555(0.4189)
2023/09/17 17:15:31 - INFO - root -   Epoch: [108/400][120/346], lr: 0.00000025 	 loss = 0.5808(0.4517)
2023/09/17 17:16:14 - INFO - root -   Epoch: [108/400][140/346], lr: 0.00000025 	 loss = 0.2981(0.4523)
2023/09/17 17:17:14 - INFO - root -   Epoch: [108/400][160/346], lr: 0.00000025 	 loss = 0.0934(0.4638)
2023/09/17 17:17:57 - INFO - root -   Epoch: [108/400][180/346], lr: 0.00000025 	 loss = 0.7296(0.4675)
2023/09/17 17:18:58 - INFO - root -   Epoch: [108/400][200/346], lr: 0.00000025 	 loss = 0.0898(0.4531)
2023/09/17 17:19:41 - INFO - root -   Epoch: [108/400][220/346], lr: 0.00000025 	 loss = 0.2840(0.4603)
2023/09/17 17:20:42 - INFO - root -   Epoch: [108/400][240/346], lr: 0.00000025 	 loss = 0.0673(0.4530)
2023/09/17 17:21:25 - INFO - root -   Epoch: [108/400][260/346], lr: 0.00000025 	 loss = 1.7358(0.4533)
2023/09/17 17:22:25 - INFO - root -   Epoch: [108/400][280/346], lr: 0.00000025 	 loss = 0.3165(0.4648)
2023/09/17 17:23:08 - INFO - root -   Epoch: [108/400][300/346], lr: 0.00000025 	 loss = 0.1928(0.4682)
2023/09/17 17:24:09 - INFO - root -   Epoch: [108/400][320/346], lr: 0.00000025 	 loss = 0.2722(0.4623)
2023/09/17 17:24:51 - INFO - root -   Epoch: [108/400][340/346], lr: 0.00000025 	 loss = 0.2725(0.4614)
2023/09/17 17:24:55 - INFO - root -   Epoch: [108/400] 	 loss = 0.4634
2023/09/17 17:24:55 - INFO - root -   train_accuracy = 0.7775
2023/09/17 17:25:17 - INFO - root -   Epoch: [109/400][0/346], lr: 0.00000026 	 loss = 0.1186(0.1186)
2023/09/17 17:26:00 - INFO - root -   Epoch: [109/400][20/346], lr: 0.00000026 	 loss = 0.1376(0.3288)
2023/09/17 17:27:01 - INFO - root -   Epoch: [109/400][40/346], lr: 0.00000026 	 loss = 0.4136(0.4346)
2023/09/17 17:27:44 - INFO - root -   Epoch: [109/400][60/346], lr: 0.00000026 	 loss = 0.6167(0.3852)
2023/09/17 17:28:44 - INFO - root -   Epoch: [109/400][80/346], lr: 0.00000026 	 loss = 0.3404(0.4112)
2023/09/17 17:29:27 - INFO - root -   Epoch: [109/400][100/346], lr: 0.00000026 	 loss = 0.8375(0.4533)
2023/09/17 17:30:28 - INFO - root -   Epoch: [109/400][120/346], lr: 0.00000026 	 loss = 0.4147(0.4876)
2023/09/17 17:31:11 - INFO - root -   Epoch: [109/400][140/346], lr: 0.00000026 	 loss = 0.3216(0.4746)
2023/09/17 17:32:11 - INFO - root -   Epoch: [109/400][160/346], lr: 0.00000026 	 loss = 0.1142(0.4915)
2023/09/17 17:32:54 - INFO - root -   Epoch: [109/400][180/346], lr: 0.00000026 	 loss = 0.5617(0.5174)
2023/09/17 17:33:54 - INFO - root -   Epoch: [109/400][200/346], lr: 0.00000026 	 loss = 0.0893(0.5358)
2023/09/17 17:34:37 - INFO - root -   Epoch: [109/400][220/346], lr: 0.00000026 	 loss = 0.8181(0.5376)
2023/09/17 17:35:38 - INFO - root -   Epoch: [109/400][240/346], lr: 0.00000026 	 loss = 0.3230(0.5420)
2023/09/17 17:36:21 - INFO - root -   Epoch: [109/400][260/346], lr: 0.00000026 	 loss = 1.2798(0.5576)
2023/09/17 17:37:21 - INFO - root -   Epoch: [109/400][280/346], lr: 0.00000026 	 loss = 0.2082(0.5596)
2023/09/17 17:38:04 - INFO - root -   Epoch: [109/400][300/346], lr: 0.00000026 	 loss = 0.1598(0.5646)
2023/09/17 17:39:05 - INFO - root -   Epoch: [109/400][320/346], lr: 0.00000026 	 loss = 0.0904(0.5632)
2023/09/17 17:39:47 - INFO - root -   Epoch: [109/400][340/346], lr: 0.00000026 	 loss = 0.3561(0.5590)
2023/09/17 17:39:51 - INFO - root -   Epoch: [109/400] 	 loss = 0.5594
2023/09/17 17:43:39 - INFO - root -   precision = 0.6552
2023/09/17 17:43:39 - INFO - root -   eval_loss = 0.6313
2023/09/17 17:43:40 - INFO - root -   train_accuracy = 0.7269
2023/09/17 17:44:01 - INFO - root -   Epoch: [110/400][0/346], lr: 0.00000026 	 loss = 0.5852(0.5852)
2023/09/17 17:44:45 - INFO - root -   Epoch: [110/400][20/346], lr: 0.00000026 	 loss = 0.0567(0.4225)
2023/09/17 17:45:46 - INFO - root -   Epoch: [110/400][40/346], lr: 0.00000026 	 loss = 0.4745(0.4933)
2023/09/17 17:46:30 - INFO - root -   Epoch: [110/400][60/346], lr: 0.00000026 	 loss = 0.5583(0.4923)
2023/09/17 17:47:31 - INFO - root -   Epoch: [110/400][80/346], lr: 0.00000026 	 loss = 0.2016(0.5241)
2023/09/17 17:48:14 - INFO - root -   Epoch: [110/400][100/346], lr: 0.00000026 	 loss = 0.5804(0.5065)
2023/09/17 17:49:15 - INFO - root -   Epoch: [110/400][120/346], lr: 0.00000026 	 loss = 0.0636(0.5211)
2023/09/17 17:49:58 - INFO - root -   Epoch: [110/400][140/346], lr: 0.00000026 	 loss = 0.3487(0.5148)
2023/09/17 17:50:59 - INFO - root -   Epoch: [110/400][160/346], lr: 0.00000026 	 loss = 0.1218(0.5199)
2023/09/17 17:51:42 - INFO - root -   Epoch: [110/400][180/346], lr: 0.00000026 	 loss = 0.0975(0.5194)
2023/09/17 17:52:43 - INFO - root -   Epoch: [110/400][200/346], lr: 0.00000026 	 loss = 0.1083(0.5134)
2023/09/17 17:53:26 - INFO - root -   Epoch: [110/400][220/346], lr: 0.00000026 	 loss = 0.3030(0.5166)
2023/09/17 17:54:27 - INFO - root -   Epoch: [110/400][240/346], lr: 0.00000026 	 loss = 0.0991(0.5108)
2023/09/17 17:55:10 - INFO - root -   Epoch: [110/400][260/346], lr: 0.00000026 	 loss = 1.0361(0.5055)
2023/09/17 17:56:11 - INFO - root -   Epoch: [110/400][280/346], lr: 0.00000026 	 loss = 0.1145(0.5040)
2023/09/17 17:56:54 - INFO - root -   Epoch: [110/400][300/346], lr: 0.00000026 	 loss = 0.2587(0.5117)
2023/09/17 17:57:54 - INFO - root -   Epoch: [110/400][320/346], lr: 0.00000026 	 loss = 0.1880(0.5084)
2023/09/17 17:58:36 - INFO - root -   Epoch: [110/400][340/346], lr: 0.00000026 	 loss = 0.5630(0.5101)
2023/09/17 17:58:41 - INFO - root -   Epoch: [110/400] 	 loss = 0.5132
2023/09/17 17:58:41 - INFO - root -   train_accuracy = 0.7587
2023/09/17 17:59:02 - INFO - root -   Epoch: [111/400][0/346], lr: 0.00000026 	 loss = 0.3408(0.3408)
2023/09/17 17:59:45 - INFO - root -   Epoch: [111/400][20/346], lr: 0.00000026 	 loss = 0.1292(0.3848)
2023/09/17 18:00:45 - INFO - root -   Epoch: [111/400][40/346], lr: 0.00000026 	 loss = 0.5041(0.4688)
2023/09/17 18:01:28 - INFO - root -   Epoch: [111/400][60/346], lr: 0.00000026 	 loss = 0.7612(0.4133)
2023/09/17 18:02:29 - INFO - root -   Epoch: [111/400][80/346], lr: 0.00000026 	 loss = 0.5596(0.4532)
2023/09/17 18:03:12 - INFO - root -   Epoch: [111/400][100/346], lr: 0.00000026 	 loss = 0.5120(0.4715)
2023/09/17 18:04:13 - INFO - root -   Epoch: [111/400][120/346], lr: 0.00000026 	 loss = 0.0930(0.4926)
2023/09/17 18:04:56 - INFO - root -   Epoch: [111/400][140/346], lr: 0.00000026 	 loss = 0.4962(0.4951)
2023/09/17 18:05:57 - INFO - root -   Epoch: [111/400][160/346], lr: 0.00000026 	 loss = 0.0950(0.4943)
2023/09/17 18:06:40 - INFO - root -   Epoch: [111/400][180/346], lr: 0.00000026 	 loss = 0.4005(0.4981)
2023/09/17 18:07:40 - INFO - root -   Epoch: [111/400][200/346], lr: 0.00000026 	 loss = 0.1407(0.4827)
2023/09/17 18:08:23 - INFO - root -   Epoch: [111/400][220/346], lr: 0.00000026 	 loss = 0.2299(0.4894)
2023/09/17 18:09:24 - INFO - root -   Epoch: [111/400][240/346], lr: 0.00000026 	 loss = 0.0612(0.4844)
2023/09/17 18:10:07 - INFO - root -   Epoch: [111/400][260/346], lr: 0.00000026 	 loss = 0.6724(0.4788)
2023/09/17 18:11:08 - INFO - root -   Epoch: [111/400][280/346], lr: 0.00000026 	 loss = 0.2337(0.4895)
2023/09/17 18:11:51 - INFO - root -   Epoch: [111/400][300/346], lr: 0.00000026 	 loss = 0.2417(0.4897)
2023/09/17 18:12:51 - INFO - root -   Epoch: [111/400][320/346], lr: 0.00000026 	 loss = 0.2024(0.4805)
2023/09/17 18:13:33 - INFO - root -   Epoch: [111/400][340/346], lr: 0.00000026 	 loss = 0.4803(0.4834)
2023/09/17 18:13:37 - INFO - root -   Epoch: [111/400] 	 loss = 0.4871
2023/09/17 18:13:37 - INFO - root -   train_accuracy = 0.7760
2023/09/17 18:13:58 - INFO - root -   Epoch: [112/400][0/346], lr: 0.00000026 	 loss = 0.4022(0.4022)
2023/09/17 18:14:41 - INFO - root -   Epoch: [112/400][20/346], lr: 0.00000026 	 loss = 0.0280(0.3788)
2023/09/17 18:15:42 - INFO - root -   Epoch: [112/400][40/346], lr: 0.00000026 	 loss = 0.3115(0.4336)
2023/09/17 18:16:26 - INFO - root -   Epoch: [112/400][60/346], lr: 0.00000026 	 loss = 0.4317(0.3936)
2023/09/17 18:17:27 - INFO - root -   Epoch: [112/400][80/346], lr: 0.00000026 	 loss = 0.3228(0.4063)
2023/09/17 18:18:10 - INFO - root -   Epoch: [112/400][100/346], lr: 0.00000026 	 loss = 0.3491(0.4165)
2023/09/17 18:19:11 - INFO - root -   Epoch: [112/400][120/346], lr: 0.00000026 	 loss = 0.1193(0.4449)
2023/09/17 18:19:55 - INFO - root -   Epoch: [112/400][140/346], lr: 0.00000026 	 loss = 0.3814(0.4318)
2023/09/17 18:20:55 - INFO - root -   Epoch: [112/400][160/346], lr: 0.00000026 	 loss = 0.0687(0.4361)
2023/09/17 18:21:40 - INFO - root -   Epoch: [112/400][180/346], lr: 0.00000026 	 loss = 0.1412(0.4412)
2023/09/17 18:22:39 - INFO - root -   Epoch: [112/400][200/346], lr: 0.00000026 	 loss = 0.1378(0.4343)
2023/09/17 18:23:24 - INFO - root -   Epoch: [112/400][220/346], lr: 0.00000026 	 loss = 0.4057(0.4484)
2023/09/17 18:24:23 - INFO - root -   Epoch: [112/400][240/346], lr: 0.00000026 	 loss = 0.0934(0.4511)
2023/09/17 18:25:08 - INFO - root -   Epoch: [112/400][260/346], lr: 0.00000026 	 loss = 0.5667(0.4418)
2023/09/17 18:26:07 - INFO - root -   Epoch: [112/400][280/346], lr: 0.00000026 	 loss = 0.1398(0.4548)
2023/09/17 18:26:52 - INFO - root -   Epoch: [112/400][300/346], lr: 0.00000026 	 loss = 0.1782(0.4595)
2023/09/17 18:27:51 - INFO - root -   Epoch: [112/400][320/346], lr: 0.00000026 	 loss = 0.1168(0.4561)
2023/09/17 18:28:35 - INFO - root -   Epoch: [112/400][340/346], lr: 0.00000026 	 loss = 0.6831(0.4571)
2023/09/17 18:28:39 - INFO - root -   Epoch: [112/400] 	 loss = 0.4614
2023/09/17 18:28:39 - INFO - root -   train_accuracy = 0.7876
2023/09/17 18:29:01 - INFO - root -   Epoch: [113/400][0/346], lr: 0.00000026 	 loss = 0.6759(0.6759)
2023/09/17 18:29:44 - INFO - root -   Epoch: [113/400][20/346], lr: 0.00000026 	 loss = 0.2934(0.4498)
2023/09/17 18:30:45 - INFO - root -   Epoch: [113/400][40/346], lr: 0.00000026 	 loss = 0.2460(0.4463)
2023/09/17 18:31:28 - INFO - root -   Epoch: [113/400][60/346], lr: 0.00000026 	 loss = 0.4860(0.3923)
2023/09/17 18:32:29 - INFO - root -   Epoch: [113/400][80/346], lr: 0.00000026 	 loss = 0.2973(0.4393)
2023/09/17 18:33:13 - INFO - root -   Epoch: [113/400][100/346], lr: 0.00000026 	 loss = 0.8306(0.4373)
2023/09/17 18:34:14 - INFO - root -   Epoch: [113/400][120/346], lr: 0.00000026 	 loss = 0.0662(0.4707)
2023/09/17 18:34:57 - INFO - root -   Epoch: [113/400][140/346], lr: 0.00000026 	 loss = 0.7409(0.4655)
2023/09/17 18:35:58 - INFO - root -   Epoch: [113/400][160/346], lr: 0.00000026 	 loss = 0.0816(0.4723)
2023/09/17 18:36:41 - INFO - root -   Epoch: [113/400][180/346], lr: 0.00000026 	 loss = 0.1435(0.4644)
2023/09/17 18:37:42 - INFO - root -   Epoch: [113/400][200/346], lr: 0.00000026 	 loss = 0.0835(0.4511)
2023/09/17 18:38:25 - INFO - root -   Epoch: [113/400][220/346], lr: 0.00000026 	 loss = 0.4715(0.4537)
2023/09/17 18:39:26 - INFO - root -   Epoch: [113/400][240/346], lr: 0.00000026 	 loss = 0.0970(0.4502)
2023/09/17 18:40:09 - INFO - root -   Epoch: [113/400][260/346], lr: 0.00000026 	 loss = 0.3386(0.4534)
2023/09/17 18:41:09 - INFO - root -   Epoch: [113/400][280/346], lr: 0.00000026 	 loss = 0.3938(0.4553)
2023/09/17 18:41:53 - INFO - root -   Epoch: [113/400][300/346], lr: 0.00000026 	 loss = 0.0902(0.4573)
2023/09/17 18:42:54 - INFO - root -   Epoch: [113/400][320/346], lr: 0.00000026 	 loss = 0.1043(0.4530)
2023/09/17 18:43:35 - INFO - root -   Epoch: [113/400][340/346], lr: 0.00000026 	 loss = 0.5258(0.4557)
2023/09/17 18:43:39 - INFO - root -   Epoch: [113/400] 	 loss = 0.4590
2023/09/17 18:43:39 - INFO - root -   train_accuracy = 0.7861
2023/09/17 18:44:00 - INFO - root -   Epoch: [114/400][0/346], lr: 0.00000026 	 loss = 0.3996(0.3996)
2023/09/17 18:44:44 - INFO - root -   Epoch: [114/400][20/346], lr: 0.00000026 	 loss = 0.0144(0.3825)
2023/09/17 18:45:45 - INFO - root -   Epoch: [114/400][40/346], lr: 0.00000026 	 loss = 0.4023(0.4234)
2023/09/17 18:46:29 - INFO - root -   Epoch: [114/400][60/346], lr: 0.00000026 	 loss = 0.4379(0.3761)
2023/09/17 18:47:30 - INFO - root -   Epoch: [114/400][80/346], lr: 0.00000026 	 loss = 0.2940(0.4264)
2023/09/17 18:48:14 - INFO - root -   Epoch: [114/400][100/346], lr: 0.00000026 	 loss = 0.4830(0.4199)
2023/09/17 18:49:15 - INFO - root -   Epoch: [114/400][120/346], lr: 0.00000026 	 loss = 0.0904(0.4406)
2023/09/17 18:49:58 - INFO - root -   Epoch: [114/400][140/346], lr: 0.00000026 	 loss = 0.5531(0.4320)
2023/09/17 18:50:59 - INFO - root -   Epoch: [114/400][160/346], lr: 0.00000026 	 loss = 0.0413(0.4448)
2023/09/17 18:51:43 - INFO - root -   Epoch: [114/400][180/346], lr: 0.00000026 	 loss = 0.6101(0.4529)
2023/09/17 18:52:44 - INFO - root -   Epoch: [114/400][200/346], lr: 0.00000026 	 loss = 0.1242(0.4477)
2023/09/17 18:53:28 - INFO - root -   Epoch: [114/400][220/346], lr: 0.00000026 	 loss = 0.2598(0.4561)
2023/09/17 18:54:28 - INFO - root -   Epoch: [114/400][240/346], lr: 0.00000026 	 loss = 0.0955(0.4497)
2023/09/17 18:55:12 - INFO - root -   Epoch: [114/400][260/346], lr: 0.00000026 	 loss = 0.3756(0.4388)
2023/09/17 18:56:13 - INFO - root -   Epoch: [114/400][280/346], lr: 0.00000026 	 loss = 0.1051(0.4528)
2023/09/17 18:56:57 - INFO - root -   Epoch: [114/400][300/346], lr: 0.00000026 	 loss = 0.2607(0.4520)
2023/09/17 18:57:57 - INFO - root -   Epoch: [114/400][320/346], lr: 0.00000026 	 loss = 0.1911(0.4531)
2023/09/17 18:58:41 - INFO - root -   Epoch: [114/400][340/346], lr: 0.00000026 	 loss = 1.0616(0.4567)
2023/09/17 18:58:45 - INFO - root -   Epoch: [114/400] 	 loss = 0.4590
2023/09/17 19:02:32 - INFO - root -   precision = 0.6839
2023/09/17 19:02:32 - INFO - root -   eval_loss = 0.6506
2023/09/17 19:02:33 - INFO - root -   train_accuracy = 0.7919
2023/09/17 19:02:55 - INFO - root -   Epoch: [115/400][0/346], lr: 0.00000026 	 loss = 0.3800(0.3800)
2023/09/17 19:03:38 - INFO - root -   Epoch: [115/400][20/346], lr: 0.00000026 	 loss = 0.0844(0.3919)
2023/09/17 19:04:38 - INFO - root -   Epoch: [115/400][40/346], lr: 0.00000026 	 loss = 0.4652(0.4640)
2023/09/17 19:05:21 - INFO - root -   Epoch: [115/400][60/346], lr: 0.00000026 	 loss = 0.6378(0.4156)
2023/09/17 19:06:22 - INFO - root -   Epoch: [115/400][80/346], lr: 0.00000026 	 loss = 0.2773(0.4680)
2023/09/17 19:07:05 - INFO - root -   Epoch: [115/400][100/346], lr: 0.00000026 	 loss = 0.4715(0.4654)
2023/09/17 19:08:05 - INFO - root -   Epoch: [115/400][120/346], lr: 0.00000026 	 loss = 0.1230(0.4962)
2023/09/17 19:08:48 - INFO - root -   Epoch: [115/400][140/346], lr: 0.00000026 	 loss = 0.2473(0.4867)
2023/09/17 19:09:49 - INFO - root -   Epoch: [115/400][160/346], lr: 0.00000026 	 loss = 0.1871(0.4933)
2023/09/17 19:10:32 - INFO - root -   Epoch: [115/400][180/346], lr: 0.00000026 	 loss = 0.1141(0.4937)
2023/09/17 19:11:32 - INFO - root -   Epoch: [115/400][200/346], lr: 0.00000026 	 loss = 0.1369(0.4836)
2023/09/17 19:12:16 - INFO - root -   Epoch: [115/400][220/346], lr: 0.00000026 	 loss = 0.4040(0.4884)
2023/09/17 19:13:16 - INFO - root -   Epoch: [115/400][240/346], lr: 0.00000026 	 loss = 0.0570(0.4824)
2023/09/17 19:14:00 - INFO - root -   Epoch: [115/400][260/346], lr: 0.00000026 	 loss = 0.2507(0.4679)
2023/09/17 19:14:59 - INFO - root -   Epoch: [115/400][280/346], lr: 0.00000026 	 loss = 0.1529(0.4830)
2023/09/17 19:15:43 - INFO - root -   Epoch: [115/400][300/346], lr: 0.00000026 	 loss = 0.2202(0.4817)
2023/09/17 19:16:43 - INFO - root -   Epoch: [115/400][320/346], lr: 0.00000026 	 loss = 0.0799(0.4802)
2023/09/17 19:17:26 - INFO - root -   Epoch: [115/400][340/346], lr: 0.00000026 	 loss = 0.8120(0.4815)
2023/09/17 19:17:30 - INFO - root -   Epoch: [115/400] 	 loss = 0.4812
2023/09/17 19:17:30 - INFO - root -   train_accuracy = 0.7760
2023/09/17 19:17:52 - INFO - root -   Epoch: [116/400][0/346], lr: 0.00000027 	 loss = 0.2004(0.2004)
2023/09/17 19:18:34 - INFO - root -   Epoch: [116/400][20/346], lr: 0.00000027 	 loss = 0.0820(0.3879)
2023/09/17 19:19:35 - INFO - root -   Epoch: [116/400][40/346], lr: 0.00000027 	 loss = 0.5115(0.4486)
2023/09/17 19:20:18 - INFO - root -   Epoch: [116/400][60/346], lr: 0.00000027 	 loss = 0.4567(0.3978)
2023/09/17 19:21:18 - INFO - root -   Epoch: [116/400][80/346], lr: 0.00000027 	 loss = 0.1281(0.4035)
2023/09/17 19:22:01 - INFO - root -   Epoch: [116/400][100/346], lr: 0.00000027 	 loss = 0.8297(0.4121)
2023/09/17 19:23:02 - INFO - root -   Epoch: [116/400][120/346], lr: 0.00000027 	 loss = 0.0477(0.4331)
2023/09/17 19:23:45 - INFO - root -   Epoch: [116/400][140/346], lr: 0.00000027 	 loss = 0.2221(0.4350)
2023/09/17 19:24:45 - INFO - root -   Epoch: [116/400][160/346], lr: 0.00000027 	 loss = 0.0852(0.4342)
2023/09/17 19:25:28 - INFO - root -   Epoch: [116/400][180/346], lr: 0.00000027 	 loss = 0.6273(0.4475)
2023/09/17 19:26:28 - INFO - root -   Epoch: [116/400][200/346], lr: 0.00000027 	 loss = 0.1235(0.4420)
2023/09/17 19:27:11 - INFO - root -   Epoch: [116/400][220/346], lr: 0.00000027 	 loss = 0.2642(0.4464)
2023/09/17 19:28:11 - INFO - root -   Epoch: [116/400][240/346], lr: 0.00000027 	 loss = 0.0894(0.4500)
2023/09/17 19:28:54 - INFO - root -   Epoch: [116/400][260/346], lr: 0.00000027 	 loss = 0.4327(0.4479)
2023/09/17 19:29:55 - INFO - root -   Epoch: [116/400][280/346], lr: 0.00000027 	 loss = 0.3134(0.4597)
2023/09/17 19:30:38 - INFO - root -   Epoch: [116/400][300/346], lr: 0.00000027 	 loss = 0.1722(0.4607)
2023/09/17 19:31:38 - INFO - root -   Epoch: [116/400][320/346], lr: 0.00000027 	 loss = 0.2109(0.4550)
2023/09/17 19:32:20 - INFO - root -   Epoch: [116/400][340/346], lr: 0.00000027 	 loss = 1.0162(0.4577)
2023/09/17 19:32:24 - INFO - root -   Epoch: [116/400] 	 loss = 0.4612
2023/09/17 19:32:24 - INFO - root -   train_accuracy = 0.7731
2023/09/17 19:32:46 - INFO - root -   Epoch: [117/400][0/346], lr: 0.00000027 	 loss = 0.2510(0.2510)
2023/09/17 19:33:29 - INFO - root -   Epoch: [117/400][20/346], lr: 0.00000027 	 loss = 0.1359(0.3525)
2023/09/17 19:34:30 - INFO - root -   Epoch: [117/400][40/346], lr: 0.00000027 	 loss = 0.3215(0.4677)
2023/09/17 19:35:13 - INFO - root -   Epoch: [117/400][60/346], lr: 0.00000027 	 loss = 0.5103(0.4864)
2023/09/17 19:36:14 - INFO - root -   Epoch: [117/400][80/346], lr: 0.00000027 	 loss = 1.3251(0.5849)
2023/09/17 19:36:57 - INFO - root -   Epoch: [117/400][100/346], lr: 0.00000027 	 loss = 0.7221(0.6089)
2023/09/17 19:37:58 - INFO - root -   Epoch: [117/400][120/346], lr: 0.00000027 	 loss = 0.1681(0.6487)
2023/09/17 19:38:41 - INFO - root -   Epoch: [117/400][140/346], lr: 0.00000027 	 loss = 0.6664(0.6228)
2023/09/17 19:39:42 - INFO - root -   Epoch: [117/400][160/346], lr: 0.00000027 	 loss = 0.2344(0.6210)
2023/09/17 19:40:25 - INFO - root -   Epoch: [117/400][180/346], lr: 0.00000027 	 loss = 0.2275(0.6144)
2023/09/17 19:41:26 - INFO - root -   Epoch: [117/400][200/346], lr: 0.00000027 	 loss = 0.0742(0.6014)
2023/09/17 19:42:09 - INFO - root -   Epoch: [117/400][220/346], lr: 0.00000027 	 loss = 0.2490(0.5936)
2023/09/17 19:43:09 - INFO - root -   Epoch: [117/400][240/346], lr: 0.00000027 	 loss = 0.0543(0.5803)
2023/09/17 19:43:52 - INFO - root -   Epoch: [117/400][260/346], lr: 0.00000027 	 loss = 0.3891(0.5711)
2023/09/17 19:44:53 - INFO - root -   Epoch: [117/400][280/346], lr: 0.00000027 	 loss = 0.3096(0.5751)
2023/09/17 19:45:36 - INFO - root -   Epoch: [117/400][300/346], lr: 0.00000027 	 loss = 0.1221(0.5690)
2023/09/17 19:46:37 - INFO - root -   Epoch: [117/400][320/346], lr: 0.00000027 	 loss = 0.7199(0.5662)
2023/09/17 19:47:19 - INFO - root -   Epoch: [117/400][340/346], lr: 0.00000027 	 loss = 0.4428(0.5681)
2023/09/17 19:47:23 - INFO - root -   Epoch: [117/400] 	 loss = 0.5672
2023/09/17 19:47:23 - INFO - root -   train_accuracy = 0.7283
2023/09/17 19:47:44 - INFO - root -   Epoch: [118/400][0/346], lr: 0.00000027 	 loss = 0.3847(0.3847)
2023/09/17 19:48:27 - INFO - root -   Epoch: [118/400][20/346], lr: 0.00000027 	 loss = 0.1027(0.3835)
2023/09/17 19:49:28 - INFO - root -   Epoch: [118/400][40/346], lr: 0.00000027 	 loss = 0.7989(0.4541)
2023/09/17 19:50:11 - INFO - root -   Epoch: [118/400][60/346], lr: 0.00000027 	 loss = 0.4534(0.3989)
2023/09/17 19:51:12 - INFO - root -   Epoch: [118/400][80/346], lr: 0.00000027 	 loss = 0.3470(0.4622)
2023/09/17 19:51:55 - INFO - root -   Epoch: [118/400][100/346], lr: 0.00000027 	 loss = 0.5581(0.4636)
2023/09/17 19:52:56 - INFO - root -   Epoch: [118/400][120/346], lr: 0.00000027 	 loss = 0.2573(0.4939)
2023/09/17 19:53:39 - INFO - root -   Epoch: [118/400][140/346], lr: 0.00000027 	 loss = 0.5162(0.4759)
2023/09/17 19:54:39 - INFO - root -   Epoch: [118/400][160/346], lr: 0.00000027 	 loss = 0.2074(0.4823)
2023/09/17 19:55:23 - INFO - root -   Epoch: [118/400][180/346], lr: 0.00000027 	 loss = 0.1496(0.4905)
2023/09/17 19:56:23 - INFO - root -   Epoch: [118/400][200/346], lr: 0.00000027 	 loss = 0.0813(0.4825)
2023/09/17 19:57:06 - INFO - root -   Epoch: [118/400][220/346], lr: 0.00000027 	 loss = 0.2485(0.4899)
2023/09/17 19:58:07 - INFO - root -   Epoch: [118/400][240/346], lr: 0.00000027 	 loss = 0.0906(0.4896)
2023/09/17 19:58:50 - INFO - root -   Epoch: [118/400][260/346], lr: 0.00000027 	 loss = 0.9367(0.4873)
2023/09/17 19:59:50 - INFO - root -   Epoch: [118/400][280/346], lr: 0.00000027 	 loss = 0.1158(0.4961)
2023/09/17 20:00:34 - INFO - root -   Epoch: [118/400][300/346], lr: 0.00000027 	 loss = 0.3512(0.4924)
2023/09/17 20:01:34 - INFO - root -   Epoch: [118/400][320/346], lr: 0.00000027 	 loss = 0.2149(0.4910)
2023/09/17 20:02:16 - INFO - root -   Epoch: [118/400][340/346], lr: 0.00000027 	 loss = 0.5446(0.4928)
2023/09/17 20:02:20 - INFO - root -   Epoch: [118/400] 	 loss = 0.4930
2023/09/17 20:02:20 - INFO - root -   train_accuracy = 0.7601
2023/09/17 20:02:41 - INFO - root -   Epoch: [119/400][0/346], lr: 0.00000027 	 loss = 0.3135(0.3135)
2023/09/17 20:03:24 - INFO - root -   Epoch: [119/400][20/346], lr: 0.00000027 	 loss = 0.1895(0.3878)
2023/09/17 20:04:25 - INFO - root -   Epoch: [119/400][40/346], lr: 0.00000027 	 loss = 0.3135(0.4426)
2023/09/17 20:05:08 - INFO - root -   Epoch: [119/400][60/346], lr: 0.00000027 	 loss = 0.4480(0.3991)
2023/09/17 20:06:09 - INFO - root -   Epoch: [119/400][80/346], lr: 0.00000027 	 loss = 0.2599(0.4267)
2023/09/17 20:06:52 - INFO - root -   Epoch: [119/400][100/346], lr: 0.00000027 	 loss = 0.3743(0.4390)
2023/09/17 20:07:52 - INFO - root -   Epoch: [119/400][120/346], lr: 0.00000027 	 loss = 0.4204(0.4813)
2023/09/17 20:08:35 - INFO - root -   Epoch: [119/400][140/346], lr: 0.00000027 	 loss = 0.7389(0.4772)
2023/09/17 20:09:36 - INFO - root -   Epoch: [119/400][160/346], lr: 0.00000027 	 loss = 0.0674(0.4913)
2023/09/17 20:10:19 - INFO - root -   Epoch: [119/400][180/346], lr: 0.00000027 	 loss = 0.0970(0.4940)
2023/09/17 20:11:19 - INFO - root -   Epoch: [119/400][200/346], lr: 0.00000027 	 loss = 0.0518(0.4854)
2023/09/17 20:12:02 - INFO - root -   Epoch: [119/400][220/346], lr: 0.00000027 	 loss = 0.1817(0.4877)
2023/09/17 20:13:03 - INFO - root -   Epoch: [119/400][240/346], lr: 0.00000027 	 loss = 0.2144(0.4797)
2023/09/17 20:13:46 - INFO - root -   Epoch: [119/400][260/346], lr: 0.00000027 	 loss = 0.2813(0.4690)
2023/09/17 20:14:47 - INFO - root -   Epoch: [119/400][280/346], lr: 0.00000027 	 loss = 0.1167(0.4815)
2023/09/17 20:15:30 - INFO - root -   Epoch: [119/400][300/346], lr: 0.00000027 	 loss = 0.1764(0.4772)
2023/09/17 20:16:30 - INFO - root -   Epoch: [119/400][320/346], lr: 0.00000027 	 loss = 0.0780(0.4752)
2023/09/17 20:17:12 - INFO - root -   Epoch: [119/400][340/346], lr: 0.00000027 	 loss = 0.3709(0.4682)
2023/09/17 20:17:16 - INFO - root -   Epoch: [119/400] 	 loss = 0.4701
2023/09/17 20:21:04 - INFO - root -   precision = 0.6782
2023/09/17 20:21:04 - INFO - root -   eval_loss = 0.6754
2023/09/17 20:21:06 - INFO - root -   train_accuracy = 0.7746
2023/09/17 20:21:27 - INFO - root -   Epoch: [120/400][0/346], lr: 0.00000027 	 loss = 0.6040(0.6040)
2023/09/17 20:22:10 - INFO - root -   Epoch: [120/400][20/346], lr: 0.00000027 	 loss = 0.0741(0.3948)
2023/09/17 20:23:10 - INFO - root -   Epoch: [120/400][40/346], lr: 0.00000027 	 loss = 0.4930(0.4719)
2023/09/17 20:23:53 - INFO - root -   Epoch: [120/400][60/346], lr: 0.00000027 	 loss = 0.4216(0.4267)
2023/09/17 20:24:53 - INFO - root -   Epoch: [120/400][80/346], lr: 0.00000027 	 loss = 0.2113(0.4656)
2023/09/17 20:25:36 - INFO - root -   Epoch: [120/400][100/346], lr: 0.00000027 	 loss = 0.4929(0.4530)
2023/09/17 20:26:36 - INFO - root -   Epoch: [120/400][120/346], lr: 0.00000027 	 loss = 0.1017(0.4589)
2023/09/17 20:27:19 - INFO - root -   Epoch: [120/400][140/346], lr: 0.00000027 	 loss = 0.4902(0.4495)
2023/09/17 20:28:19 - INFO - root -   Epoch: [120/400][160/346], lr: 0.00000027 	 loss = 0.1447(0.4711)
2023/09/17 20:29:02 - INFO - root -   Epoch: [120/400][180/346], lr: 0.00000027 	 loss = 0.1087(0.4744)
2023/09/17 20:30:02 - INFO - root -   Epoch: [120/400][200/346], lr: 0.00000027 	 loss = 0.0839(0.4676)
2023/09/17 20:30:44 - INFO - root -   Epoch: [120/400][220/346], lr: 0.00000027 	 loss = 0.1592(0.4753)
2023/09/17 20:31:45 - INFO - root -   Epoch: [120/400][240/346], lr: 0.00000027 	 loss = 0.0487(0.4754)
2023/09/17 20:32:27 - INFO - root -   Epoch: [120/400][260/346], lr: 0.00000027 	 loss = 0.7945(0.4738)
2023/09/17 20:33:27 - INFO - root -   Epoch: [120/400][280/346], lr: 0.00000027 	 loss = 0.3189(0.4863)
2023/09/17 20:34:10 - INFO - root -   Epoch: [120/400][300/346], lr: 0.00000027 	 loss = 0.1676(0.4914)
2023/09/17 20:35:10 - INFO - root -   Epoch: [120/400][320/346], lr: 0.00000027 	 loss = 0.1007(0.4885)
2023/09/17 20:35:52 - INFO - root -   Epoch: [120/400][340/346], lr: 0.00000027 	 loss = 0.7992(0.4891)
2023/09/17 20:35:56 - INFO - root -   Epoch: [120/400] 	 loss = 0.4893
2023/09/17 20:35:56 - INFO - root -   train_accuracy = 0.7616
2023/09/17 20:36:18 - INFO - root -   Epoch: [121/400][0/346], lr: 0.00000027 	 loss = 0.3797(0.3797)
2023/09/17 20:37:01 - INFO - root -   Epoch: [121/400][20/346], lr: 0.00000027 	 loss = 0.0799(0.3842)
2023/09/17 20:38:01 - INFO - root -   Epoch: [121/400][40/346], lr: 0.00000027 	 loss = 0.7716(0.4308)
2023/09/17 20:38:44 - INFO - root -   Epoch: [121/400][60/346], lr: 0.00000027 	 loss = 0.4389(0.4090)
2023/09/17 20:39:45 - INFO - root -   Epoch: [121/400][80/346], lr: 0.00000027 	 loss = 0.2091(0.4257)
2023/09/17 20:40:28 - INFO - root -   Epoch: [121/400][100/346], lr: 0.00000027 	 loss = 0.5497(0.4274)
2023/09/17 20:41:28 - INFO - root -   Epoch: [121/400][120/346], lr: 0.00000027 	 loss = 0.1273(0.4401)
2023/09/17 20:42:11 - INFO - root -   Epoch: [121/400][140/346], lr: 0.00000027 	 loss = 0.2505(0.4264)
2023/09/17 20:43:12 - INFO - root -   Epoch: [121/400][160/346], lr: 0.00000027 	 loss = 0.0551(0.4337)
2023/09/17 20:43:55 - INFO - root -   Epoch: [121/400][180/346], lr: 0.00000027 	 loss = 0.1956(0.4390)
2023/09/17 20:44:55 - INFO - root -   Epoch: [121/400][200/346], lr: 0.00000027 	 loss = 0.0339(0.4318)
2023/09/17 20:45:39 - INFO - root -   Epoch: [121/400][220/346], lr: 0.00000027 	 loss = 0.3943(0.4378)
2023/09/17 20:46:39 - INFO - root -   Epoch: [121/400][240/346], lr: 0.00000027 	 loss = 0.0244(0.4393)
2023/09/17 20:47:22 - INFO - root -   Epoch: [121/400][260/346], lr: 0.00000027 	 loss = 1.7813(0.4371)
2023/09/17 20:48:22 - INFO - root -   Epoch: [121/400][280/346], lr: 0.00000027 	 loss = 0.0843(0.4448)
2023/09/17 20:49:05 - INFO - root -   Epoch: [121/400][300/346], lr: 0.00000027 	 loss = 0.1739(0.4489)
2023/09/17 20:50:05 - INFO - root -   Epoch: [121/400][320/346], lr: 0.00000027 	 loss = 0.0888(0.4510)
2023/09/17 20:50:47 - INFO - root -   Epoch: [121/400][340/346], lr: 0.00000027 	 loss = 0.5015(0.4497)
2023/09/17 20:50:51 - INFO - root -   Epoch: [121/400] 	 loss = 0.4528
2023/09/17 20:50:51 - INFO - root -   train_accuracy = 0.7861
2023/09/17 20:51:13 - INFO - root -   Epoch: [122/400][0/346], lr: 0.00000027 	 loss = 0.3377(0.3377)
2023/09/17 20:51:56 - INFO - root -   Epoch: [122/400][20/346], lr: 0.00000027 	 loss = 0.0507(0.3473)
2023/09/17 20:52:57 - INFO - root -   Epoch: [122/400][40/346], lr: 0.00000027 	 loss = 0.3255(0.3560)
2023/09/17 20:53:40 - INFO - root -   Epoch: [122/400][60/346], lr: 0.00000027 	 loss = 0.4210(0.3325)
2023/09/17 20:54:41 - INFO - root -   Epoch: [122/400][80/346], lr: 0.00000027 	 loss = 0.4167(0.3833)
2023/09/17 20:55:24 - INFO - root -   Epoch: [122/400][100/346], lr: 0.00000027 	 loss = 0.3799(0.3989)
2023/09/17 20:56:24 - INFO - root -   Epoch: [122/400][120/346], lr: 0.00000027 	 loss = 0.0703(0.4219)
2023/09/17 20:57:07 - INFO - root -   Epoch: [122/400][140/346], lr: 0.00000027 	 loss = 0.5268(0.4153)
2023/09/17 20:58:08 - INFO - root -   Epoch: [122/400][160/346], lr: 0.00000027 	 loss = 0.0539(0.4167)
2023/09/17 20:58:51 - INFO - root -   Epoch: [122/400][180/346], lr: 0.00000027 	 loss = 0.1491(0.4281)
2023/09/17 20:59:52 - INFO - root -   Epoch: [122/400][200/346], lr: 0.00000027 	 loss = 0.0303(0.4170)
2023/09/17 21:00:35 - INFO - root -   Epoch: [122/400][220/346], lr: 0.00000027 	 loss = 0.3476(0.4272)
2023/09/17 21:01:36 - INFO - root -   Epoch: [122/400][240/346], lr: 0.00000027 	 loss = 0.0812(0.4246)
2023/09/17 21:02:19 - INFO - root -   Epoch: [122/400][260/346], lr: 0.00000027 	 loss = 0.5166(0.4224)
2023/09/17 21:03:19 - INFO - root -   Epoch: [122/400][280/346], lr: 0.00000027 	 loss = 0.2993(0.4402)
2023/09/17 21:04:02 - INFO - root -   Epoch: [122/400][300/346], lr: 0.00000027 	 loss = 0.2919(0.4389)
2023/09/17 21:05:03 - INFO - root -   Epoch: [122/400][320/346], lr: 0.00000027 	 loss = 0.2176(0.4380)
2023/09/17 21:05:45 - INFO - root -   Epoch: [122/400][340/346], lr: 0.00000027 	 loss = 0.9716(0.4437)
2023/09/17 21:05:48 - INFO - root -   Epoch: [122/400] 	 loss = 0.4449
2023/09/17 21:05:48 - INFO - root -   train_accuracy = 0.8020
2023/09/17 21:06:10 - INFO - root -   Epoch: [123/400][0/346], lr: 0.00000028 	 loss = 0.3003(0.3003)
2023/09/17 21:06:53 - INFO - root -   Epoch: [123/400][20/346], lr: 0.00000028 	 loss = 0.0494(0.4032)
2023/09/17 21:07:54 - INFO - root -   Epoch: [123/400][40/346], lr: 0.00000028 	 loss = 0.2678(0.4023)
2023/09/17 21:08:37 - INFO - root -   Epoch: [123/400][60/346], lr: 0.00000028 	 loss = 0.3683(0.3542)
2023/09/17 21:09:38 - INFO - root -   Epoch: [123/400][80/346], lr: 0.00000028 	 loss = 0.2149(0.3993)
2023/09/17 21:10:21 - INFO - root -   Epoch: [123/400][100/346], lr: 0.00000028 	 loss = 0.4300(0.3929)
2023/09/17 21:11:21 - INFO - root -   Epoch: [123/400][120/346], lr: 0.00000028 	 loss = 0.0871(0.4133)
2023/09/17 21:12:04 - INFO - root -   Epoch: [123/400][140/346], lr: 0.00000028 	 loss = 0.4131(0.4060)
2023/09/17 21:13:05 - INFO - root -   Epoch: [123/400][160/346], lr: 0.00000028 	 loss = 0.1689(0.4175)
2023/09/17 21:13:48 - INFO - root -   Epoch: [123/400][180/346], lr: 0.00000028 	 loss = 0.1070(0.4222)
2023/09/17 21:14:48 - INFO - root -   Epoch: [123/400][200/346], lr: 0.00000028 	 loss = 0.1804(0.4163)
2023/09/17 21:15:31 - INFO - root -   Epoch: [123/400][220/346], lr: 0.00000028 	 loss = 0.3168(0.4301)
2023/09/17 21:16:32 - INFO - root -   Epoch: [123/400][240/346], lr: 0.00000028 	 loss = 0.0911(0.4250)
2023/09/17 21:17:15 - INFO - root -   Epoch: [123/400][260/346], lr: 0.00000028 	 loss = 0.3496(0.4221)
2023/09/17 21:18:16 - INFO - root -   Epoch: [123/400][280/346], lr: 0.00000028 	 loss = 0.1209(0.4378)
2023/09/17 21:18:59 - INFO - root -   Epoch: [123/400][300/346], lr: 0.00000028 	 loss = 0.2715(0.4325)
2023/09/17 21:19:59 - INFO - root -   Epoch: [123/400][320/346], lr: 0.00000028 	 loss = 0.1011(0.4365)
2023/09/17 21:20:41 - INFO - root -   Epoch: [123/400][340/346], lr: 0.00000028 	 loss = 0.7276(0.4393)
2023/09/17 21:20:45 - INFO - root -   Epoch: [123/400] 	 loss = 0.4406
2023/09/17 21:20:45 - INFO - root -   train_accuracy = 0.7948
2023/09/17 21:21:06 - INFO - root -   Epoch: [124/400][0/346], lr: 0.00000028 	 loss = 0.5718(0.5718)
2023/09/17 21:21:49 - INFO - root -   Epoch: [124/400][20/346], lr: 0.00000028 	 loss = 0.0090(0.3285)
2023/09/17 21:22:50 - INFO - root -   Epoch: [124/400][40/346], lr: 0.00000028 	 loss = 0.3307(0.3766)
2023/09/17 21:23:33 - INFO - root -   Epoch: [124/400][60/346], lr: 0.00000028 	 loss = 0.3357(0.3462)
2023/09/17 21:24:34 - INFO - root -   Epoch: [124/400][80/346], lr: 0.00000028 	 loss = 0.2247(0.4088)
2023/09/17 21:25:17 - INFO - root -   Epoch: [124/400][100/346], lr: 0.00000028 	 loss = 0.4849(0.4200)
2023/09/17 21:26:17 - INFO - root -   Epoch: [124/400][120/346], lr: 0.00000028 	 loss = 0.1249(0.4326)
2023/09/17 21:27:00 - INFO - root -   Epoch: [124/400][140/346], lr: 0.00000028 	 loss = 0.2424(0.4313)
2023/09/17 21:28:01 - INFO - root -   Epoch: [124/400][160/346], lr: 0.00000028 	 loss = 0.0816(0.4344)
2023/09/17 21:28:44 - INFO - root -   Epoch: [124/400][180/346], lr: 0.00000028 	 loss = 0.1189(0.4326)
2023/09/17 21:29:44 - INFO - root -   Epoch: [124/400][200/346], lr: 0.00000028 	 loss = 0.0622(0.4303)
2023/09/17 21:30:27 - INFO - root -   Epoch: [124/400][220/346], lr: 0.00000028 	 loss = 0.3674(0.4456)
2023/09/17 21:31:27 - INFO - root -   Epoch: [124/400][240/346], lr: 0.00000028 	 loss = 0.2742(0.4400)
2023/09/17 21:32:11 - INFO - root -   Epoch: [124/400][260/346], lr: 0.00000028 	 loss = 1.6684(0.4453)
2023/09/17 21:33:11 - INFO - root -   Epoch: [124/400][280/346], lr: 0.00000028 	 loss = 0.2541(0.4784)
2023/09/17 21:33:54 - INFO - root -   Epoch: [124/400][300/346], lr: 0.00000028 	 loss = 0.4861(0.4837)
2023/09/17 21:34:54 - INFO - root -   Epoch: [124/400][320/346], lr: 0.00000028 	 loss = 0.1219(0.4892)
2023/09/17 21:35:36 - INFO - root -   Epoch: [124/400][340/346], lr: 0.00000028 	 loss = 1.1276(0.4897)
2023/09/17 21:35:40 - INFO - root -   Epoch: [124/400] 	 loss = 0.4877
2023/09/17 21:39:27 - INFO - root -   precision = 0.6782
2023/09/17 21:39:27 - INFO - root -   eval_loss = 0.6579
2023/09/17 21:39:28 - INFO - root -   train_accuracy = 0.7760
2023/09/17 21:39:50 - INFO - root -   Epoch: [125/400][0/346], lr: 0.00000028 	 loss = 0.2779(0.2779)
2023/09/17 21:40:32 - INFO - root -   Epoch: [125/400][20/346], lr: 0.00000028 	 loss = 0.0695(0.3642)
2023/09/17 21:41:33 - INFO - root -   Epoch: [125/400][40/346], lr: 0.00000028 	 loss = 0.6982(0.4302)
2023/09/17 21:42:16 - INFO - root -   Epoch: [125/400][60/346], lr: 0.00000028 	 loss = 0.6167(0.3820)
2023/09/17 21:43:16 - INFO - root -   Epoch: [125/400][80/346], lr: 0.00000028 	 loss = 0.2208(0.3973)
2023/09/17 21:43:59 - INFO - root -   Epoch: [125/400][100/346], lr: 0.00000028 	 loss = 0.4564(0.4008)
2023/09/17 21:45:00 - INFO - root -   Epoch: [125/400][120/346], lr: 0.00000028 	 loss = 0.1878(0.4138)
2023/09/17 21:45:43 - INFO - root -   Epoch: [125/400][140/346], lr: 0.00000028 	 loss = 0.4173(0.4197)
2023/09/17 21:46:43 - INFO - root -   Epoch: [125/400][160/346], lr: 0.00000028 	 loss = 0.1140(0.4265)
2023/09/17 21:47:26 - INFO - root -   Epoch: [125/400][180/346], lr: 0.00000028 	 loss = 0.1339(0.4303)
2023/09/17 21:48:26 - INFO - root -   Epoch: [125/400][200/346], lr: 0.00000028 	 loss = 0.0743(0.4304)
2023/09/17 21:49:09 - INFO - root -   Epoch: [125/400][220/346], lr: 0.00000028 	 loss = 0.4360(0.4431)
2023/09/17 21:50:09 - INFO - root -   Epoch: [125/400][240/346], lr: 0.00000028 	 loss = 0.3039(0.4414)
2023/09/17 21:50:53 - INFO - root -   Epoch: [125/400][260/346], lr: 0.00000028 	 loss = 0.3647(0.4293)
2023/09/17 21:51:52 - INFO - root -   Epoch: [125/400][280/346], lr: 0.00000028 	 loss = 0.1124(0.4427)
2023/09/17 21:52:36 - INFO - root -   Epoch: [125/400][300/346], lr: 0.00000028 	 loss = 0.1405(0.4396)
2023/09/17 21:53:35 - INFO - root -   Epoch: [125/400][320/346], lr: 0.00000028 	 loss = 0.0909(0.4464)
2023/09/17 21:54:17 - INFO - root -   Epoch: [125/400][340/346], lr: 0.00000028 	 loss = 0.5251(0.4533)
2023/09/17 21:54:21 - INFO - root -   Epoch: [125/400] 	 loss = 0.4533
2023/09/17 21:54:21 - INFO - root -   train_accuracy = 0.7948
2023/09/17 21:54:43 - INFO - root -   Epoch: [126/400][0/346], lr: 0.00000028 	 loss = 0.4828(0.4828)
2023/09/17 21:55:26 - INFO - root -   Epoch: [126/400][20/346], lr: 0.00000028 	 loss = 0.1125(0.3725)
2023/09/17 21:56:27 - INFO - root -   Epoch: [126/400][40/346], lr: 0.00000028 	 loss = 0.3855(0.4253)
2023/09/17 21:57:10 - INFO - root -   Epoch: [126/400][60/346], lr: 0.00000028 	 loss = 0.5067(0.3779)
2023/09/17 21:58:11 - INFO - root -   Epoch: [126/400][80/346], lr: 0.00000028 	 loss = 0.1874(0.3973)
2023/09/17 21:58:54 - INFO - root -   Epoch: [126/400][100/346], lr: 0.00000028 	 loss = 0.8104(0.4116)
2023/09/17 21:59:55 - INFO - root -   Epoch: [126/400][120/346], lr: 0.00000028 	 loss = 0.1291(0.4386)
2023/09/17 22:00:38 - INFO - root -   Epoch: [126/400][140/346], lr: 0.00000028 	 loss = 0.4604(0.4352)
2023/09/17 22:01:39 - INFO - root -   Epoch: [126/400][160/346], lr: 0.00000028 	 loss = 0.0938(0.4421)
2023/09/17 22:02:22 - INFO - root -   Epoch: [126/400][180/346], lr: 0.00000028 	 loss = 0.2134(0.4496)
2023/09/17 22:03:22 - INFO - root -   Epoch: [126/400][200/346], lr: 0.00000028 	 loss = 0.1061(0.4485)
2023/09/17 22:04:05 - INFO - root -   Epoch: [126/400][220/346], lr: 0.00000028 	 loss = 0.2981(0.4625)
2023/09/17 22:05:06 - INFO - root -   Epoch: [126/400][240/346], lr: 0.00000028 	 loss = 0.0602(0.4623)
2023/09/17 22:05:49 - INFO - root -   Epoch: [126/400][260/346], lr: 0.00000028 	 loss = 1.2810(0.4603)
2023/09/17 22:06:49 - INFO - root -   Epoch: [126/400][280/346], lr: 0.00000028 	 loss = 0.1812(0.4669)
2023/09/17 22:07:32 - INFO - root -   Epoch: [126/400][300/346], lr: 0.00000028 	 loss = 0.2865(0.4676)
2023/09/17 22:08:33 - INFO - root -   Epoch: [126/400][320/346], lr: 0.00000028 	 loss = 0.0875(0.4644)
2023/09/17 22:09:15 - INFO - root -   Epoch: [126/400][340/346], lr: 0.00000028 	 loss = 0.1771(0.4596)
2023/09/17 22:09:19 - INFO - root -   Epoch: [126/400] 	 loss = 0.4614
2023/09/17 22:09:19 - INFO - root -   train_accuracy = 0.7775
2023/09/17 22:09:41 - INFO - root -   Epoch: [127/400][0/346], lr: 0.00000028 	 loss = 0.3273(0.3273)
2023/09/17 22:10:23 - INFO - root -   Epoch: [127/400][20/346], lr: 0.00000028 	 loss = 0.0935(0.3555)
2023/09/17 22:11:24 - INFO - root -   Epoch: [127/400][40/346], lr: 0.00000028 	 loss = 0.4975(0.3855)
2023/09/17 22:12:07 - INFO - root -   Epoch: [127/400][60/346], lr: 0.00000028 	 loss = 0.2961(0.3705)
2023/09/17 22:13:07 - INFO - root -   Epoch: [127/400][80/346], lr: 0.00000028 	 loss = 0.2948(0.4117)
2023/09/17 22:13:50 - INFO - root -   Epoch: [127/400][100/346], lr: 0.00000028 	 loss = 0.4726(0.4121)
2023/09/17 22:14:51 - INFO - root -   Epoch: [127/400][120/346], lr: 0.00000028 	 loss = 0.2014(0.4203)
2023/09/17 22:15:34 - INFO - root -   Epoch: [127/400][140/346], lr: 0.00000028 	 loss = 0.7637(0.4178)
2023/09/17 22:16:34 - INFO - root -   Epoch: [127/400][160/346], lr: 0.00000028 	 loss = 0.0476(0.4227)
2023/09/17 22:17:17 - INFO - root -   Epoch: [127/400][180/346], lr: 0.00000028 	 loss = 0.2802(0.4262)
2023/09/17 22:18:17 - INFO - root -   Epoch: [127/400][200/346], lr: 0.00000028 	 loss = 0.0550(0.4174)
2023/09/17 22:19:01 - INFO - root -   Epoch: [127/400][220/346], lr: 0.00000028 	 loss = 0.3995(0.4256)
2023/09/17 22:20:01 - INFO - root -   Epoch: [127/400][240/346], lr: 0.00000028 	 loss = 0.0515(0.4203)
2023/09/17 22:20:44 - INFO - root -   Epoch: [127/400][260/346], lr: 0.00000028 	 loss = 1.4295(0.4143)
2023/09/17 22:21:44 - INFO - root -   Epoch: [127/400][280/346], lr: 0.00000028 	 loss = 0.0704(0.4217)
2023/09/17 22:22:27 - INFO - root -   Epoch: [127/400][300/346], lr: 0.00000028 	 loss = 0.2065(0.4261)
2023/09/17 22:23:27 - INFO - root -   Epoch: [127/400][320/346], lr: 0.00000028 	 loss = 0.5035(0.4261)
2023/09/17 22:24:10 - INFO - root -   Epoch: [127/400][340/346], lr: 0.00000028 	 loss = 0.8866(0.4295)
2023/09/17 22:24:14 - INFO - root -   Epoch: [127/400] 	 loss = 0.4336
2023/09/17 22:24:14 - INFO - root -   train_accuracy = 0.7962
2023/09/17 22:24:35 - INFO - root -   Epoch: [128/400][0/346], lr: 0.00000028 	 loss = 0.7077(0.7077)
2023/09/17 22:25:19 - INFO - root -   Epoch: [128/400][20/346], lr: 0.00000028 	 loss = 0.0768(0.3869)
2023/09/17 22:26:19 - INFO - root -   Epoch: [128/400][40/346], lr: 0.00000028 	 loss = 0.4500(0.4504)
2023/09/17 22:27:03 - INFO - root -   Epoch: [128/400][60/346], lr: 0.00000028 	 loss = 0.3468(0.4048)
2023/09/17 22:28:04 - INFO - root -   Epoch: [128/400][80/346], lr: 0.00000028 	 loss = 0.4223(0.4072)
2023/09/17 22:28:47 - INFO - root -   Epoch: [128/400][100/346], lr: 0.00000028 	 loss = 0.5129(0.4084)
2023/09/17 22:29:48 - INFO - root -   Epoch: [128/400][120/346], lr: 0.00000028 	 loss = 0.1486(0.4285)
2023/09/17 22:30:31 - INFO - root -   Epoch: [128/400][140/346], lr: 0.00000028 	 loss = 0.3407(0.4188)
2023/09/17 22:31:31 - INFO - root -   Epoch: [128/400][160/346], lr: 0.00000028 	 loss = 0.1168(0.4295)
2023/09/17 22:32:14 - INFO - root -   Epoch: [128/400][180/346], lr: 0.00000028 	 loss = 0.1828(0.4279)
2023/09/17 22:33:15 - INFO - root -   Epoch: [128/400][200/346], lr: 0.00000028 	 loss = 0.0241(0.4226)
2023/09/17 22:33:58 - INFO - root -   Epoch: [128/400][220/346], lr: 0.00000028 	 loss = 0.4272(0.4262)
2023/09/17 22:34:59 - INFO - root -   Epoch: [128/400][240/346], lr: 0.00000028 	 loss = 0.0255(0.4223)
2023/09/17 22:35:42 - INFO - root -   Epoch: [128/400][260/346], lr: 0.00000028 	 loss = 0.9071(0.4226)
2023/09/17 22:36:42 - INFO - root -   Epoch: [128/400][280/346], lr: 0.00000028 	 loss = 0.2177(0.4279)
2023/09/17 22:37:26 - INFO - root -   Epoch: [128/400][300/346], lr: 0.00000028 	 loss = 0.2876(0.4286)
2023/09/17 22:38:26 - INFO - root -   Epoch: [128/400][320/346], lr: 0.00000028 	 loss = 0.0707(0.4373)
2023/09/17 22:39:08 - INFO - root -   Epoch: [128/400][340/346], lr: 0.00000028 	 loss = 0.6095(0.4389)
2023/09/17 22:39:13 - INFO - root -   Epoch: [128/400] 	 loss = 0.4424
2023/09/17 22:39:13 - INFO - root -   train_accuracy = 0.7948
2023/09/17 22:39:34 - INFO - root -   Epoch: [129/400][0/346], lr: 0.00000028 	 loss = 0.3249(0.3249)
2023/09/17 22:40:17 - INFO - root -   Epoch: [129/400][20/346], lr: 0.00000028 	 loss = 0.1284(0.2749)
2023/09/17 22:41:18 - INFO - root -   Epoch: [129/400][40/346], lr: 0.00000028 	 loss = 0.2171(0.3621)
2023/09/17 22:42:01 - INFO - root -   Epoch: [129/400][60/346], lr: 0.00000028 	 loss = 0.6143(0.3334)
2023/09/17 22:43:02 - INFO - root -   Epoch: [129/400][80/346], lr: 0.00000028 	 loss = 0.1449(0.3798)
2023/09/17 22:43:45 - INFO - root -   Epoch: [129/400][100/346], lr: 0.00000028 	 loss = 0.8910(0.3915)
2023/09/17 22:44:46 - INFO - root -   Epoch: [129/400][120/346], lr: 0.00000028 	 loss = 0.0647(0.4256)
2023/09/17 22:45:29 - INFO - root -   Epoch: [129/400][140/346], lr: 0.00000028 	 loss = 0.3424(0.4217)
2023/09/17 22:46:29 - INFO - root -   Epoch: [129/400][160/346], lr: 0.00000028 	 loss = 0.0889(0.4310)
2023/09/17 22:47:13 - INFO - root -   Epoch: [129/400][180/346], lr: 0.00000028 	 loss = 0.1732(0.4311)
2023/09/17 22:48:13 - INFO - root -   Epoch: [129/400][200/346], lr: 0.00000028 	 loss = 0.0747(0.4163)
2023/09/17 22:48:57 - INFO - root -   Epoch: [129/400][220/346], lr: 0.00000028 	 loss = 0.5893(0.4176)
2023/09/17 22:49:57 - INFO - root -   Epoch: [129/400][240/346], lr: 0.00000028 	 loss = 0.0760(0.4230)
2023/09/17 22:50:40 - INFO - root -   Epoch: [129/400][260/346], lr: 0.00000028 	 loss = 0.4548(0.4237)
2023/09/17 22:51:41 - INFO - root -   Epoch: [129/400][280/346], lr: 0.00000028 	 loss = 0.3394(0.4368)
2023/09/17 22:52:24 - INFO - root -   Epoch: [129/400][300/346], lr: 0.00000028 	 loss = 0.1319(0.4414)
2023/09/17 22:53:24 - INFO - root -   Epoch: [129/400][320/346], lr: 0.00000028 	 loss = 0.0418(0.4444)
2023/09/17 22:54:07 - INFO - root -   Epoch: [129/400][340/346], lr: 0.00000028 	 loss = 0.3603(0.4435)
2023/09/17 22:54:12 - INFO - root -   Epoch: [129/400] 	 loss = 0.4446
2023/09/17 22:58:00 - INFO - root -   precision = 0.6724
2023/09/17 22:58:00 - INFO - root -   eval_loss = 0.7060
2023/09/17 22:58:01 - INFO - root -   train_accuracy = 0.8064
2023/09/17 22:58:23 - INFO - root -   Epoch: [130/400][0/346], lr: 0.00000029 	 loss = 0.2386(0.2386)
2023/09/17 22:59:06 - INFO - root -   Epoch: [130/400][20/346], lr: 0.00000029 	 loss = 0.1447(0.4923)
2023/09/17 23:00:07 - INFO - root -   Epoch: [130/400][40/346], lr: 0.00000029 	 loss = 0.3892(0.5028)
2023/09/17 23:00:51 - INFO - root -   Epoch: [130/400][60/346], lr: 0.00000029 	 loss = 0.4288(0.4264)
2023/09/17 23:01:52 - INFO - root -   Epoch: [130/400][80/346], lr: 0.00000029 	 loss = 0.1656(0.4562)
2023/09/17 23:02:35 - INFO - root -   Epoch: [130/400][100/346], lr: 0.00000029 	 loss = 0.3162(0.4525)
2023/09/17 23:03:36 - INFO - root -   Epoch: [130/400][120/346], lr: 0.00000029 	 loss = 0.1863(0.4550)
2023/09/17 23:04:19 - INFO - root -   Epoch: [130/400][140/346], lr: 0.00000029 	 loss = 0.3401(0.4442)
2023/09/17 23:05:20 - INFO - root -   Epoch: [130/400][160/346], lr: 0.00000029 	 loss = 0.1407(0.4480)
2023/09/17 23:06:03 - INFO - root -   Epoch: [130/400][180/346], lr: 0.00000029 	 loss = 0.6896(0.4547)
2023/09/17 23:07:04 - INFO - root -   Epoch: [130/400][200/346], lr: 0.00000029 	 loss = 0.0451(0.4460)
2023/09/17 23:07:48 - INFO - root -   Epoch: [130/400][220/346], lr: 0.00000029 	 loss = 0.1747(0.4524)
2023/09/17 23:08:48 - INFO - root -   Epoch: [130/400][240/346], lr: 0.00000029 	 loss = 0.2862(0.4501)
2023/09/17 23:09:32 - INFO - root -   Epoch: [130/400][260/346], lr: 0.00000029 	 loss = 0.2521(0.4446)
2023/09/17 23:10:32 - INFO - root -   Epoch: [130/400][280/346], lr: 0.00000029 	 loss = 0.1295(0.4623)
2023/09/17 23:11:16 - INFO - root -   Epoch: [130/400][300/346], lr: 0.00000029 	 loss = 0.1826(0.4607)
2023/09/17 23:12:16 - INFO - root -   Epoch: [130/400][320/346], lr: 0.00000029 	 loss = 0.2595(0.4615)
2023/09/17 23:12:58 - INFO - root -   Epoch: [130/400][340/346], lr: 0.00000029 	 loss = 0.5553(0.4617)
2023/09/17 23:13:02 - INFO - root -   Epoch: [130/400] 	 loss = 0.4617
2023/09/17 23:13:02 - INFO - root -   train_accuracy = 0.7934
2023/09/17 23:13:24 - INFO - root -   Epoch: [131/400][0/346], lr: 0.00000029 	 loss = 0.5135(0.5135)
2023/09/17 23:14:07 - INFO - root -   Epoch: [131/400][20/346], lr: 0.00000029 	 loss = 0.0779(0.3625)
2023/09/17 23:15:08 - INFO - root -   Epoch: [131/400][40/346], lr: 0.00000029 	 loss = 0.4942(0.4117)
2023/09/17 23:15:51 - INFO - root -   Epoch: [131/400][60/346], lr: 0.00000029 	 loss = 0.5830(0.3923)
2023/09/17 23:16:52 - INFO - root -   Epoch: [131/400][80/346], lr: 0.00000029 	 loss = 0.2881(0.4274)
2023/09/17 23:17:36 - INFO - root -   Epoch: [131/400][100/346], lr: 0.00000029 	 loss = 0.6164(0.4300)
2023/09/17 23:18:36 - INFO - root -   Epoch: [131/400][120/346], lr: 0.00000029 	 loss = 0.2157(0.4389)
2023/09/17 23:19:21 - INFO - root -   Epoch: [131/400][140/346], lr: 0.00000029 	 loss = 0.3714(0.4269)
2023/09/17 23:20:20 - INFO - root -   Epoch: [131/400][160/346], lr: 0.00000029 	 loss = 0.0910(0.4328)
2023/09/17 23:21:05 - INFO - root -   Epoch: [131/400][180/346], lr: 0.00000029 	 loss = 0.4012(0.4454)
2023/09/17 23:22:04 - INFO - root -   Epoch: [131/400][200/346], lr: 0.00000029 	 loss = 0.0976(0.4322)
2023/09/17 23:22:49 - INFO - root -   Epoch: [131/400][220/346], lr: 0.00000029 	 loss = 0.3531(0.4404)
2023/09/17 23:23:49 - INFO - root -   Epoch: [131/400][240/346], lr: 0.00000029 	 loss = 0.0818(0.4463)
2023/09/17 23:24:33 - INFO - root -   Epoch: [131/400][260/346], lr: 0.00000029 	 loss = 0.6017(0.4380)
2023/09/17 23:25:33 - INFO - root -   Epoch: [131/400][280/346], lr: 0.00000029 	 loss = 0.2358(0.4462)
2023/09/17 23:26:18 - INFO - root -   Epoch: [131/400][300/346], lr: 0.00000029 	 loss = 0.1139(0.4411)
2023/09/17 23:27:18 - INFO - root -   Epoch: [131/400][320/346], lr: 0.00000029 	 loss = 0.0704(0.4421)
2023/09/17 23:28:01 - INFO - root -   Epoch: [131/400][340/346], lr: 0.00000029 	 loss = 0.9986(0.4476)
2023/09/17 23:28:05 - INFO - root -   Epoch: [131/400] 	 loss = 0.4483
2023/09/17 23:28:05 - INFO - root -   train_accuracy = 0.7934
2023/09/17 23:28:27 - INFO - root -   Epoch: [132/400][0/346], lr: 0.00000029 	 loss = 0.5331(0.5331)
2023/09/17 23:29:10 - INFO - root -   Epoch: [132/400][20/346], lr: 0.00000029 	 loss = 0.0152(0.4154)
2023/09/17 23:30:11 - INFO - root -   Epoch: [132/400][40/346], lr: 0.00000029 	 loss = 0.5922(0.4331)
2023/09/17 23:30:55 - INFO - root -   Epoch: [132/400][60/346], lr: 0.00000029 	 loss = 0.6964(0.3740)
2023/09/17 23:31:56 - INFO - root -   Epoch: [132/400][80/346], lr: 0.00000029 	 loss = 0.0986(0.4027)
2023/09/17 23:32:40 - INFO - root -   Epoch: [132/400][100/346], lr: 0.00000029 	 loss = 0.7156(0.4044)
2023/09/17 23:33:41 - INFO - root -   Epoch: [132/400][120/346], lr: 0.00000029 	 loss = 0.1482(0.4060)
2023/09/17 23:34:25 - INFO - root -   Epoch: [132/400][140/346], lr: 0.00000029 	 loss = 0.5237(0.4106)
2023/09/17 23:35:25 - INFO - root -   Epoch: [132/400][160/346], lr: 0.00000029 	 loss = 0.1106(0.4209)
2023/09/17 23:36:09 - INFO - root -   Epoch: [132/400][180/346], lr: 0.00000029 	 loss = 0.1357(0.4175)
2023/09/17 23:37:09 - INFO - root -   Epoch: [132/400][200/346], lr: 0.00000029 	 loss = 0.0930(0.4187)
2023/09/17 23:37:54 - INFO - root -   Epoch: [132/400][220/346], lr: 0.00000029 	 loss = 0.3308(0.4267)
2023/09/17 23:38:54 - INFO - root -   Epoch: [132/400][240/346], lr: 0.00000029 	 loss = 0.0459(0.4290)
2023/09/17 23:39:38 - INFO - root -   Epoch: [132/400][260/346], lr: 0.00000029 	 loss = 0.2987(0.4153)
2023/09/17 23:40:38 - INFO - root -   Epoch: [132/400][280/346], lr: 0.00000029 	 loss = 0.1418(0.4265)
2023/09/17 23:41:22 - INFO - root -   Epoch: [132/400][300/346], lr: 0.00000029 	 loss = 0.1137(0.4281)
2023/09/17 23:42:23 - INFO - root -   Epoch: [132/400][320/346], lr: 0.00000029 	 loss = 0.2023(0.4255)
2023/09/17 23:43:05 - INFO - root -   Epoch: [132/400][340/346], lr: 0.00000029 	 loss = 0.2968(0.4258)
2023/09/17 23:43:10 - INFO - root -   Epoch: [132/400] 	 loss = 0.4269
2023/09/17 23:43:10 - INFO - root -   train_accuracy = 0.8064
2023/09/17 23:43:31 - INFO - root -   Epoch: [133/400][0/346], lr: 0.00000029 	 loss = 0.1436(0.1436)
2023/09/17 23:44:14 - INFO - root -   Epoch: [133/400][20/346], lr: 0.00000029 	 loss = 0.0234(0.3341)
2023/09/17 23:45:14 - INFO - root -   Epoch: [133/400][40/346], lr: 0.00000029 	 loss = 0.4058(0.4477)
2023/09/17 23:45:57 - INFO - root -   Epoch: [133/400][60/346], lr: 0.00000029 	 loss = 0.4881(0.4173)
2023/09/17 23:46:58 - INFO - root -   Epoch: [133/400][80/346], lr: 0.00000029 	 loss = 0.0928(0.4405)
2023/09/17 23:47:41 - INFO - root -   Epoch: [133/400][100/346], lr: 0.00000029 	 loss = 0.3158(0.4558)
2023/09/17 23:48:42 - INFO - root -   Epoch: [133/400][120/346], lr: 0.00000029 	 loss = 0.0840(0.4970)
2023/09/17 23:49:25 - INFO - root -   Epoch: [133/400][140/346], lr: 0.00000029 	 loss = 0.6415(0.4810)
2023/09/17 23:50:25 - INFO - root -   Epoch: [133/400][160/346], lr: 0.00000029 	 loss = 0.0851(0.4862)
2023/09/17 23:51:08 - INFO - root -   Epoch: [133/400][180/346], lr: 0.00000029 	 loss = 0.0959(0.4827)
2023/09/17 23:52:08 - INFO - root -   Epoch: [133/400][200/346], lr: 0.00000029 	 loss = 0.1986(0.4701)
2023/09/17 23:52:51 - INFO - root -   Epoch: [133/400][220/346], lr: 0.00000029 	 loss = 0.4946(0.4692)
2023/09/17 23:53:51 - INFO - root -   Epoch: [133/400][240/346], lr: 0.00000029 	 loss = 0.1285(0.4670)
2023/09/17 23:54:34 - INFO - root -   Epoch: [133/400][260/346], lr: 0.00000029 	 loss = 0.1127(0.4628)
2023/09/17 23:55:34 - INFO - root -   Epoch: [133/400][280/346], lr: 0.00000029 	 loss = 0.1035(0.4688)
2023/09/17 23:56:18 - INFO - root -   Epoch: [133/400][300/346], lr: 0.00000029 	 loss = 0.2638(0.4618)
2023/09/17 23:57:17 - INFO - root -   Epoch: [133/400][320/346], lr: 0.00000029 	 loss = 0.1636(0.4608)
2023/09/17 23:58:00 - INFO - root -   Epoch: [133/400][340/346], lr: 0.00000029 	 loss = 0.6844(0.4577)
2023/09/17 23:58:04 - INFO - root -   Epoch: [133/400] 	 loss = 0.4615
2023/09/17 23:58:04 - INFO - root -   train_accuracy = 0.7847
2023/09/17 23:58:26 - INFO - root -   Epoch: [134/400][0/346], lr: 0.00000029 	 loss = 0.5054(0.5054)
2023/09/17 23:59:09 - INFO - root -   Epoch: [134/400][20/346], lr: 0.00000029 	 loss = 0.0286(0.3033)
2023/09/18 00:00:10 - INFO - root -   Epoch: [134/400][40/346], lr: 0.00000029 	 loss = 0.7819(0.4136)
2023/09/18 00:00:53 - INFO - root -   Epoch: [134/400][60/346], lr: 0.00000029 	 loss = 0.3556(0.3803)
2023/09/18 00:01:54 - INFO - root -   Epoch: [134/400][80/346], lr: 0.00000029 	 loss = 0.2748(0.4496)
2023/09/18 00:02:37 - INFO - root -   Epoch: [134/400][100/346], lr: 0.00000029 	 loss = 0.5868(0.4684)
2023/09/18 00:03:37 - INFO - root -   Epoch: [134/400][120/346], lr: 0.00000029 	 loss = 0.1927(0.4892)
2023/09/18 00:04:21 - INFO - root -   Epoch: [134/400][140/346], lr: 0.00000029 	 loss = 0.5862(0.4845)
2023/09/18 00:05:21 - INFO - root -   Epoch: [134/400][160/346], lr: 0.00000029 	 loss = 0.0706(0.4781)
2023/09/18 00:06:04 - INFO - root -   Epoch: [134/400][180/346], lr: 0.00000029 	 loss = 0.1202(0.4722)
2023/09/18 00:07:04 - INFO - root -   Epoch: [134/400][200/346], lr: 0.00000029 	 loss = 0.0307(0.4527)
2023/09/18 00:07:47 - INFO - root -   Epoch: [134/400][220/346], lr: 0.00000029 	 loss = 0.1941(0.4553)
2023/09/18 00:08:48 - INFO - root -   Epoch: [134/400][240/346], lr: 0.00000029 	 loss = 0.0429(0.4436)
2023/09/18 00:09:31 - INFO - root -   Epoch: [134/400][260/346], lr: 0.00000029 	 loss = 0.5052(0.4389)
2023/09/18 00:10:32 - INFO - root -   Epoch: [134/400][280/346], lr: 0.00000029 	 loss = 0.1042(0.4559)
2023/09/18 00:11:15 - INFO - root -   Epoch: [134/400][300/346], lr: 0.00000029 	 loss = 0.1589(0.4522)
2023/09/18 00:12:15 - INFO - root -   Epoch: [134/400][320/346], lr: 0.00000029 	 loss = 0.1599(0.4524)
2023/09/18 00:12:57 - INFO - root -   Epoch: [134/400][340/346], lr: 0.00000029 	 loss = 0.2573(0.4503)
2023/09/18 00:13:01 - INFO - root -   Epoch: [134/400] 	 loss = 0.4523
2023/09/18 00:30:40 - INFO - root -   precision = 0.6954
2023/09/18 00:30:40 - INFO - root -   eval_loss = 0.6333
2023/09/18 00:30:41 - INFO - root -   train_accuracy = 0.7948
2023/09/18 00:31:03 - INFO - root -   Epoch: [135/400][0/346], lr: 0.00000029 	 loss = 0.8471(0.8471)
2023/09/18 00:31:46 - INFO - root -   Epoch: [135/400][20/346], lr: 0.00000029 	 loss = 0.0427(0.3499)
2023/09/18 00:32:47 - INFO - root -   Epoch: [135/400][40/346], lr: 0.00000029 	 loss = 0.4763(0.3987)
2023/09/18 00:33:30 - INFO - root -   Epoch: [135/400][60/346], lr: 0.00000029 	 loss = 0.4700(0.3658)
2023/09/18 00:34:31 - INFO - root -   Epoch: [135/400][80/346], lr: 0.00000029 	 loss = 0.1043(0.4109)
2023/09/18 00:35:14 - INFO - root -   Epoch: [135/400][100/346], lr: 0.00000029 	 loss = 0.8680(0.4305)
2023/09/18 00:36:14 - INFO - root -   Epoch: [135/400][120/346], lr: 0.00000029 	 loss = 0.2317(0.4565)
2023/09/18 00:36:57 - INFO - root -   Epoch: [135/400][140/346], lr: 0.00000029 	 loss = 0.2863(0.4480)
2023/09/18 00:37:58 - INFO - root -   Epoch: [135/400][160/346], lr: 0.00000029 	 loss = 0.0637(0.4472)
2023/09/18 00:38:41 - INFO - root -   Epoch: [135/400][180/346], lr: 0.00000029 	 loss = 0.1861(0.4582)
2023/09/18 00:39:41 - INFO - root -   Epoch: [135/400][200/346], lr: 0.00000029 	 loss = 0.0437(0.4377)
2023/09/18 00:40:24 - INFO - root -   Epoch: [135/400][220/346], lr: 0.00000029 	 loss = 0.2373(0.4439)
2023/09/18 00:41:25 - INFO - root -   Epoch: [135/400][240/346], lr: 0.00000029 	 loss = 0.0336(0.4364)
2023/09/18 00:42:08 - INFO - root -   Epoch: [135/400][260/346], lr: 0.00000029 	 loss = 1.1692(0.4280)
2023/09/18 00:43:08 - INFO - root -   Epoch: [135/400][280/346], lr: 0.00000029 	 loss = 0.1537(0.4438)
2023/09/18 00:43:51 - INFO - root -   Epoch: [135/400][300/346], lr: 0.00000029 	 loss = 0.1185(0.4434)
2023/09/18 00:44:51 - INFO - root -   Epoch: [135/400][320/346], lr: 0.00000029 	 loss = 0.0495(0.4488)
2023/09/18 00:45:33 - INFO - root -   Epoch: [135/400][340/346], lr: 0.00000029 	 loss = 0.5420(0.4487)
2023/09/18 00:45:37 - INFO - root -   Epoch: [135/400] 	 loss = 0.4496
2023/09/18 00:45:37 - INFO - root -   train_accuracy = 0.7919
2023/09/18 00:45:59 - INFO - root -   Epoch: [136/400][0/346], lr: 0.00000029 	 loss = 0.3797(0.3797)
2023/09/18 00:46:43 - INFO - root -   Epoch: [136/400][20/346], lr: 0.00000029 	 loss = 0.0669(0.4690)
2023/09/18 00:47:44 - INFO - root -   Epoch: [136/400][40/346], lr: 0.00000029 	 loss = 0.4642(0.4663)
2023/09/18 00:48:27 - INFO - root -   Epoch: [136/400][60/346], lr: 0.00000029 	 loss = 0.6269(0.4248)
2023/09/18 00:49:28 - INFO - root -   Epoch: [136/400][80/346], lr: 0.00000029 	 loss = 0.2142(0.4347)
2023/09/18 00:50:12 - INFO - root -   Epoch: [136/400][100/346], lr: 0.00000029 	 loss = 0.5202(0.4230)
2023/09/18 00:51:13 - INFO - root -   Epoch: [136/400][120/346], lr: 0.00000029 	 loss = 0.0747(0.4280)
2023/09/18 00:51:56 - INFO - root -   Epoch: [136/400][140/346], lr: 0.00000029 	 loss = 0.5577(0.4180)
2023/09/18 00:52:57 - INFO - root -   Epoch: [136/400][160/346], lr: 0.00000029 	 loss = 0.0896(0.4172)
2023/09/18 00:53:40 - INFO - root -   Epoch: [136/400][180/346], lr: 0.00000029 	 loss = 0.1605(0.4214)
2023/09/18 00:54:41 - INFO - root -   Epoch: [136/400][200/346], lr: 0.00000029 	 loss = 0.1353(0.4136)
2023/09/18 00:55:24 - INFO - root -   Epoch: [136/400][220/346], lr: 0.00000029 	 loss = 0.2142(0.4239)
2023/09/18 00:56:25 - INFO - root -   Epoch: [136/400][240/346], lr: 0.00000029 	 loss = 0.0601(0.4262)
2023/09/18 00:57:09 - INFO - root -   Epoch: [136/400][260/346], lr: 0.00000029 	 loss = 0.3532(0.4259)
2023/09/18 00:58:09 - INFO - root -   Epoch: [136/400][280/346], lr: 0.00000029 	 loss = 0.0787(0.4325)
2023/09/18 00:58:53 - INFO - root -   Epoch: [136/400][300/346], lr: 0.00000029 	 loss = 0.1447(0.4296)
2023/09/18 00:59:53 - INFO - root -   Epoch: [136/400][320/346], lr: 0.00000029 	 loss = 0.0571(0.4247)
2023/09/18 01:00:36 - INFO - root -   Epoch: [136/400][340/346], lr: 0.00000029 	 loss = 0.7842(0.4288)
2023/09/18 01:00:40 - INFO - root -   Epoch: [136/400] 	 loss = 0.4304
2023/09/18 01:00:40 - INFO - root -   train_accuracy = 0.7890
2023/09/18 01:01:02 - INFO - root -   Epoch: [137/400][0/346], lr: 0.00000030 	 loss = 0.4656(0.4656)
2023/09/18 01:01:45 - INFO - root -   Epoch: [137/400][20/346], lr: 0.00000030 	 loss = 0.0354(0.3700)
2023/09/18 01:02:45 - INFO - root -   Epoch: [137/400][40/346], lr: 0.00000030 	 loss = 0.4950(0.3831)
2023/09/18 01:03:28 - INFO - root -   Epoch: [137/400][60/346], lr: 0.00000030 	 loss = 0.2877(0.3445)
2023/09/18 01:04:29 - INFO - root -   Epoch: [137/400][80/346], lr: 0.00000030 	 loss = 0.1125(0.4264)
2023/09/18 01:05:12 - INFO - root -   Epoch: [137/400][100/346], lr: 0.00000030 	 loss = 0.3574(0.4360)
2023/09/18 01:06:12 - INFO - root -   Epoch: [137/400][120/346], lr: 0.00000030 	 loss = 0.0812(0.4532)
2023/09/18 01:06:55 - INFO - root -   Epoch: [137/400][140/346], lr: 0.00000030 	 loss = 1.2370(0.4551)
2023/09/18 01:07:55 - INFO - root -   Epoch: [137/400][160/346], lr: 0.00000030 	 loss = 0.0472(0.4585)
2023/09/18 01:08:38 - INFO - root -   Epoch: [137/400][180/346], lr: 0.00000030 	 loss = 0.1454(0.4626)
2023/09/18 01:09:38 - INFO - root -   Epoch: [137/400][200/346], lr: 0.00000030 	 loss = 0.0338(0.4474)
2023/09/18 01:10:21 - INFO - root -   Epoch: [137/400][220/346], lr: 0.00000030 	 loss = 0.1878(0.4471)
2023/09/18 01:11:22 - INFO - root -   Epoch: [137/400][240/346], lr: 0.00000030 	 loss = 0.0226(0.4422)
2023/09/18 01:12:05 - INFO - root -   Epoch: [137/400][260/346], lr: 0.00000030 	 loss = 0.7106(0.4381)
2023/09/18 01:13:05 - INFO - root -   Epoch: [137/400][280/346], lr: 0.00000030 	 loss = 0.0549(0.4485)
2023/09/18 01:13:48 - INFO - root -   Epoch: [137/400][300/346], lr: 0.00000030 	 loss = 0.1934(0.4453)
2023/09/18 01:14:48 - INFO - root -   Epoch: [137/400][320/346], lr: 0.00000030 	 loss = 0.1359(0.4426)
2023/09/18 01:15:30 - INFO - root -   Epoch: [137/400][340/346], lr: 0.00000030 	 loss = 0.7390(0.4412)
2023/09/18 01:15:34 - INFO - root -   Epoch: [137/400] 	 loss = 0.4442
2023/09/18 01:15:34 - INFO - root -   train_accuracy = 0.7962
2023/09/18 01:15:56 - INFO - root -   Epoch: [138/400][0/346], lr: 0.00000030 	 loss = 0.4632(0.4632)
2023/09/18 01:16:39 - INFO - root -   Epoch: [138/400][20/346], lr: 0.00000030 	 loss = 0.0287(0.3481)
2023/09/18 01:17:39 - INFO - root -   Epoch: [138/400][40/346], lr: 0.00000030 	 loss = 0.4776(0.3459)
2023/09/18 01:18:22 - INFO - root -   Epoch: [138/400][60/346], lr: 0.00000030 	 loss = 0.1616(0.3202)
2023/09/18 01:19:23 - INFO - root -   Epoch: [138/400][80/346], lr: 0.00000030 	 loss = 0.3222(0.3714)
2023/09/18 01:20:06 - INFO - root -   Epoch: [138/400][100/346], lr: 0.00000030 	 loss = 0.9091(0.3784)
2023/09/18 01:21:06 - INFO - root -   Epoch: [138/400][120/346], lr: 0.00000030 	 loss = 0.0297(0.3866)
2023/09/18 01:21:49 - INFO - root -   Epoch: [138/400][140/346], lr: 0.00000030 	 loss = 0.3169(0.3946)
2023/09/18 01:22:50 - INFO - root -   Epoch: [138/400][160/346], lr: 0.00000030 	 loss = 0.0976(0.4118)
2023/09/18 01:23:33 - INFO - root -   Epoch: [138/400][180/346], lr: 0.00000030 	 loss = 0.1069(0.4119)
2023/09/18 01:24:33 - INFO - root -   Epoch: [138/400][200/346], lr: 0.00000030 	 loss = 0.0666(0.4021)
2023/09/18 01:25:16 - INFO - root -   Epoch: [138/400][220/346], lr: 0.00000030 	 loss = 0.2035(0.4063)
2023/09/18 01:26:16 - INFO - root -   Epoch: [138/400][240/346], lr: 0.00000030 	 loss = 0.0699(0.4074)
2023/09/18 01:26:59 - INFO - root -   Epoch: [138/400][260/346], lr: 0.00000030 	 loss = 0.5912(0.4155)
2023/09/18 01:28:00 - INFO - root -   Epoch: [138/400][280/346], lr: 0.00000030 	 loss = 0.0636(0.4345)
2023/09/18 01:28:43 - INFO - root -   Epoch: [138/400][300/346], lr: 0.00000030 	 loss = 0.1443(0.4280)
2023/09/18 01:29:44 - INFO - root -   Epoch: [138/400][320/346], lr: 0.00000030 	 loss = 0.0603(0.4299)
2023/09/18 01:30:25 - INFO - root -   Epoch: [138/400][340/346], lr: 0.00000030 	 loss = 0.2505(0.4362)
2023/09/18 01:30:29 - INFO - root -   Epoch: [138/400] 	 loss = 0.4357
2023/09/18 01:30:29 - INFO - root -   train_accuracy = 0.8092
2023/09/18 01:30:51 - INFO - root -   Epoch: [139/400][0/346], lr: 0.00000030 	 loss = 0.4004(0.4004)
2023/09/18 01:31:34 - INFO - root -   Epoch: [139/400][20/346], lr: 0.00000030 	 loss = 0.0506(0.2912)
2023/09/18 01:32:35 - INFO - root -   Epoch: [139/400][40/346], lr: 0.00000030 	 loss = 0.5369(0.3698)
2023/09/18 01:33:18 - INFO - root -   Epoch: [139/400][60/346], lr: 0.00000030 	 loss = 0.3076(0.3344)
2023/09/18 01:34:19 - INFO - root -   Epoch: [139/400][80/346], lr: 0.00000030 	 loss = 0.0973(0.3810)
2023/09/18 01:35:02 - INFO - root -   Epoch: [139/400][100/346], lr: 0.00000030 	 loss = 0.7802(0.3791)
2023/09/18 01:36:02 - INFO - root -   Epoch: [139/400][120/346], lr: 0.00000030 	 loss = 0.1657(0.3942)
2023/09/18 01:36:45 - INFO - root -   Epoch: [139/400][140/346], lr: 0.00000030 	 loss = 0.8854(0.4016)
2023/09/18 01:37:46 - INFO - root -   Epoch: [139/400][160/346], lr: 0.00000030 	 loss = 0.1908(0.4065)
2023/09/18 01:38:29 - INFO - root -   Epoch: [139/400][180/346], lr: 0.00000030 	 loss = 0.1572(0.4172)
2023/09/18 01:39:29 - INFO - root -   Epoch: [139/400][200/346], lr: 0.00000030 	 loss = 0.0210(0.4004)
2023/09/18 01:40:13 - INFO - root -   Epoch: [139/400][220/346], lr: 0.00000030 	 loss = 0.5799(0.4053)
2023/09/18 01:41:13 - INFO - root -   Epoch: [139/400][240/346], lr: 0.00000030 	 loss = 0.0274(0.4036)
2023/09/18 01:41:56 - INFO - root -   Epoch: [139/400][260/346], lr: 0.00000030 	 loss = 0.3695(0.4016)
2023/09/18 01:42:57 - INFO - root -   Epoch: [139/400][280/346], lr: 0.00000030 	 loss = 0.1069(0.4210)
2023/09/18 01:43:40 - INFO - root -   Epoch: [139/400][300/346], lr: 0.00000030 	 loss = 0.1629(0.4155)
2023/09/18 01:44:41 - INFO - root -   Epoch: [139/400][320/346], lr: 0.00000030 	 loss = 0.2978(0.4176)
2023/09/18 01:45:22 - INFO - root -   Epoch: [139/400][340/346], lr: 0.00000030 	 loss = 0.6730(0.4212)
2023/09/18 01:45:26 - INFO - root -   Epoch: [139/400] 	 loss = 0.4236
2023/09/18 01:49:13 - INFO - root -   precision = 0.6667
2023/09/18 01:49:13 - INFO - root -   eval_loss = 0.7548
2023/09/18 01:49:14 - INFO - root -   train_accuracy = 0.8020
2023/09/18 01:49:36 - INFO - root -   Epoch: [140/400][0/346], lr: 0.00000030 	 loss = 0.6750(0.6750)
2023/09/18 01:50:19 - INFO - root -   Epoch: [140/400][20/346], lr: 0.00000030 	 loss = 0.0433(0.4516)
2023/09/18 01:51:20 - INFO - root -   Epoch: [140/400][40/346], lr: 0.00000030 	 loss = 0.4409(0.5201)
2023/09/18 01:52:03 - INFO - root -   Epoch: [140/400][60/346], lr: 0.00000030 	 loss = 0.5347(0.4439)
2023/09/18 01:53:03 - INFO - root -   Epoch: [140/400][80/346], lr: 0.00000030 	 loss = 0.2666(0.4361)
2023/09/18 01:53:47 - INFO - root -   Epoch: [140/400][100/346], lr: 0.00000030 	 loss = 0.7550(0.4501)
2023/09/18 01:54:47 - INFO - root -   Epoch: [140/400][120/346], lr: 0.00000030 	 loss = 0.0822(0.4442)
2023/09/18 01:55:30 - INFO - root -   Epoch: [140/400][140/346], lr: 0.00000030 	 loss = 0.3571(0.4298)
2023/09/18 01:56:30 - INFO - root -   Epoch: [140/400][160/346], lr: 0.00000030 	 loss = 0.0452(0.4241)
2023/09/18 01:57:14 - INFO - root -   Epoch: [140/400][180/346], lr: 0.00000030 	 loss = 0.0999(0.4239)
2023/09/18 01:58:14 - INFO - root -   Epoch: [140/400][200/346], lr: 0.00000030 	 loss = 0.0414(0.4050)
2023/09/18 01:58:57 - INFO - root -   Epoch: [140/400][220/346], lr: 0.00000030 	 loss = 0.2639(0.4101)
2023/09/18 01:59:58 - INFO - root -   Epoch: [140/400][240/346], lr: 0.00000030 	 loss = 0.0592(0.4089)
2023/09/18 02:00:41 - INFO - root -   Epoch: [140/400][260/346], lr: 0.00000030 	 loss = 0.5087(0.4003)
2023/09/18 02:01:41 - INFO - root -   Epoch: [140/400][280/346], lr: 0.00000030 	 loss = 0.1827(0.4186)
2023/09/18 02:02:25 - INFO - root -   Epoch: [140/400][300/346], lr: 0.00000030 	 loss = 0.0932(0.4112)
2023/09/18 02:03:25 - INFO - root -   Epoch: [140/400][320/346], lr: 0.00000030 	 loss = 0.0315(0.4113)
2023/09/18 02:04:07 - INFO - root -   Epoch: [140/400][340/346], lr: 0.00000030 	 loss = 1.8036(0.4206)
2023/09/18 02:04:11 - INFO - root -   Epoch: [140/400] 	 loss = 0.4263
2023/09/18 02:04:11 - INFO - root -   train_accuracy = 0.7991
2023/09/18 02:04:32 - INFO - root -   Epoch: [141/400][0/346], lr: 0.00000030 	 loss = 0.3377(0.3377)
2023/09/18 02:05:15 - INFO - root -   Epoch: [141/400][20/346], lr: 0.00000030 	 loss = 0.0829(0.3404)
2023/09/18 02:06:16 - INFO - root -   Epoch: [141/400][40/346], lr: 0.00000030 	 loss = 0.3242(0.3636)
2023/09/18 02:06:59 - INFO - root -   Epoch: [141/400][60/346], lr: 0.00000030 	 loss = 0.6436(0.3510)
2023/09/18 02:08:00 - INFO - root -   Epoch: [141/400][80/346], lr: 0.00000030 	 loss = 0.1729(0.4123)
2023/09/18 02:08:43 - INFO - root -   Epoch: [141/400][100/346], lr: 0.00000030 	 loss = 0.5964(0.4015)
2023/09/18 02:09:43 - INFO - root -   Epoch: [141/400][120/346], lr: 0.00000030 	 loss = 0.0593(0.4128)
2023/09/18 02:10:27 - INFO - root -   Epoch: [141/400][140/346], lr: 0.00000030 	 loss = 0.3540(0.4091)
2023/09/18 02:11:27 - INFO - root -   Epoch: [141/400][160/346], lr: 0.00000030 	 loss = 0.0690(0.4246)
2023/09/18 02:12:10 - INFO - root -   Epoch: [141/400][180/346], lr: 0.00000030 	 loss = 1.1875(0.4556)
2023/09/18 02:13:10 - INFO - root -   Epoch: [141/400][200/346], lr: 0.00000030 	 loss = 0.0266(0.4467)
2023/09/18 02:13:54 - INFO - root -   Epoch: [141/400][220/346], lr: 0.00000030 	 loss = 0.2380(0.4514)
2023/09/18 02:14:54 - INFO - root -   Epoch: [141/400][240/346], lr: 0.00000030 	 loss = 0.2042(0.4688)
2023/09/18 02:15:38 - INFO - root -   Epoch: [141/400][260/346], lr: 0.00000030 	 loss = 1.0339(0.4725)
2023/09/18 02:16:37 - INFO - root -   Epoch: [141/400][280/346], lr: 0.00000030 	 loss = 0.1666(0.4920)
2023/09/18 02:17:21 - INFO - root -   Epoch: [141/400][300/346], lr: 0.00000030 	 loss = 0.0787(0.4841)
2023/09/18 02:18:20 - INFO - root -   Epoch: [141/400][320/346], lr: 0.00000030 	 loss = 0.2575(0.4809)
2023/09/18 02:19:03 - INFO - root -   Epoch: [141/400][340/346], lr: 0.00000030 	 loss = 1.8608(0.4868)
2023/09/18 02:19:07 - INFO - root -   Epoch: [141/400] 	 loss = 0.4877
2023/09/18 02:19:07 - INFO - root -   train_accuracy = 0.7818
2023/09/18 02:19:28 - INFO - root -   Epoch: [142/400][0/346], lr: 0.00000030 	 loss = 0.7470(0.7470)
2023/09/18 02:20:12 - INFO - root -   Epoch: [142/400][20/346], lr: 0.00000030 	 loss = 0.1714(0.4118)
2023/09/18 02:21:12 - INFO - root -   Epoch: [142/400][40/346], lr: 0.00000030 	 loss = 0.5463(0.4806)
2023/09/18 02:21:55 - INFO - root -   Epoch: [142/400][60/346], lr: 0.00000030 	 loss = 0.5838(0.4188)
2023/09/18 02:22:56 - INFO - root -   Epoch: [142/400][80/346], lr: 0.00000030 	 loss = 0.1595(0.4101)
2023/09/18 02:23:40 - INFO - root -   Epoch: [142/400][100/346], lr: 0.00000030 	 loss = 0.5342(0.3976)
2023/09/18 02:24:40 - INFO - root -   Epoch: [142/400][120/346], lr: 0.00000030 	 loss = 0.1165(0.4215)
2023/09/18 02:25:23 - INFO - root -   Epoch: [142/400][140/346], lr: 0.00000030 	 loss = 0.3739(0.4205)
2023/09/18 02:26:24 - INFO - root -   Epoch: [142/400][160/346], lr: 0.00000030 	 loss = 0.0970(0.4205)
2023/09/18 02:27:07 - INFO - root -   Epoch: [142/400][180/346], lr: 0.00000030 	 loss = 0.0770(0.4306)
2023/09/18 02:28:07 - INFO - root -   Epoch: [142/400][200/346], lr: 0.00000030 	 loss = 0.0571(0.4220)
2023/09/18 02:28:51 - INFO - root -   Epoch: [142/400][220/346], lr: 0.00000030 	 loss = 0.2228(0.4250)
2023/09/18 02:29:51 - INFO - root -   Epoch: [142/400][240/346], lr: 0.00000030 	 loss = 0.1137(0.4222)
2023/09/18 02:30:35 - INFO - root -   Epoch: [142/400][260/346], lr: 0.00000030 	 loss = 1.2866(0.4197)
2023/09/18 02:31:34 - INFO - root -   Epoch: [142/400][280/346], lr: 0.00000030 	 loss = 0.1298(0.4264)
2023/09/18 02:32:18 - INFO - root -   Epoch: [142/400][300/346], lr: 0.00000030 	 loss = 0.1579(0.4218)
2023/09/18 02:33:18 - INFO - root -   Epoch: [142/400][320/346], lr: 0.00000030 	 loss = 0.1229(0.4247)
2023/09/18 02:34:00 - INFO - root -   Epoch: [142/400][340/346], lr: 0.00000030 	 loss = 0.7227(0.4240)
2023/09/18 02:34:05 - INFO - root -   Epoch: [142/400] 	 loss = 0.4265
2023/09/18 02:34:05 - INFO - root -   train_accuracy = 0.7977
2023/09/18 02:34:26 - INFO - root -   Epoch: [143/400][0/346], lr: 0.00000030 	 loss = 0.2834(0.2834)
2023/09/18 02:35:09 - INFO - root -   Epoch: [143/400][20/346], lr: 0.00000030 	 loss = 0.0415(0.3910)
2023/09/18 02:36:11 - INFO - root -   Epoch: [143/400][40/346], lr: 0.00000030 	 loss = 0.4514(0.3950)
2023/09/18 02:36:54 - INFO - root -   Epoch: [143/400][60/346], lr: 0.00000030 	 loss = 0.2849(0.3940)
2023/09/18 02:37:56 - INFO - root -   Epoch: [143/400][80/346], lr: 0.00000030 	 loss = 0.1246(0.4079)
2023/09/18 02:38:39 - INFO - root -   Epoch: [143/400][100/346], lr: 0.00000030 	 loss = 0.5936(0.4005)
2023/09/18 02:39:40 - INFO - root -   Epoch: [143/400][120/346], lr: 0.00000030 	 loss = 0.0854(0.4208)
2023/09/18 02:40:24 - INFO - root -   Epoch: [143/400][140/346], lr: 0.00000030 	 loss = 0.6656(0.4146)
2023/09/18 02:41:25 - INFO - root -   Epoch: [143/400][160/346], lr: 0.00000030 	 loss = 0.2708(0.4194)
2023/09/18 02:42:08 - INFO - root -   Epoch: [143/400][180/346], lr: 0.00000030 	 loss = 0.1120(0.4202)
2023/09/18 02:43:09 - INFO - root -   Epoch: [143/400][200/346], lr: 0.00000030 	 loss = 0.0209(0.4062)
2023/09/18 02:43:53 - INFO - root -   Epoch: [143/400][220/346], lr: 0.00000030 	 loss = 0.3374(0.4109)
2023/09/18 02:44:54 - INFO - root -   Epoch: [143/400][240/346], lr: 0.00000030 	 loss = 0.0356(0.4119)
2023/09/18 02:45:37 - INFO - root -   Epoch: [143/400][260/346], lr: 0.00000030 	 loss = 0.7509(0.4119)
2023/09/18 02:46:38 - INFO - root -   Epoch: [143/400][280/346], lr: 0.00000030 	 loss = 0.3352(0.4310)
2023/09/18 02:47:22 - INFO - root -   Epoch: [143/400][300/346], lr: 0.00000030 	 loss = 0.2654(0.4215)
2023/09/18 02:48:22 - INFO - root -   Epoch: [143/400][320/346], lr: 0.00000030 	 loss = 0.0661(0.4167)
2023/09/18 02:49:05 - INFO - root -   Epoch: [143/400][340/346], lr: 0.00000030 	 loss = 0.6058(0.4211)
2023/09/18 02:49:09 - INFO - root -   Epoch: [143/400] 	 loss = 0.4267
2023/09/18 02:49:09 - INFO - root -   train_accuracy = 0.7905
2023/09/18 02:49:31 - INFO - root -   Epoch: [144/400][0/346], lr: 0.00000031 	 loss = 0.3382(0.3382)
2023/09/18 02:50:14 - INFO - root -   Epoch: [144/400][20/346], lr: 0.00000031 	 loss = 0.0372(0.3198)
2023/09/18 02:51:15 - INFO - root -   Epoch: [144/400][40/346], lr: 0.00000031 	 loss = 0.5771(0.3507)
2023/09/18 02:51:58 - INFO - root -   Epoch: [144/400][60/346], lr: 0.00000031 	 loss = 0.8498(0.3186)
2023/09/18 02:52:59 - INFO - root -   Epoch: [144/400][80/346], lr: 0.00000031 	 loss = 0.2041(0.3946)
2023/09/18 02:53:42 - INFO - root -   Epoch: [144/400][100/346], lr: 0.00000031 	 loss = 1.3171(0.3970)
2023/09/18 02:54:42 - INFO - root -   Epoch: [144/400][120/346], lr: 0.00000031 	 loss = 0.1054(0.4134)
2023/09/18 02:55:26 - INFO - root -   Epoch: [144/400][140/346], lr: 0.00000031 	 loss = 0.2468(0.3992)
2023/09/18 02:56:26 - INFO - root -   Epoch: [144/400][160/346], lr: 0.00000031 	 loss = 0.0936(0.4083)
2023/09/18 02:57:09 - INFO - root -   Epoch: [144/400][180/346], lr: 0.00000031 	 loss = 0.8636(0.4283)
2023/09/18 02:58:10 - INFO - root -   Epoch: [144/400][200/346], lr: 0.00000031 	 loss = 0.1057(0.4215)
2023/09/18 02:58:54 - INFO - root -   Epoch: [144/400][220/346], lr: 0.00000031 	 loss = 0.3290(0.4204)
2023/09/18 02:59:54 - INFO - root -   Epoch: [144/400][240/346], lr: 0.00000031 	 loss = 0.1979(0.4222)
2023/09/18 03:00:37 - INFO - root -   Epoch: [144/400][260/346], lr: 0.00000031 	 loss = 0.2250(0.4100)
2023/09/18 03:01:38 - INFO - root -   Epoch: [144/400][280/346], lr: 0.00000031 	 loss = 0.0352(0.4308)
2023/09/18 03:02:21 - INFO - root -   Epoch: [144/400][300/346], lr: 0.00000031 	 loss = 0.0949(0.4298)
2023/09/18 03:03:22 - INFO - root -   Epoch: [144/400][320/346], lr: 0.00000031 	 loss = 0.0465(0.4255)
2023/09/18 03:04:04 - INFO - root -   Epoch: [144/400][340/346], lr: 0.00000031 	 loss = 1.2544(0.4276)
2023/09/18 03:04:08 - INFO - root -   Epoch: [144/400] 	 loss = 0.4305
2023/09/18 03:07:56 - INFO - root -   precision = 0.6897
2023/09/18 03:07:56 - INFO - root -   eval_loss = 0.6833
2023/09/18 03:07:57 - INFO - root -   train_accuracy = 0.8064
2023/09/18 03:08:19 - INFO - root -   Epoch: [145/400][0/346], lr: 0.00000031 	 loss = 0.4224(0.4224)
2023/09/18 03:09:02 - INFO - root -   Epoch: [145/400][20/346], lr: 0.00000031 	 loss = 0.0779(0.4010)
2023/09/18 03:10:02 - INFO - root -   Epoch: [145/400][40/346], lr: 0.00000031 	 loss = 0.5564(0.4267)
2023/09/18 03:10:45 - INFO - root -   Epoch: [145/400][60/346], lr: 0.00000031 	 loss = 0.4249(0.3827)
2023/09/18 03:11:46 - INFO - root -   Epoch: [145/400][80/346], lr: 0.00000031 	 loss = 0.1556(0.3956)
2023/09/18 03:12:29 - INFO - root -   Epoch: [145/400][100/346], lr: 0.00000031 	 loss = 0.4907(0.4035)
2023/09/18 03:13:29 - INFO - root -   Epoch: [145/400][120/346], lr: 0.00000031 	 loss = 0.2050(0.4139)
2023/09/18 03:14:12 - INFO - root -   Epoch: [145/400][140/346], lr: 0.00000031 	 loss = 0.4662(0.4121)
2023/09/18 03:15:13 - INFO - root -   Epoch: [145/400][160/346], lr: 0.00000031 	 loss = 0.0617(0.4077)
2023/09/18 03:15:56 - INFO - root -   Epoch: [145/400][180/346], lr: 0.00000031 	 loss = 0.1446(0.4184)
2023/09/18 03:16:56 - INFO - root -   Epoch: [145/400][200/346], lr: 0.00000031 	 loss = 0.0234(0.4026)
2023/09/18 03:17:39 - INFO - root -   Epoch: [145/400][220/346], lr: 0.00000031 	 loss = 0.5817(0.4093)
2023/09/18 03:18:40 - INFO - root -   Epoch: [145/400][240/346], lr: 0.00000031 	 loss = 0.0679(0.4092)
2023/09/18 03:19:23 - INFO - root -   Epoch: [145/400][260/346], lr: 0.00000031 	 loss = 0.4349(0.4006)
2023/09/18 03:20:23 - INFO - root -   Epoch: [145/400][280/346], lr: 0.00000031 	 loss = 0.0801(0.4097)
2023/09/18 03:21:06 - INFO - root -   Epoch: [145/400][300/346], lr: 0.00000031 	 loss = 0.0622(0.4084)
2023/09/18 03:22:06 - INFO - root -   Epoch: [145/400][320/346], lr: 0.00000031 	 loss = 0.1236(0.4085)
2023/09/18 03:22:49 - INFO - root -   Epoch: [145/400][340/346], lr: 0.00000031 	 loss = 1.6700(0.4188)
2023/09/18 03:22:53 - INFO - root -   Epoch: [145/400] 	 loss = 0.4212
2023/09/18 03:22:53 - INFO - root -   train_accuracy = 0.8006
2023/09/18 03:23:14 - INFO - root -   Epoch: [146/400][0/346], lr: 0.00000031 	 loss = 0.4610(0.4610)
2023/09/18 03:23:57 - INFO - root -   Epoch: [146/400][20/346], lr: 0.00000031 	 loss = 0.1354(0.3742)
2023/09/18 03:24:58 - INFO - root -   Epoch: [146/400][40/346], lr: 0.00000031 	 loss = 0.4310(0.3940)
2023/09/18 03:25:41 - INFO - root -   Epoch: [146/400][60/346], lr: 0.00000031 	 loss = 0.4268(0.3546)
2023/09/18 03:26:41 - INFO - root -   Epoch: [146/400][80/346], lr: 0.00000031 	 loss = 0.2242(0.3809)
2023/09/18 03:27:24 - INFO - root -   Epoch: [146/400][100/346], lr: 0.00000031 	 loss = 0.6217(0.3798)
2023/09/18 03:28:24 - INFO - root -   Epoch: [146/400][120/346], lr: 0.00000031 	 loss = 0.1844(0.3900)
2023/09/18 03:29:07 - INFO - root -   Epoch: [146/400][140/346], lr: 0.00000031 	 loss = 0.3254(0.3869)
2023/09/18 03:30:07 - INFO - root -   Epoch: [146/400][160/346], lr: 0.00000031 	 loss = 0.1033(0.3944)
2023/09/18 03:30:50 - INFO - root -   Epoch: [146/400][180/346], lr: 0.00000031 	 loss = 0.0558(0.3908)
2023/09/18 03:31:50 - INFO - root -   Epoch: [146/400][200/346], lr: 0.00000031 	 loss = 0.0474(0.3812)
2023/09/18 03:32:33 - INFO - root -   Epoch: [146/400][220/346], lr: 0.00000031 	 loss = 0.3397(0.3922)
2023/09/18 03:33:33 - INFO - root -   Epoch: [146/400][240/346], lr: 0.00000031 	 loss = 0.0550(0.3904)
2023/09/18 03:34:17 - INFO - root -   Epoch: [146/400][260/346], lr: 0.00000031 	 loss = 0.2665(0.3797)
2023/09/18 03:35:16 - INFO - root -   Epoch: [146/400][280/346], lr: 0.00000031 	 loss = 0.0836(0.3930)
2023/09/18 03:36:00 - INFO - root -   Epoch: [146/400][300/346], lr: 0.00000031 	 loss = 0.1823(0.3958)
2023/09/18 03:37:00 - INFO - root -   Epoch: [146/400][320/346], lr: 0.00000031 	 loss = 0.1156(0.3890)
2023/09/18 03:37:42 - INFO - root -   Epoch: [146/400][340/346], lr: 0.00000031 	 loss = 0.9769(0.3939)
2023/09/18 03:37:46 - INFO - root -   Epoch: [146/400] 	 loss = 0.3933
2023/09/18 03:37:46 - INFO - root -   train_accuracy = 0.8165
2023/09/18 03:38:08 - INFO - root -   Epoch: [147/400][0/346], lr: 0.00000031 	 loss = 0.1358(0.1358)
2023/09/18 03:38:51 - INFO - root -   Epoch: [147/400][20/346], lr: 0.00000031 	 loss = 0.0325(0.3273)
2023/09/18 03:39:52 - INFO - root -   Epoch: [147/400][40/346], lr: 0.00000031 	 loss = 0.6378(0.4020)
2023/09/18 03:40:35 - INFO - root -   Epoch: [147/400][60/346], lr: 0.00000031 	 loss = 0.2966(0.3602)
2023/09/18 03:41:37 - INFO - root -   Epoch: [147/400][80/346], lr: 0.00000031 	 loss = 0.0458(0.3682)
2023/09/18 03:42:20 - INFO - root -   Epoch: [147/400][100/346], lr: 0.00000031 	 loss = 1.0883(0.3689)
2023/09/18 03:43:21 - INFO - root -   Epoch: [147/400][120/346], lr: 0.00000031 	 loss = 0.0875(0.3804)
2023/09/18 03:44:04 - INFO - root -   Epoch: [147/400][140/346], lr: 0.00000031 	 loss = 0.4257(0.3780)
2023/09/18 03:45:05 - INFO - root -   Epoch: [147/400][160/346], lr: 0.00000031 	 loss = 0.1563(0.3806)
2023/09/18 03:45:49 - INFO - root -   Epoch: [147/400][180/346], lr: 0.00000031 	 loss = 1.8072(0.3993)
2023/09/18 03:46:50 - INFO - root -   Epoch: [147/400][200/346], lr: 0.00000031 	 loss = 0.0928(0.3976)
2023/09/18 03:47:33 - INFO - root -   Epoch: [147/400][220/346], lr: 0.00000031 	 loss = 0.2929(0.4129)
2023/09/18 03:48:34 - INFO - root -   Epoch: [147/400][240/346], lr: 0.00000031 	 loss = 0.0995(0.4239)
2023/09/18 03:49:17 - INFO - root -   Epoch: [147/400][260/346], lr: 0.00000031 	 loss = 0.1472(0.4343)
2023/09/18 03:50:18 - INFO - root -   Epoch: [147/400][280/346], lr: 0.00000031 	 loss = 0.1575(0.4599)
2023/09/18 03:51:01 - INFO - root -   Epoch: [147/400][300/346], lr: 0.00000031 	 loss = 0.3820(0.4568)
2023/09/18 03:52:02 - INFO - root -   Epoch: [147/400][320/346], lr: 0.00000031 	 loss = 0.2056(0.4571)
2023/09/18 03:52:44 - INFO - root -   Epoch: [147/400][340/346], lr: 0.00000031 	 loss = 1.2124(0.4631)
2023/09/18 03:52:48 - INFO - root -   Epoch: [147/400] 	 loss = 0.4655
2023/09/18 03:52:48 - INFO - root -   train_accuracy = 0.7977
2023/09/18 03:53:09 - INFO - root -   Epoch: [148/400][0/346], lr: 0.00000031 	 loss = 0.1525(0.1525)
2023/09/18 03:53:52 - INFO - root -   Epoch: [148/400][20/346], lr: 0.00000031 	 loss = 0.0147(0.3376)
2023/09/18 03:54:53 - INFO - root -   Epoch: [148/400][40/346], lr: 0.00000031 	 loss = 0.6719(0.4004)
2023/09/18 03:55:36 - INFO - root -   Epoch: [148/400][60/346], lr: 0.00000031 	 loss = 0.3019(0.3580)
2023/09/18 03:56:37 - INFO - root -   Epoch: [148/400][80/346], lr: 0.00000031 	 loss = 0.1369(0.3922)
2023/09/18 03:57:20 - INFO - root -   Epoch: [148/400][100/346], lr: 0.00000031 	 loss = 0.5042(0.4026)
2023/09/18 03:58:21 - INFO - root -   Epoch: [148/400][120/346], lr: 0.00000031 	 loss = 0.1293(0.4266)
2023/09/18 03:59:04 - INFO - root -   Epoch: [148/400][140/346], lr: 0.00000031 	 loss = 0.2512(0.4195)
2023/09/18 04:00:04 - INFO - root -   Epoch: [148/400][160/346], lr: 0.00000031 	 loss = 0.1179(0.4398)
2023/09/18 04:00:48 - INFO - root -   Epoch: [148/400][180/346], lr: 0.00000031 	 loss = 0.0697(0.4525)
2023/09/18 04:01:48 - INFO - root -   Epoch: [148/400][200/346], lr: 0.00000031 	 loss = 0.0755(0.4458)
2023/09/18 04:02:31 - INFO - root -   Epoch: [148/400][220/346], lr: 0.00000031 	 loss = 0.7324(0.4429)
2023/09/18 04:03:32 - INFO - root -   Epoch: [148/400][240/346], lr: 0.00000031 	 loss = 0.0728(0.4339)
2023/09/18 04:04:15 - INFO - root -   Epoch: [148/400][260/346], lr: 0.00000031 	 loss = 0.2686(0.4247)
2023/09/18 04:05:15 - INFO - root -   Epoch: [148/400][280/346], lr: 0.00000031 	 loss = 0.0601(0.4304)
2023/09/18 04:05:59 - INFO - root -   Epoch: [148/400][300/346], lr: 0.00000031 	 loss = 0.1864(0.4305)
2023/09/18 04:06:59 - INFO - root -   Epoch: [148/400][320/346], lr: 0.00000031 	 loss = 0.1477(0.4249)
2023/09/18 04:07:41 - INFO - root -   Epoch: [148/400][340/346], lr: 0.00000031 	 loss = 0.6776(0.4219)
2023/09/18 04:07:45 - INFO - root -   Epoch: [148/400] 	 loss = 0.4249
2023/09/18 04:07:45 - INFO - root -   train_accuracy = 0.8064
2023/09/18 04:08:07 - INFO - root -   Epoch: [149/400][0/346], lr: 0.00000031 	 loss = 0.3159(0.3159)
2023/09/18 04:08:50 - INFO - root -   Epoch: [149/400][20/346], lr: 0.00000031 	 loss = 0.0644(0.3331)
2023/09/18 04:09:52 - INFO - root -   Epoch: [149/400][40/346], lr: 0.00000031 	 loss = 0.1932(0.3426)
2023/09/18 04:10:35 - INFO - root -   Epoch: [149/400][60/346], lr: 0.00000031 	 loss = 0.3675(0.3239)
2023/09/18 04:11:37 - INFO - root -   Epoch: [149/400][80/346], lr: 0.00000031 	 loss = 0.1984(0.3708)
2023/09/18 04:12:20 - INFO - root -   Epoch: [149/400][100/346], lr: 0.00000031 	 loss = 0.7482(0.3645)
2023/09/18 04:13:22 - INFO - root -   Epoch: [149/400][120/346], lr: 0.00000031 	 loss = 0.1757(0.3883)
2023/09/18 04:14:05 - INFO - root -   Epoch: [149/400][140/346], lr: 0.00000031 	 loss = 0.2417(0.3775)
2023/09/18 04:15:06 - INFO - root -   Epoch: [149/400][160/346], lr: 0.00000031 	 loss = 0.0568(0.3857)
2023/09/18 04:15:50 - INFO - root -   Epoch: [149/400][180/346], lr: 0.00000031 	 loss = 0.1487(0.3916)
2023/09/18 04:16:51 - INFO - root -   Epoch: [149/400][200/346], lr: 0.00000031 	 loss = 0.0127(0.3839)
2023/09/18 04:17:35 - INFO - root -   Epoch: [149/400][220/346], lr: 0.00000031 	 loss = 0.2363(0.3897)
2023/09/18 04:18:36 - INFO - root -   Epoch: [149/400][240/346], lr: 0.00000031 	 loss = 0.0446(0.3873)
2023/09/18 04:19:20 - INFO - root -   Epoch: [149/400][260/346], lr: 0.00000031 	 loss = 0.9476(0.3836)
2023/09/18 04:20:21 - INFO - root -   Epoch: [149/400][280/346], lr: 0.00000031 	 loss = 0.2096(0.4066)
2023/09/18 04:21:04 - INFO - root -   Epoch: [149/400][300/346], lr: 0.00000031 	 loss = 0.1612(0.4013)
2023/09/18 04:22:06 - INFO - root -   Epoch: [149/400][320/346], lr: 0.00000031 	 loss = 0.1191(0.4056)
2023/09/18 04:22:48 - INFO - root -   Epoch: [149/400][340/346], lr: 0.00000031 	 loss = 0.7115(0.4025)
2023/09/18 04:22:52 - INFO - root -   Epoch: [149/400] 	 loss = 0.4031
2023/09/18 04:26:39 - INFO - root -   precision = 0.7184
2023/09/18 04:26:39 - INFO - root -   eval_loss = 0.6214
2023/09/18 04:26:40 - INFO - root -   train_accuracy = 0.8107
2023/09/18 04:27:02 - INFO - root -   Epoch: [150/400][0/346], lr: 0.00000031 	 loss = 0.4751(0.4751)
2023/09/18 04:27:45 - INFO - root -   Epoch: [150/400][20/346], lr: 0.00000031 	 loss = 0.0089(0.3373)
2023/09/18 04:28:46 - INFO - root -   Epoch: [150/400][40/346], lr: 0.00000031 	 loss = 0.3725(0.3796)
2023/09/18 04:29:29 - INFO - root -   Epoch: [150/400][60/346], lr: 0.00000031 	 loss = 0.4425(0.3617)
2023/09/18 04:30:30 - INFO - root -   Epoch: [150/400][80/346], lr: 0.00000031 	 loss = 0.1067(0.3818)
2023/09/18 04:31:13 - INFO - root -   Epoch: [150/400][100/346], lr: 0.00000031 	 loss = 0.5027(0.3771)
2023/09/18 04:32:14 - INFO - root -   Epoch: [150/400][120/346], lr: 0.00000031 	 loss = 0.1874(0.3808)
2023/09/18 04:32:57 - INFO - root -   Epoch: [150/400][140/346], lr: 0.00000031 	 loss = 0.1897(0.3774)
2023/09/18 04:33:58 - INFO - root -   Epoch: [150/400][160/346], lr: 0.00000031 	 loss = 0.0850(0.3925)
2023/09/18 04:34:41 - INFO - root -   Epoch: [150/400][180/346], lr: 0.00000031 	 loss = 0.0494(0.3931)
2023/09/18 04:35:42 - INFO - root -   Epoch: [150/400][200/346], lr: 0.00000031 	 loss = 0.0355(0.3814)
2023/09/18 04:36:25 - INFO - root -   Epoch: [150/400][220/346], lr: 0.00000031 	 loss = 0.2363(0.3861)
2023/09/18 04:37:26 - INFO - root -   Epoch: [150/400][240/346], lr: 0.00000031 	 loss = 0.1163(0.3832)
2023/09/18 04:38:09 - INFO - root -   Epoch: [150/400][260/346], lr: 0.00000031 	 loss = 0.1826(0.3770)
2023/09/18 04:39:10 - INFO - root -   Epoch: [150/400][280/346], lr: 0.00000031 	 loss = 0.0453(0.3800)
2023/09/18 04:39:53 - INFO - root -   Epoch: [150/400][300/346], lr: 0.00000031 	 loss = 0.1529(0.3757)
2023/09/18 04:40:53 - INFO - root -   Epoch: [150/400][320/346], lr: 0.00000031 	 loss = 0.0403(0.3779)
2023/09/18 04:41:35 - INFO - root -   Epoch: [150/400][340/346], lr: 0.00000031 	 loss = 0.3185(0.3772)
2023/09/18 04:41:39 - INFO - root -   Epoch: [150/400] 	 loss = 0.3803
2023/09/18 04:41:39 - INFO - root -   train_accuracy = 0.8223
2023/09/18 04:42:01 - INFO - root -   Epoch: [151/400][0/346], lr: 0.00000032 	 loss = 0.1871(0.1871)
2023/09/18 04:42:43 - INFO - root -   Epoch: [151/400][20/346], lr: 0.00000032 	 loss = 0.0221(0.3141)
2023/09/18 04:43:44 - INFO - root -   Epoch: [151/400][40/346], lr: 0.00000032 	 loss = 0.2818(0.3568)
2023/09/18 04:44:27 - INFO - root -   Epoch: [151/400][60/346], lr: 0.00000032 	 loss = 0.3825(0.3316)
2023/09/18 04:45:28 - INFO - root -   Epoch: [151/400][80/346], lr: 0.00000032 	 loss = 0.1065(0.3449)
2023/09/18 04:46:10 - INFO - root -   Epoch: [151/400][100/346], lr: 0.00000032 	 loss = 0.7463(0.3400)
2023/09/18 04:47:11 - INFO - root -   Epoch: [151/400][120/346], lr: 0.00000032 	 loss = 0.0689(0.3569)
2023/09/18 04:47:54 - INFO - root -   Epoch: [151/400][140/346], lr: 0.00000032 	 loss = 0.3013(0.3635)
2023/09/18 04:48:54 - INFO - root -   Epoch: [151/400][160/346], lr: 0.00000032 	 loss = 0.0724(0.3894)
2023/09/18 04:49:38 - INFO - root -   Epoch: [151/400][180/346], lr: 0.00000032 	 loss = 0.0411(0.3926)
2023/09/18 04:50:37 - INFO - root -   Epoch: [151/400][200/346], lr: 0.00000032 	 loss = 0.1058(0.3885)
2023/09/18 04:51:22 - INFO - root -   Epoch: [151/400][220/346], lr: 0.00000032 	 loss = 0.2885(0.3971)
2023/09/18 04:52:21 - INFO - root -   Epoch: [151/400][240/346], lr: 0.00000032 	 loss = 0.1316(0.3956)
2023/09/18 04:53:05 - INFO - root -   Epoch: [151/400][260/346], lr: 0.00000032 	 loss = 0.4864(0.3949)
2023/09/18 04:54:04 - INFO - root -   Epoch: [151/400][280/346], lr: 0.00000032 	 loss = 0.1108(0.4057)
2023/09/18 04:54:49 - INFO - root -   Epoch: [151/400][300/346], lr: 0.00000032 	 loss = 0.0764(0.3989)
2023/09/18 04:55:47 - INFO - root -   Epoch: [151/400][320/346], lr: 0.00000032 	 loss = 0.0474(0.3957)
2023/09/18 04:56:31 - INFO - root -   Epoch: [151/400][340/346], lr: 0.00000032 	 loss = 0.2435(0.3954)
2023/09/18 04:56:35 - INFO - root -   Epoch: [151/400] 	 loss = 0.3985
2023/09/18 04:56:35 - INFO - root -   train_accuracy = 0.8092
2023/09/18 04:56:57 - INFO - root -   Epoch: [152/400][0/346], lr: 0.00000032 	 loss = 0.5311(0.5311)
2023/09/18 04:57:40 - INFO - root -   Epoch: [152/400][20/346], lr: 0.00000032 	 loss = 0.0601(0.3204)
2023/09/18 04:58:42 - INFO - root -   Epoch: [152/400][40/346], lr: 0.00000032 	 loss = 0.2296(0.3461)
2023/09/18 04:59:26 - INFO - root -   Epoch: [152/400][60/346], lr: 0.00000032 	 loss = 0.1720(0.2928)
2023/09/18 05:00:27 - INFO - root -   Epoch: [152/400][80/346], lr: 0.00000032 	 loss = 0.0588(0.3348)
2023/09/18 05:01:11 - INFO - root -   Epoch: [152/400][100/346], lr: 0.00000032 	 loss = 0.6669(0.3342)
2023/09/18 05:02:13 - INFO - root -   Epoch: [152/400][120/346], lr: 0.00000032 	 loss = 0.2974(0.3512)
2023/09/18 05:02:56 - INFO - root -   Epoch: [152/400][140/346], lr: 0.00000032 	 loss = 0.1967(0.3492)
2023/09/18 05:03:57 - INFO - root -   Epoch: [152/400][160/346], lr: 0.00000032 	 loss = 0.0784(0.3572)
2023/09/18 05:04:41 - INFO - root -   Epoch: [152/400][180/346], lr: 0.00000032 	 loss = 1.5174(0.3778)
2023/09/18 05:05:42 - INFO - root -   Epoch: [152/400][200/346], lr: 0.00000032 	 loss = 0.0457(0.3657)
2023/09/18 05:06:26 - INFO - root -   Epoch: [152/400][220/346], lr: 0.00000032 	 loss = 0.4247(0.3755)
2023/09/18 05:07:27 - INFO - root -   Epoch: [152/400][240/346], lr: 0.00000032 	 loss = 0.1902(0.3748)
2023/09/18 05:08:11 - INFO - root -   Epoch: [152/400][260/346], lr: 0.00000032 	 loss = 1.6623(0.3748)
2023/09/18 05:09:11 - INFO - root -   Epoch: [152/400][280/346], lr: 0.00000032 	 loss = 0.0671(0.3809)
2023/09/18 05:09:56 - INFO - root -   Epoch: [152/400][300/346], lr: 0.00000032 	 loss = 0.1711(0.3784)
2023/09/18 05:10:56 - INFO - root -   Epoch: [152/400][320/346], lr: 0.00000032 	 loss = 0.2307(0.3856)
2023/09/18 05:11:39 - INFO - root -   Epoch: [152/400][340/346], lr: 0.00000032 	 loss = 0.5782(0.3869)
2023/09/18 05:11:43 - INFO - root -   Epoch: [152/400] 	 loss = 0.3883
2023/09/18 05:11:43 - INFO - root -   train_accuracy = 0.8237
2023/09/18 05:12:05 - INFO - root -   Epoch: [153/400][0/346], lr: 0.00000032 	 loss = 0.4232(0.4232)
2023/09/18 05:12:47 - INFO - root -   Epoch: [153/400][20/346], lr: 0.00000032 	 loss = 0.0272(0.3320)
2023/09/18 05:13:48 - INFO - root -   Epoch: [153/400][40/346], lr: 0.00000032 	 loss = 0.2667(0.3213)
2023/09/18 05:14:31 - INFO - root -   Epoch: [153/400][60/346], lr: 0.00000032 	 loss = 0.2054(0.2985)
2023/09/18 05:15:31 - INFO - root -   Epoch: [153/400][80/346], lr: 0.00000032 	 loss = 0.0654(0.3011)
2023/09/18 05:16:14 - INFO - root -   Epoch: [153/400][100/346], lr: 0.00000032 	 loss = 0.3929(0.3202)
2023/09/18 05:17:14 - INFO - root -   Epoch: [153/400][120/346], lr: 0.00000032 	 loss = 0.4424(0.3592)
2023/09/18 05:17:58 - INFO - root -   Epoch: [153/400][140/346], lr: 0.00000032 	 loss = 0.2376(0.3583)
2023/09/18 05:18:58 - INFO - root -   Epoch: [153/400][160/346], lr: 0.00000032 	 loss = 0.0610(0.3785)
2023/09/18 05:19:41 - INFO - root -   Epoch: [153/400][180/346], lr: 0.00000032 	 loss = 0.7445(0.4089)
2023/09/18 05:20:41 - INFO - root -   Epoch: [153/400][200/346], lr: 0.00000032 	 loss = 0.1343(0.4063)
2023/09/18 05:21:25 - INFO - root -   Epoch: [153/400][220/346], lr: 0.00000032 	 loss = 0.1991(0.4108)
2023/09/18 05:22:24 - INFO - root -   Epoch: [153/400][240/346], lr: 0.00000032 	 loss = 0.0362(0.4147)
2023/09/18 05:23:08 - INFO - root -   Epoch: [153/400][260/346], lr: 0.00000032 	 loss = 0.1387(0.4104)
2023/09/18 05:24:07 - INFO - root -   Epoch: [153/400][280/346], lr: 0.00000032 	 loss = 0.1237(0.4229)
2023/09/18 05:24:52 - INFO - root -   Epoch: [153/400][300/346], lr: 0.00000032 	 loss = 0.2083(0.4241)
2023/09/18 05:25:50 - INFO - root -   Epoch: [153/400][320/346], lr: 0.00000032 	 loss = 0.0430(0.4209)
2023/09/18 05:26:34 - INFO - root -   Epoch: [153/400][340/346], lr: 0.00000032 	 loss = 0.8091(0.4206)
2023/09/18 05:26:38 - INFO - root -   Epoch: [153/400] 	 loss = 0.4244
2023/09/18 05:26:38 - INFO - root -   train_accuracy = 0.8006
2023/09/18 05:26:59 - INFO - root -   Epoch: [154/400][0/346], lr: 0.00000032 	 loss = 0.1406(0.1406)
2023/09/18 05:27:42 - INFO - root -   Epoch: [154/400][20/346], lr: 0.00000032 	 loss = 0.0270(0.3378)
2023/09/18 05:28:43 - INFO - root -   Epoch: [154/400][40/346], lr: 0.00000032 	 loss = 0.3058(0.3410)
2023/09/18 05:29:27 - INFO - root -   Epoch: [154/400][60/346], lr: 0.00000032 	 loss = 0.1197(0.3199)
2023/09/18 05:30:27 - INFO - root -   Epoch: [154/400][80/346], lr: 0.00000032 	 loss = 0.1130(0.3521)
2023/09/18 05:31:10 - INFO - root -   Epoch: [154/400][100/346], lr: 0.00000032 	 loss = 0.4941(0.3575)
2023/09/18 05:32:11 - INFO - root -   Epoch: [154/400][120/346], lr: 0.00000032 	 loss = 0.0271(0.3701)
2023/09/18 05:32:54 - INFO - root -   Epoch: [154/400][140/346], lr: 0.00000032 	 loss = 0.2252(0.3715)
2023/09/18 05:33:55 - INFO - root -   Epoch: [154/400][160/346], lr: 0.00000032 	 loss = 0.1191(0.3724)
2023/09/18 05:34:38 - INFO - root -   Epoch: [154/400][180/346], lr: 0.00000032 	 loss = 0.0383(0.3769)
2023/09/18 05:35:38 - INFO - root -   Epoch: [154/400][200/346], lr: 0.00000032 	 loss = 0.0376(0.3739)
2023/09/18 05:36:22 - INFO - root -   Epoch: [154/400][220/346], lr: 0.00000032 	 loss = 0.3404(0.3814)
2023/09/18 05:37:22 - INFO - root -   Epoch: [154/400][240/346], lr: 0.00000032 	 loss = 0.1171(0.3804)
2023/09/18 05:38:06 - INFO - root -   Epoch: [154/400][260/346], lr: 0.00000032 	 loss = 0.5397(0.3745)
2023/09/18 05:39:06 - INFO - root -   Epoch: [154/400][280/346], lr: 0.00000032 	 loss = 0.0969(0.3846)
2023/09/18 05:39:50 - INFO - root -   Epoch: [154/400][300/346], lr: 0.00000032 	 loss = 0.2267(0.3888)
2023/09/18 05:40:49 - INFO - root -   Epoch: [154/400][320/346], lr: 0.00000032 	 loss = 0.0490(0.3914)
2023/09/18 05:41:32 - INFO - root -   Epoch: [154/400][340/346], lr: 0.00000032 	 loss = 0.4312(0.3934)
2023/09/18 05:41:36 - INFO - root -   Epoch: [154/400] 	 loss = 0.3939
2023/09/18 05:45:24 - INFO - root -   precision = 0.6897
2023/09/18 05:45:24 - INFO - root -   eval_loss = 0.7257
2023/09/18 05:45:25 - INFO - root -   train_accuracy = 0.8237
2023/09/18 05:45:47 - INFO - root -   Epoch: [155/400][0/346], lr: 0.00000032 	 loss = 0.1563(0.1563)
2023/09/18 05:46:29 - INFO - root -   Epoch: [155/400][20/346], lr: 0.00000032 	 loss = 0.0202(0.3561)
2023/09/18 05:47:30 - INFO - root -   Epoch: [155/400][40/346], lr: 0.00000032 	 loss = 0.4397(0.3840)
2023/09/18 05:48:13 - INFO - root -   Epoch: [155/400][60/346], lr: 0.00000032 	 loss = 0.3032(0.3388)
2023/09/18 05:49:13 - INFO - root -   Epoch: [155/400][80/346], lr: 0.00000032 	 loss = 0.1567(0.3436)
2023/09/18 05:49:56 - INFO - root -   Epoch: [155/400][100/346], lr: 0.00000032 	 loss = 0.8382(0.3402)
2023/09/18 05:50:56 - INFO - root -   Epoch: [155/400][120/346], lr: 0.00000032 	 loss = 0.0675(0.3527)
2023/09/18 05:51:39 - INFO - root -   Epoch: [155/400][140/346], lr: 0.00000032 	 loss = 0.7909(0.3590)
2023/09/18 05:52:39 - INFO - root -   Epoch: [155/400][160/346], lr: 0.00000032 	 loss = 0.0620(0.3633)
2023/09/18 05:53:22 - INFO - root -   Epoch: [155/400][180/346], lr: 0.00000032 	 loss = 0.1063(0.3569)
2023/09/18 05:54:22 - INFO - root -   Epoch: [155/400][200/346], lr: 0.00000032 	 loss = 0.0285(0.3468)
2023/09/18 05:55:05 - INFO - root -   Epoch: [155/400][220/346], lr: 0.00000032 	 loss = 0.4397(0.3634)
2023/09/18 05:56:05 - INFO - root -   Epoch: [155/400][240/346], lr: 0.00000032 	 loss = 0.0235(0.3642)
2023/09/18 05:56:48 - INFO - root -   Epoch: [155/400][260/346], lr: 0.00000032 	 loss = 0.2007(0.3582)
2023/09/18 05:57:48 - INFO - root -   Epoch: [155/400][280/346], lr: 0.00000032 	 loss = 0.0643(0.3697)
2023/09/18 05:58:31 - INFO - root -   Epoch: [155/400][300/346], lr: 0.00000032 	 loss = 0.1645(0.3744)
2023/09/18 05:59:31 - INFO - root -   Epoch: [155/400][320/346], lr: 0.00000032 	 loss = 0.0210(0.3720)
2023/09/18 06:00:13 - INFO - root -   Epoch: [155/400][340/346], lr: 0.00000032 	 loss = 0.5867(0.3758)
2023/09/18 06:00:17 - INFO - root -   Epoch: [155/400] 	 loss = 0.3818
2023/09/18 06:00:17 - INFO - root -   train_accuracy = 0.8280
2023/09/18 06:00:39 - INFO - root -   Epoch: [156/400][0/346], lr: 0.00000032 	 loss = 0.4781(0.4781)
2023/09/18 06:01:22 - INFO - root -   Epoch: [156/400][20/346], lr: 0.00000032 	 loss = 0.0457(0.3665)
2023/09/18 06:02:23 - INFO - root -   Epoch: [156/400][40/346], lr: 0.00000032 	 loss = 0.6995(0.4138)
2023/09/18 06:03:06 - INFO - root -   Epoch: [156/400][60/346], lr: 0.00000032 	 loss = 0.1865(0.3508)
2023/09/18 06:04:07 - INFO - root -   Epoch: [156/400][80/346], lr: 0.00000032 	 loss = 0.3137(0.3743)
2023/09/18 06:04:50 - INFO - root -   Epoch: [156/400][100/346], lr: 0.00000032 	 loss = 0.9832(0.3667)
2023/09/18 06:05:51 - INFO - root -   Epoch: [156/400][120/346], lr: 0.00000032 	 loss = 0.0351(0.3723)
2023/09/18 06:06:35 - INFO - root -   Epoch: [156/400][140/346], lr: 0.00000032 	 loss = 0.6302(0.3790)
2023/09/18 06:07:35 - INFO - root -   Epoch: [156/400][160/346], lr: 0.00000032 	 loss = 0.1763(0.3841)
2023/09/18 06:08:19 - INFO - root -   Epoch: [156/400][180/346], lr: 0.00000032 	 loss = 0.0709(0.3849)
2023/09/18 06:09:19 - INFO - root -   Epoch: [156/400][200/346], lr: 0.00000032 	 loss = 0.0323(0.3731)
2023/09/18 06:10:03 - INFO - root -   Epoch: [156/400][220/346], lr: 0.00000032 	 loss = 0.1458(0.3752)
2023/09/18 06:11:03 - INFO - root -   Epoch: [156/400][240/346], lr: 0.00000032 	 loss = 0.0284(0.3720)
2023/09/18 06:11:46 - INFO - root -   Epoch: [156/400][260/346], lr: 0.00000032 	 loss = 0.1419(0.3672)
2023/09/18 06:12:46 - INFO - root -   Epoch: [156/400][280/346], lr: 0.00000032 	 loss = 0.0481(0.3725)
2023/09/18 06:13:30 - INFO - root -   Epoch: [156/400][300/346], lr: 0.00000032 	 loss = 0.3260(0.3653)
2023/09/18 06:14:29 - INFO - root -   Epoch: [156/400][320/346], lr: 0.00000032 	 loss = 0.0249(0.3646)
2023/09/18 06:15:13 - INFO - root -   Epoch: [156/400][340/346], lr: 0.00000032 	 loss = 0.5457(0.3681)
2023/09/18 06:15:17 - INFO - root -   Epoch: [156/400] 	 loss = 0.3737
2023/09/18 06:15:17 - INFO - root -   train_accuracy = 0.8324
2023/09/18 06:15:38 - INFO - root -   Epoch: [157/400][0/346], lr: 0.00000032 	 loss = 0.7513(0.7513)
2023/09/18 06:16:21 - INFO - root -   Epoch: [157/400][20/346], lr: 0.00000032 	 loss = 0.0774(0.3693)
2023/09/18 06:17:22 - INFO - root -   Epoch: [157/400][40/346], lr: 0.00000032 	 loss = 0.5591(0.3945)
2023/09/18 06:18:05 - INFO - root -   Epoch: [157/400][60/346], lr: 0.00000032 	 loss = 0.4442(0.3563)
2023/09/18 06:19:05 - INFO - root -   Epoch: [157/400][80/346], lr: 0.00000032 	 loss = 0.0724(0.3798)
2023/09/18 06:19:48 - INFO - root -   Epoch: [157/400][100/346], lr: 0.00000032 	 loss = 1.0436(0.3713)
2023/09/18 06:20:48 - INFO - root -   Epoch: [157/400][120/346], lr: 0.00000032 	 loss = 0.1065(0.3694)
2023/09/18 06:21:31 - INFO - root -   Epoch: [157/400][140/346], lr: 0.00000032 	 loss = 0.1674(0.3650)
2023/09/18 06:22:31 - INFO - root -   Epoch: [157/400][160/346], lr: 0.00000032 	 loss = 0.0985(0.3782)
2023/09/18 06:23:14 - INFO - root -   Epoch: [157/400][180/346], lr: 0.00000032 	 loss = 0.3840(0.3839)
2023/09/18 06:24:15 - INFO - root -   Epoch: [157/400][200/346], lr: 0.00000032 	 loss = 0.0358(0.3781)
2023/09/18 06:24:57 - INFO - root -   Epoch: [157/400][220/346], lr: 0.00000032 	 loss = 0.3526(0.3813)
2023/09/18 06:25:58 - INFO - root -   Epoch: [157/400][240/346], lr: 0.00000032 	 loss = 0.0340(0.3804)
2023/09/18 06:26:40 - INFO - root -   Epoch: [157/400][260/346], lr: 0.00000032 	 loss = 0.8324(0.3875)
2023/09/18 06:27:40 - INFO - root -   Epoch: [157/400][280/346], lr: 0.00000032 	 loss = 0.0667(0.3933)
2023/09/18 06:28:23 - INFO - root -   Epoch: [157/400][300/346], lr: 0.00000032 	 loss = 0.2067(0.3939)
2023/09/18 06:29:23 - INFO - root -   Epoch: [157/400][320/346], lr: 0.00000032 	 loss = 0.0766(0.3946)
2023/09/18 06:30:06 - INFO - root -   Epoch: [157/400][340/346], lr: 0.00000032 	 loss = 0.3998(0.3991)
2023/09/18 06:30:10 - INFO - root -   Epoch: [157/400] 	 loss = 0.4021
2023/09/18 06:30:10 - INFO - root -   train_accuracy = 0.8251
2023/09/18 06:30:31 - INFO - root -   Epoch: [158/400][0/346], lr: 0.00000033 	 loss = 0.5212(0.5212)
2023/09/18 06:31:14 - INFO - root -   Epoch: [158/400][20/346], lr: 0.00000033 	 loss = 0.0152(0.2987)
2023/09/18 06:32:15 - INFO - root -   Epoch: [158/400][40/346], lr: 0.00000033 	 loss = 0.2421(0.3302)
2023/09/18 06:32:58 - INFO - root -   Epoch: [158/400][60/346], lr: 0.00000033 	 loss = 0.2268(0.3081)
2023/09/18 06:33:58 - INFO - root -   Epoch: [158/400][80/346], lr: 0.00000033 	 loss = 0.0585(0.3234)
2023/09/18 06:34:41 - INFO - root -   Epoch: [158/400][100/346], lr: 0.00000033 	 loss = 0.7601(0.3441)
2023/09/18 06:35:42 - INFO - root -   Epoch: [158/400][120/346], lr: 0.00000033 	 loss = 0.0989(0.3540)
2023/09/18 06:36:25 - INFO - root -   Epoch: [158/400][140/346], lr: 0.00000033 	 loss = 0.4234(0.3566)
2023/09/18 06:37:25 - INFO - root -   Epoch: [158/400][160/346], lr: 0.00000033 	 loss = 0.0890(0.3615)
2023/09/18 06:38:08 - INFO - root -   Epoch: [158/400][180/346], lr: 0.00000033 	 loss = 0.3563(0.3662)
2023/09/18 06:39:09 - INFO - root -   Epoch: [158/400][200/346], lr: 0.00000033 	 loss = 0.0318(0.3519)
2023/09/18 06:39:52 - INFO - root -   Epoch: [158/400][220/346], lr: 0.00000033 	 loss = 0.1953(0.3502)
2023/09/18 06:40:52 - INFO - root -   Epoch: [158/400][240/346], lr: 0.00000033 	 loss = 0.1060(0.3483)
2023/09/18 06:41:36 - INFO - root -   Epoch: [158/400][260/346], lr: 0.00000033 	 loss = 0.7300(0.3397)
2023/09/18 06:42:36 - INFO - root -   Epoch: [158/400][280/346], lr: 0.00000033 	 loss = 0.2893(0.3616)
2023/09/18 06:43:20 - INFO - root -   Epoch: [158/400][300/346], lr: 0.00000033 	 loss = 0.3422(0.3610)
2023/09/18 06:44:19 - INFO - root -   Epoch: [158/400][320/346], lr: 0.00000033 	 loss = 0.1091(0.3621)
2023/09/18 06:45:02 - INFO - root -   Epoch: [158/400][340/346], lr: 0.00000033 	 loss = 0.6534(0.3604)
2023/09/18 06:45:06 - INFO - root -   Epoch: [158/400] 	 loss = 0.3623
2023/09/18 06:45:06 - INFO - root -   train_accuracy = 0.8367
2023/09/18 06:45:28 - INFO - root -   Epoch: [159/400][0/346], lr: 0.00000033 	 loss = 0.2016(0.2016)
2023/09/18 06:46:11 - INFO - root -   Epoch: [159/400][20/346], lr: 0.00000033 	 loss = 0.0713(0.2900)
2023/09/18 06:47:12 - INFO - root -   Epoch: [159/400][40/346], lr: 0.00000033 	 loss = 0.8171(0.3287)
2023/09/18 06:47:55 - INFO - root -   Epoch: [159/400][60/346], lr: 0.00000033 	 loss = 0.4455(0.3412)
2023/09/18 06:48:55 - INFO - root -   Epoch: [159/400][80/346], lr: 0.00000033 	 loss = 0.0248(0.3600)
2023/09/18 06:49:39 - INFO - root -   Epoch: [159/400][100/346], lr: 0.00000033 	 loss = 1.2284(0.3734)
2023/09/18 06:50:39 - INFO - root -   Epoch: [159/400][120/346], lr: 0.00000033 	 loss = 0.0237(0.3912)
2023/09/18 06:51:22 - INFO - root -   Epoch: [159/400][140/346], lr: 0.00000033 	 loss = 0.3460(0.3749)
2023/09/18 06:52:23 - INFO - root -   Epoch: [159/400][160/346], lr: 0.00000033 	 loss = 0.1815(0.3806)
2023/09/18 06:53:06 - INFO - root -   Epoch: [159/400][180/346], lr: 0.00000033 	 loss = 0.0939(0.3698)
2023/09/18 06:54:06 - INFO - root -   Epoch: [159/400][200/346], lr: 0.00000033 	 loss = 0.0698(0.3538)
2023/09/18 06:54:49 - INFO - root -   Epoch: [159/400][220/346], lr: 0.00000033 	 loss = 0.3309(0.3602)
2023/09/18 06:55:50 - INFO - root -   Epoch: [159/400][240/346], lr: 0.00000033 	 loss = 0.0304(0.3564)
2023/09/18 06:56:33 - INFO - root -   Epoch: [159/400][260/346], lr: 0.00000033 	 loss = 1.3356(0.3587)
2023/09/18 06:57:34 - INFO - root -   Epoch: [159/400][280/346], lr: 0.00000033 	 loss = 0.1697(0.3836)
2023/09/18 06:58:17 - INFO - root -   Epoch: [159/400][300/346], lr: 0.00000033 	 loss = 0.2614(0.3824)
2023/09/18 06:59:17 - INFO - root -   Epoch: [159/400][320/346], lr: 0.00000033 	 loss = 0.1179(0.3837)
2023/09/18 07:00:00 - INFO - root -   Epoch: [159/400][340/346], lr: 0.00000033 	 loss = 0.2986(0.3826)
2023/09/18 07:00:04 - INFO - root -   Epoch: [159/400] 	 loss = 0.3935
2023/09/18 07:03:51 - INFO - root -   precision = 0.6782
2023/09/18 07:03:51 - INFO - root -   eval_loss = 0.6854
2023/09/18 07:03:52 - INFO - root -   train_accuracy = 0.8223
2023/09/18 07:04:14 - INFO - root -   Epoch: [160/400][0/346], lr: 0.00000033 	 loss = 1.1339(1.1339)
2023/09/18 07:04:57 - INFO - root -   Epoch: [160/400][20/346], lr: 0.00000033 	 loss = 0.3299(0.3710)
2023/09/18 07:05:58 - INFO - root -   Epoch: [160/400][40/346], lr: 0.00000033 	 loss = 0.8484(0.3900)
2023/09/18 07:06:41 - INFO - root -   Epoch: [160/400][60/346], lr: 0.00000033 	 loss = 0.2750(0.3470)
2023/09/18 07:07:42 - INFO - root -   Epoch: [160/400][80/346], lr: 0.00000033 	 loss = 0.1478(0.3931)
2023/09/18 07:08:25 - INFO - root -   Epoch: [160/400][100/346], lr: 0.00000033 	 loss = 0.3335(0.4233)
2023/09/18 07:09:25 - INFO - root -   Epoch: [160/400][120/346], lr: 0.00000033 	 loss = 0.0417(0.4445)
2023/09/18 07:10:08 - INFO - root -   Epoch: [160/400][140/346], lr: 0.00000033 	 loss = 0.2607(0.4309)
2023/09/18 07:11:09 - INFO - root -   Epoch: [160/400][160/346], lr: 0.00000033 	 loss = 0.0710(0.4307)
2023/09/18 07:11:52 - INFO - root -   Epoch: [160/400][180/346], lr: 0.00000033 	 loss = 0.0572(0.4238)
2023/09/18 07:12:52 - INFO - root -   Epoch: [160/400][200/346], lr: 0.00000033 	 loss = 0.0191(0.4202)
2023/09/18 07:13:35 - INFO - root -   Epoch: [160/400][220/346], lr: 0.00000033 	 loss = 0.3682(0.4180)
2023/09/18 07:14:35 - INFO - root -   Epoch: [160/400][240/346], lr: 0.00000033 	 loss = 0.0606(0.4126)
2023/09/18 07:15:19 - INFO - root -   Epoch: [160/400][260/346], lr: 0.00000033 	 loss = 0.1854(0.4002)
2023/09/18 07:16:19 - INFO - root -   Epoch: [160/400][280/346], lr: 0.00000033 	 loss = 0.0314(0.4090)
2023/09/18 07:17:02 - INFO - root -   Epoch: [160/400][300/346], lr: 0.00000033 	 loss = 0.1533(0.3985)
2023/09/18 07:18:03 - INFO - root -   Epoch: [160/400][320/346], lr: 0.00000033 	 loss = 0.0803(0.3963)
2023/09/18 07:18:44 - INFO - root -   Epoch: [160/400][340/346], lr: 0.00000033 	 loss = 0.3253(0.3942)
2023/09/18 07:18:48 - INFO - root -   Epoch: [160/400] 	 loss = 0.3974
2023/09/18 07:18:48 - INFO - root -   train_accuracy = 0.8179
2023/09/18 07:19:10 - INFO - root -   Epoch: [161/400][0/346], lr: 0.00000033 	 loss = 0.3611(0.3611)
2023/09/18 07:19:54 - INFO - root -   Epoch: [161/400][20/346], lr: 0.00000033 	 loss = 0.0308(0.2540)
2023/09/18 07:20:58 - INFO - root -   Epoch: [161/400][40/346], lr: 0.00000033 	 loss = 0.7781(0.2937)
2023/09/18 07:21:45 - INFO - root -   Epoch: [161/400][60/346], lr: 0.00000033 	 loss = 0.3873(0.2790)
2023/09/18 07:22:51 - INFO - root -   Epoch: [161/400][80/346], lr: 0.00000033 	 loss = 0.0990(0.3110)
2023/09/18 07:23:38 - INFO - root -   Epoch: [161/400][100/346], lr: 0.00000033 	 loss = 0.9572(0.3309)
2023/09/18 07:24:44 - INFO - root -   Epoch: [161/400][120/346], lr: 0.00000033 	 loss = 0.1227(0.3831)
2023/09/18 07:25:31 - INFO - root -   Epoch: [161/400][140/346], lr: 0.00000033 	 loss = 0.4468(0.3720)
2023/09/18 07:26:36 - INFO - root -   Epoch: [161/400][160/346], lr: 0.00000033 	 loss = 0.1135(0.3653)
2023/09/18 07:27:24 - INFO - root -   Epoch: [161/400][180/346], lr: 0.00000033 	 loss = 0.1589(0.3609)
2023/09/18 07:28:29 - INFO - root -   Epoch: [161/400][200/346], lr: 0.00000033 	 loss = 0.0467(0.3458)
2023/09/18 07:29:17 - INFO - root -   Epoch: [161/400][220/346], lr: 0.00000033 	 loss = 0.1857(0.3510)
2023/09/18 07:30:21 - INFO - root -   Epoch: [161/400][240/346], lr: 0.00000033 	 loss = 0.0369(0.3486)
2023/09/18 07:31:08 - INFO - root -   Epoch: [161/400][260/346], lr: 0.00000033 	 loss = 0.0702(0.3389)
2023/09/18 07:32:13 - INFO - root -   Epoch: [161/400][280/346], lr: 0.00000033 	 loss = 0.0822(0.3483)
2023/09/18 07:32:59 - INFO - root -   Epoch: [161/400][300/346], lr: 0.00000033 	 loss = 0.3683(0.3513)
2023/09/18 07:34:05 - INFO - root -   Epoch: [161/400][320/346], lr: 0.00000033 	 loss = 0.1607(0.3535)
2023/09/18 07:34:49 - INFO - root -   Epoch: [161/400][340/346], lr: 0.00000033 	 loss = 0.6332(0.3534)
2023/09/18 07:34:54 - INFO - root -   Epoch: [161/400] 	 loss = 0.3556
2023/09/18 07:34:54 - INFO - root -   train_accuracy = 0.8584
2023/09/18 07:35:15 - INFO - root -   Epoch: [162/400][0/346], lr: 0.00000033 	 loss = 0.6111(0.6111)
2023/09/18 07:35:58 - INFO - root -   Epoch: [162/400][20/346], lr: 0.00000033 	 loss = 0.0066(0.2930)
2023/09/18 07:36:59 - INFO - root -   Epoch: [162/400][40/346], lr: 0.00000033 	 loss = 0.3840(0.3668)
2023/09/18 07:37:42 - INFO - root -   Epoch: [162/400][60/346], lr: 0.00000033 	 loss = 0.2404(0.3487)
2023/09/18 07:38:43 - INFO - root -   Epoch: [162/400][80/346], lr: 0.00000033 	 loss = 0.1802(0.3577)
2023/09/18 07:39:26 - INFO - root -   Epoch: [162/400][100/346], lr: 0.00000033 	 loss = 0.5730(0.3535)
2023/09/18 07:40:27 - INFO - root -   Epoch: [162/400][120/346], lr: 0.00000033 	 loss = 0.1171(0.3714)
2023/09/18 07:41:10 - INFO - root -   Epoch: [162/400][140/346], lr: 0.00000033 	 loss = 0.2360(0.3735)
2023/09/18 07:42:11 - INFO - root -   Epoch: [162/400][160/346], lr: 0.00000033 	 loss = 0.0783(0.3751)
2023/09/18 07:42:53 - INFO - root -   Epoch: [162/400][180/346], lr: 0.00000033 	 loss = 0.0700(0.3720)
2023/09/18 07:43:54 - INFO - root -   Epoch: [162/400][200/346], lr: 0.00000033 	 loss = 0.0276(0.3554)
2023/09/18 07:44:37 - INFO - root -   Epoch: [162/400][220/346], lr: 0.00000033 	 loss = 0.1688(0.3614)
2023/09/18 07:45:38 - INFO - root -   Epoch: [162/400][240/346], lr: 0.00000033 	 loss = 0.0183(0.3547)
2023/09/18 07:46:21 - INFO - root -   Epoch: [162/400][260/346], lr: 0.00000033 	 loss = 0.6041(0.3474)
2023/09/18 07:47:21 - INFO - root -   Epoch: [162/400][280/346], lr: 0.00000033 	 loss = 0.1723(0.3550)
2023/09/18 07:48:04 - INFO - root -   Epoch: [162/400][300/346], lr: 0.00000033 	 loss = 0.1424(0.3473)
2023/09/18 07:49:05 - INFO - root -   Epoch: [162/400][320/346], lr: 0.00000033 	 loss = 0.0168(0.3466)
2023/09/18 07:49:46 - INFO - root -   Epoch: [162/400][340/346], lr: 0.00000033 	 loss = 0.1508(0.3443)
2023/09/18 07:49:50 - INFO - root -   Epoch: [162/400] 	 loss = 0.3457
2023/09/18 07:49:50 - INFO - root -   train_accuracy = 0.8468
2023/09/18 07:50:12 - INFO - root -   Epoch: [163/400][0/346], lr: 0.00000033 	 loss = 0.0463(0.0463)
2023/09/18 07:50:55 - INFO - root -   Epoch: [163/400][20/346], lr: 0.00000033 	 loss = 0.0116(0.2748)
2023/09/18 07:51:56 - INFO - root -   Epoch: [163/400][40/346], lr: 0.00000033 	 loss = 0.1496(0.2787)
2023/09/18 07:52:40 - INFO - root -   Epoch: [163/400][60/346], lr: 0.00000033 	 loss = 0.6342(0.3245)
2023/09/18 07:53:41 - INFO - root -   Epoch: [163/400][80/346], lr: 0.00000033 	 loss = 0.0393(0.3698)
2023/09/18 07:54:24 - INFO - root -   Epoch: [163/400][100/346], lr: 0.00000033 	 loss = 0.8034(0.3516)
2023/09/18 07:55:25 - INFO - root -   Epoch: [163/400][120/346], lr: 0.00000033 	 loss = 0.1644(0.3470)
2023/09/18 07:56:08 - INFO - root -   Epoch: [163/400][140/346], lr: 0.00000033 	 loss = 0.2560(0.3380)
2023/09/18 07:57:09 - INFO - root -   Epoch: [163/400][160/346], lr: 0.00000033 	 loss = 0.0537(0.3468)
2023/09/18 07:57:52 - INFO - root -   Epoch: [163/400][180/346], lr: 0.00000033 	 loss = 0.0425(0.3445)
2023/09/18 07:58:53 - INFO - root -   Epoch: [163/400][200/346], lr: 0.00000033 	 loss = 0.0305(0.3331)
2023/09/18 07:59:36 - INFO - root -   Epoch: [163/400][220/346], lr: 0.00000033 	 loss = 0.2416(0.3408)
2023/09/18 08:00:37 - INFO - root -   Epoch: [163/400][240/346], lr: 0.00000033 	 loss = 0.0174(0.3449)
2023/09/18 08:01:20 - INFO - root -   Epoch: [163/400][260/346], lr: 0.00000033 	 loss = 0.3391(0.3438)
2023/09/18 08:02:21 - INFO - root -   Epoch: [163/400][280/346], lr: 0.00000033 	 loss = 0.0543(0.3532)
2023/09/18 08:03:04 - INFO - root -   Epoch: [163/400][300/346], lr: 0.00000033 	 loss = 0.0523(0.3455)
2023/09/18 08:04:05 - INFO - root -   Epoch: [163/400][320/346], lr: 0.00000033 	 loss = 0.0250(0.3415)
2023/09/18 08:04:46 - INFO - root -   Epoch: [163/400][340/346], lr: 0.00000033 	 loss = 0.5639(0.3417)
2023/09/18 08:04:50 - INFO - root -   Epoch: [163/400] 	 loss = 0.3416
2023/09/18 08:04:50 - INFO - root -   train_accuracy = 0.8497
2023/09/18 08:05:12 - INFO - root -   Epoch: [164/400][0/346], lr: 0.00000033 	 loss = 0.2336(0.2336)
2023/09/18 08:05:55 - INFO - root -   Epoch: [164/400][20/346], lr: 0.00000033 	 loss = 0.0150(0.2902)
2023/09/18 08:06:55 - INFO - root -   Epoch: [164/400][40/346], lr: 0.00000033 	 loss = 0.3001(0.3298)
2023/09/18 08:07:38 - INFO - root -   Epoch: [164/400][60/346], lr: 0.00000033 	 loss = 0.0765(0.3342)
2023/09/18 08:08:39 - INFO - root -   Epoch: [164/400][80/346], lr: 0.00000033 	 loss = 0.0418(0.3668)
2023/09/18 08:09:22 - INFO - root -   Epoch: [164/400][100/346], lr: 0.00000033 	 loss = 0.3705(0.3701)
2023/09/18 08:10:23 - INFO - root -   Epoch: [164/400][120/346], lr: 0.00000033 	 loss = 0.0511(0.3858)
2023/09/18 08:11:06 - INFO - root -   Epoch: [164/400][140/346], lr: 0.00000033 	 loss = 0.3473(0.3820)
2023/09/18 08:12:07 - INFO - root -   Epoch: [164/400][160/346], lr: 0.00000033 	 loss = 0.0336(0.3851)
2023/09/18 08:12:50 - INFO - root -   Epoch: [164/400][180/346], lr: 0.00000033 	 loss = 0.0873(0.3781)
2023/09/18 08:13:50 - INFO - root -   Epoch: [164/400][200/346], lr: 0.00000033 	 loss = 0.0236(0.3603)
2023/09/18 08:14:33 - INFO - root -   Epoch: [164/400][220/346], lr: 0.00000033 	 loss = 0.1938(0.3584)
2023/09/18 08:15:34 - INFO - root -   Epoch: [164/400][240/346], lr: 0.00000033 	 loss = 0.0161(0.3541)
2023/09/18 08:16:17 - INFO - root -   Epoch: [164/400][260/346], lr: 0.00000033 	 loss = 1.9305(0.3651)
2023/09/18 08:17:17 - INFO - root -   Epoch: [164/400][280/346], lr: 0.00000033 	 loss = 0.0687(0.3938)
2023/09/18 08:18:00 - INFO - root -   Epoch: [164/400][300/346], lr: 0.00000033 	 loss = 0.0765(0.4050)
2023/09/18 08:19:01 - INFO - root -   Epoch: [164/400][320/346], lr: 0.00000033 	 loss = 0.0107(0.4086)
2023/09/18 08:19:42 - INFO - root -   Epoch: [164/400][340/346], lr: 0.00000033 	 loss = 0.7566(0.4154)
2023/09/18 08:19:46 - INFO - root -   Epoch: [164/400] 	 loss = 0.4181
2023/09/18 08:23:35 - INFO - root -   precision = 0.6839
2023/09/18 08:23:35 - INFO - root -   eval_loss = 0.6499
2023/09/18 08:23:36 - INFO - root -   train_accuracy = 0.8208
2023/09/18 08:23:57 - INFO - root -   Epoch: [165/400][0/346], lr: 0.00000034 	 loss = 0.2686(0.2686)
2023/09/18 08:24:41 - INFO - root -   Epoch: [165/400][20/346], lr: 0.00000034 	 loss = 0.0190(0.3530)
2023/09/18 08:25:44 - INFO - root -   Epoch: [165/400][40/346], lr: 0.00000034 	 loss = 0.1754(0.3812)
2023/09/18 08:26:28 - INFO - root -   Epoch: [165/400][60/346], lr: 0.00000034 	 loss = 0.1829(0.3483)
2023/09/18 08:27:30 - INFO - root -   Epoch: [165/400][80/346], lr: 0.00000034 	 loss = 0.0879(0.3515)
2023/09/18 08:28:14 - INFO - root -   Epoch: [165/400][100/346], lr: 0.00000034 	 loss = 0.2622(0.3465)
2023/09/18 08:29:16 - INFO - root -   Epoch: [165/400][120/346], lr: 0.00000034 	 loss = 0.0299(0.3553)
2023/09/18 08:30:00 - INFO - root -   Epoch: [165/400][140/346], lr: 0.00000034 	 loss = 0.3926(0.3587)
2023/09/18 08:31:02 - INFO - root -   Epoch: [165/400][160/346], lr: 0.00000034 	 loss = 0.0968(0.3653)
2023/09/18 08:31:46 - INFO - root -   Epoch: [165/400][180/346], lr: 0.00000034 	 loss = 0.0634(0.3698)
2023/09/18 08:32:49 - INFO - root -   Epoch: [165/400][200/346], lr: 0.00000034 	 loss = 0.0142(0.3559)
2023/09/18 08:33:33 - INFO - root -   Epoch: [165/400][220/346], lr: 0.00000034 	 loss = 0.2721(0.3621)
2023/09/18 08:34:35 - INFO - root -   Epoch: [165/400][240/346], lr: 0.00000034 	 loss = 0.0572(0.3612)
2023/09/18 08:35:19 - INFO - root -   Epoch: [165/400][260/346], lr: 0.00000034 	 loss = 0.1854(0.3475)
2023/09/18 08:36:21 - INFO - root -   Epoch: [165/400][280/346], lr: 0.00000034 	 loss = 0.1327(0.3567)
2023/09/18 08:37:05 - INFO - root -   Epoch: [165/400][300/346], lr: 0.00000034 	 loss = 0.1839(0.3594)
2023/09/18 08:38:07 - INFO - root -   Epoch: [165/400][320/346], lr: 0.00000034 	 loss = 0.0384(0.3611)
2023/09/18 08:38:48 - INFO - root -   Epoch: [165/400][340/346], lr: 0.00000034 	 loss = 0.5107(0.3605)
2023/09/18 08:38:51 - INFO - root -   Epoch: [165/400] 	 loss = 0.3621
2023/09/18 08:38:51 - INFO - root -   train_accuracy = 0.8425
2023/09/18 08:39:13 - INFO - root -   Epoch: [166/400][0/346], lr: 0.00000034 	 loss = 0.0630(0.0630)
2023/09/18 08:39:56 - INFO - root -   Epoch: [166/400][20/346], lr: 0.00000034 	 loss = 0.0547(0.2496)
2023/09/18 08:40:57 - INFO - root -   Epoch: [166/400][40/346], lr: 0.00000034 	 loss = 0.2912(0.3561)
2023/09/18 08:41:40 - INFO - root -   Epoch: [166/400][60/346], lr: 0.00000034 	 loss = 0.6371(0.3335)
2023/09/18 08:42:41 - INFO - root -   Epoch: [166/400][80/346], lr: 0.00000034 	 loss = 0.0499(0.3555)
2023/09/18 08:43:24 - INFO - root -   Epoch: [166/400][100/346], lr: 0.00000034 	 loss = 0.4270(0.3513)
2023/09/18 08:44:24 - INFO - root -   Epoch: [166/400][120/346], lr: 0.00000034 	 loss = 0.0333(0.3422)
2023/09/18 08:45:07 - INFO - root -   Epoch: [166/400][140/346], lr: 0.00000034 	 loss = 0.4635(0.3425)
2023/09/18 08:46:08 - INFO - root -   Epoch: [166/400][160/346], lr: 0.00000034 	 loss = 0.0736(0.3511)
2023/09/18 08:46:52 - INFO - root -   Epoch: [166/400][180/346], lr: 0.00000034 	 loss = 0.2067(0.3447)
2023/09/18 08:47:52 - INFO - root -   Epoch: [166/400][200/346], lr: 0.00000034 	 loss = 0.0123(0.3286)
2023/09/18 08:48:35 - INFO - root -   Epoch: [166/400][220/346], lr: 0.00000034 	 loss = 0.6001(0.3363)
2023/09/18 08:49:36 - INFO - root -   Epoch: [166/400][240/346], lr: 0.00000034 	 loss = 0.0330(0.3331)
2023/09/18 08:50:19 - INFO - root -   Epoch: [166/400][260/346], lr: 0.00000034 	 loss = 1.1185(0.3272)
2023/09/18 08:51:20 - INFO - root -   Epoch: [166/400][280/346], lr: 0.00000034 	 loss = 0.1128(0.3398)
2023/09/18 08:52:03 - INFO - root -   Epoch: [166/400][300/346], lr: 0.00000034 	 loss = 0.1259(0.3401)
2023/09/18 08:53:03 - INFO - root -   Epoch: [166/400][320/346], lr: 0.00000034 	 loss = 0.0237(0.3409)
2023/09/18 08:53:46 - INFO - root -   Epoch: [166/400][340/346], lr: 0.00000034 	 loss = 1.3147(0.3454)
2023/09/18 08:53:50 - INFO - root -   Epoch: [166/400] 	 loss = 0.3480
2023/09/18 08:53:50 - INFO - root -   train_accuracy = 0.8439
2023/09/18 08:54:11 - INFO - root -   Epoch: [167/400][0/346], lr: 0.00000034 	 loss = 0.0871(0.0871)
2023/09/18 08:54:54 - INFO - root -   Epoch: [167/400][20/346], lr: 0.00000034 	 loss = 0.0631(0.3561)
2023/09/18 08:55:55 - INFO - root -   Epoch: [167/400][40/346], lr: 0.00000034 	 loss = 0.3300(0.3705)
2023/09/18 08:56:38 - INFO - root -   Epoch: [167/400][60/346], lr: 0.00000034 	 loss = 0.0852(0.3315)
2023/09/18 08:57:38 - INFO - root -   Epoch: [167/400][80/346], lr: 0.00000034 	 loss = 0.0240(0.3445)
2023/09/18 08:58:21 - INFO - root -   Epoch: [167/400][100/346], lr: 0.00000034 	 loss = 0.5398(0.3381)
2023/09/18 08:59:21 - INFO - root -   Epoch: [167/400][120/346], lr: 0.00000034 	 loss = 0.0230(0.3449)
2023/09/18 09:00:05 - INFO - root -   Epoch: [167/400][140/346], lr: 0.00000034 	 loss = 0.2440(0.3362)
2023/09/18 09:01:05 - INFO - root -   Epoch: [167/400][160/346], lr: 0.00000034 	 loss = 0.0311(0.3452)
2023/09/18 09:01:49 - INFO - root -   Epoch: [167/400][180/346], lr: 0.00000034 	 loss = 0.0142(0.3449)
2023/09/18 09:02:48 - INFO - root -   Epoch: [167/400][200/346], lr: 0.00000034 	 loss = 0.1474(0.3380)
2023/09/18 09:03:32 - INFO - root -   Epoch: [167/400][220/346], lr: 0.00000034 	 loss = 0.0872(0.3396)
2023/09/18 09:04:32 - INFO - root -   Epoch: [167/400][240/346], lr: 0.00000034 	 loss = 0.0444(0.3381)
2023/09/18 09:05:16 - INFO - root -   Epoch: [167/400][260/346], lr: 0.00000034 	 loss = 0.2404(0.3260)
2023/09/18 09:06:15 - INFO - root -   Epoch: [167/400][280/346], lr: 0.00000034 	 loss = 0.0290(0.3386)
2023/09/18 09:06:59 - INFO - root -   Epoch: [167/400][300/346], lr: 0.00000034 	 loss = 0.3103(0.3441)
2023/09/18 09:07:58 - INFO - root -   Epoch: [167/400][320/346], lr: 0.00000034 	 loss = 0.0499(0.3451)
2023/09/18 09:08:41 - INFO - root -   Epoch: [167/400][340/346], lr: 0.00000034 	 loss = 0.2549(0.3413)
2023/09/18 09:08:45 - INFO - root -   Epoch: [167/400] 	 loss = 0.3432
2023/09/18 09:08:45 - INFO - root -   train_accuracy = 0.8526
2023/09/18 09:09:07 - INFO - root -   Epoch: [168/400][0/346], lr: 0.00000034 	 loss = 0.2803(0.2803)
2023/09/18 09:09:49 - INFO - root -   Epoch: [168/400][20/346], lr: 0.00000034 	 loss = 0.1127(0.3002)
2023/09/18 09:10:50 - INFO - root -   Epoch: [168/400][40/346], lr: 0.00000034 	 loss = 0.1697(0.3286)
2023/09/18 09:11:33 - INFO - root -   Epoch: [168/400][60/346], lr: 0.00000034 	 loss = 1.5585(0.3577)
2023/09/18 09:12:34 - INFO - root -   Epoch: [168/400][80/346], lr: 0.00000034 	 loss = 1.5841(0.5910)
2023/09/18 09:13:17 - INFO - root -   Epoch: [168/400][100/346], lr: 0.00000034 	 loss = 1.1212(0.6491)
2023/09/18 09:14:18 - INFO - root -   Epoch: [168/400][120/346], lr: 0.00000034 	 loss = 0.4877(0.7148)
2023/09/18 09:15:01 - INFO - root -   Epoch: [168/400][140/346], lr: 0.00000034 	 loss = 0.7699(0.6922)
2023/09/18 09:16:01 - INFO - root -   Epoch: [168/400][160/346], lr: 0.00000034 	 loss = 0.0187(0.6725)
2023/09/18 09:16:45 - INFO - root -   Epoch: [168/400][180/346], lr: 0.00000034 	 loss = 0.0743(0.6753)
2023/09/18 09:17:45 - INFO - root -   Epoch: [168/400][200/346], lr: 0.00000034 	 loss = 0.0014(0.6593)
2023/09/18 09:18:28 - INFO - root -   Epoch: [168/400][220/346], lr: 0.00000034 	 loss = 0.0666(0.6545)
2023/09/18 09:19:28 - INFO - root -   Epoch: [168/400][240/346], lr: 0.00000034 	 loss = 0.1457(0.6479)
2023/09/18 09:20:12 - INFO - root -   Epoch: [168/400][260/346], lr: 0.00000034 	 loss = 1.0793(0.6310)
2023/09/18 09:21:12 - INFO - root -   Epoch: [168/400][280/346], lr: 0.00000034 	 loss = 0.0126(0.6278)
2023/09/18 09:21:55 - INFO - root -   Epoch: [168/400][300/346], lr: 0.00000034 	 loss = 0.2095(0.6140)
2023/09/18 09:22:55 - INFO - root -   Epoch: [168/400][320/346], lr: 0.00000034 	 loss = 0.3651(0.6031)
2023/09/18 09:23:38 - INFO - root -   Epoch: [168/400][340/346], lr: 0.00000034 	 loss = 0.9490(0.5913)
2023/09/18 09:23:42 - INFO - root -   Epoch: [168/400] 	 loss = 0.5907
2023/09/18 09:23:42 - INFO - root -   train_accuracy = 0.7240
2023/09/18 09:24:04 - INFO - root -   Epoch: [169/400][0/346], lr: 0.00000034 	 loss = 0.3888(0.3888)
2023/09/18 09:24:46 - INFO - root -   Epoch: [169/400][20/346], lr: 0.00000034 	 loss = 0.0621(0.3723)
2023/09/18 09:25:47 - INFO - root -   Epoch: [169/400][40/346], lr: 0.00000034 	 loss = 0.7605(0.4986)
2023/09/18 09:26:30 - INFO - root -   Epoch: [169/400][60/346], lr: 0.00000034 	 loss = 0.4132(0.4639)
2023/09/18 09:27:31 - INFO - root -   Epoch: [169/400][80/346], lr: 0.00000034 	 loss = 0.3181(0.5080)
2023/09/18 09:28:14 - INFO - root -   Epoch: [169/400][100/346], lr: 0.00000034 	 loss = 0.5546(0.5159)
2023/09/18 09:29:15 - INFO - root -   Epoch: [169/400][120/346], lr: 0.00000034 	 loss = 0.2133(0.5199)
2023/09/18 09:29:58 - INFO - root -   Epoch: [169/400][140/346], lr: 0.00000034 	 loss = 0.1726(0.4975)
2023/09/18 09:30:58 - INFO - root -   Epoch: [169/400][160/346], lr: 0.00000034 	 loss = 0.0461(0.5051)
2023/09/18 09:31:41 - INFO - root -   Epoch: [169/400][180/346], lr: 0.00000034 	 loss = 0.1899(0.5065)
2023/09/18 09:32:42 - INFO - root -   Epoch: [169/400][200/346], lr: 0.00000034 	 loss = 0.0080(0.4826)
2023/09/18 09:33:25 - INFO - root -   Epoch: [169/400][220/346], lr: 0.00000034 	 loss = 0.1267(0.4842)
2023/09/18 09:34:25 - INFO - root -   Epoch: [169/400][240/346], lr: 0.00000034 	 loss = 0.0219(0.4807)
2023/09/18 09:35:09 - INFO - root -   Epoch: [169/400][260/346], lr: 0.00000034 	 loss = 0.8246(0.4667)
2023/09/18 09:36:09 - INFO - root -   Epoch: [169/400][280/346], lr: 0.00000034 	 loss = 0.0682(0.4688)
2023/09/18 09:36:52 - INFO - root -   Epoch: [169/400][300/346], lr: 0.00000034 	 loss = 0.1379(0.4638)
2023/09/18 09:37:52 - INFO - root -   Epoch: [169/400][320/346], lr: 0.00000034 	 loss = 0.0801(0.4609)
2023/09/18 09:38:35 - INFO - root -   Epoch: [169/400][340/346], lr: 0.00000034 	 loss = 0.3807(0.4555)
2023/09/18 09:38:39 - INFO - root -   Epoch: [169/400] 	 loss = 0.4561
2023/09/18 09:42:27 - INFO - root -   precision = 0.7184
2023/09/18 09:42:27 - INFO - root -   eval_loss = 0.6542
2023/09/18 09:42:28 - INFO - root -   train_accuracy = 0.7775
2023/09/18 09:42:49 - INFO - root -   Epoch: [170/400][0/346], lr: 0.00000034 	 loss = 0.4192(0.4192)
2023/09/18 09:43:32 - INFO - root -   Epoch: [170/400][20/346], lr: 0.00000034 	 loss = 0.0422(0.3224)
2023/09/18 09:44:33 - INFO - root -   Epoch: [170/400][40/346], lr: 0.00000034 	 loss = 0.2827(0.3612)
2023/09/18 09:45:16 - INFO - root -   Epoch: [170/400][60/346], lr: 0.00000034 	 loss = 0.2574(0.3216)
2023/09/18 09:46:16 - INFO - root -   Epoch: [170/400][80/346], lr: 0.00000034 	 loss = 0.0688(0.3534)
2023/09/18 09:46:59 - INFO - root -   Epoch: [170/400][100/346], lr: 0.00000034 	 loss = 0.2844(0.3247)
2023/09/18 09:47:59 - INFO - root -   Epoch: [170/400][120/346], lr: 0.00000034 	 loss = 0.0646(0.3400)
2023/09/18 09:48:43 - INFO - root -   Epoch: [170/400][140/346], lr: 0.00000034 	 loss = 1.2608(0.3498)
2023/09/18 09:49:43 - INFO - root -   Epoch: [170/400][160/346], lr: 0.00000034 	 loss = 0.0386(0.3492)
2023/09/18 09:50:26 - INFO - root -   Epoch: [170/400][180/346], lr: 0.00000034 	 loss = 0.0547(0.3480)
2023/09/18 09:51:26 - INFO - root -   Epoch: [170/400][200/346], lr: 0.00000034 	 loss = 0.0342(0.3330)
2023/09/18 09:52:09 - INFO - root -   Epoch: [170/400][220/346], lr: 0.00000034 	 loss = 0.1412(0.3370)
2023/09/18 09:53:09 - INFO - root -   Epoch: [170/400][240/346], lr: 0.00000034 	 loss = 0.0075(0.3383)
2023/09/18 09:53:52 - INFO - root -   Epoch: [170/400][260/346], lr: 0.00000034 	 loss = 0.1848(0.3291)
2023/09/18 09:54:52 - INFO - root -   Epoch: [170/400][280/346], lr: 0.00000034 	 loss = 0.0511(0.3351)
2023/09/18 09:55:36 - INFO - root -   Epoch: [170/400][300/346], lr: 0.00000034 	 loss = 0.1310(0.3320)
2023/09/18 09:56:35 - INFO - root -   Epoch: [170/400][320/346], lr: 0.00000034 	 loss = 0.0396(0.3285)
2023/09/18 09:57:17 - INFO - root -   Epoch: [170/400][340/346], lr: 0.00000034 	 loss = 0.2721(0.3282)
2023/09/18 09:57:21 - INFO - root -   Epoch: [170/400] 	 loss = 0.3317
2023/09/18 09:57:21 - INFO - root -   train_accuracy = 0.8540
2023/09/18 09:57:42 - INFO - root -   Epoch: [171/400][0/346], lr: 0.00000034 	 loss = 0.1269(0.1269)
2023/09/18 09:58:25 - INFO - root -   Epoch: [171/400][20/346], lr: 0.00000034 	 loss = 0.0431(0.2842)
2023/09/18 09:59:26 - INFO - root -   Epoch: [171/400][40/346], lr: 0.00000034 	 loss = 0.1247(0.2927)
2023/09/18 10:00:09 - INFO - root -   Epoch: [171/400][60/346], lr: 0.00000034 	 loss = 0.0801(0.2599)
2023/09/18 10:01:10 - INFO - root -   Epoch: [171/400][80/346], lr: 0.00000034 	 loss = 0.2851(0.3112)
2023/09/18 10:01:53 - INFO - root -   Epoch: [171/400][100/346], lr: 0.00000034 	 loss = 0.7416(0.3122)
2023/09/18 10:02:53 - INFO - root -   Epoch: [171/400][120/346], lr: 0.00000034 	 loss = 0.0322(0.3408)
2023/09/18 10:03:36 - INFO - root -   Epoch: [171/400][140/346], lr: 0.00000034 	 loss = 0.3487(0.3379)
2023/09/18 10:04:36 - INFO - root -   Epoch: [171/400][160/346], lr: 0.00000034 	 loss = 0.0491(0.3402)
2023/09/18 10:05:19 - INFO - root -   Epoch: [171/400][180/346], lr: 0.00000034 	 loss = 0.0649(0.3417)
2023/09/18 10:06:20 - INFO - root -   Epoch: [171/400][200/346], lr: 0.00000034 	 loss = 0.0232(0.3302)
2023/09/18 10:07:03 - INFO - root -   Epoch: [171/400][220/346], lr: 0.00000034 	 loss = 0.5262(0.3353)
2023/09/18 10:08:03 - INFO - root -   Epoch: [171/400][240/346], lr: 0.00000034 	 loss = 0.0326(0.3291)
2023/09/18 10:08:47 - INFO - root -   Epoch: [171/400][260/346], lr: 0.00000034 	 loss = 0.3274(0.3199)
2023/09/18 10:09:46 - INFO - root -   Epoch: [171/400][280/346], lr: 0.00000034 	 loss = 0.1364(0.3325)
2023/09/18 10:10:30 - INFO - root -   Epoch: [171/400][300/346], lr: 0.00000034 	 loss = 0.1037(0.3310)
2023/09/18 10:11:30 - INFO - root -   Epoch: [171/400][320/346], lr: 0.00000034 	 loss = 0.0904(0.3296)
2023/09/18 10:12:12 - INFO - root -   Epoch: [171/400][340/346], lr: 0.00000034 	 loss = 0.7470(0.3286)
2023/09/18 10:12:16 - INFO - root -   Epoch: [171/400] 	 loss = 0.3303
2023/09/18 10:12:16 - INFO - root -   train_accuracy = 0.8540
2023/09/18 10:12:38 - INFO - root -   Epoch: [172/400][0/346], lr: 0.00000035 	 loss = 0.1132(0.1132)
2023/09/18 10:13:22 - INFO - root -   Epoch: [172/400][20/346], lr: 0.00000035 	 loss = 0.0093(0.3537)
2023/09/18 10:14:23 - INFO - root -   Epoch: [172/400][40/346], lr: 0.00000035 	 loss = 0.1592(0.3054)
2023/09/18 10:15:06 - INFO - root -   Epoch: [172/400][60/346], lr: 0.00000035 	 loss = 0.3052(0.2908)
2023/09/18 10:16:08 - INFO - root -   Epoch: [172/400][80/346], lr: 0.00000035 	 loss = 0.0214(0.3018)
2023/09/18 10:16:51 - INFO - root -   Epoch: [172/400][100/346], lr: 0.00000035 	 loss = 0.0959(0.3125)
2023/09/18 10:17:52 - INFO - root -   Epoch: [172/400][120/346], lr: 0.00000035 	 loss = 0.0229(0.3208)
2023/09/18 10:18:36 - INFO - root -   Epoch: [172/400][140/346], lr: 0.00000035 	 loss = 1.2921(0.3292)
2023/09/18 10:19:37 - INFO - root -   Epoch: [172/400][160/346], lr: 0.00000035 	 loss = 0.0481(0.3310)
2023/09/18 10:20:20 - INFO - root -   Epoch: [172/400][180/346], lr: 0.00000035 	 loss = 0.0330(0.3249)
2023/09/18 10:21:21 - INFO - root -   Epoch: [172/400][200/346], lr: 0.00000035 	 loss = 0.0431(0.3328)
2023/09/18 10:22:04 - INFO - root -   Epoch: [172/400][220/346], lr: 0.00000035 	 loss = 0.4909(0.3365)
2023/09/18 10:23:05 - INFO - root -   Epoch: [172/400][240/346], lr: 0.00000035 	 loss = 0.0752(0.3312)
2023/09/18 10:23:49 - INFO - root -   Epoch: [172/400][260/346], lr: 0.00000035 	 loss = 0.7365(0.3187)
2023/09/18 10:24:49 - INFO - root -   Epoch: [172/400][280/346], lr: 0.00000035 	 loss = 0.0842(0.3283)
2023/09/18 10:25:33 - INFO - root -   Epoch: [172/400][300/346], lr: 0.00000035 	 loss = 0.2622(0.3258)
2023/09/18 10:26:34 - INFO - root -   Epoch: [172/400][320/346], lr: 0.00000035 	 loss = 0.0925(0.3261)
2023/09/18 10:27:14 - INFO - root -   Epoch: [172/400][340/346], lr: 0.00000035 	 loss = 1.1150(0.3250)
2023/09/18 10:27:19 - INFO - root -   Epoch: [172/400] 	 loss = 0.3290
2023/09/18 10:27:19 - INFO - root -   train_accuracy = 0.8569
2023/09/18 10:27:40 - INFO - root -   Epoch: [173/400][0/346], lr: 0.00000035 	 loss = 0.2644(0.2644)
2023/09/18 10:28:23 - INFO - root -   Epoch: [173/400][20/346], lr: 0.00000035 	 loss = 0.0196(0.3916)
2023/09/18 10:29:24 - INFO - root -   Epoch: [173/400][40/346], lr: 0.00000035 	 loss = 0.1042(0.3425)
2023/09/18 10:30:06 - INFO - root -   Epoch: [173/400][60/346], lr: 0.00000035 	 loss = 0.1018(0.3009)
2023/09/18 10:31:07 - INFO - root -   Epoch: [173/400][80/346], lr: 0.00000035 	 loss = 0.1796(0.3292)
2023/09/18 10:31:50 - INFO - root -   Epoch: [173/400][100/346], lr: 0.00000035 	 loss = 0.3384(0.3102)
2023/09/18 10:32:51 - INFO - root -   Epoch: [173/400][120/346], lr: 0.00000035 	 loss = 0.0089(0.3404)
2023/09/18 10:33:34 - INFO - root -   Epoch: [173/400][140/346], lr: 0.00000035 	 loss = 0.6364(0.3617)
2023/09/18 10:34:34 - INFO - root -   Epoch: [173/400][160/346], lr: 0.00000035 	 loss = 0.0160(0.3520)
2023/09/18 10:35:17 - INFO - root -   Epoch: [173/400][180/346], lr: 0.00000035 	 loss = 0.0395(0.3403)
2023/09/18 10:36:20 - INFO - root -   Epoch: [173/400][200/346], lr: 0.00000035 	 loss = 0.0163(0.3234)
2023/09/18 10:37:02 - INFO - root -   Epoch: [173/400][220/346], lr: 0.00000035 	 loss = 0.0999(0.3275)
2023/09/18 10:38:03 - INFO - root -   Epoch: [173/400][240/346], lr: 0.00000035 	 loss = 0.4582(0.3354)
2023/09/18 10:38:46 - INFO - root -   Epoch: [173/400][260/346], lr: 0.00000035 	 loss = 0.1685(0.3324)
2023/09/18 10:39:46 - INFO - root -   Epoch: [173/400][280/346], lr: 0.00000035 	 loss = 0.0563(0.3378)
2023/09/18 10:40:29 - INFO - root -   Epoch: [173/400][300/346], lr: 0.00000035 	 loss = 0.1054(0.3388)
2023/09/18 10:41:29 - INFO - root -   Epoch: [173/400][320/346], lr: 0.00000035 	 loss = 0.3413(0.3413)
2023/09/18 10:42:10 - INFO - root -   Epoch: [173/400][340/346], lr: 0.00000035 	 loss = 0.8954(0.3560)
2023/09/18 10:42:13 - INFO - root -   Epoch: [173/400] 	 loss = 0.3585
2023/09/18 10:42:13 - INFO - root -   train_accuracy = 0.8569
2023/09/18 10:42:35 - INFO - root -   Epoch: [174/400][0/346], lr: 0.00000035 	 loss = 0.2115(0.2115)
2023/09/18 10:43:18 - INFO - root -   Epoch: [174/400][20/346], lr: 0.00000035 	 loss = 0.0410(0.3852)
2023/09/18 10:44:19 - INFO - root -   Epoch: [174/400][40/346], lr: 0.00000035 	 loss = 0.2971(0.3921)
2023/09/18 10:45:02 - INFO - root -   Epoch: [174/400][60/346], lr: 0.00000035 	 loss = 0.2014(0.3536)
2023/09/18 10:46:03 - INFO - root -   Epoch: [174/400][80/346], lr: 0.00000035 	 loss = 0.0503(0.3920)
2023/09/18 10:46:46 - INFO - root -   Epoch: [174/400][100/346], lr: 0.00000035 	 loss = 0.5824(0.3881)
2023/09/18 10:47:47 - INFO - root -   Epoch: [174/400][120/346], lr: 0.00000035 	 loss = 0.0873(0.3945)
2023/09/18 10:48:30 - INFO - root -   Epoch: [174/400][140/346], lr: 0.00000035 	 loss = 0.2887(0.3880)
2023/09/18 10:49:30 - INFO - root -   Epoch: [174/400][160/346], lr: 0.00000035 	 loss = 0.0838(0.3842)
2023/09/18 10:50:13 - INFO - root -   Epoch: [174/400][180/346], lr: 0.00000035 	 loss = 0.0395(0.3822)
2023/09/18 10:51:14 - INFO - root -   Epoch: [174/400][200/346], lr: 0.00000035 	 loss = 0.0302(0.3639)
2023/09/18 10:51:57 - INFO - root -   Epoch: [174/400][220/346], lr: 0.00000035 	 loss = 0.2858(0.3582)
2023/09/18 10:52:58 - INFO - root -   Epoch: [174/400][240/346], lr: 0.00000035 	 loss = 0.0506(0.3518)
2023/09/18 10:53:41 - INFO - root -   Epoch: [174/400][260/346], lr: 0.00000035 	 loss = 0.2778(0.3386)
2023/09/18 10:54:41 - INFO - root -   Epoch: [174/400][280/346], lr: 0.00000035 	 loss = 0.0830(0.3558)
2023/09/18 10:55:25 - INFO - root -   Epoch: [174/400][300/346], lr: 0.00000035 	 loss = 0.1336(0.3453)
2023/09/18 10:56:25 - INFO - root -   Epoch: [174/400][320/346], lr: 0.00000035 	 loss = 0.1045(0.3490)
2023/09/18 10:57:07 - INFO - root -   Epoch: [174/400][340/346], lr: 0.00000035 	 loss = 0.7792(0.3503)
2023/09/18 10:57:11 - INFO - root -   Epoch: [174/400] 	 loss = 0.3500
2023/09/18 11:01:00 - INFO - root -   precision = 0.6954
2023/09/18 11:01:00 - INFO - root -   eval_loss = 0.7185
2023/09/18 11:01:01 - INFO - root -   train_accuracy = 0.8497
2023/09/18 11:01:23 - INFO - root -   Epoch: [175/400][0/346], lr: 0.00000035 	 loss = 0.1801(0.1801)
2023/09/18 11:02:05 - INFO - root -   Epoch: [175/400][20/346], lr: 0.00000035 	 loss = 0.0054(0.2284)
2023/09/18 11:03:06 - INFO - root -   Epoch: [175/400][40/346], lr: 0.00000035 	 loss = 0.6718(0.3089)
2023/09/18 11:03:50 - INFO - root -   Epoch: [175/400][60/346], lr: 0.00000035 	 loss = 0.4324(0.2827)
2023/09/18 11:04:51 - INFO - root -   Epoch: [175/400][80/346], lr: 0.00000035 	 loss = 0.2428(0.3492)
2023/09/18 11:05:34 - INFO - root -   Epoch: [175/400][100/346], lr: 0.00000035 	 loss = 0.8760(0.3380)
2023/09/18 11:06:35 - INFO - root -   Epoch: [175/400][120/346], lr: 0.00000035 	 loss = 0.0587(0.3489)
2023/09/18 11:07:18 - INFO - root -   Epoch: [175/400][140/346], lr: 0.00000035 	 loss = 0.2458(0.3434)
2023/09/18 11:08:19 - INFO - root -   Epoch: [175/400][160/346], lr: 0.00000035 	 loss = 0.0420(0.3485)
2023/09/18 11:09:02 - INFO - root -   Epoch: [175/400][180/346], lr: 0.00000035 	 loss = 0.0403(0.3348)
2023/09/18 11:10:02 - INFO - root -   Epoch: [175/400][200/346], lr: 0.00000035 	 loss = 0.0140(0.3217)
2023/09/18 11:10:46 - INFO - root -   Epoch: [175/400][220/346], lr: 0.00000035 	 loss = 0.0389(0.3240)
2023/09/18 11:11:46 - INFO - root -   Epoch: [175/400][240/346], lr: 0.00000035 	 loss = 0.5949(0.3223)
2023/09/18 11:12:30 - INFO - root -   Epoch: [175/400][260/346], lr: 0.00000035 	 loss = 0.2887(0.3139)
2023/09/18 11:13:29 - INFO - root -   Epoch: [175/400][280/346], lr: 0.00000035 	 loss = 0.0817(0.3243)
2023/09/18 11:14:14 - INFO - root -   Epoch: [175/400][300/346], lr: 0.00000035 	 loss = 0.1221(0.3208)
2023/09/18 11:15:12 - INFO - root -   Epoch: [175/400][320/346], lr: 0.00000035 	 loss = 0.0515(0.3236)
2023/09/18 11:15:56 - INFO - root -   Epoch: [175/400][340/346], lr: 0.00000035 	 loss = 0.6488(0.3262)
2023/09/18 11:16:00 - INFO - root -   Epoch: [175/400] 	 loss = 0.3311
2023/09/18 11:16:00 - INFO - root -   train_accuracy = 0.8512
2023/09/18 11:16:22 - INFO - root -   Epoch: [176/400][0/346], lr: 0.00000035 	 loss = 0.1273(0.1273)
2023/09/18 11:17:05 - INFO - root -   Epoch: [176/400][20/346], lr: 0.00000035 	 loss = 0.0065(0.4123)
2023/09/18 11:18:06 - INFO - root -   Epoch: [176/400][40/346], lr: 0.00000035 	 loss = 0.5337(0.4005)
2023/09/18 11:18:49 - INFO - root -   Epoch: [176/400][60/346], lr: 0.00000035 	 loss = 0.1355(0.3523)
2023/09/18 11:19:50 - INFO - root -   Epoch: [176/400][80/346], lr: 0.00000035 	 loss = 0.1035(0.3754)
2023/09/18 11:20:33 - INFO - root -   Epoch: [176/400][100/346], lr: 0.00000035 	 loss = 0.4050(0.3647)
2023/09/18 11:21:34 - INFO - root -   Epoch: [176/400][120/346], lr: 0.00000035 	 loss = 0.0239(0.3548)
2023/09/18 11:22:18 - INFO - root -   Epoch: [176/400][140/346], lr: 0.00000035 	 loss = 0.1425(0.3547)
2023/09/18 11:23:18 - INFO - root -   Epoch: [176/400][160/346], lr: 0.00000035 	 loss = 0.1047(0.3758)
2023/09/18 11:24:02 - INFO - root -   Epoch: [176/400][180/346], lr: 0.00000035 	 loss = 0.1914(0.3726)
2023/09/18 11:25:02 - INFO - root -   Epoch: [176/400][200/346], lr: 0.00000035 	 loss = 0.0342(0.3587)
2023/09/18 11:25:46 - INFO - root -   Epoch: [176/400][220/346], lr: 0.00000035 	 loss = 0.4561(0.3567)
2023/09/18 11:26:46 - INFO - root -   Epoch: [176/400][240/346], lr: 0.00000035 	 loss = 0.1061(0.3536)
2023/09/18 11:27:30 - INFO - root -   Epoch: [176/400][260/346], lr: 0.00000035 	 loss = 0.2681(0.3488)
2023/09/18 11:28:30 - INFO - root -   Epoch: [176/400][280/346], lr: 0.00000035 	 loss = 0.0362(0.3657)
2023/09/18 11:29:15 - INFO - root -   Epoch: [176/400][300/346], lr: 0.00000035 	 loss = 0.0466(0.3608)
2023/09/18 11:30:14 - INFO - root -   Epoch: [176/400][320/346], lr: 0.00000035 	 loss = 0.0286(0.3630)
2023/09/18 11:30:57 - INFO - root -   Epoch: [176/400][340/346], lr: 0.00000035 	 loss = 0.4638(0.3593)
2023/09/18 11:31:01 - INFO - root -   Epoch: [176/400] 	 loss = 0.3586
2023/09/18 11:31:01 - INFO - root -   train_accuracy = 0.8367
2023/09/18 11:31:23 - INFO - root -   Epoch: [177/400][0/346], lr: 0.00000035 	 loss = 0.2130(0.2130)
2023/09/18 11:32:06 - INFO - root -   Epoch: [177/400][20/346], lr: 0.00000035 	 loss = 0.0166(0.3453)
2023/09/18 11:33:06 - INFO - root -   Epoch: [177/400][40/346], lr: 0.00000035 	 loss = 0.3162(0.3211)
2023/09/18 11:33:49 - INFO - root -   Epoch: [177/400][60/346], lr: 0.00000035 	 loss = 0.0863(0.2729)
2023/09/18 11:34:50 - INFO - root -   Epoch: [177/400][80/346], lr: 0.00000035 	 loss = 0.0800(0.3064)
2023/09/18 11:35:34 - INFO - root -   Epoch: [177/400][100/346], lr: 0.00000035 	 loss = 0.7344(0.3168)
2023/09/18 11:36:34 - INFO - root -   Epoch: [177/400][120/346], lr: 0.00000035 	 loss = 0.0257(0.3443)
2023/09/18 11:37:17 - INFO - root -   Epoch: [177/400][140/346], lr: 0.00000035 	 loss = 0.2456(0.3317)
2023/09/18 11:38:18 - INFO - root -   Epoch: [177/400][160/346], lr: 0.00000035 	 loss = 0.0482(0.3281)
2023/09/18 11:39:01 - INFO - root -   Epoch: [177/400][180/346], lr: 0.00000035 	 loss = 0.1150(0.3239)
2023/09/18 11:40:01 - INFO - root -   Epoch: [177/400][200/346], lr: 0.00000035 	 loss = 0.0559(0.3047)
2023/09/18 11:40:44 - INFO - root -   Epoch: [177/400][220/346], lr: 0.00000035 	 loss = 0.1452(0.3100)
2023/09/18 11:41:45 - INFO - root -   Epoch: [177/400][240/346], lr: 0.00000035 	 loss = 0.0080(0.3117)
2023/09/18 11:42:28 - INFO - root -   Epoch: [177/400][260/346], lr: 0.00000035 	 loss = 0.3624(0.3031)
2023/09/18 11:43:29 - INFO - root -   Epoch: [177/400][280/346], lr: 0.00000035 	 loss = 0.0341(0.3153)
2023/09/18 11:44:12 - INFO - root -   Epoch: [177/400][300/346], lr: 0.00000035 	 loss = 0.0519(0.3131)
2023/09/18 11:45:12 - INFO - root -   Epoch: [177/400][320/346], lr: 0.00000035 	 loss = 0.0140(0.3118)
2023/09/18 11:45:55 - INFO - root -   Epoch: [177/400][340/346], lr: 0.00000035 	 loss = 0.5928(0.3150)
2023/09/18 11:45:59 - INFO - root -   Epoch: [177/400] 	 loss = 0.3159
2023/09/18 11:45:59 - INFO - root -   train_accuracy = 0.8699
2023/09/18 11:46:20 - INFO - root -   Epoch: [178/400][0/346], lr: 0.00000035 	 loss = 0.0418(0.0418)
2023/09/18 11:47:03 - INFO - root -   Epoch: [178/400][20/346], lr: 0.00000035 	 loss = 0.0387(0.3295)
2023/09/18 11:48:04 - INFO - root -   Epoch: [178/400][40/346], lr: 0.00000035 	 loss = 0.8893(0.3380)
2023/09/18 11:48:48 - INFO - root -   Epoch: [178/400][60/346], lr: 0.00000035 	 loss = 0.1409(0.2990)
2023/09/18 11:49:48 - INFO - root -   Epoch: [178/400][80/346], lr: 0.00000035 	 loss = 0.2464(0.3487)
2023/09/18 11:50:31 - INFO - root -   Epoch: [178/400][100/346], lr: 0.00000035 	 loss = 0.4359(0.3223)
2023/09/18 11:51:32 - INFO - root -   Epoch: [178/400][120/346], lr: 0.00000035 	 loss = 0.0369(0.3280)
2023/09/18 11:52:15 - INFO - root -   Epoch: [178/400][140/346], lr: 0.00000035 	 loss = 0.1244(0.3304)
2023/09/18 11:53:16 - INFO - root -   Epoch: [178/400][160/346], lr: 0.00000035 	 loss = 0.0652(0.3513)
2023/09/18 11:53:58 - INFO - root -   Epoch: [178/400][180/346], lr: 0.00000035 	 loss = 0.0319(0.3571)
2023/09/18 11:54:59 - INFO - root -   Epoch: [178/400][200/346], lr: 0.00000035 	 loss = 0.1518(0.3434)
2023/09/18 11:55:42 - INFO - root -   Epoch: [178/400][220/346], lr: 0.00000035 	 loss = 0.0537(0.3403)
2023/09/18 11:56:43 - INFO - root -   Epoch: [178/400][240/346], lr: 0.00000035 	 loss = 0.0462(0.3380)
2023/09/18 11:57:26 - INFO - root -   Epoch: [178/400][260/346], lr: 0.00000035 	 loss = 0.3405(0.3283)
2023/09/18 11:58:26 - INFO - root -   Epoch: [178/400][280/346], lr: 0.00000035 	 loss = 0.0090(0.3354)
2023/09/18 11:59:09 - INFO - root -   Epoch: [178/400][300/346], lr: 0.00000035 	 loss = 0.0974(0.3356)
2023/09/18 12:00:10 - INFO - root -   Epoch: [178/400][320/346], lr: 0.00000035 	 loss = 0.1600(0.3335)
2023/09/18 12:00:52 - INFO - root -   Epoch: [178/400][340/346], lr: 0.00000035 	 loss = 0.2634(0.3335)
2023/09/18 12:00:56 - INFO - root -   Epoch: [178/400] 	 loss = 0.3343
2023/09/18 12:00:56 - INFO - root -   train_accuracy = 0.8526
2023/09/18 12:01:17 - INFO - root -   Epoch: [179/400][0/346], lr: 0.00000036 	 loss = 0.1849(0.1849)
2023/09/18 12:02:01 - INFO - root -   Epoch: [179/400][20/346], lr: 0.00000036 	 loss = 0.0199(0.2586)
2023/09/18 12:03:02 - INFO - root -   Epoch: [179/400][40/346], lr: 0.00000036 	 loss = 0.0593(0.2937)
2023/09/18 12:03:46 - INFO - root -   Epoch: [179/400][60/346], lr: 0.00000036 	 loss = 0.1338(0.2870)
2023/09/18 12:04:47 - INFO - root -   Epoch: [179/400][80/346], lr: 0.00000036 	 loss = 0.1565(0.3117)
2023/09/18 12:05:31 - INFO - root -   Epoch: [179/400][100/346], lr: 0.00000036 	 loss = 0.8377(0.3028)
2023/09/18 12:06:32 - INFO - root -   Epoch: [179/400][120/346], lr: 0.00000036 	 loss = 0.0612(0.3002)
2023/09/18 12:07:16 - INFO - root -   Epoch: [179/400][140/346], lr: 0.00000036 	 loss = 0.8065(0.3128)
2023/09/18 12:08:17 - INFO - root -   Epoch: [179/400][160/346], lr: 0.00000036 	 loss = 0.1091(0.3127)
2023/09/18 12:09:01 - INFO - root -   Epoch: [179/400][180/346], lr: 0.00000036 	 loss = 0.0110(0.3118)
2023/09/18 12:10:02 - INFO - root -   Epoch: [179/400][200/346], lr: 0.00000036 	 loss = 0.0142(0.3008)
2023/09/18 12:10:45 - INFO - root -   Epoch: [179/400][220/346], lr: 0.00000036 	 loss = 0.3095(0.3017)
2023/09/18 12:11:46 - INFO - root -   Epoch: [179/400][240/346], lr: 0.00000036 	 loss = 0.1376(0.3070)
2023/09/18 12:12:30 - INFO - root -   Epoch: [179/400][260/346], lr: 0.00000036 	 loss = 0.1438(0.3005)
2023/09/18 12:13:31 - INFO - root -   Epoch: [179/400][280/346], lr: 0.00000036 	 loss = 0.0117(0.3083)
2023/09/18 12:14:14 - INFO - root -   Epoch: [179/400][300/346], lr: 0.00000036 	 loss = 0.1056(0.3113)
2023/09/18 12:15:15 - INFO - root -   Epoch: [179/400][320/346], lr: 0.00000036 	 loss = 0.0959(0.3104)
2023/09/18 12:15:58 - INFO - root -   Epoch: [179/400][340/346], lr: 0.00000036 	 loss = 0.4443(0.3124)
2023/09/18 12:16:02 - INFO - root -   Epoch: [179/400] 	 loss = 0.3140
2023/09/18 12:19:49 - INFO - root -   precision = 0.6897
2023/09/18 12:19:49 - INFO - root -   eval_loss = 0.8000
2023/09/18 12:19:50 - INFO - root -   train_accuracy = 0.8714
2023/09/18 12:20:12 - INFO - root -   Epoch: [180/400][0/346], lr: 0.00000036 	 loss = 0.1107(0.1107)
2023/09/18 12:20:55 - INFO - root -   Epoch: [180/400][20/346], lr: 0.00000036 	 loss = 0.0165(0.2201)
2023/09/18 12:21:56 - INFO - root -   Epoch: [180/400][40/346], lr: 0.00000036 	 loss = 0.3258(0.2310)
2023/09/18 12:22:40 - INFO - root -   Epoch: [180/400][60/346], lr: 0.00000036 	 loss = 0.5807(0.2225)
2023/09/18 12:23:41 - INFO - root -   Epoch: [180/400][80/346], lr: 0.00000036 	 loss = 0.0355(0.2370)
2023/09/18 12:24:24 - INFO - root -   Epoch: [180/400][100/346], lr: 0.00000036 	 loss = 0.6199(0.2260)
2023/09/18 12:25:25 - INFO - root -   Epoch: [180/400][120/346], lr: 0.00000036 	 loss = 0.0131(0.2471)
2023/09/18 12:26:10 - INFO - root -   Epoch: [180/400][140/346], lr: 0.00000036 	 loss = 0.5257(0.2677)
2023/09/18 12:27:11 - INFO - root -   Epoch: [180/400][160/346], lr: 0.00000036 	 loss = 0.0285(0.2648)
2023/09/18 12:27:54 - INFO - root -   Epoch: [180/400][180/346], lr: 0.00000036 	 loss = 0.0186(0.2735)
2023/09/18 12:28:55 - INFO - root -   Epoch: [180/400][200/346], lr: 0.00000036 	 loss = 0.0036(0.2652)
2023/09/18 12:29:39 - INFO - root -   Epoch: [180/400][220/346], lr: 0.00000036 	 loss = 0.2300(0.2680)
2023/09/18 12:30:40 - INFO - root -   Epoch: [180/400][240/346], lr: 0.00000036 	 loss = 0.0169(0.2655)
2023/09/18 12:31:25 - INFO - root -   Epoch: [180/400][260/346], lr: 0.00000036 	 loss = 1.0248(0.2565)
2023/09/18 12:32:26 - INFO - root -   Epoch: [180/400][280/346], lr: 0.00000036 	 loss = 0.0190(0.2584)
2023/09/18 12:33:09 - INFO - root -   Epoch: [180/400][300/346], lr: 0.00000036 	 loss = 0.2614(0.2548)
2023/09/18 12:34:10 - INFO - root -   Epoch: [180/400][320/346], lr: 0.00000036 	 loss = 0.1740(0.2540)
2023/09/18 12:34:50 - INFO - root -   Epoch: [180/400][340/346], lr: 0.00000036 	 loss = 0.1828(0.2560)
2023/09/18 12:34:53 - INFO - root -   Epoch: [180/400] 	 loss = 0.2586
2023/09/18 12:34:53 - INFO - root -   train_accuracy = 0.8931
2023/09/18 12:35:14 - INFO - root -   Epoch: [181/400][0/346], lr: 0.00000036 	 loss = 0.0961(0.0961)
2023/09/18 12:35:57 - INFO - root -   Epoch: [181/400][20/346], lr: 0.00000036 	 loss = 0.1436(0.2119)
2023/09/18 12:36:58 - INFO - root -   Epoch: [181/400][40/346], lr: 0.00000036 	 loss = 0.3268(0.2810)
2023/09/18 12:37:41 - INFO - root -   Epoch: [181/400][60/346], lr: 0.00000036 	 loss = 0.1807(0.2624)
2023/09/18 12:38:42 - INFO - root -   Epoch: [181/400][80/346], lr: 0.00000036 	 loss = 0.2716(0.2685)
2023/09/18 12:39:25 - INFO - root -   Epoch: [181/400][100/346], lr: 0.00000036 	 loss = 0.8005(0.2678)
2023/09/18 12:40:26 - INFO - root -   Epoch: [181/400][120/346], lr: 0.00000036 	 loss = 0.0110(0.2729)
2023/09/18 12:41:09 - INFO - root -   Epoch: [181/400][140/346], lr: 0.00000036 	 loss = 0.2221(0.2729)
2023/09/18 12:42:10 - INFO - root -   Epoch: [181/400][160/346], lr: 0.00000036 	 loss = 0.0041(0.2644)
2023/09/18 12:42:53 - INFO - root -   Epoch: [181/400][180/346], lr: 0.00000036 	 loss = 0.0129(0.2665)
2023/09/18 12:43:53 - INFO - root -   Epoch: [181/400][200/346], lr: 0.00000036 	 loss = 0.0045(0.2585)
2023/09/18 12:44:36 - INFO - root -   Epoch: [181/400][220/346], lr: 0.00000036 	 loss = 0.1307(0.2603)
2023/09/18 12:45:37 - INFO - root -   Epoch: [181/400][240/346], lr: 0.00000036 	 loss = 0.0448(0.2606)
2023/09/18 12:46:20 - INFO - root -   Epoch: [181/400][260/346], lr: 0.00000036 	 loss = 1.0359(0.2584)
2023/09/18 12:47:21 - INFO - root -   Epoch: [181/400][280/346], lr: 0.00000036 	 loss = 0.0204(0.2711)
2023/09/18 12:48:04 - INFO - root -   Epoch: [181/400][300/346], lr: 0.00000036 	 loss = 0.0612(0.2670)
2023/09/18 12:49:05 - INFO - root -   Epoch: [181/400][320/346], lr: 0.00000036 	 loss = 0.1208(0.2624)
2023/09/18 12:49:46 - INFO - root -   Epoch: [181/400][340/346], lr: 0.00000036 	 loss = 0.8352(0.2597)
2023/09/18 12:49:50 - INFO - root -   Epoch: [181/400] 	 loss = 0.2663
2023/09/18 12:49:50 - INFO - root -   train_accuracy = 0.8873
2023/09/18 12:50:12 - INFO - root -   Epoch: [182/400][0/346], lr: 0.00000036 	 loss = 0.0526(0.0526)
2023/09/18 12:50:55 - INFO - root -   Epoch: [182/400][20/346], lr: 0.00000036 	 loss = 0.0346(0.3758)
2023/09/18 12:51:56 - INFO - root -   Epoch: [182/400][40/346], lr: 0.00000036 	 loss = 0.7234(0.3795)
2023/09/18 12:52:39 - INFO - root -   Epoch: [182/400][60/346], lr: 0.00000036 	 loss = 0.0683(0.3372)
2023/09/18 12:53:40 - INFO - root -   Epoch: [182/400][80/346], lr: 0.00000036 	 loss = 0.0119(0.3381)
2023/09/18 12:54:23 - INFO - root -   Epoch: [182/400][100/346], lr: 0.00000036 	 loss = 0.1647(0.3209)
2023/09/18 12:55:23 - INFO - root -   Epoch: [182/400][120/346], lr: 0.00000036 	 loss = 0.0193(0.3466)
2023/09/18 12:56:06 - INFO - root -   Epoch: [182/400][140/346], lr: 0.00000036 	 loss = 0.3408(0.3404)
2023/09/18 12:57:06 - INFO - root -   Epoch: [182/400][160/346], lr: 0.00000036 	 loss = 0.0159(0.3341)
2023/09/18 12:57:49 - INFO - root -   Epoch: [182/400][180/346], lr: 0.00000036 	 loss = 0.0443(0.3320)
2023/09/18 12:58:50 - INFO - root -   Epoch: [182/400][200/346], lr: 0.00000036 	 loss = 0.0095(0.3199)
2023/09/18 12:59:33 - INFO - root -   Epoch: [182/400][220/346], lr: 0.00000036 	 loss = 0.2665(0.3200)
2023/09/18 13:00:33 - INFO - root -   Epoch: [182/400][240/346], lr: 0.00000036 	 loss = 0.0348(0.3132)
2023/09/18 13:01:17 - INFO - root -   Epoch: [182/400][260/346], lr: 0.00000036 	 loss = 0.4873(0.3000)
2023/09/18 13:02:17 - INFO - root -   Epoch: [182/400][280/346], lr: 0.00000036 	 loss = 0.0097(0.3025)
2023/09/18 13:03:00 - INFO - root -   Epoch: [182/400][300/346], lr: 0.00000036 	 loss = 0.0554(0.2967)
2023/09/18 13:04:00 - INFO - root -   Epoch: [182/400][320/346], lr: 0.00000036 	 loss = 0.0157(0.2880)
2023/09/18 13:04:42 - INFO - root -   Epoch: [182/400][340/346], lr: 0.00000036 	 loss = 0.6847(0.2891)
2023/09/18 13:04:46 - INFO - root -   Epoch: [182/400] 	 loss = 0.2916
2023/09/18 13:04:46 - INFO - root -   train_accuracy = 0.8829
2023/09/18 13:05:08 - INFO - root -   Epoch: [183/400][0/346], lr: 0.00000036 	 loss = 0.0698(0.0698)
2023/09/18 13:05:51 - INFO - root -   Epoch: [183/400][20/346], lr: 0.00000036 	 loss = 0.0028(0.2601)
2023/09/18 13:06:52 - INFO - root -   Epoch: [183/400][40/346], lr: 0.00000036 	 loss = 0.0659(0.4029)
2023/09/18 13:07:35 - INFO - root -   Epoch: [183/400][60/346], lr: 0.00000036 	 loss = 0.5319(0.3777)
2023/09/18 13:08:36 - INFO - root -   Epoch: [183/400][80/346], lr: 0.00000036 	 loss = 0.0848(0.3991)
2023/09/18 13:09:19 - INFO - root -   Epoch: [183/400][100/346], lr: 0.00000036 	 loss = 0.4945(0.3597)
2023/09/18 13:10:19 - INFO - root -   Epoch: [183/400][120/346], lr: 0.00000036 	 loss = 0.0532(0.3814)
2023/09/18 13:11:02 - INFO - root -   Epoch: [183/400][140/346], lr: 0.00000036 	 loss = 0.1460(0.3777)
2023/09/18 13:12:03 - INFO - root -   Epoch: [183/400][160/346], lr: 0.00000036 	 loss = 0.0577(0.3683)
2023/09/18 13:12:46 - INFO - root -   Epoch: [183/400][180/346], lr: 0.00000036 	 loss = 0.1519(0.3791)
2023/09/18 13:13:46 - INFO - root -   Epoch: [183/400][200/346], lr: 0.00000036 	 loss = 0.0157(0.3681)
2023/09/18 13:14:29 - INFO - root -   Epoch: [183/400][220/346], lr: 0.00000036 	 loss = 0.2235(0.3670)
2023/09/18 13:15:30 - INFO - root -   Epoch: [183/400][240/346], lr: 0.00000036 	 loss = 0.1597(0.3576)
2023/09/18 13:16:13 - INFO - root -   Epoch: [183/400][260/346], lr: 0.00000036 	 loss = 0.1361(0.3432)
2023/09/18 13:17:13 - INFO - root -   Epoch: [183/400][280/346], lr: 0.00000036 	 loss = 0.0136(0.3436)
2023/09/18 13:17:57 - INFO - root -   Epoch: [183/400][300/346], lr: 0.00000036 	 loss = 0.0961(0.3361)
2023/09/18 13:18:57 - INFO - root -   Epoch: [183/400][320/346], lr: 0.00000036 	 loss = 0.0085(0.3309)
2023/09/18 13:19:38 - INFO - root -   Epoch: [183/400][340/346], lr: 0.00000036 	 loss = 0.5560(0.3315)
2023/09/18 13:19:42 - INFO - root -   Epoch: [183/400] 	 loss = 0.3381
2023/09/18 13:19:42 - INFO - root -   train_accuracy = 0.8512
2023/09/18 13:20:04 - INFO - root -   Epoch: [184/400][0/346], lr: 0.00000036 	 loss = 0.3548(0.3548)
2023/09/18 13:20:47 - INFO - root -   Epoch: [184/400][20/346], lr: 0.00000036 	 loss = 0.0599(0.2968)
2023/09/18 13:21:47 - INFO - root -   Epoch: [184/400][40/346], lr: 0.00000036 	 loss = 0.0534(0.3191)
2023/09/18 13:22:31 - INFO - root -   Epoch: [184/400][60/346], lr: 0.00000036 	 loss = 0.0534(0.2930)
2023/09/18 13:23:31 - INFO - root -   Epoch: [184/400][80/346], lr: 0.00000036 	 loss = 0.0355(0.3134)
2023/09/18 13:24:14 - INFO - root -   Epoch: [184/400][100/346], lr: 0.00000036 	 loss = 0.1667(0.3075)
2023/09/18 13:25:15 - INFO - root -   Epoch: [184/400][120/346], lr: 0.00000036 	 loss = 0.0155(0.2964)
2023/09/18 13:25:58 - INFO - root -   Epoch: [184/400][140/346], lr: 0.00000036 	 loss = 0.4176(0.2837)
2023/09/18 13:26:59 - INFO - root -   Epoch: [184/400][160/346], lr: 0.00000036 	 loss = 0.0245(0.2917)
2023/09/18 13:27:42 - INFO - root -   Epoch: [184/400][180/346], lr: 0.00000036 	 loss = 0.0353(0.2909)
2023/09/18 13:28:42 - INFO - root -   Epoch: [184/400][200/346], lr: 0.00000036 	 loss = 0.0661(0.2788)
2023/09/18 13:29:25 - INFO - root -   Epoch: [184/400][220/346], lr: 0.00000036 	 loss = 0.0220(0.2846)
2023/09/18 13:30:25 - INFO - root -   Epoch: [184/400][240/346], lr: 0.00000036 	 loss = 0.0052(0.2779)
2023/09/18 13:31:08 - INFO - root -   Epoch: [184/400][260/346], lr: 0.00000036 	 loss = 0.1848(0.2659)
2023/09/18 13:32:09 - INFO - root -   Epoch: [184/400][280/346], lr: 0.00000036 	 loss = 0.0059(0.2789)
2023/09/18 13:32:51 - INFO - root -   Epoch: [184/400][300/346], lr: 0.00000036 	 loss = 0.1401(0.2820)
2023/09/18 13:33:52 - INFO - root -   Epoch: [184/400][320/346], lr: 0.00000036 	 loss = 0.0071(0.2774)
2023/09/18 13:34:33 - INFO - root -   Epoch: [184/400][340/346], lr: 0.00000036 	 loss = 0.0640(0.2792)
2023/09/18 13:34:37 - INFO - root -   Epoch: [184/400] 	 loss = 0.2848
2023/09/18 13:38:25 - INFO - root -   precision = 0.6494
2023/09/18 13:38:25 - INFO - root -   eval_loss = 0.9309
2023/09/18 13:38:26 - INFO - root -   train_accuracy = 0.8844
2023/09/18 13:38:48 - INFO - root -   Epoch: [185/400][0/346], lr: 0.00000036 	 loss = 0.1307(0.1307)
2023/09/18 13:39:30 - INFO - root -   Epoch: [185/400][20/346], lr: 0.00000036 	 loss = 0.0096(0.1681)
2023/09/18 13:40:31 - INFO - root -   Epoch: [185/400][40/346], lr: 0.00000036 	 loss = 0.3476(0.2267)
2023/09/18 13:41:15 - INFO - root -   Epoch: [185/400][60/346], lr: 0.00000036 	 loss = 0.4171(0.2141)
2023/09/18 13:42:16 - INFO - root -   Epoch: [185/400][80/346], lr: 0.00000036 	 loss = 0.1559(0.2756)
2023/09/18 13:42:59 - INFO - root -   Epoch: [185/400][100/346], lr: 0.00000036 	 loss = 0.1032(0.2934)
2023/09/18 13:43:59 - INFO - root -   Epoch: [185/400][120/346], lr: 0.00000036 	 loss = 0.0202(0.3126)
2023/09/18 13:44:43 - INFO - root -   Epoch: [185/400][140/346], lr: 0.00000036 	 loss = 0.6361(0.3295)
2023/09/18 13:45:43 - INFO - root -   Epoch: [185/400][160/346], lr: 0.00000036 	 loss = 0.0292(0.3339)
2023/09/18 13:46:27 - INFO - root -   Epoch: [185/400][180/346], lr: 0.00000036 	 loss = 0.0207(0.3451)
2023/09/18 13:47:27 - INFO - root -   Epoch: [185/400][200/346], lr: 0.00000036 	 loss = 0.0094(0.3320)
2023/09/18 13:48:10 - INFO - root -   Epoch: [185/400][220/346], lr: 0.00000036 	 loss = 0.0538(0.3291)
2023/09/18 13:49:11 - INFO - root -   Epoch: [185/400][240/346], lr: 0.00000036 	 loss = 0.0424(0.3258)
2023/09/18 13:49:54 - INFO - root -   Epoch: [185/400][260/346], lr: 0.00000036 	 loss = 0.9815(0.3169)
2023/09/18 13:50:55 - INFO - root -   Epoch: [185/400][280/346], lr: 0.00000036 	 loss = 0.2219(0.3259)
2023/09/18 13:51:38 - INFO - root -   Epoch: [185/400][300/346], lr: 0.00000036 	 loss = 0.0701(0.3202)
2023/09/18 13:52:38 - INFO - root -   Epoch: [185/400][320/346], lr: 0.00000036 	 loss = 0.0299(0.3172)
2023/09/18 13:53:20 - INFO - root -   Epoch: [185/400][340/346], lr: 0.00000036 	 loss = 0.0657(0.3162)
2023/09/18 13:53:25 - INFO - root -   Epoch: [185/400] 	 loss = 0.3197
2023/09/18 13:53:25 - INFO - root -   train_accuracy = 0.8627
2023/09/18 13:53:46 - INFO - root -   Epoch: [186/400][0/346], lr: 0.00000037 	 loss = 0.1264(0.1264)
2023/09/18 13:54:29 - INFO - root -   Epoch: [186/400][20/346], lr: 0.00000037 	 loss = 0.0477(0.2557)
2023/09/18 13:55:30 - INFO - root -   Epoch: [186/400][40/346], lr: 0.00000037 	 loss = 0.8743(0.3322)
2023/09/18 13:56:13 - INFO - root -   Epoch: [186/400][60/346], lr: 0.00000037 	 loss = 0.0206(0.2642)
2023/09/18 13:57:14 - INFO - root -   Epoch: [186/400][80/346], lr: 0.00000037 	 loss = 0.0623(0.2696)
2023/09/18 13:57:58 - INFO - root -   Epoch: [186/400][100/346], lr: 0.00000037 	 loss = 0.3828(0.2912)
2023/09/18 13:58:58 - INFO - root -   Epoch: [186/400][120/346], lr: 0.00000037 	 loss = 0.3313(0.3195)
2023/09/18 13:59:41 - INFO - root -   Epoch: [186/400][140/346], lr: 0.00000037 	 loss = 0.1324(0.3122)
2023/09/18 14:00:42 - INFO - root -   Epoch: [186/400][160/346], lr: 0.00000037 	 loss = 0.0998(0.3269)
2023/09/18 14:01:25 - INFO - root -   Epoch: [186/400][180/346], lr: 0.00000037 	 loss = 0.0056(0.3291)
2023/09/18 14:02:26 - INFO - root -   Epoch: [186/400][200/346], lr: 0.00000037 	 loss = 0.0174(0.3102)
2023/09/18 14:03:09 - INFO - root -   Epoch: [186/400][220/346], lr: 0.00000037 	 loss = 0.0580(0.3095)
2023/09/18 14:04:10 - INFO - root -   Epoch: [186/400][240/346], lr: 0.00000037 	 loss = 0.3369(0.3080)
2023/09/18 14:04:53 - INFO - root -   Epoch: [186/400][260/346], lr: 0.00000037 	 loss = 0.1107(0.2935)
2023/09/18 14:05:54 - INFO - root -   Epoch: [186/400][280/346], lr: 0.00000037 	 loss = 0.0309(0.3045)
2023/09/18 14:06:37 - INFO - root -   Epoch: [186/400][300/346], lr: 0.00000037 	 loss = 0.1231(0.3025)
2023/09/18 14:07:38 - INFO - root -   Epoch: [186/400][320/346], lr: 0.00000037 	 loss = 0.0437(0.2981)
2023/09/18 14:08:20 - INFO - root -   Epoch: [186/400][340/346], lr: 0.00000037 	 loss = 0.2965(0.3020)
2023/09/18 14:08:24 - INFO - root -   Epoch: [186/400] 	 loss = 0.3079
2023/09/18 14:08:24 - INFO - root -   train_accuracy = 0.8757
2023/09/18 14:08:46 - INFO - root -   Epoch: [187/400][0/346], lr: 0.00000037 	 loss = 0.2146(0.2146)
2023/09/18 14:09:29 - INFO - root -   Epoch: [187/400][20/346], lr: 0.00000037 	 loss = 0.0250(0.1912)
2023/09/18 14:10:30 - INFO - root -   Epoch: [187/400][40/346], lr: 0.00000037 	 loss = 0.0507(0.1892)
2023/09/18 14:11:13 - INFO - root -   Epoch: [187/400][60/346], lr: 0.00000037 	 loss = 0.1016(0.1854)
2023/09/18 14:12:14 - INFO - root -   Epoch: [187/400][80/346], lr: 0.00000037 	 loss = 0.0074(0.1991)
2023/09/18 14:12:57 - INFO - root -   Epoch: [187/400][100/346], lr: 0.00000037 	 loss = 0.2810(0.2000)
2023/09/18 14:13:57 - INFO - root -   Epoch: [187/400][120/346], lr: 0.00000037 	 loss = 0.0147(0.2367)
2023/09/18 14:14:41 - INFO - root -   Epoch: [187/400][140/346], lr: 0.00000037 	 loss = 0.1058(0.2477)
2023/09/18 14:15:41 - INFO - root -   Epoch: [187/400][160/346], lr: 0.00000037 	 loss = 0.0257(0.2582)
2023/09/18 14:16:24 - INFO - root -   Epoch: [187/400][180/346], lr: 0.00000037 	 loss = 0.0095(0.2823)
2023/09/18 14:17:25 - INFO - root -   Epoch: [187/400][200/346], lr: 0.00000037 	 loss = 0.0766(0.2701)
2023/09/18 14:18:08 - INFO - root -   Epoch: [187/400][220/346], lr: 0.00000037 	 loss = 0.5208(0.2697)
2023/09/18 14:19:09 - INFO - root -   Epoch: [187/400][240/346], lr: 0.00000037 	 loss = 0.0736(0.2696)
2023/09/18 14:19:52 - INFO - root -   Epoch: [187/400][260/346], lr: 0.00000037 	 loss = 0.0631(0.2640)
2023/09/18 14:20:53 - INFO - root -   Epoch: [187/400][280/346], lr: 0.00000037 	 loss = 0.0341(0.2747)
2023/09/18 14:21:36 - INFO - root -   Epoch: [187/400][300/346], lr: 0.00000037 	 loss = 0.0522(0.2689)
2023/09/18 14:22:37 - INFO - root -   Epoch: [187/400][320/346], lr: 0.00000037 	 loss = 0.1829(0.2651)
2023/09/18 14:23:19 - INFO - root -   Epoch: [187/400][340/346], lr: 0.00000037 	 loss = 1.1457(0.2638)
2023/09/18 14:23:23 - INFO - root -   Epoch: [187/400] 	 loss = 0.2736
2023/09/18 14:23:23 - INFO - root -   train_accuracy = 0.9003
2023/09/18 14:23:44 - INFO - root -   Epoch: [188/400][0/346], lr: 0.00000037 	 loss = 0.0632(0.0632)
2023/09/18 14:24:27 - INFO - root -   Epoch: [188/400][20/346], lr: 0.00000037 	 loss = 0.0122(0.2272)
2023/09/18 14:25:28 - INFO - root -   Epoch: [188/400][40/346], lr: 0.00000037 	 loss = 0.1359(0.2638)
2023/09/18 14:26:11 - INFO - root -   Epoch: [188/400][60/346], lr: 0.00000037 	 loss = 0.3575(0.2294)
2023/09/18 14:27:12 - INFO - root -   Epoch: [188/400][80/346], lr: 0.00000037 	 loss = 0.1359(0.2856)
2023/09/18 14:27:55 - INFO - root -   Epoch: [188/400][100/346], lr: 0.00000037 	 loss = 0.3885(0.3368)
2023/09/18 14:28:55 - INFO - root -   Epoch: [188/400][120/346], lr: 0.00000037 	 loss = 0.0999(0.3475)
2023/09/18 14:29:39 - INFO - root -   Epoch: [188/400][140/346], lr: 0.00000037 	 loss = 0.4213(0.3613)
2023/09/18 14:30:39 - INFO - root -   Epoch: [188/400][160/346], lr: 0.00000037 	 loss = 0.0041(0.3690)
2023/09/18 14:31:22 - INFO - root -   Epoch: [188/400][180/346], lr: 0.00000037 	 loss = 0.0504(0.3711)
2023/09/18 14:32:23 - INFO - root -   Epoch: [188/400][200/346], lr: 0.00000037 	 loss = 0.0126(0.3560)
2023/09/18 14:33:06 - INFO - root -   Epoch: [188/400][220/346], lr: 0.00000037 	 loss = 0.0923(0.3500)
2023/09/18 14:34:07 - INFO - root -   Epoch: [188/400][240/346], lr: 0.00000037 	 loss = 0.3622(0.3478)
2023/09/18 14:34:50 - INFO - root -   Epoch: [188/400][260/346], lr: 0.00000037 	 loss = 0.0709(0.3312)
2023/09/18 14:35:50 - INFO - root -   Epoch: [188/400][280/346], lr: 0.00000037 	 loss = 0.1757(0.3431)
2023/09/18 14:36:34 - INFO - root -   Epoch: [188/400][300/346], lr: 0.00000037 	 loss = 0.0444(0.3383)
2023/09/18 14:37:34 - INFO - root -   Epoch: [188/400][320/346], lr: 0.00000037 	 loss = 0.0050(0.3333)
2023/09/18 14:38:17 - INFO - root -   Epoch: [188/400][340/346], lr: 0.00000037 	 loss = 0.2197(0.3323)
2023/09/18 14:38:21 - INFO - root -   Epoch: [188/400] 	 loss = 0.3318
2023/09/18 14:38:21 - INFO - root -   train_accuracy = 0.8627
2023/09/18 14:38:43 - INFO - root -   Epoch: [189/400][0/346], lr: 0.00000037 	 loss = 0.0349(0.0349)
2023/09/18 14:39:26 - INFO - root -   Epoch: [189/400][20/346], lr: 0.00000037 	 loss = 0.0063(0.2168)
2023/09/18 14:40:27 - INFO - root -   Epoch: [189/400][40/346], lr: 0.00000037 	 loss = 0.0555(0.2936)
2023/09/18 14:41:10 - INFO - root -   Epoch: [189/400][60/346], lr: 0.00000037 	 loss = 0.1324(0.3012)
2023/09/18 14:42:12 - INFO - root -   Epoch: [189/400][80/346], lr: 0.00000037 	 loss = 0.0536(0.3036)
2023/09/18 14:42:55 - INFO - root -   Epoch: [189/400][100/346], lr: 0.00000037 	 loss = 0.2601(0.3114)
2023/09/18 14:43:56 - INFO - root -   Epoch: [189/400][120/346], lr: 0.00000037 	 loss = 0.0473(0.3160)
2023/09/18 14:44:39 - INFO - root -   Epoch: [189/400][140/346], lr: 0.00000037 	 loss = 0.1489(0.3210)
2023/09/18 14:45:40 - INFO - root -   Epoch: [189/400][160/346], lr: 0.00000037 	 loss = 0.0048(0.3283)
2023/09/18 14:46:23 - INFO - root -   Epoch: [189/400][180/346], lr: 0.00000037 	 loss = 0.0548(0.3261)
2023/09/18 14:47:24 - INFO - root -   Epoch: [189/400][200/346], lr: 0.00000037 	 loss = 0.0282(0.3109)
2023/09/18 14:48:07 - INFO - root -   Epoch: [189/400][220/346], lr: 0.00000037 	 loss = 0.0434(0.3035)
2023/09/18 14:49:08 - INFO - root -   Epoch: [189/400][240/346], lr: 0.00000037 	 loss = 0.0045(0.2988)
2023/09/18 14:49:51 - INFO - root -   Epoch: [189/400][260/346], lr: 0.00000037 	 loss = 0.1560(0.2840)
2023/09/18 14:50:52 - INFO - root -   Epoch: [189/400][280/346], lr: 0.00000037 	 loss = 0.0336(0.2851)
2023/09/18 14:51:35 - INFO - root -   Epoch: [189/400][300/346], lr: 0.00000037 	 loss = 0.0787(0.2828)
2023/09/18 14:52:36 - INFO - root -   Epoch: [189/400][320/346], lr: 0.00000037 	 loss = 0.0100(0.2753)
2023/09/18 14:53:18 - INFO - root -   Epoch: [189/400][340/346], lr: 0.00000037 	 loss = 1.1387(0.2695)
2023/09/18 14:53:22 - INFO - root -   Epoch: [189/400] 	 loss = 0.2750
2023/09/18 14:57:08 - INFO - root -   precision = 0.6897
2023/09/18 14:57:08 - INFO - root -   eval_loss = 0.8975
2023/09/18 14:57:10 - INFO - root -   train_accuracy = 0.8829
2023/09/18 14:57:31 - INFO - root -   Epoch: [190/400][0/346], lr: 0.00000037 	 loss = 0.1391(0.1391)
2023/09/18 14:58:14 - INFO - root -   Epoch: [190/400][20/346], lr: 0.00000037 	 loss = 0.0463(0.1943)
2023/09/18 14:59:16 - INFO - root -   Epoch: [190/400][40/346], lr: 0.00000037 	 loss = 0.1737(0.1994)
2023/09/18 14:59:59 - INFO - root -   Epoch: [190/400][60/346], lr: 0.00000037 	 loss = 0.1717(0.1949)
2023/09/18 15:01:00 - INFO - root -   Epoch: [190/400][80/346], lr: 0.00000037 	 loss = 0.0415(0.2108)
2023/09/18 15:01:44 - INFO - root -   Epoch: [190/400][100/346], lr: 0.00000037 	 loss = 0.1653(0.2014)
2023/09/18 15:02:45 - INFO - root -   Epoch: [190/400][120/346], lr: 0.00000037 	 loss = 0.0154(0.2036)
2023/09/18 15:03:28 - INFO - root -   Epoch: [190/400][140/346], lr: 0.00000037 	 loss = 0.1194(0.2125)
2023/09/18 15:04:29 - INFO - root -   Epoch: [190/400][160/346], lr: 0.00000037 	 loss = 0.0307(0.2195)
2023/09/18 15:05:13 - INFO - root -   Epoch: [190/400][180/346], lr: 0.00000037 	 loss = 0.0178(0.2336)
2023/09/18 15:06:13 - INFO - root -   Epoch: [190/400][200/346], lr: 0.00000037 	 loss = 0.0208(0.2284)
2023/09/18 15:06:58 - INFO - root -   Epoch: [190/400][220/346], lr: 0.00000037 	 loss = 0.0228(0.2283)
2023/09/18 15:07:58 - INFO - root -   Epoch: [190/400][240/346], lr: 0.00000037 	 loss = 0.0012(0.2329)
2023/09/18 15:08:42 - INFO - root -   Epoch: [190/400][260/346], lr: 0.00000037 	 loss = 0.3628(0.2233)
2023/09/18 15:09:42 - INFO - root -   Epoch: [190/400][280/346], lr: 0.00000037 	 loss = 0.2084(0.2453)
2023/09/18 15:10:27 - INFO - root -   Epoch: [190/400][300/346], lr: 0.00000037 	 loss = 0.0321(0.2504)
2023/09/18 15:11:27 - INFO - root -   Epoch: [190/400][320/346], lr: 0.00000037 	 loss = 0.0426(0.2594)
2023/09/18 15:12:10 - INFO - root -   Epoch: [190/400][340/346], lr: 0.00000037 	 loss = 0.7066(0.2624)
2023/09/18 15:12:14 - INFO - root -   Epoch: [190/400] 	 loss = 0.2653
2023/09/18 15:12:14 - INFO - root -   train_accuracy = 0.8974
2023/09/18 15:12:36 - INFO - root -   Epoch: [191/400][0/346], lr: 0.00000037 	 loss = 0.0209(0.0209)
2023/09/18 15:13:19 - INFO - root -   Epoch: [191/400][20/346], lr: 0.00000037 	 loss = 0.1017(0.1886)
2023/09/18 15:14:19 - INFO - root -   Epoch: [191/400][40/346], lr: 0.00000037 	 loss = 0.3386(0.2238)
2023/09/18 15:15:02 - INFO - root -   Epoch: [191/400][60/346], lr: 0.00000037 	 loss = 0.0402(0.1945)
2023/09/18 15:16:03 - INFO - root -   Epoch: [191/400][80/346], lr: 0.00000037 	 loss = 0.0677(0.2358)
2023/09/18 15:16:46 - INFO - root -   Epoch: [191/400][100/346], lr: 0.00000037 	 loss = 0.0454(0.2307)
2023/09/18 15:17:46 - INFO - root -   Epoch: [191/400][120/346], lr: 0.00000037 	 loss = 0.0252(0.2393)
2023/09/18 15:18:30 - INFO - root -   Epoch: [191/400][140/346], lr: 0.00000037 	 loss = 0.2487(0.2337)
2023/09/18 15:19:30 - INFO - root -   Epoch: [191/400][160/346], lr: 0.00000037 	 loss = 0.0077(0.2460)
2023/09/18 15:20:13 - INFO - root -   Epoch: [191/400][180/346], lr: 0.00000037 	 loss = 0.0896(0.2457)
2023/09/18 15:21:13 - INFO - root -   Epoch: [191/400][200/346], lr: 0.00000037 	 loss = 0.1176(0.2345)
2023/09/18 15:21:56 - INFO - root -   Epoch: [191/400][220/346], lr: 0.00000037 	 loss = 0.1436(0.2365)
2023/09/18 15:22:57 - INFO - root -   Epoch: [191/400][240/346], lr: 0.00000037 	 loss = 0.0139(0.2376)
2023/09/18 15:23:40 - INFO - root -   Epoch: [191/400][260/346], lr: 0.00000037 	 loss = 0.1446(0.2268)
2023/09/18 15:24:40 - INFO - root -   Epoch: [191/400][280/346], lr: 0.00000037 	 loss = 0.0130(0.2366)
2023/09/18 15:25:23 - INFO - root -   Epoch: [191/400][300/346], lr: 0.00000037 	 loss = 0.0755(0.2339)
2023/09/18 15:26:23 - INFO - root -   Epoch: [191/400][320/346], lr: 0.00000037 	 loss = 0.1670(0.2397)
2023/09/18 15:27:05 - INFO - root -   Epoch: [191/400][340/346], lr: 0.00000037 	 loss = 0.7043(0.2372)
2023/09/18 15:27:09 - INFO - root -   Epoch: [191/400] 	 loss = 0.2422
2023/09/18 15:27:09 - INFO - root -   train_accuracy = 0.8988
2023/09/18 15:27:30 - INFO - root -   Epoch: [192/400][0/346], lr: 0.00000037 	 loss = 0.0287(0.0287)
2023/09/18 15:28:13 - INFO - root -   Epoch: [192/400][20/346], lr: 0.00000037 	 loss = 0.0838(0.2640)
2023/09/18 15:29:14 - INFO - root -   Epoch: [192/400][40/346], lr: 0.00000037 	 loss = 0.0789(0.2441)
2023/09/18 15:29:57 - INFO - root -   Epoch: [192/400][60/346], lr: 0.00000037 	 loss = 0.4282(0.2299)
2023/09/18 15:30:57 - INFO - root -   Epoch: [192/400][80/346], lr: 0.00000037 	 loss = 0.0082(0.2621)
2023/09/18 15:31:41 - INFO - root -   Epoch: [192/400][100/346], lr: 0.00000037 	 loss = 0.2382(0.2848)
2023/09/18 15:32:41 - INFO - root -   Epoch: [192/400][120/346], lr: 0.00000037 	 loss = 0.0305(0.2875)
2023/09/18 15:33:24 - INFO - root -   Epoch: [192/400][140/346], lr: 0.00000037 	 loss = 0.0530(0.2811)
2023/09/18 15:34:24 - INFO - root -   Epoch: [192/400][160/346], lr: 0.00000037 	 loss = 0.0785(0.2980)
2023/09/18 15:35:07 - INFO - root -   Epoch: [192/400][180/346], lr: 0.00000037 	 loss = 0.0067(0.2896)
2023/09/18 15:36:08 - INFO - root -   Epoch: [192/400][200/346], lr: 0.00000037 	 loss = 0.0097(0.2741)
2023/09/18 15:36:51 - INFO - root -   Epoch: [192/400][220/346], lr: 0.00000037 	 loss = 0.0356(0.2599)
2023/09/18 15:37:51 - INFO - root -   Epoch: [192/400][240/346], lr: 0.00000037 	 loss = 0.1142(0.2527)
2023/09/18 15:38:34 - INFO - root -   Epoch: [192/400][260/346], lr: 0.00000037 	 loss = 0.7489(0.2575)
2023/09/18 15:39:34 - INFO - root -   Epoch: [192/400][280/346], lr: 0.00000037 	 loss = 0.0336(0.2733)
2023/09/18 15:40:17 - INFO - root -   Epoch: [192/400][300/346], lr: 0.00000037 	 loss = 0.2478(0.2698)
2023/09/18 15:41:17 - INFO - root -   Epoch: [192/400][320/346], lr: 0.00000037 	 loss = 0.0142(0.2666)
2023/09/18 15:41:59 - INFO - root -   Epoch: [192/400][340/346], lr: 0.00000037 	 loss = 0.2884(0.2603)
2023/09/18 15:42:03 - INFO - root -   Epoch: [192/400] 	 loss = 0.2599
2023/09/18 15:42:03 - INFO - root -   train_accuracy = 0.9017
2023/09/18 15:42:24 - INFO - root -   Epoch: [193/400][0/346], lr: 0.00000038 	 loss = 0.1395(0.1395)
2023/09/18 15:43:07 - INFO - root -   Epoch: [193/400][20/346], lr: 0.00000038 	 loss = 0.0049(0.2180)
2023/09/18 15:44:08 - INFO - root -   Epoch: [193/400][40/346], lr: 0.00000038 	 loss = 0.0230(0.2778)
2023/09/18 15:44:51 - INFO - root -   Epoch: [193/400][60/346], lr: 0.00000038 	 loss = 0.1974(0.2282)
2023/09/18 15:45:52 - INFO - root -   Epoch: [193/400][80/346], lr: 0.00000038 	 loss = 0.0174(0.2665)
2023/09/18 15:46:35 - INFO - root -   Epoch: [193/400][100/346], lr: 0.00000038 	 loss = 0.2547(0.2506)
2023/09/18 15:47:35 - INFO - root -   Epoch: [193/400][120/346], lr: 0.00000038 	 loss = 0.0165(0.2526)
2023/09/18 15:48:18 - INFO - root -   Epoch: [193/400][140/346], lr: 0.00000038 	 loss = 0.0382(0.2434)
2023/09/18 15:49:19 - INFO - root -   Epoch: [193/400][160/346], lr: 0.00000038 	 loss = 0.0571(0.2449)
2023/09/18 15:50:02 - INFO - root -   Epoch: [193/400][180/346], lr: 0.00000038 	 loss = 0.0080(0.2413)
2023/09/18 15:51:02 - INFO - root -   Epoch: [193/400][200/346], lr: 0.00000038 	 loss = 0.0035(0.2294)
2023/09/18 15:51:45 - INFO - root -   Epoch: [193/400][220/346], lr: 0.00000038 	 loss = 0.0355(0.2302)
2023/09/18 15:52:45 - INFO - root -   Epoch: [193/400][240/346], lr: 0.00000038 	 loss = 0.0019(0.2238)
2023/09/18 15:53:28 - INFO - root -   Epoch: [193/400][260/346], lr: 0.00000038 	 loss = 0.0136(0.2122)
2023/09/18 15:54:29 - INFO - root -   Epoch: [193/400][280/346], lr: 0.00000038 	 loss = 0.0027(0.2263)
2023/09/18 15:55:12 - INFO - root -   Epoch: [193/400][300/346], lr: 0.00000038 	 loss = 0.1132(0.2318)
2023/09/18 15:56:12 - INFO - root -   Epoch: [193/400][320/346], lr: 0.00000038 	 loss = 0.2332(0.2328)
2023/09/18 15:56:54 - INFO - root -   Epoch: [193/400][340/346], lr: 0.00000038 	 loss = 0.1910(0.2286)
2023/09/18 15:56:58 - INFO - root -   Epoch: [193/400] 	 loss = 0.2316
2023/09/18 15:56:58 - INFO - root -   train_accuracy = 0.9090
2023/09/18 15:57:20 - INFO - root -   Epoch: [194/400][0/346], lr: 0.00000038 	 loss = 0.0482(0.0482)
2023/09/18 15:58:03 - INFO - root -   Epoch: [194/400][20/346], lr: 0.00000038 	 loss = 0.0105(0.2271)
2023/09/18 15:59:05 - INFO - root -   Epoch: [194/400][40/346], lr: 0.00000038 	 loss = 0.2184(0.2247)
2023/09/18 15:59:49 - INFO - root -   Epoch: [194/400][60/346], lr: 0.00000038 	 loss = 0.0477(0.2529)
2023/09/18 16:00:50 - INFO - root -   Epoch: [194/400][80/346], lr: 0.00000038 	 loss = 0.0077(0.2337)
2023/09/18 16:01:34 - INFO - root -   Epoch: [194/400][100/346], lr: 0.00000038 	 loss = 0.6899(0.2164)
2023/09/18 16:02:35 - INFO - root -   Epoch: [194/400][120/346], lr: 0.00000038 	 loss = 0.0320(0.2366)
2023/09/18 16:03:18 - INFO - root -   Epoch: [194/400][140/346], lr: 0.00000038 	 loss = 0.2295(0.2411)
2023/09/18 16:04:19 - INFO - root -   Epoch: [194/400][160/346], lr: 0.00000038 	 loss = 0.0228(0.2516)
2023/09/18 16:05:02 - INFO - root -   Epoch: [194/400][180/346], lr: 0.00000038 	 loss = 0.1067(0.2475)
2023/09/18 16:06:03 - INFO - root -   Epoch: [194/400][200/346], lr: 0.00000038 	 loss = 0.0341(0.2434)
2023/09/18 16:06:47 - INFO - root -   Epoch: [194/400][220/346], lr: 0.00000038 	 loss = 0.2209(0.2438)
2023/09/18 16:07:47 - INFO - root -   Epoch: [194/400][240/346], lr: 0.00000038 	 loss = 0.1611(0.2340)
2023/09/18 16:08:33 - INFO - root -   Epoch: [194/400][260/346], lr: 0.00000038 	 loss = 0.6643(0.2367)
2023/09/18 16:09:31 - INFO - root -   Epoch: [194/400][280/346], lr: 0.00000038 	 loss = 0.1211(0.2472)
2023/09/18 16:10:17 - INFO - root -   Epoch: [194/400][300/346], lr: 0.00000038 	 loss = 0.0523(0.2666)
2023/09/18 16:11:16 - INFO - root -   Epoch: [194/400][320/346], lr: 0.00000038 	 loss = 0.2648(0.2684)
2023/09/18 16:12:01 - INFO - root -   Epoch: [194/400][340/346], lr: 0.00000038 	 loss = 0.3077(0.2691)
2023/09/18 16:12:04 - INFO - root -   Epoch: [194/400] 	 loss = 0.2690
2023/09/18 16:15:52 - INFO - root -   precision = 0.7011
2023/09/18 16:15:52 - INFO - root -   eval_loss = 0.9287
2023/09/18 16:15:53 - INFO - root -   train_accuracy = 0.8815
2023/09/18 16:16:15 - INFO - root -   Epoch: [195/400][0/346], lr: 0.00000038 	 loss = 0.2143(0.2143)
2023/09/18 16:16:58 - INFO - root -   Epoch: [195/400][20/346], lr: 0.00000038 	 loss = 0.0031(0.2177)
2023/09/18 16:17:58 - INFO - root -   Epoch: [195/400][40/346], lr: 0.00000038 	 loss = 0.3200(0.2185)
2023/09/18 16:18:41 - INFO - root -   Epoch: [195/400][60/346], lr: 0.00000038 	 loss = 0.2944(0.2029)
2023/09/18 16:19:42 - INFO - root -   Epoch: [195/400][80/346], lr: 0.00000038 	 loss = 0.0401(0.2450)
2023/09/18 16:20:25 - INFO - root -   Epoch: [195/400][100/346], lr: 0.00000038 	 loss = 0.4202(0.2354)
2023/09/18 16:21:25 - INFO - root -   Epoch: [195/400][120/346], lr: 0.00000038 	 loss = 0.0102(0.2473)
2023/09/18 16:22:08 - INFO - root -   Epoch: [195/400][140/346], lr: 0.00000038 	 loss = 0.0679(0.2447)
2023/09/18 16:23:08 - INFO - root -   Epoch: [195/400][160/346], lr: 0.00000038 	 loss = 0.0028(0.2538)
2023/09/18 16:23:51 - INFO - root -   Epoch: [195/400][180/346], lr: 0.00000038 	 loss = 0.0736(0.2590)
2023/09/18 16:24:51 - INFO - root -   Epoch: [195/400][200/346], lr: 0.00000038 	 loss = 0.0051(0.2424)
2023/09/18 16:25:34 - INFO - root -   Epoch: [195/400][220/346], lr: 0.00000038 	 loss = 0.2715(0.2497)
2023/09/18 16:26:34 - INFO - root -   Epoch: [195/400][240/346], lr: 0.00000038 	 loss = 0.0054(0.2630)
2023/09/18 16:27:17 - INFO - root -   Epoch: [195/400][260/346], lr: 0.00000038 	 loss = 0.2137(0.2528)
2023/09/18 16:28:17 - INFO - root -   Epoch: [195/400][280/346], lr: 0.00000038 	 loss = 0.1652(0.2659)
2023/09/18 16:29:00 - INFO - root -   Epoch: [195/400][300/346], lr: 0.00000038 	 loss = 0.0366(0.2613)
2023/09/18 16:30:00 - INFO - root -   Epoch: [195/400][320/346], lr: 0.00000038 	 loss = 0.0683(0.2604)
2023/09/18 16:30:43 - INFO - root -   Epoch: [195/400][340/346], lr: 0.00000038 	 loss = 0.4299(0.2645)
2023/09/18 16:30:46 - INFO - root -   Epoch: [195/400] 	 loss = 0.2639
2023/09/18 16:30:46 - INFO - root -   train_accuracy = 0.8873
2023/09/18 16:31:08 - INFO - root -   Epoch: [196/400][0/346], lr: 0.00000038 	 loss = 0.0295(0.0295)
2023/09/18 16:31:51 - INFO - root -   Epoch: [196/400][20/346], lr: 0.00000038 	 loss = 0.0449(0.2757)
2023/09/18 16:32:52 - INFO - root -   Epoch: [196/400][40/346], lr: 0.00000038 	 loss = 0.5471(0.3038)
2023/09/18 16:33:35 - INFO - root -   Epoch: [196/400][60/346], lr: 0.00000038 	 loss = 0.2402(0.3536)
2023/09/18 16:34:35 - INFO - root -   Epoch: [196/400][80/346], lr: 0.00000038 	 loss = 0.1759(0.3159)
2023/09/18 16:35:19 - INFO - root -   Epoch: [196/400][100/346], lr: 0.00000038 	 loss = 0.4880(0.2972)
2023/09/18 16:36:19 - INFO - root -   Epoch: [196/400][120/346], lr: 0.00000038 	 loss = 0.0216(0.2872)
2023/09/18 16:37:02 - INFO - root -   Epoch: [196/400][140/346], lr: 0.00000038 	 loss = 0.3393(0.2722)
2023/09/18 16:38:03 - INFO - root -   Epoch: [196/400][160/346], lr: 0.00000038 	 loss = 0.0071(0.2686)
2023/09/18 16:38:46 - INFO - root -   Epoch: [196/400][180/346], lr: 0.00000038 	 loss = 0.0216(0.2667)
2023/09/18 16:39:46 - INFO - root -   Epoch: [196/400][200/346], lr: 0.00000038 	 loss = 0.0040(0.2539)
2023/09/18 16:40:29 - INFO - root -   Epoch: [196/400][220/346], lr: 0.00000038 	 loss = 0.0468(0.2578)
2023/09/18 16:41:29 - INFO - root -   Epoch: [196/400][240/346], lr: 0.00000038 	 loss = 0.0113(0.2586)
2023/09/18 16:42:12 - INFO - root -   Epoch: [196/400][260/346], lr: 0.00000038 	 loss = 0.0896(0.2522)
2023/09/18 16:43:13 - INFO - root -   Epoch: [196/400][280/346], lr: 0.00000038 	 loss = 0.0071(0.2616)
2023/09/18 16:43:56 - INFO - root -   Epoch: [196/400][300/346], lr: 0.00000038 	 loss = 0.1059(0.2543)
2023/09/18 16:44:56 - INFO - root -   Epoch: [196/400][320/346], lr: 0.00000038 	 loss = 0.0118(0.2546)
2023/09/18 16:45:38 - INFO - root -   Epoch: [196/400][340/346], lr: 0.00000038 	 loss = 1.2242(0.2544)
2023/09/18 16:45:42 - INFO - root -   Epoch: [196/400] 	 loss = 0.2560
2023/09/18 16:45:42 - INFO - root -   train_accuracy = 0.8815
2023/09/18 16:46:04 - INFO - root -   Epoch: [197/400][0/346], lr: 0.00000038 	 loss = 0.1083(0.1083)
2023/09/18 16:46:47 - INFO - root -   Epoch: [197/400][20/346], lr: 0.00000038 	 loss = 0.0034(0.1987)
2023/09/18 16:47:48 - INFO - root -   Epoch: [197/400][40/346], lr: 0.00000038 	 loss = 0.0560(0.2165)
2023/09/18 16:48:31 - INFO - root -   Epoch: [197/400][60/346], lr: 0.00000038 	 loss = 0.0812(0.2007)
2023/09/18 16:49:32 - INFO - root -   Epoch: [197/400][80/346], lr: 0.00000038 	 loss = 0.0661(0.2053)
2023/09/18 16:50:15 - INFO - root -   Epoch: [197/400][100/346], lr: 0.00000038 	 loss = 0.1575(0.2002)
2023/09/18 16:51:16 - INFO - root -   Epoch: [197/400][120/346], lr: 0.00000038 	 loss = 0.0452(0.1945)
2023/09/18 16:51:59 - INFO - root -   Epoch: [197/400][140/346], lr: 0.00000038 	 loss = 0.4269(0.2134)
2023/09/18 16:52:59 - INFO - root -   Epoch: [197/400][160/346], lr: 0.00000038 	 loss = 0.0148(0.2154)
2023/09/18 16:53:42 - INFO - root -   Epoch: [197/400][180/346], lr: 0.00000038 	 loss = 0.0255(0.2106)
2023/09/18 16:54:43 - INFO - root -   Epoch: [197/400][200/346], lr: 0.00000038 	 loss = 0.0081(0.2021)
2023/09/18 16:55:26 - INFO - root -   Epoch: [197/400][220/346], lr: 0.00000038 	 loss = 0.0887(0.2037)
2023/09/18 16:56:27 - INFO - root -   Epoch: [197/400][240/346], lr: 0.00000038 	 loss = 0.0049(0.1964)
2023/09/18 16:57:10 - INFO - root -   Epoch: [197/400][260/346], lr: 0.00000038 	 loss = 0.0324(0.1846)
2023/09/18 16:58:10 - INFO - root -   Epoch: [197/400][280/346], lr: 0.00000038 	 loss = 0.0133(0.2016)
2023/09/18 16:58:53 - INFO - root -   Epoch: [197/400][300/346], lr: 0.00000038 	 loss = 0.0197(0.1985)
2023/09/18 16:59:54 - INFO - root -   Epoch: [197/400][320/346], lr: 0.00000038 	 loss = 0.0015(0.1976)
2023/09/18 17:00:36 - INFO - root -   Epoch: [197/400][340/346], lr: 0.00000038 	 loss = 0.3515(0.2025)
2023/09/18 17:00:41 - INFO - root -   Epoch: [197/400] 	 loss = 0.2082
2023/09/18 17:00:41 - INFO - root -   train_accuracy = 0.9263
2023/09/18 17:01:02 - INFO - root -   Epoch: [198/400][0/346], lr: 0.00000038 	 loss = 0.0358(0.0358)
2023/09/18 17:01:45 - INFO - root -   Epoch: [198/400][20/346], lr: 0.00000038 	 loss = 0.0025(0.1738)
2023/09/18 17:02:46 - INFO - root -   Epoch: [198/400][40/346], lr: 0.00000038 	 loss = 0.5856(0.1532)
2023/09/18 17:03:29 - INFO - root -   Epoch: [198/400][60/346], lr: 0.00000038 	 loss = 0.0778(0.1660)
2023/09/18 17:04:30 - INFO - root -   Epoch: [198/400][80/346], lr: 0.00000038 	 loss = 0.0070(0.2101)
2023/09/18 17:05:13 - INFO - root -   Epoch: [198/400][100/346], lr: 0.00000038 	 loss = 1.2970(0.2472)
2023/09/18 17:06:13 - INFO - root -   Epoch: [198/400][120/346], lr: 0.00000038 	 loss = 0.0110(0.2620)
2023/09/18 17:06:56 - INFO - root -   Epoch: [198/400][140/346], lr: 0.00000038 	 loss = 0.1155(0.2651)
2023/09/18 17:07:57 - INFO - root -   Epoch: [198/400][160/346], lr: 0.00000038 	 loss = 0.0406(0.2680)
2023/09/18 17:08:40 - INFO - root -   Epoch: [198/400][180/346], lr: 0.00000038 	 loss = 0.0077(0.2641)
2023/09/18 17:09:40 - INFO - root -   Epoch: [198/400][200/346], lr: 0.00000038 	 loss = 0.0045(0.2568)
2023/09/18 17:10:24 - INFO - root -   Epoch: [198/400][220/346], lr: 0.00000038 	 loss = 0.7009(0.2593)
2023/09/18 17:11:24 - INFO - root -   Epoch: [198/400][240/346], lr: 0.00000038 	 loss = 0.0041(0.2502)
2023/09/18 17:12:07 - INFO - root -   Epoch: [198/400][260/346], lr: 0.00000038 	 loss = 0.0499(0.2407)
2023/09/18 17:13:08 - INFO - root -   Epoch: [198/400][280/346], lr: 0.00000038 	 loss = 0.0126(0.2438)
2023/09/18 17:13:51 - INFO - root -   Epoch: [198/400][300/346], lr: 0.00000038 	 loss = 0.0450(0.2501)
2023/09/18 17:14:52 - INFO - root -   Epoch: [198/400][320/346], lr: 0.00000038 	 loss = 0.3545(0.2462)
2023/09/18 17:15:34 - INFO - root -   Epoch: [198/400][340/346], lr: 0.00000038 	 loss = 1.4974(0.2445)
2023/09/18 17:15:38 - INFO - root -   Epoch: [198/400] 	 loss = 0.2462
2023/09/18 17:15:38 - INFO - root -   train_accuracy = 0.8815
2023/09/18 17:16:00 - INFO - root -   Epoch: [199/400][0/346], lr: 0.00000038 	 loss = 0.0965(0.0965)
2023/09/18 17:16:43 - INFO - root -   Epoch: [199/400][20/346], lr: 0.00000038 	 loss = 0.0216(0.2087)
2023/09/18 17:17:45 - INFO - root -   Epoch: [199/400][40/346], lr: 0.00000038 	 loss = 0.0108(0.1920)
2023/09/18 17:18:29 - INFO - root -   Epoch: [199/400][60/346], lr: 0.00000038 	 loss = 0.1509(0.1868)
2023/09/18 17:19:31 - INFO - root -   Epoch: [199/400][80/346], lr: 0.00000038 	 loss = 0.0160(0.1955)
2023/09/18 17:20:14 - INFO - root -   Epoch: [199/400][100/346], lr: 0.00000038 	 loss = 0.0887(0.1920)
2023/09/18 17:21:16 - INFO - root -   Epoch: [199/400][120/346], lr: 0.00000038 	 loss = 0.0386(0.1883)
2023/09/18 17:21:59 - INFO - root -   Epoch: [199/400][140/346], lr: 0.00000038 	 loss = 0.1439(0.1946)
2023/09/18 17:23:00 - INFO - root -   Epoch: [199/400][160/346], lr: 0.00000038 	 loss = 0.0239(0.1959)
2023/09/18 17:23:44 - INFO - root -   Epoch: [199/400][180/346], lr: 0.00000038 	 loss = 0.1190(0.1999)
2023/09/18 17:24:45 - INFO - root -   Epoch: [199/400][200/346], lr: 0.00000038 	 loss = 0.0160(0.1950)
2023/09/18 17:25:29 - INFO - root -   Epoch: [199/400][220/346], lr: 0.00000038 	 loss = 0.5138(0.1945)
2023/09/18 17:26:30 - INFO - root -   Epoch: [199/400][240/346], lr: 0.00000038 	 loss = 0.0085(0.1864)
2023/09/18 17:27:14 - INFO - root -   Epoch: [199/400][260/346], lr: 0.00000038 	 loss = 0.0439(0.1866)
2023/09/18 17:28:15 - INFO - root -   Epoch: [199/400][280/346], lr: 0.00000038 	 loss = 0.0044(0.2002)
2023/09/18 17:28:59 - INFO - root -   Epoch: [199/400][300/346], lr: 0.00000038 	 loss = 0.0386(0.1982)
2023/09/18 17:30:00 - INFO - root -   Epoch: [199/400][320/346], lr: 0.00000038 	 loss = 0.0146(0.2007)
2023/09/18 17:30:42 - INFO - root -   Epoch: [199/400][340/346], lr: 0.00000038 	 loss = 1.0159(0.2010)
2023/09/18 17:30:47 - INFO - root -   Epoch: [199/400] 	 loss = 0.2064
2023/09/18 17:34:34 - INFO - root -   precision = 0.6609
2023/09/18 17:34:34 - INFO - root -   eval_loss = 0.9743
2023/09/18 17:34:35 - INFO - root -   train_accuracy = 0.9176
2023/09/18 17:34:56 - INFO - root -   Epoch: [200/400][0/346], lr: 0.00000039 	 loss = 0.0142(0.0142)
2023/09/18 17:35:39 - INFO - root -   Epoch: [200/400][20/346], lr: 0.00000039 	 loss = 0.0073(0.2929)
2023/09/18 17:36:40 - INFO - root -   Epoch: [200/400][40/346], lr: 0.00000039 	 loss = 0.0260(0.2690)
2023/09/18 17:37:23 - INFO - root -   Epoch: [200/400][60/346], lr: 0.00000039 	 loss = 0.0482(0.2720)
2023/09/18 17:38:23 - INFO - root -   Epoch: [200/400][80/346], lr: 0.00000039 	 loss = 0.2477(0.2379)
2023/09/18 17:39:06 - INFO - root -   Epoch: [200/400][100/346], lr: 0.00000039 	 loss = 0.3934(0.2481)
2023/09/18 17:40:06 - INFO - root -   Epoch: [200/400][120/346], lr: 0.00000039 	 loss = 0.0098(0.2713)
2023/09/18 17:40:49 - INFO - root -   Epoch: [200/400][140/346], lr: 0.00000039 	 loss = 0.1974(0.2461)
2023/09/18 17:41:49 - INFO - root -   Epoch: [200/400][160/346], lr: 0.00000039 	 loss = 0.0958(0.2599)
2023/09/18 17:42:32 - INFO - root -   Epoch: [200/400][180/346], lr: 0.00000039 	 loss = 0.0211(0.2673)
2023/09/18 17:43:32 - INFO - root -   Epoch: [200/400][200/346], lr: 0.00000039 	 loss = 0.0365(0.2602)
2023/09/18 17:44:16 - INFO - root -   Epoch: [200/400][220/346], lr: 0.00000039 	 loss = 0.0229(0.2558)
2023/09/18 17:45:16 - INFO - root -   Epoch: [200/400][240/346], lr: 0.00000039 	 loss = 0.0277(0.2591)
2023/09/18 17:45:59 - INFO - root -   Epoch: [200/400][260/346], lr: 0.00000039 	 loss = 0.1004(0.2527)
2023/09/18 17:46:59 - INFO - root -   Epoch: [200/400][280/346], lr: 0.00000039 	 loss = 0.0057(0.2590)
2023/09/18 17:47:42 - INFO - root -   Epoch: [200/400][300/346], lr: 0.00000039 	 loss = 0.0373(0.2512)
2023/09/18 17:48:43 - INFO - root -   Epoch: [200/400][320/346], lr: 0.00000039 	 loss = 0.0035(0.2411)
2023/09/18 17:49:25 - INFO - root -   Epoch: [200/400][340/346], lr: 0.00000039 	 loss = 0.3095(0.2352)
2023/09/18 17:49:29 - INFO - root -   Epoch: [200/400] 	 loss = 0.2341
2023/09/18 17:49:29 - INFO - root -   train_accuracy = 0.9003
2023/09/18 17:49:50 - INFO - root -   Epoch: [201/400][0/346], lr: 0.00000039 	 loss = 0.0163(0.0163)
2023/09/18 17:50:33 - INFO - root -   Epoch: [201/400][20/346], lr: 0.00000039 	 loss = 0.0050(0.0999)
2023/09/18 17:51:34 - INFO - root -   Epoch: [201/400][40/346], lr: 0.00000039 	 loss = 0.0332(0.1153)
2023/09/18 17:52:17 - INFO - root -   Epoch: [201/400][60/346], lr: 0.00000039 	 loss = 0.0161(0.1203)
2023/09/18 17:53:17 - INFO - root -   Epoch: [201/400][80/346], lr: 0.00000039 	 loss = 0.0220(0.1257)
2023/09/18 17:54:00 - INFO - root -   Epoch: [201/400][100/346], lr: 0.00000039 	 loss = 0.6771(0.1357)
2023/09/18 17:55:01 - INFO - root -   Epoch: [201/400][120/346], lr: 0.00000039 	 loss = 0.0022(0.1416)
2023/09/18 17:55:44 - INFO - root -   Epoch: [201/400][140/346], lr: 0.00000039 	 loss = 1.6829(0.1635)
2023/09/18 17:56:44 - INFO - root -   Epoch: [201/400][160/346], lr: 0.00000039 	 loss = 0.0450(0.1761)
2023/09/18 17:57:27 - INFO - root -   Epoch: [201/400][180/346], lr: 0.00000039 	 loss = 0.0084(0.1699)
2023/09/18 17:58:27 - INFO - root -   Epoch: [201/400][200/346], lr: 0.00000039 	 loss = 0.0007(0.1632)
2023/09/18 17:59:10 - INFO - root -   Epoch: [201/400][220/346], lr: 0.00000039 	 loss = 0.1123(0.1664)
2023/09/18 18:00:10 - INFO - root -   Epoch: [201/400][240/346], lr: 0.00000039 	 loss = 0.0123(0.1892)
2023/09/18 18:00:53 - INFO - root -   Epoch: [201/400][260/346], lr: 0.00000039 	 loss = 0.0759(0.1886)
2023/09/18 18:01:54 - INFO - root -   Epoch: [201/400][280/346], lr: 0.00000039 	 loss = 0.0251(0.2104)
2023/09/18 18:02:36 - INFO - root -   Epoch: [201/400][300/346], lr: 0.00000039 	 loss = 0.1156(0.2113)
2023/09/18 18:03:37 - INFO - root -   Epoch: [201/400][320/346], lr: 0.00000039 	 loss = 0.0182(0.2091)
2023/09/18 18:04:19 - INFO - root -   Epoch: [201/400][340/346], lr: 0.00000039 	 loss = 0.6348(0.2060)
2023/09/18 18:04:23 - INFO - root -   Epoch: [201/400] 	 loss = 0.2097
2023/09/18 18:04:23 - INFO - root -   train_accuracy = 0.9075
2023/09/18 18:04:45 - INFO - root -   Epoch: [202/400][0/346], lr: 0.00000039 	 loss = 0.1914(0.1914)
2023/09/18 18:05:27 - INFO - root -   Epoch: [202/400][20/346], lr: 0.00000039 	 loss = 0.0100(0.1658)
2023/09/18 18:06:28 - INFO - root -   Epoch: [202/400][40/346], lr: 0.00000039 	 loss = 0.3394(0.1918)
2023/09/18 18:07:11 - INFO - root -   Epoch: [202/400][60/346], lr: 0.00000039 	 loss = 0.0303(0.1634)
2023/09/18 18:08:11 - INFO - root -   Epoch: [202/400][80/346], lr: 0.00000039 	 loss = 0.0038(0.1675)
2023/09/18 18:08:55 - INFO - root -   Epoch: [202/400][100/346], lr: 0.00000039 	 loss = 0.4990(0.1686)
2023/09/18 18:09:55 - INFO - root -   Epoch: [202/400][120/346], lr: 0.00000039 	 loss = 0.0063(0.2047)
2023/09/18 18:10:38 - INFO - root -   Epoch: [202/400][140/346], lr: 0.00000039 	 loss = 0.0048(0.1962)
2023/09/18 18:11:39 - INFO - root -   Epoch: [202/400][160/346], lr: 0.00000039 	 loss = 0.0938(0.2013)
2023/09/18 18:12:22 - INFO - root -   Epoch: [202/400][180/346], lr: 0.00000039 	 loss = 0.0142(0.2134)
2023/09/18 18:13:22 - INFO - root -   Epoch: [202/400][200/346], lr: 0.00000039 	 loss = 0.0065(0.1992)
2023/09/18 18:14:05 - INFO - root -   Epoch: [202/400][220/346], lr: 0.00000039 	 loss = 0.0224(0.1985)
2023/09/18 18:15:05 - INFO - root -   Epoch: [202/400][240/346], lr: 0.00000039 	 loss = 0.0246(0.1941)
2023/09/18 18:15:49 - INFO - root -   Epoch: [202/400][260/346], lr: 0.00000039 	 loss = 0.0147(0.1991)
2023/09/18 18:16:49 - INFO - root -   Epoch: [202/400][280/346], lr: 0.00000039 	 loss = 0.0045(0.2109)
2023/09/18 18:17:33 - INFO - root -   Epoch: [202/400][300/346], lr: 0.00000039 	 loss = 0.1614(0.2123)
2023/09/18 18:18:32 - INFO - root -   Epoch: [202/400][320/346], lr: 0.00000039 	 loss = 0.0028(0.2174)
2023/09/18 18:19:15 - INFO - root -   Epoch: [202/400][340/346], lr: 0.00000039 	 loss = 0.6391(0.2121)
2023/09/18 18:19:19 - INFO - root -   Epoch: [202/400] 	 loss = 0.2130
2023/09/18 18:19:19 - INFO - root -   train_accuracy = 0.9118
2023/09/18 18:19:40 - INFO - root -   Epoch: [203/400][0/346], lr: 0.00000039 	 loss = 0.0070(0.0070)
2023/09/18 18:20:23 - INFO - root -   Epoch: [203/400][20/346], lr: 0.00000039 	 loss = 0.0286(0.1384)
2023/09/18 18:21:24 - INFO - root -   Epoch: [203/400][40/346], lr: 0.00000039 	 loss = 0.0109(0.2093)
2023/09/18 18:22:07 - INFO - root -   Epoch: [203/400][60/346], lr: 0.00000039 	 loss = 0.0169(0.1961)
2023/09/18 18:23:07 - INFO - root -   Epoch: [203/400][80/346], lr: 0.00000039 	 loss = 0.1729(0.2017)
2023/09/18 18:23:50 - INFO - root -   Epoch: [203/400][100/346], lr: 0.00000039 	 loss = 1.2240(0.2233)
2023/09/18 18:24:51 - INFO - root -   Epoch: [203/400][120/346], lr: 0.00000039 	 loss = 0.0082(0.2656)
2023/09/18 18:25:33 - INFO - root -   Epoch: [203/400][140/346], lr: 0.00000039 	 loss = 0.2067(0.2674)
2023/09/18 18:26:34 - INFO - root -   Epoch: [203/400][160/346], lr: 0.00000039 	 loss = 0.0453(0.2684)
2023/09/18 18:27:16 - INFO - root -   Epoch: [203/400][180/346], lr: 0.00000039 	 loss = 0.1467(0.2617)
2023/09/18 18:28:17 - INFO - root -   Epoch: [203/400][200/346], lr: 0.00000039 	 loss = 0.0291(0.2527)
2023/09/18 18:28:59 - INFO - root -   Epoch: [203/400][220/346], lr: 0.00000039 	 loss = 0.1420(0.2494)
2023/09/18 18:30:00 - INFO - root -   Epoch: [203/400][240/346], lr: 0.00000039 	 loss = 0.0299(0.2510)
2023/09/18 18:30:43 - INFO - root -   Epoch: [203/400][260/346], lr: 0.00000039 	 loss = 0.0098(0.2480)
2023/09/18 18:31:43 - INFO - root -   Epoch: [203/400][280/346], lr: 0.00000039 	 loss = 0.0101(0.2559)
2023/09/18 18:32:26 - INFO - root -   Epoch: [203/400][300/346], lr: 0.00000039 	 loss = 0.0045(0.2478)
2023/09/18 18:33:26 - INFO - root -   Epoch: [203/400][320/346], lr: 0.00000039 	 loss = 0.0007(0.2410)
2023/09/18 18:34:08 - INFO - root -   Epoch: [203/400][340/346], lr: 0.00000039 	 loss = 0.1477(0.2450)
2023/09/18 18:34:12 - INFO - root -   Epoch: [203/400] 	 loss = 0.2443
2023/09/18 18:34:12 - INFO - root -   train_accuracy = 0.9061
2023/09/18 18:34:34 - INFO - root -   Epoch: [204/400][0/346], lr: 0.00000039 	 loss = 0.0684(0.0684)
2023/09/18 18:35:17 - INFO - root -   Epoch: [204/400][20/346], lr: 0.00000039 	 loss = 0.0326(0.1239)
2023/09/18 18:36:17 - INFO - root -   Epoch: [204/400][40/346], lr: 0.00000039 	 loss = 0.0458(0.1438)
2023/09/18 18:37:00 - INFO - root -   Epoch: [204/400][60/346], lr: 0.00000039 	 loss = 0.0301(0.1410)
2023/09/18 18:38:01 - INFO - root -   Epoch: [204/400][80/346], lr: 0.00000039 	 loss = 0.0549(0.1921)
2023/09/18 18:38:44 - INFO - root -   Epoch: [204/400][100/346], lr: 0.00000039 	 loss = 0.7749(0.2021)
2023/09/18 18:39:44 - INFO - root -   Epoch: [204/400][120/346], lr: 0.00000039 	 loss = 0.1486(0.1984)
2023/09/18 18:40:27 - INFO - root -   Epoch: [204/400][140/346], lr: 0.00000039 	 loss = 0.1208(0.1938)
2023/09/18 18:41:28 - INFO - root -   Epoch: [204/400][160/346], lr: 0.00000039 	 loss = 0.0989(0.1937)
2023/09/18 18:42:10 - INFO - root -   Epoch: [204/400][180/346], lr: 0.00000039 	 loss = 0.0196(0.1889)
2023/09/18 18:43:11 - INFO - root -   Epoch: [204/400][200/346], lr: 0.00000039 	 loss = 0.0301(0.1835)
2023/09/18 18:43:54 - INFO - root -   Epoch: [204/400][220/346], lr: 0.00000039 	 loss = 0.4868(0.1872)
2023/09/18 18:44:54 - INFO - root -   Epoch: [204/400][240/346], lr: 0.00000039 	 loss = 0.0058(0.1830)
2023/09/18 18:45:37 - INFO - root -   Epoch: [204/400][260/346], lr: 0.00000039 	 loss = 0.0230(0.1751)
2023/09/18 18:46:38 - INFO - root -   Epoch: [204/400][280/346], lr: 0.00000039 	 loss = 0.0018(0.1939)
2023/09/18 18:47:21 - INFO - root -   Epoch: [204/400][300/346], lr: 0.00000039 	 loss = 0.0137(0.1952)
2023/09/18 18:48:21 - INFO - root -   Epoch: [204/400][320/346], lr: 0.00000039 	 loss = 0.0031(0.1946)
2023/09/18 18:49:03 - INFO - root -   Epoch: [204/400][340/346], lr: 0.00000039 	 loss = 1.0150(0.1988)
2023/09/18 18:49:07 - INFO - root -   Epoch: [204/400] 	 loss = 0.2019
2023/09/18 18:52:56 - INFO - root -   precision = 0.6437
2023/09/18 18:52:56 - INFO - root -   eval_loss = 1.1335
2023/09/18 18:52:57 - INFO - root -   train_accuracy = 0.9176
2023/09/18 18:53:18 - INFO - root -   Epoch: [205/400][0/346], lr: 0.00000039 	 loss = 0.0128(0.0128)
2023/09/18 18:54:01 - INFO - root -   Epoch: [205/400][20/346], lr: 0.00000039 	 loss = 0.0133(0.0755)
2023/09/18 18:55:03 - INFO - root -   Epoch: [205/400][40/346], lr: 0.00000039 	 loss = 1.0645(0.1669)
2023/09/18 18:55:46 - INFO - root -   Epoch: [205/400][60/346], lr: 0.00000039 	 loss = 0.0049(0.1408)
2023/09/18 18:56:48 - INFO - root -   Epoch: [205/400][80/346], lr: 0.00000039 	 loss = 0.2166(0.2193)
2023/09/18 18:57:32 - INFO - root -   Epoch: [205/400][100/346], lr: 0.00000039 	 loss = 0.4453(0.2311)
2023/09/18 18:58:33 - INFO - root -   Epoch: [205/400][120/346], lr: 0.00000039 	 loss = 0.7741(0.2626)
2023/09/18 18:59:17 - INFO - root -   Epoch: [205/400][140/346], lr: 0.00000039 	 loss = 0.0703(0.2567)
2023/09/18 19:00:18 - INFO - root -   Epoch: [205/400][160/346], lr: 0.00000039 	 loss = 0.0463(0.2731)
2023/09/18 19:01:01 - INFO - root -   Epoch: [205/400][180/346], lr: 0.00000039 	 loss = 0.0167(0.2662)
2023/09/18 19:02:03 - INFO - root -   Epoch: [205/400][200/346], lr: 0.00000039 	 loss = 0.0014(0.2525)
2023/09/18 19:02:46 - INFO - root -   Epoch: [205/400][220/346], lr: 0.00000039 	 loss = 0.3066(0.2546)
2023/09/18 19:03:47 - INFO - root -   Epoch: [205/400][240/346], lr: 0.00000039 	 loss = 0.0014(0.2581)
2023/09/18 19:04:31 - INFO - root -   Epoch: [205/400][260/346], lr: 0.00000039 	 loss = 0.0331(0.2521)
2023/09/18 19:05:32 - INFO - root -   Epoch: [205/400][280/346], lr: 0.00000039 	 loss = 0.0059(0.2584)
2023/09/18 19:06:16 - INFO - root -   Epoch: [205/400][300/346], lr: 0.00000039 	 loss = 0.0041(0.2522)
2023/09/18 19:07:16 - INFO - root -   Epoch: [205/400][320/346], lr: 0.00000039 	 loss = 0.0101(0.2493)
2023/09/18 19:07:59 - INFO - root -   Epoch: [205/400][340/346], lr: 0.00000039 	 loss = 0.0988(0.2486)
2023/09/18 19:08:03 - INFO - root -   Epoch: [205/400] 	 loss = 0.2497
2023/09/18 19:08:03 - INFO - root -   train_accuracy = 0.8858
2023/09/18 19:08:25 - INFO - root -   Epoch: [206/400][0/346], lr: 0.00000039 	 loss = 0.0208(0.0208)
2023/09/18 19:09:08 - INFO - root -   Epoch: [206/400][20/346], lr: 0.00000039 	 loss = 0.0082(0.1435)
2023/09/18 19:10:09 - INFO - root -   Epoch: [206/400][40/346], lr: 0.00000039 	 loss = 0.0233(0.1853)
2023/09/18 19:10:52 - INFO - root -   Epoch: [206/400][60/346], lr: 0.00000039 	 loss = 0.0804(0.1689)
2023/09/18 19:11:53 - INFO - root -   Epoch: [206/400][80/346], lr: 0.00000039 	 loss = 0.0212(0.1737)
2023/09/18 19:12:37 - INFO - root -   Epoch: [206/400][100/346], lr: 0.00000039 	 loss = 0.0099(0.1606)
2023/09/18 19:13:38 - INFO - root -   Epoch: [206/400][120/346], lr: 0.00000039 	 loss = 0.0111(0.2121)
2023/09/18 19:14:21 - INFO - root -   Epoch: [206/400][140/346], lr: 0.00000039 	 loss = 0.1055(0.1994)
2023/09/18 19:15:22 - INFO - root -   Epoch: [206/400][160/346], lr: 0.00000039 	 loss = 0.0480(0.2199)
2023/09/18 19:16:05 - INFO - root -   Epoch: [206/400][180/346], lr: 0.00000039 	 loss = 0.0434(0.2193)
2023/09/18 19:17:06 - INFO - root -   Epoch: [206/400][200/346], lr: 0.00000039 	 loss = 0.0030(0.2138)
2023/09/18 19:17:49 - INFO - root -   Epoch: [206/400][220/346], lr: 0.00000039 	 loss = 0.0676(0.2146)
2023/09/18 19:18:50 - INFO - root -   Epoch: [206/400][240/346], lr: 0.00000039 	 loss = 0.0119(0.2118)
2023/09/18 19:19:34 - INFO - root -   Epoch: [206/400][260/346], lr: 0.00000039 	 loss = 0.0942(0.2112)
2023/09/18 19:20:35 - INFO - root -   Epoch: [206/400][280/346], lr: 0.00000039 	 loss = 0.0595(0.2333)
2023/09/18 19:21:18 - INFO - root -   Epoch: [206/400][300/346], lr: 0.00000039 	 loss = 0.0512(0.2387)
2023/09/18 19:22:19 - INFO - root -   Epoch: [206/400][320/346], lr: 0.00000039 	 loss = 0.0122(0.2320)
2023/09/18 19:23:01 - INFO - root -   Epoch: [206/400][340/346], lr: 0.00000039 	 loss = 0.5849(0.2234)
2023/09/18 19:23:05 - INFO - root -   Epoch: [206/400] 	 loss = 0.2221
2023/09/18 19:23:06 - INFO - root -   train_accuracy = 0.9075
2023/09/18 19:23:27 - INFO - root -   Epoch: [207/400][0/346], lr: 0.00000040 	 loss = 0.0241(0.0241)
2023/09/18 19:24:10 - INFO - root -   Epoch: [207/400][20/346], lr: 0.00000040 	 loss = 0.0625(0.1636)
2023/09/18 19:25:10 - INFO - root -   Epoch: [207/400][40/346], lr: 0.00000040 	 loss = 0.7630(0.1753)
2023/09/18 19:25:53 - INFO - root -   Epoch: [207/400][60/346], lr: 0.00000040 	 loss = 0.0149(0.1744)
2023/09/18 19:26:54 - INFO - root -   Epoch: [207/400][80/346], lr: 0.00000040 	 loss = 0.0274(0.1631)
2023/09/18 19:27:37 - INFO - root -   Epoch: [207/400][100/346], lr: 0.00000040 	 loss = 0.0176(0.1680)
2023/09/18 19:28:38 - INFO - root -   Epoch: [207/400][120/346], lr: 0.00000040 	 loss = 0.0074(0.1627)
2023/09/18 19:29:21 - INFO - root -   Epoch: [207/400][140/346], lr: 0.00000040 	 loss = 0.1531(0.1662)
2023/09/18 19:30:21 - INFO - root -   Epoch: [207/400][160/346], lr: 0.00000040 	 loss = 0.4595(0.1750)
2023/09/18 19:31:04 - INFO - root -   Epoch: [207/400][180/346], lr: 0.00000040 	 loss = 0.0549(0.1817)
2023/09/18 19:32:04 - INFO - root -   Epoch: [207/400][200/346], lr: 0.00000040 	 loss = 0.0994(0.1802)
2023/09/18 19:32:47 - INFO - root -   Epoch: [207/400][220/346], lr: 0.00000040 	 loss = 0.0079(0.1860)
2023/09/18 19:33:47 - INFO - root -   Epoch: [207/400][240/346], lr: 0.00000040 	 loss = 0.0012(0.1809)
2023/09/18 19:34:30 - INFO - root -   Epoch: [207/400][260/346], lr: 0.00000040 	 loss = 0.4868(0.1829)
2023/09/18 19:35:30 - INFO - root -   Epoch: [207/400][280/346], lr: 0.00000040 	 loss = 0.0084(0.2069)
2023/09/18 19:36:13 - INFO - root -   Epoch: [207/400][300/346], lr: 0.00000040 	 loss = 0.3831(0.2096)
2023/09/18 19:37:14 - INFO - root -   Epoch: [207/400][320/346], lr: 0.00000040 	 loss = 0.0321(0.2068)
2023/09/18 19:37:56 - INFO - root -   Epoch: [207/400][340/346], lr: 0.00000040 	 loss = 0.0760(0.2168)
2023/09/18 19:38:00 - INFO - root -   Epoch: [207/400] 	 loss = 0.2219
2023/09/18 19:38:00 - INFO - root -   train_accuracy = 0.9162
2023/09/18 19:38:21 - INFO - root -   Epoch: [208/400][0/346], lr: 0.00000040 	 loss = 0.1971(0.1971)
2023/09/18 19:39:04 - INFO - root -   Epoch: [208/400][20/346], lr: 0.00000040 	 loss = 0.0043(0.1791)
2023/09/18 19:40:05 - INFO - root -   Epoch: [208/400][40/346], lr: 0.00000040 	 loss = 0.0659(0.2126)
2023/09/18 19:40:48 - INFO - root -   Epoch: [208/400][60/346], lr: 0.00000040 	 loss = 0.0995(0.1735)
2023/09/18 19:41:48 - INFO - root -   Epoch: [208/400][80/346], lr: 0.00000040 	 loss = 0.5369(0.1750)
2023/09/18 19:42:31 - INFO - root -   Epoch: [208/400][100/346], lr: 0.00000040 	 loss = 0.0317(0.2003)
2023/09/18 19:43:32 - INFO - root -   Epoch: [208/400][120/346], lr: 0.00000040 	 loss = 0.0172(0.1954)
2023/09/18 19:44:15 - INFO - root -   Epoch: [208/400][140/346], lr: 0.00000040 	 loss = 0.0147(0.2078)
2023/09/18 19:45:16 - INFO - root -   Epoch: [208/400][160/346], lr: 0.00000040 	 loss = 0.1697(0.2074)
2023/09/18 19:45:59 - INFO - root -   Epoch: [208/400][180/346], lr: 0.00000040 	 loss = 0.0167(0.1985)
2023/09/18 19:46:59 - INFO - root -   Epoch: [208/400][200/346], lr: 0.00000040 	 loss = 0.0008(0.2025)
2023/09/18 19:47:42 - INFO - root -   Epoch: [208/400][220/346], lr: 0.00000040 	 loss = 0.0233(0.2140)
2023/09/18 19:48:42 - INFO - root -   Epoch: [208/400][240/346], lr: 0.00000040 	 loss = 0.0039(0.2145)
2023/09/18 19:49:25 - INFO - root -   Epoch: [208/400][260/346], lr: 0.00000040 	 loss = 1.1339(0.2124)
2023/09/18 19:50:26 - INFO - root -   Epoch: [208/400][280/346], lr: 0.00000040 	 loss = 0.0127(0.2170)
2023/09/18 19:51:09 - INFO - root -   Epoch: [208/400][300/346], lr: 0.00000040 	 loss = 0.2226(0.2112)
2023/09/18 19:52:09 - INFO - root -   Epoch: [208/400][320/346], lr: 0.00000040 	 loss = 0.0950(0.2086)
2023/09/18 19:52:51 - INFO - root -   Epoch: [208/400][340/346], lr: 0.00000040 	 loss = 0.3976(0.2087)
2023/09/18 19:52:56 - INFO - root -   Epoch: [208/400] 	 loss = 0.2137
2023/09/18 19:52:56 - INFO - root -   train_accuracy = 0.9090
2023/09/18 19:53:17 - INFO - root -   Epoch: [209/400][0/346], lr: 0.00000040 	 loss = 0.0083(0.0083)
2023/09/18 19:54:00 - INFO - root -   Epoch: [209/400][20/346], lr: 0.00000040 	 loss = 0.0098(0.2299)
2023/09/18 19:55:01 - INFO - root -   Epoch: [209/400][40/346], lr: 0.00000040 	 loss = 0.0266(0.1752)
2023/09/18 19:55:44 - INFO - root -   Epoch: [209/400][60/346], lr: 0.00000040 	 loss = 0.1960(0.1595)
2023/09/18 19:56:45 - INFO - root -   Epoch: [209/400][80/346], lr: 0.00000040 	 loss = 0.1932(0.1678)
2023/09/18 19:57:28 - INFO - root -   Epoch: [209/400][100/346], lr: 0.00000040 	 loss = 0.1498(0.1643)
2023/09/18 19:58:29 - INFO - root -   Epoch: [209/400][120/346], lr: 0.00000040 	 loss = 0.0072(0.2093)
2023/09/18 19:59:12 - INFO - root -   Epoch: [209/400][140/346], lr: 0.00000040 	 loss = 0.0179(0.2180)
2023/09/18 20:00:13 - INFO - root -   Epoch: [209/400][160/346], lr: 0.00000040 	 loss = 0.1166(0.2188)
2023/09/18 20:00:56 - INFO - root -   Epoch: [209/400][180/346], lr: 0.00000040 	 loss = 0.0022(0.2271)
2023/09/18 20:01:57 - INFO - root -   Epoch: [209/400][200/346], lr: 0.00000040 	 loss = 0.0268(0.2161)
2023/09/18 20:02:40 - INFO - root -   Epoch: [209/400][220/346], lr: 0.00000040 	 loss = 0.1805(0.2145)
2023/09/18 20:03:41 - INFO - root -   Epoch: [209/400][240/346], lr: 0.00000040 	 loss = 0.0036(0.2097)
2023/09/18 20:04:24 - INFO - root -   Epoch: [209/400][260/346], lr: 0.00000040 	 loss = 0.2717(0.2050)
2023/09/18 20:05:24 - INFO - root -   Epoch: [209/400][280/346], lr: 0.00000040 	 loss = 0.0046(0.2139)
2023/09/18 20:06:08 - INFO - root -   Epoch: [209/400][300/346], lr: 0.00000040 	 loss = 0.1138(0.2119)
2023/09/18 20:07:08 - INFO - root -   Epoch: [209/400][320/346], lr: 0.00000040 	 loss = 0.0017(0.2080)
2023/09/18 20:07:51 - INFO - root -   Epoch: [209/400][340/346], lr: 0.00000040 	 loss = 0.0776(0.2018)
2023/09/18 20:07:55 - INFO - root -   Epoch: [209/400] 	 loss = 0.2055
2023/09/18 20:11:44 - INFO - root -   precision = 0.6552
2023/09/18 20:11:44 - INFO - root -   eval_loss = 1.1295
2023/09/18 20:11:45 - INFO - root -   train_accuracy = 0.9133
2023/09/18 20:12:06 - INFO - root -   Epoch: [210/400][0/346], lr: 0.00000040 	 loss = 0.0092(0.0092)
2023/09/18 20:12:49 - INFO - root -   Epoch: [210/400][20/346], lr: 0.00000040 	 loss = 0.0240(0.2465)
2023/09/18 20:13:50 - INFO - root -   Epoch: [210/400][40/346], lr: 0.00000040 	 loss = 0.2227(0.1903)
2023/09/18 20:14:33 - INFO - root -   Epoch: [210/400][60/346], lr: 0.00000040 	 loss = 0.0215(0.1743)
2023/09/18 20:15:34 - INFO - root -   Epoch: [210/400][80/346], lr: 0.00000040 	 loss = 0.0055(0.1724)
2023/09/18 20:16:17 - INFO - root -   Epoch: [210/400][100/346], lr: 0.00000040 	 loss = 0.0159(0.1491)
2023/09/18 20:17:17 - INFO - root -   Epoch: [210/400][120/346], lr: 0.00000040 	 loss = 0.0017(0.1572)
2023/09/18 20:18:00 - INFO - root -   Epoch: [210/400][140/346], lr: 0.00000040 	 loss = 0.0138(0.1708)
2023/09/18 20:19:00 - INFO - root -   Epoch: [210/400][160/346], lr: 0.00000040 	 loss = 0.0066(0.1663)
2023/09/18 20:19:43 - INFO - root -   Epoch: [210/400][180/346], lr: 0.00000040 	 loss = 0.0075(0.1604)
2023/09/18 20:20:44 - INFO - root -   Epoch: [210/400][200/346], lr: 0.00000040 	 loss = 0.0049(0.1590)
2023/09/18 20:21:27 - INFO - root -   Epoch: [210/400][220/346], lr: 0.00000040 	 loss = 0.2047(0.1548)
2023/09/18 20:22:27 - INFO - root -   Epoch: [210/400][240/346], lr: 0.00000040 	 loss = 0.0020(0.1537)
2023/09/18 20:23:10 - INFO - root -   Epoch: [210/400][260/346], lr: 0.00000040 	 loss = 0.0143(0.1567)
2023/09/18 20:24:10 - INFO - root -   Epoch: [210/400][280/346], lr: 0.00000040 	 loss = 0.0234(0.1828)
2023/09/18 20:24:53 - INFO - root -   Epoch: [210/400][300/346], lr: 0.00000040 	 loss = 0.0011(0.2113)
2023/09/18 20:25:53 - INFO - root -   Epoch: [210/400][320/346], lr: 0.00000040 	 loss = 0.0006(0.2160)
2023/09/18 20:26:35 - INFO - root -   Epoch: [210/400][340/346], lr: 0.00000040 	 loss = 1.1409(0.2178)
2023/09/18 20:26:39 - INFO - root -   Epoch: [210/400] 	 loss = 0.2165
2023/09/18 20:26:39 - INFO - root -   train_accuracy = 0.9162
2023/09/18 20:27:00 - INFO - root -   Epoch: [211/400][0/346], lr: 0.00000040 	 loss = 0.0461(0.0461)
2023/09/18 20:27:44 - INFO - root -   Epoch: [211/400][20/346], lr: 0.00000040 	 loss = 0.0397(0.1770)
2023/09/18 20:28:44 - INFO - root -   Epoch: [211/400][40/346], lr: 0.00000040 	 loss = 0.0388(0.1752)
2023/09/18 20:29:27 - INFO - root -   Epoch: [211/400][60/346], lr: 0.00000040 	 loss = 0.0861(0.2404)
2023/09/18 20:30:28 - INFO - root -   Epoch: [211/400][80/346], lr: 0.00000040 	 loss = 0.0011(0.2480)
2023/09/18 20:31:12 - INFO - root -   Epoch: [211/400][100/346], lr: 0.00000040 	 loss = 0.0084(0.2477)
2023/09/18 20:32:12 - INFO - root -   Epoch: [211/400][120/346], lr: 0.00000040 	 loss = 0.0081(0.2499)
2023/09/18 20:32:56 - INFO - root -   Epoch: [211/400][140/346], lr: 0.00000040 	 loss = 0.0192(0.2577)
2023/09/18 20:33:56 - INFO - root -   Epoch: [211/400][160/346], lr: 0.00000040 	 loss = 0.0080(0.2679)
2023/09/18 20:34:40 - INFO - root -   Epoch: [211/400][180/346], lr: 0.00000040 	 loss = 0.0038(0.2553)
2023/09/18 20:35:40 - INFO - root -   Epoch: [211/400][200/346], lr: 0.00000040 	 loss = 0.0020(0.2419)
2023/09/18 20:36:24 - INFO - root -   Epoch: [211/400][220/346], lr: 0.00000040 	 loss = 0.0052(0.2403)
2023/09/18 20:37:24 - INFO - root -   Epoch: [211/400][240/346], lr: 0.00000040 	 loss = 0.0031(0.2310)
2023/09/18 20:38:08 - INFO - root -   Epoch: [211/400][260/346], lr: 0.00000040 	 loss = 0.0179(0.2233)
2023/09/18 20:39:08 - INFO - root -   Epoch: [211/400][280/346], lr: 0.00000040 	 loss = 0.3023(0.2328)
2023/09/18 20:39:52 - INFO - root -   Epoch: [211/400][300/346], lr: 0.00000040 	 loss = 0.0045(0.2396)
2023/09/18 20:40:52 - INFO - root -   Epoch: [211/400][320/346], lr: 0.00000040 	 loss = 0.0031(0.2478)
2023/09/18 20:41:35 - INFO - root -   Epoch: [211/400][340/346], lr: 0.00000040 	 loss = 0.1670(0.2409)
2023/09/18 20:41:39 - INFO - root -   Epoch: [211/400] 	 loss = 0.2426
2023/09/18 20:41:39 - INFO - root -   train_accuracy = 0.9017
2023/09/18 20:42:01 - INFO - root -   Epoch: [212/400][0/346], lr: 0.00000040 	 loss = 0.0128(0.0128)
2023/09/18 20:42:44 - INFO - root -   Epoch: [212/400][20/346], lr: 0.00000040 	 loss = 0.0100(0.1659)
2023/09/18 20:43:44 - INFO - root -   Epoch: [212/400][40/346], lr: 0.00000040 	 loss = 0.0185(0.2167)
2023/09/18 20:44:27 - INFO - root -   Epoch: [212/400][60/346], lr: 0.00000040 	 loss = 0.3904(0.1992)
2023/09/18 20:45:28 - INFO - root -   Epoch: [212/400][80/346], lr: 0.00000040 	 loss = 0.0183(0.1877)
2023/09/18 20:46:11 - INFO - root -   Epoch: [212/400][100/346], lr: 0.00000040 	 loss = 0.1092(0.1838)
2023/09/18 20:47:12 - INFO - root -   Epoch: [212/400][120/346], lr: 0.00000040 	 loss = 0.0024(0.1653)
2023/09/18 20:47:55 - INFO - root -   Epoch: [212/400][140/346], lr: 0.00000040 	 loss = 0.0192(0.1654)
2023/09/18 20:48:55 - INFO - root -   Epoch: [212/400][160/346], lr: 0.00000040 	 loss = 0.0010(0.1687)
2023/09/18 20:49:38 - INFO - root -   Epoch: [212/400][180/346], lr: 0.00000040 	 loss = 0.0061(0.1823)
2023/09/18 20:50:39 - INFO - root -   Epoch: [212/400][200/346], lr: 0.00000040 	 loss = 0.0012(0.1717)
2023/09/18 20:51:22 - INFO - root -   Epoch: [212/400][220/346], lr: 0.00000040 	 loss = 0.0046(0.1649)
2023/09/18 20:52:23 - INFO - root -   Epoch: [212/400][240/346], lr: 0.00000040 	 loss = 0.0033(0.1559)
2023/09/18 20:53:06 - INFO - root -   Epoch: [212/400][260/346], lr: 0.00000040 	 loss = 0.0275(0.1549)
2023/09/18 20:54:06 - INFO - root -   Epoch: [212/400][280/346], lr: 0.00000040 	 loss = 0.0022(0.1774)
2023/09/18 20:54:49 - INFO - root -   Epoch: [212/400][300/346], lr: 0.00000040 	 loss = 0.0124(0.1863)
2023/09/18 20:55:49 - INFO - root -   Epoch: [212/400][320/346], lr: 0.00000040 	 loss = 0.0045(0.1884)
2023/09/18 20:56:31 - INFO - root -   Epoch: [212/400][340/346], lr: 0.00000040 	 loss = 0.5357(0.1906)
2023/09/18 20:56:35 - INFO - root -   Epoch: [212/400] 	 loss = 0.1918
2023/09/18 20:56:35 - INFO - root -   train_accuracy = 0.9176
2023/09/18 20:56:57 - INFO - root -   Epoch: [213/400][0/346], lr: 0.00000040 	 loss = 0.2454(0.2454)
2023/09/18 20:57:40 - INFO - root -   Epoch: [213/400][20/346], lr: 0.00000040 	 loss = 0.0077(0.2412)
2023/09/18 20:58:41 - INFO - root -   Epoch: [213/400][40/346], lr: 0.00000040 	 loss = 0.8777(0.2259)
2023/09/18 20:59:24 - INFO - root -   Epoch: [213/400][60/346], lr: 0.00000040 	 loss = 0.0134(0.2059)
2023/09/18 21:00:25 - INFO - root -   Epoch: [213/400][80/346], lr: 0.00000040 	 loss = 0.0060(0.2495)
2023/09/18 21:01:08 - INFO - root -   Epoch: [213/400][100/346], lr: 0.00000040 	 loss = 0.6404(0.2433)
2023/09/18 21:02:08 - INFO - root -   Epoch: [213/400][120/346], lr: 0.00000040 	 loss = 0.0032(0.2354)
2023/09/18 21:02:52 - INFO - root -   Epoch: [213/400][140/346], lr: 0.00000040 	 loss = 0.9201(0.2325)
2023/09/18 21:03:52 - INFO - root -   Epoch: [213/400][160/346], lr: 0.00000040 	 loss = 0.2466(0.2489)
2023/09/18 21:04:35 - INFO - root -   Epoch: [213/400][180/346], lr: 0.00000040 	 loss = 0.1295(0.2589)
2023/09/18 21:05:36 - INFO - root -   Epoch: [213/400][200/346], lr: 0.00000040 	 loss = 0.0410(0.2479)
2023/09/18 21:06:19 - INFO - root -   Epoch: [213/400][220/346], lr: 0.00000040 	 loss = 0.2922(0.2421)
2023/09/18 21:07:19 - INFO - root -   Epoch: [213/400][240/346], lr: 0.00000040 	 loss = 0.0141(0.2426)
2023/09/18 21:08:03 - INFO - root -   Epoch: [213/400][260/346], lr: 0.00000040 	 loss = 0.0805(0.2334)
2023/09/18 21:09:03 - INFO - root -   Epoch: [213/400][280/346], lr: 0.00000040 	 loss = 0.0013(0.2295)
2023/09/18 21:09:46 - INFO - root -   Epoch: [213/400][300/346], lr: 0.00000040 	 loss = 0.0308(0.2309)
2023/09/18 21:10:47 - INFO - root -   Epoch: [213/400][320/346], lr: 0.00000040 	 loss = 0.0080(0.2231)
2023/09/18 21:11:29 - INFO - root -   Epoch: [213/400][340/346], lr: 0.00000040 	 loss = 0.0872(0.2229)
2023/09/18 21:11:33 - INFO - root -   Epoch: [213/400] 	 loss = 0.2210
2023/09/18 21:11:33 - INFO - root -   train_accuracy = 0.9162
2023/09/18 21:11:55 - INFO - root -   Epoch: [214/400][0/346], lr: 0.00000041 	 loss = 0.0078(0.0078)
2023/09/18 21:12:38 - INFO - root -   Epoch: [214/400][20/346], lr: 0.00000041 	 loss = 0.1362(0.1982)
2023/09/18 21:13:39 - INFO - root -   Epoch: [214/400][40/346], lr: 0.00000041 	 loss = 0.5122(0.2301)
2023/09/18 21:14:23 - INFO - root -   Epoch: [214/400][60/346], lr: 0.00000041 	 loss = 0.0058(0.2082)
2023/09/18 21:15:24 - INFO - root -   Epoch: [214/400][80/346], lr: 0.00000041 	 loss = 0.0428(0.2033)
2023/09/18 21:16:08 - INFO - root -   Epoch: [214/400][100/346], lr: 0.00000041 	 loss = 0.0954(0.2000)
2023/09/18 21:17:10 - INFO - root -   Epoch: [214/400][120/346], lr: 0.00000041 	 loss = 0.0105(0.2004)
2023/09/18 21:17:53 - INFO - root -   Epoch: [214/400][140/346], lr: 0.00000041 	 loss = 0.0418(0.2069)
2023/09/18 21:18:54 - INFO - root -   Epoch: [214/400][160/346], lr: 0.00000041 	 loss = 0.0655(0.1903)
2023/09/18 21:19:38 - INFO - root -   Epoch: [214/400][180/346], lr: 0.00000041 	 loss = 0.0018(0.1944)
2023/09/18 21:20:39 - INFO - root -   Epoch: [214/400][200/346], lr: 0.00000041 	 loss = 0.0020(0.1835)
2023/09/18 21:21:23 - INFO - root -   Epoch: [214/400][220/346], lr: 0.00000041 	 loss = 0.0110(0.1793)
2023/09/18 21:22:23 - INFO - root -   Epoch: [214/400][240/346], lr: 0.00000041 	 loss = 0.0067(0.1917)
2023/09/18 21:23:07 - INFO - root -   Epoch: [214/400][260/346], lr: 0.00000041 	 loss = 0.5271(0.1884)
2023/09/18 21:24:08 - INFO - root -   Epoch: [214/400][280/346], lr: 0.00000041 	 loss = 0.0025(0.2021)
2023/09/18 21:24:52 - INFO - root -   Epoch: [214/400][300/346], lr: 0.00000041 	 loss = 0.0036(0.1936)
2023/09/18 21:25:53 - INFO - root -   Epoch: [214/400][320/346], lr: 0.00000041 	 loss = 0.0029(0.1942)
2023/09/18 21:26:35 - INFO - root -   Epoch: [214/400][340/346], lr: 0.00000041 	 loss = 0.1146(0.1904)
2023/09/18 21:26:39 - INFO - root -   Epoch: [214/400] 	 loss = 0.1966
2023/09/18 21:30:28 - INFO - root -   precision = 0.7011
2023/09/18 21:30:28 - INFO - root -   eval_loss = 1.1703
2023/09/18 21:30:29 - INFO - root -   train_accuracy = 0.9220
2023/09/18 21:30:50 - INFO - root -   Epoch: [215/400][0/346], lr: 0.00000041 	 loss = 0.0725(0.0725)
2023/09/18 21:31:33 - INFO - root -   Epoch: [215/400][20/346], lr: 0.00000041 	 loss = 0.0495(0.1189)
2023/09/18 21:32:33 - INFO - root -   Epoch: [215/400][40/346], lr: 0.00000041 	 loss = 0.0267(0.1497)
2023/09/18 21:33:16 - INFO - root -   Epoch: [215/400][60/346], lr: 0.00000041 	 loss = 0.7452(0.2489)
2023/09/18 21:34:17 - INFO - root -   Epoch: [215/400][80/346], lr: 0.00000041 	 loss = 0.2520(0.3470)
2023/09/18 21:35:00 - INFO - root -   Epoch: [215/400][100/346], lr: 0.00000041 	 loss = 0.3541(0.4520)
2023/09/18 21:36:00 - INFO - root -   Epoch: [215/400][120/346], lr: 0.00000041 	 loss = 0.0019(0.4371)
2023/09/18 21:36:43 - INFO - root -   Epoch: [215/400][140/346], lr: 0.00000041 	 loss = 0.0243(0.4410)
2023/09/18 21:37:43 - INFO - root -   Epoch: [215/400][160/346], lr: 0.00000041 	 loss = 0.0083(0.4206)
2023/09/18 21:38:26 - INFO - root -   Epoch: [215/400][180/346], lr: 0.00000041 	 loss = 0.0306(0.3942)
2023/09/18 21:39:26 - INFO - root -   Epoch: [215/400][200/346], lr: 0.00000041 	 loss = 0.0017(0.3628)
2023/09/18 21:40:09 - INFO - root -   Epoch: [215/400][220/346], lr: 0.00000041 	 loss = 0.0053(0.3519)
2023/09/18 21:41:09 - INFO - root -   Epoch: [215/400][240/346], lr: 0.00000041 	 loss = 0.0128(0.3267)
2023/09/18 21:41:52 - INFO - root -   Epoch: [215/400][260/346], lr: 0.00000041 	 loss = 0.0092(0.3089)
2023/09/18 21:42:52 - INFO - root -   Epoch: [215/400][280/346], lr: 0.00000041 	 loss = 0.1484(0.3082)
2023/09/18 21:43:35 - INFO - root -   Epoch: [215/400][300/346], lr: 0.00000041 	 loss = 0.0025(0.3066)
2023/09/18 21:44:35 - INFO - root -   Epoch: [215/400][320/346], lr: 0.00000041 	 loss = 0.0086(0.3020)
2023/09/18 21:45:16 - INFO - root -   Epoch: [215/400][340/346], lr: 0.00000041 	 loss = 0.0489(0.2937)
2023/09/18 21:45:20 - INFO - root -   Epoch: [215/400] 	 loss = 0.2908
2023/09/18 21:45:20 - INFO - root -   train_accuracy = 0.9017
2023/09/18 21:45:42 - INFO - root -   Epoch: [216/400][0/346], lr: 0.00000041 	 loss = 0.0148(0.0148)
2023/09/18 21:46:26 - INFO - root -   Epoch: [216/400][20/346], lr: 0.00000041 	 loss = 0.0018(0.1412)
2023/09/18 21:47:27 - INFO - root -   Epoch: [216/400][40/346], lr: 0.00000041 	 loss = 0.0238(0.2089)
2023/09/18 21:48:10 - INFO - root -   Epoch: [216/400][60/346], lr: 0.00000041 	 loss = 0.6797(0.1778)
2023/09/18 21:49:10 - INFO - root -   Epoch: [216/400][80/346], lr: 0.00000041 	 loss = 0.0031(0.1560)
2023/09/18 21:49:54 - INFO - root -   Epoch: [216/400][100/346], lr: 0.00000041 	 loss = 0.1361(0.1388)
2023/09/18 21:50:55 - INFO - root -   Epoch: [216/400][120/346], lr: 0.00000041 	 loss = 0.0170(0.1538)
2023/09/18 21:51:38 - INFO - root -   Epoch: [216/400][140/346], lr: 0.00000041 	 loss = 0.3261(0.1731)
2023/09/18 21:52:38 - INFO - root -   Epoch: [216/400][160/346], lr: 0.00000041 	 loss = 0.0019(0.1720)
2023/09/18 21:53:21 - INFO - root -   Epoch: [216/400][180/346], lr: 0.00000041 	 loss = 0.0494(0.1714)
2023/09/18 21:54:22 - INFO - root -   Epoch: [216/400][200/346], lr: 0.00000041 	 loss = 0.0017(0.1665)
2023/09/18 21:55:05 - INFO - root -   Epoch: [216/400][220/346], lr: 0.00000041 	 loss = 0.0082(0.1659)
2023/09/18 21:56:06 - INFO - root -   Epoch: [216/400][240/346], lr: 0.00000041 	 loss = 0.0085(0.1660)
2023/09/18 21:56:49 - INFO - root -   Epoch: [216/400][260/346], lr: 0.00000041 	 loss = 0.0457(0.1654)
2023/09/18 21:57:50 - INFO - root -   Epoch: [216/400][280/346], lr: 0.00000041 	 loss = 0.1458(0.1767)
2023/09/18 21:58:33 - INFO - root -   Epoch: [216/400][300/346], lr: 0.00000041 	 loss = 0.0013(0.1776)
2023/09/18 21:59:34 - INFO - root -   Epoch: [216/400][320/346], lr: 0.00000041 	 loss = 0.0146(0.1718)
2023/09/18 22:00:16 - INFO - root -   Epoch: [216/400][340/346], lr: 0.00000041 	 loss = 0.1220(0.1708)
2023/09/18 22:00:20 - INFO - root -   Epoch: [216/400] 	 loss = 0.1701
2023/09/18 22:00:20 - INFO - root -   train_accuracy = 0.9205
2023/09/18 22:00:42 - INFO - root -   Epoch: [217/400][0/346], lr: 0.00000041 	 loss = 0.0345(0.0345)
2023/09/18 22:01:24 - INFO - root -   Epoch: [217/400][20/346], lr: 0.00000041 	 loss = 0.0031(0.1536)
2023/09/18 22:02:25 - INFO - root -   Epoch: [217/400][40/346], lr: 0.00000041 	 loss = 0.0116(0.1696)
2023/09/18 22:03:08 - INFO - root -   Epoch: [217/400][60/346], lr: 0.00000041 	 loss = 0.0255(0.1377)
2023/09/18 22:04:09 - INFO - root -   Epoch: [217/400][80/346], lr: 0.00000041 	 loss = 0.0077(0.1189)
2023/09/18 22:04:52 - INFO - root -   Epoch: [217/400][100/346], lr: 0.00000041 	 loss = 0.3884(0.1132)
2023/09/18 22:05:52 - INFO - root -   Epoch: [217/400][120/346], lr: 0.00000041 	 loss = 0.0051(0.1645)
2023/09/18 22:06:35 - INFO - root -   Epoch: [217/400][140/346], lr: 0.00000041 	 loss = 0.0052(0.1566)
2023/09/18 22:07:35 - INFO - root -   Epoch: [217/400][160/346], lr: 0.00000041 	 loss = 0.0335(0.1656)
2023/09/18 22:08:18 - INFO - root -   Epoch: [217/400][180/346], lr: 0.00000041 	 loss = 0.0070(0.1621)
2023/09/18 22:09:19 - INFO - root -   Epoch: [217/400][200/346], lr: 0.00000041 	 loss = 0.0019(0.1645)
2023/09/18 22:10:02 - INFO - root -   Epoch: [217/400][220/346], lr: 0.00000041 	 loss = 0.2106(0.1567)
2023/09/18 22:11:02 - INFO - root -   Epoch: [217/400][240/346], lr: 0.00000041 	 loss = 0.0015(0.1508)
2023/09/18 22:11:45 - INFO - root -   Epoch: [217/400][260/346], lr: 0.00000041 	 loss = 0.0223(0.1523)
2023/09/18 22:12:46 - INFO - root -   Epoch: [217/400][280/346], lr: 0.00000041 	 loss = 0.0046(0.1666)
2023/09/18 22:13:29 - INFO - root -   Epoch: [217/400][300/346], lr: 0.00000041 	 loss = 0.0034(0.1671)
2023/09/18 22:14:29 - INFO - root -   Epoch: [217/400][320/346], lr: 0.00000041 	 loss = 0.0104(0.1660)
2023/09/18 22:15:11 - INFO - root -   Epoch: [217/400][340/346], lr: 0.00000041 	 loss = 0.3772(0.1673)
2023/09/18 22:15:15 - INFO - root -   Epoch: [217/400] 	 loss = 0.1683
2023/09/18 22:15:15 - INFO - root -   train_accuracy = 0.9335
2023/09/18 22:15:37 - INFO - root -   Epoch: [218/400][0/346], lr: 0.00000041 	 loss = 0.0436(0.0436)
2023/09/18 22:16:20 - INFO - root -   Epoch: [218/400][20/346], lr: 0.00000041 	 loss = 0.0012(0.1999)
2023/09/18 22:17:21 - INFO - root -   Epoch: [218/400][40/346], lr: 0.00000041 	 loss = 0.0370(0.1278)
2023/09/18 22:18:04 - INFO - root -   Epoch: [218/400][60/346], lr: 0.00000041 	 loss = 0.0063(0.1359)
2023/09/18 22:19:05 - INFO - root -   Epoch: [218/400][80/346], lr: 0.00000041 	 loss = 0.0015(0.1286)
2023/09/18 22:19:48 - INFO - root -   Epoch: [218/400][100/346], lr: 0.00000041 	 loss = 0.4070(0.1387)
2023/09/18 22:20:49 - INFO - root -   Epoch: [218/400][120/346], lr: 0.00000041 	 loss = 0.0025(0.1480)
2023/09/18 22:21:32 - INFO - root -   Epoch: [218/400][140/346], lr: 0.00000041 	 loss = 0.0860(0.1384)
2023/09/18 22:22:32 - INFO - root -   Epoch: [218/400][160/346], lr: 0.00000041 	 loss = 0.0020(0.1485)
2023/09/18 22:23:15 - INFO - root -   Epoch: [218/400][180/346], lr: 0.00000041 	 loss = 0.0018(0.1595)
2023/09/18 22:24:15 - INFO - root -   Epoch: [218/400][200/346], lr: 0.00000041 	 loss = 0.0304(0.1671)
2023/09/18 22:24:59 - INFO - root -   Epoch: [218/400][220/346], lr: 0.00000041 	 loss = 0.0136(0.1709)
2023/09/18 22:25:59 - INFO - root -   Epoch: [218/400][240/346], lr: 0.00000041 	 loss = 0.0674(0.1713)
2023/09/18 22:26:42 - INFO - root -   Epoch: [218/400][260/346], lr: 0.00000041 	 loss = 0.1566(0.1657)
2023/09/18 22:27:43 - INFO - root -   Epoch: [218/400][280/346], lr: 0.00000041 	 loss = 0.0766(0.1741)
2023/09/18 22:28:26 - INFO - root -   Epoch: [218/400][300/346], lr: 0.00000041 	 loss = 0.0010(0.1746)
2023/09/18 22:29:26 - INFO - root -   Epoch: [218/400][320/346], lr: 0.00000041 	 loss = 0.0235(0.1736)
2023/09/18 22:30:07 - INFO - root -   Epoch: [218/400][340/346], lr: 0.00000041 	 loss = 0.7505(0.1745)
2023/09/18 22:30:12 - INFO - root -   Epoch: [218/400] 	 loss = 0.1740
2023/09/18 22:30:12 - INFO - root -   train_accuracy = 0.9277
2023/09/18 22:30:33 - INFO - root -   Epoch: [219/400][0/346], lr: 0.00000041 	 loss = 0.0140(0.0140)
2023/09/18 22:31:16 - INFO - root -   Epoch: [219/400][20/346], lr: 0.00000041 	 loss = 0.0024(0.1371)
2023/09/18 22:32:17 - INFO - root -   Epoch: [219/400][40/346], lr: 0.00000041 	 loss = 0.0098(0.1120)
2023/09/18 22:33:02 - INFO - root -   Epoch: [219/400][60/346], lr: 0.00000041 	 loss = 0.0212(0.1119)
2023/09/18 22:34:01 - INFO - root -   Epoch: [219/400][80/346], lr: 0.00000041 	 loss = 0.0032(0.1136)
2023/09/18 22:34:45 - INFO - root -   Epoch: [219/400][100/346], lr: 0.00000041 	 loss = 0.0206(0.1042)
2023/09/18 22:35:44 - INFO - root -   Epoch: [219/400][120/346], lr: 0.00000041 	 loss = 0.0027(0.1137)
2023/09/18 22:36:28 - INFO - root -   Epoch: [219/400][140/346], lr: 0.00000041 	 loss = 0.0038(0.1308)
2023/09/18 22:37:28 - INFO - root -   Epoch: [219/400][160/346], lr: 0.00000041 	 loss = 0.0058(0.1259)
2023/09/18 22:38:12 - INFO - root -   Epoch: [219/400][180/346], lr: 0.00000041 	 loss = 0.0363(0.1342)
2023/09/18 22:39:11 - INFO - root -   Epoch: [219/400][200/346], lr: 0.00000041 	 loss = 0.0014(0.1406)
2023/09/18 22:39:55 - INFO - root -   Epoch: [219/400][220/346], lr: 0.00000041 	 loss = 0.0556(0.1686)
2023/09/18 22:40:55 - INFO - root -   Epoch: [219/400][240/346], lr: 0.00000041 	 loss = 0.0008(0.1682)
2023/09/18 22:41:38 - INFO - root -   Epoch: [219/400][260/346], lr: 0.00000041 	 loss = 0.3256(0.1644)
2023/09/18 22:42:38 - INFO - root -   Epoch: [219/400][280/346], lr: 0.00000041 	 loss = 0.0020(0.1755)
2023/09/18 22:43:24 - INFO - root -   Epoch: [219/400][300/346], lr: 0.00000041 	 loss = 0.0343(0.1706)
2023/09/18 22:44:22 - INFO - root -   Epoch: [219/400][320/346], lr: 0.00000041 	 loss = 0.0003(0.1650)
2023/09/18 22:45:05 - INFO - root -   Epoch: [219/400][340/346], lr: 0.00000041 	 loss = 0.0110(0.1620)
2023/09/18 22:45:09 - INFO - root -   Epoch: [219/400] 	 loss = 0.1613
2023/09/18 22:48:59 - INFO - root -   precision = 0.6839
2023/09/18 22:48:59 - INFO - root -   eval_loss = 1.2872
2023/09/18 22:49:00 - INFO - root -   train_accuracy = 0.9379
2023/09/18 22:49:22 - INFO - root -   Epoch: [220/400][0/346], lr: 0.00000041 	 loss = 0.0754(0.0754)
2023/09/18 22:50:04 - INFO - root -   Epoch: [220/400][20/346], lr: 0.00000041 	 loss = 0.0027(0.1303)
2023/09/18 22:51:05 - INFO - root -   Epoch: [220/400][40/346], lr: 0.00000041 	 loss = 1.3345(0.1975)
2023/09/18 22:51:48 - INFO - root -   Epoch: [220/400][60/346], lr: 0.00000041 	 loss = 0.0149(0.1613)
2023/09/18 22:52:48 - INFO - root -   Epoch: [220/400][80/346], lr: 0.00000041 	 loss = 0.0883(0.1524)
2023/09/18 22:53:31 - INFO - root -   Epoch: [220/400][100/346], lr: 0.00000041 	 loss = 0.1446(0.1494)
2023/09/18 22:54:32 - INFO - root -   Epoch: [220/400][120/346], lr: 0.00000041 	 loss = 0.0034(0.1673)
2023/09/18 22:55:15 - INFO - root -   Epoch: [220/400][140/346], lr: 0.00000041 	 loss = 0.0910(0.1701)
2023/09/18 22:56:15 - INFO - root -   Epoch: [220/400][160/346], lr: 0.00000041 	 loss = 0.0065(0.1664)
2023/09/18 22:56:58 - INFO - root -   Epoch: [220/400][180/346], lr: 0.00000041 	 loss = 0.0814(0.1641)
2023/09/18 22:57:58 - INFO - root -   Epoch: [220/400][200/346], lr: 0.00000041 	 loss = 0.0003(0.1688)
2023/09/18 22:58:41 - INFO - root -   Epoch: [220/400][220/346], lr: 0.00000041 	 loss = 0.0609(0.1777)
2023/09/18 22:59:42 - INFO - root -   Epoch: [220/400][240/346], lr: 0.00000041 	 loss = 0.0003(0.1791)
2023/09/18 23:00:25 - INFO - root -   Epoch: [220/400][260/346], lr: 0.00000041 	 loss = 0.0044(0.1741)
2023/09/18 23:01:25 - INFO - root -   Epoch: [220/400][280/346], lr: 0.00000041 	 loss = 0.0004(0.1785)
2023/09/18 23:02:08 - INFO - root -   Epoch: [220/400][300/346], lr: 0.00000041 	 loss = 0.1355(0.1753)
2023/09/18 23:03:09 - INFO - root -   Epoch: [220/400][320/346], lr: 0.00000041 	 loss = 0.0020(0.1821)
2023/09/18 23:03:51 - INFO - root -   Epoch: [220/400][340/346], lr: 0.00000041 	 loss = 0.2445(0.1808)
2023/09/18 23:03:55 - INFO - root -   Epoch: [220/400] 	 loss = 0.1798
2023/09/18 23:03:55 - INFO - root -   train_accuracy = 0.9350
2023/09/18 23:04:16 - INFO - root -   Epoch: [221/400][0/346], lr: 0.00000042 	 loss = 0.0505(0.0505)
2023/09/18 23:04:59 - INFO - root -   Epoch: [221/400][20/346], lr: 0.00000042 	 loss = 0.0013(0.2679)
2023/09/18 23:06:00 - INFO - root -   Epoch: [221/400][40/346], lr: 0.00000042 	 loss = 1.0043(0.2644)
2023/09/18 23:06:43 - INFO - root -   Epoch: [221/400][60/346], lr: 0.00000042 	 loss = 0.2680(0.2247)
2023/09/18 23:07:44 - INFO - root -   Epoch: [221/400][80/346], lr: 0.00000042 	 loss = 0.0010(0.1960)
2023/09/18 23:08:27 - INFO - root -   Epoch: [221/400][100/346], lr: 0.00000042 	 loss = 0.3216(0.1765)
2023/09/18 23:09:28 - INFO - root -   Epoch: [221/400][120/346], lr: 0.00000042 	 loss = 0.0004(0.1795)
2023/09/18 23:10:11 - INFO - root -   Epoch: [221/400][140/346], lr: 0.00000042 	 loss = 0.1597(0.1949)
2023/09/18 23:11:11 - INFO - root -   Epoch: [221/400][160/346], lr: 0.00000042 	 loss = 0.0669(0.2166)
2023/09/18 23:11:54 - INFO - root -   Epoch: [221/400][180/346], lr: 0.00000042 	 loss = 0.0947(0.2382)
2023/09/18 23:12:54 - INFO - root -   Epoch: [221/400][200/346], lr: 0.00000042 	 loss = 0.0003(0.2281)
2023/09/18 23:13:37 - INFO - root -   Epoch: [221/400][220/346], lr: 0.00000042 	 loss = 0.0203(0.2391)
2023/09/18 23:14:38 - INFO - root -   Epoch: [221/400][240/346], lr: 0.00000042 	 loss = 0.0008(0.2316)
2023/09/18 23:15:21 - INFO - root -   Epoch: [221/400][260/346], lr: 0.00000042 	 loss = 0.2106(0.2184)
2023/09/18 23:16:22 - INFO - root -   Epoch: [221/400][280/346], lr: 0.00000042 	 loss = 0.0166(0.2215)
2023/09/18 23:17:05 - INFO - root -   Epoch: [221/400][300/346], lr: 0.00000042 	 loss = 0.0014(0.2143)
2023/09/18 23:18:05 - INFO - root -   Epoch: [221/400][320/346], lr: 0.00000042 	 loss = 0.0081(0.2060)
2023/09/18 23:18:47 - INFO - root -   Epoch: [221/400][340/346], lr: 0.00000042 	 loss = 0.0628(0.1995)
2023/09/18 23:18:51 - INFO - root -   Epoch: [221/400] 	 loss = 0.2001
2023/09/18 23:18:51 - INFO - root -   train_accuracy = 0.9292
2023/09/18 23:19:13 - INFO - root -   Epoch: [222/400][0/346], lr: 0.00000042 	 loss = 0.0089(0.0089)
2023/09/18 23:19:56 - INFO - root -   Epoch: [222/400][20/346], lr: 0.00000042 	 loss = 0.0049(0.0375)
2023/09/18 23:20:57 - INFO - root -   Epoch: [222/400][40/346], lr: 0.00000042 	 loss = 0.2008(0.1168)
2023/09/18 23:21:40 - INFO - root -   Epoch: [222/400][60/346], lr: 0.00000042 	 loss = 0.0633(0.0918)
2023/09/18 23:22:41 - INFO - root -   Epoch: [222/400][80/346], lr: 0.00000042 	 loss = 0.0345(0.0939)
2023/09/18 23:23:24 - INFO - root -   Epoch: [222/400][100/346], lr: 0.00000042 	 loss = 0.0177(0.0980)
2023/09/18 23:24:24 - INFO - root -   Epoch: [222/400][120/346], lr: 0.00000042 	 loss = 0.0072(0.1063)
2023/09/18 23:25:07 - INFO - root -   Epoch: [222/400][140/346], lr: 0.00000042 	 loss = 0.3984(0.1113)
2023/09/18 23:26:08 - INFO - root -   Epoch: [222/400][160/346], lr: 0.00000042 	 loss = 0.0349(0.1176)
2023/09/18 23:26:51 - INFO - root -   Epoch: [222/400][180/346], lr: 0.00000042 	 loss = 0.0051(0.1192)
2023/09/18 23:27:51 - INFO - root -   Epoch: [222/400][200/346], lr: 0.00000042 	 loss = 0.0032(0.1241)
2023/09/18 23:28:35 - INFO - root -   Epoch: [222/400][220/346], lr: 0.00000042 	 loss = 0.0063(0.1377)
2023/09/18 23:29:35 - INFO - root -   Epoch: [222/400][240/346], lr: 0.00000042 	 loss = 0.0526(0.1442)
2023/09/18 23:30:18 - INFO - root -   Epoch: [222/400][260/346], lr: 0.00000042 	 loss = 0.0063(0.1435)
2023/09/18 23:31:19 - INFO - root -   Epoch: [222/400][280/346], lr: 0.00000042 	 loss = 0.0011(0.1541)
2023/09/18 23:32:02 - INFO - root -   Epoch: [222/400][300/346], lr: 0.00000042 	 loss = 0.0035(0.1522)
2023/09/18 23:33:02 - INFO - root -   Epoch: [222/400][320/346], lr: 0.00000042 	 loss = 0.2628(0.1542)
2023/09/18 23:33:45 - INFO - root -   Epoch: [222/400][340/346], lr: 0.00000042 	 loss = 0.3514(0.1610)
2023/09/18 23:33:49 - INFO - root -   Epoch: [222/400] 	 loss = 0.1596
2023/09/18 23:33:49 - INFO - root -   train_accuracy = 0.9335
2023/09/18 23:34:10 - INFO - root -   Epoch: [223/400][0/346], lr: 0.00000042 	 loss = 0.0049(0.0049)
2023/09/18 23:34:54 - INFO - root -   Epoch: [223/400][20/346], lr: 0.00000042 	 loss = 0.0669(0.1717)
2023/09/18 23:35:55 - INFO - root -   Epoch: [223/400][40/346], lr: 0.00000042 	 loss = 0.0208(0.1605)
2023/09/18 23:36:38 - INFO - root -   Epoch: [223/400][60/346], lr: 0.00000042 	 loss = 0.4882(0.1447)
2023/09/18 23:37:39 - INFO - root -   Epoch: [223/400][80/346], lr: 0.00000042 	 loss = 0.2215(0.2027)
2023/09/18 23:38:22 - INFO - root -   Epoch: [223/400][100/346], lr: 0.00000042 	 loss = 1.0656(0.2095)
2023/09/18 23:39:23 - INFO - root -   Epoch: [223/400][120/346], lr: 0.00000042 	 loss = 0.0130(0.2839)
2023/09/18 23:40:06 - INFO - root -   Epoch: [223/400][140/346], lr: 0.00000042 	 loss = 0.0091(0.2762)
2023/09/18 23:41:07 - INFO - root -   Epoch: [223/400][160/346], lr: 0.00000042 	 loss = 0.0019(0.2691)
2023/09/18 23:41:50 - INFO - root -   Epoch: [223/400][180/346], lr: 0.00000042 	 loss = 0.0067(0.2718)
2023/09/18 23:42:51 - INFO - root -   Epoch: [223/400][200/346], lr: 0.00000042 	 loss = 0.0007(0.2518)
2023/09/18 23:43:34 - INFO - root -   Epoch: [223/400][220/346], lr: 0.00000042 	 loss = 0.0473(0.2421)
2023/09/18 23:44:35 - INFO - root -   Epoch: [223/400][240/346], lr: 0.00000042 	 loss = 0.0044(0.2292)
2023/09/18 23:45:18 - INFO - root -   Epoch: [223/400][260/346], lr: 0.00000042 	 loss = 0.3481(0.2257)
2023/09/18 23:46:19 - INFO - root -   Epoch: [223/400][280/346], lr: 0.00000042 	 loss = 0.0011(0.2290)
2023/09/18 23:47:02 - INFO - root -   Epoch: [223/400][300/346], lr: 0.00000042 	 loss = 0.0149(0.2212)
2023/09/18 23:48:03 - INFO - root -   Epoch: [223/400][320/346], lr: 0.00000042 	 loss = 0.0124(0.2124)
2023/09/18 23:48:44 - INFO - root -   Epoch: [223/400][340/346], lr: 0.00000042 	 loss = 0.6225(0.2218)
2023/09/18 23:48:48 - INFO - root -   Epoch: [223/400] 	 loss = 0.2193
2023/09/18 23:48:48 - INFO - root -   train_accuracy = 0.9118
2023/09/18 23:49:10 - INFO - root -   Epoch: [224/400][0/346], lr: 0.00000042 	 loss = 0.0604(0.0604)
2023/09/18 23:49:53 - INFO - root -   Epoch: [224/400][20/346], lr: 0.00000042 	 loss = 0.0042(0.1360)
2023/09/18 23:50:54 - INFO - root -   Epoch: [224/400][40/346], lr: 0.00000042 	 loss = 0.0432(0.1322)
2023/09/18 23:51:37 - INFO - root -   Epoch: [224/400][60/346], lr: 0.00000042 	 loss = 0.0153(0.1584)
2023/09/18 23:52:37 - INFO - root -   Epoch: [224/400][80/346], lr: 0.00000042 	 loss = 0.0005(0.1783)
2023/09/18 23:53:20 - INFO - root -   Epoch: [224/400][100/346], lr: 0.00000042 	 loss = 0.9042(0.2173)
2023/09/18 23:54:21 - INFO - root -   Epoch: [224/400][120/346], lr: 0.00000042 	 loss = 0.2093(0.2177)
2023/09/18 23:55:04 - INFO - root -   Epoch: [224/400][140/346], lr: 0.00000042 	 loss = 0.0353(0.2138)
2023/09/18 23:56:05 - INFO - root -   Epoch: [224/400][160/346], lr: 0.00000042 	 loss = 0.0023(0.2046)
2023/09/18 23:56:48 - INFO - root -   Epoch: [224/400][180/346], lr: 0.00000042 	 loss = 0.0108(0.2043)
2023/09/18 23:57:48 - INFO - root -   Epoch: [224/400][200/346], lr: 0.00000042 	 loss = 0.0067(0.1894)
2023/09/18 23:58:31 - INFO - root -   Epoch: [224/400][220/346], lr: 0.00000042 	 loss = 0.0470(0.1970)
2023/09/18 23:59:32 - INFO - root -   Epoch: [224/400][240/346], lr: 0.00000042 	 loss = 0.0012(0.1900)
2023/09/19 00:00:15 - INFO - root -   Epoch: [224/400][260/346], lr: 0.00000042 	 loss = 0.0560(0.1804)
2023/09/19 00:01:16 - INFO - root -   Epoch: [224/400][280/346], lr: 0.00000042 	 loss = 0.0884(0.1876)
2023/09/19 00:01:59 - INFO - root -   Epoch: [224/400][300/346], lr: 0.00000042 	 loss = 0.0008(0.1858)
2023/09/19 00:03:00 - INFO - root -   Epoch: [224/400][320/346], lr: 0.00000042 	 loss = 0.0038(0.1789)
2023/09/19 00:03:41 - INFO - root -   Epoch: [224/400][340/346], lr: 0.00000042 	 loss = 0.5376(0.1786)
2023/09/19 00:03:45 - INFO - root -   Epoch: [224/400] 	 loss = 0.1763
2023/09/19 00:07:34 - INFO - root -   precision = 0.7011
2023/09/19 00:07:34 - INFO - root -   eval_loss = 1.1584
2023/09/19 00:07:35 - INFO - root -   train_accuracy = 0.9350
2023/09/19 00:07:56 - INFO - root -   Epoch: [225/400][0/346], lr: 0.00000042 	 loss = 0.0046(0.0046)
2023/09/19 00:08:39 - INFO - root -   Epoch: [225/400][20/346], lr: 0.00000042 	 loss = 0.1525(0.0806)
2023/09/19 00:09:40 - INFO - root -   Epoch: [225/400][40/346], lr: 0.00000042 	 loss = 0.0231(0.1770)
2023/09/19 00:10:23 - INFO - root -   Epoch: [225/400][60/346], lr: 0.00000042 	 loss = 0.0400(0.1506)
2023/09/19 00:11:23 - INFO - root -   Epoch: [225/400][80/346], lr: 0.00000042 	 loss = 0.0014(0.1329)
2023/09/19 00:12:06 - INFO - root -   Epoch: [225/400][100/346], lr: 0.00000042 	 loss = 0.0723(0.1311)
2023/09/19 00:13:07 - INFO - root -   Epoch: [225/400][120/346], lr: 0.00000042 	 loss = 0.0036(0.1425)
2023/09/19 00:13:50 - INFO - root -   Epoch: [225/400][140/346], lr: 0.00000042 	 loss = 0.0177(0.1439)
2023/09/19 00:14:50 - INFO - root -   Epoch: [225/400][160/346], lr: 0.00000042 	 loss = 0.0090(0.1393)
2023/09/19 00:15:34 - INFO - root -   Epoch: [225/400][180/346], lr: 0.00000042 	 loss = 0.0308(0.1490)
2023/09/19 00:16:34 - INFO - root -   Epoch: [225/400][200/346], lr: 0.00000042 	 loss = 0.0011(0.1398)
2023/09/19 00:17:17 - INFO - root -   Epoch: [225/400][220/346], lr: 0.00000042 	 loss = 0.1188(0.1517)
2023/09/19 00:18:18 - INFO - root -   Epoch: [225/400][240/346], lr: 0.00000042 	 loss = 0.0017(0.1430)
2023/09/19 00:19:01 - INFO - root -   Epoch: [225/400][260/346], lr: 0.00000042 	 loss = 0.2477(0.1469)
2023/09/19 00:20:01 - INFO - root -   Epoch: [225/400][280/346], lr: 0.00000042 	 loss = 0.0134(0.1595)
2023/09/19 00:20:44 - INFO - root -   Epoch: [225/400][300/346], lr: 0.00000042 	 loss = 0.0029(0.1566)
2023/09/19 00:21:44 - INFO - root -   Epoch: [225/400][320/346], lr: 0.00000042 	 loss = 0.0870(0.1570)
2023/09/19 00:22:27 - INFO - root -   Epoch: [225/400][340/346], lr: 0.00000042 	 loss = 0.0206(0.1561)
2023/09/19 00:22:31 - INFO - root -   Epoch: [225/400] 	 loss = 0.1543
2023/09/19 00:22:31 - INFO - root -   train_accuracy = 0.9350
2023/09/19 00:22:52 - INFO - root -   Epoch: [226/400][0/346], lr: 0.00000042 	 loss = 0.0111(0.0111)
2023/09/19 00:23:36 - INFO - root -   Epoch: [226/400][20/346], lr: 0.00000042 	 loss = 0.0024(0.1391)
2023/09/19 00:24:37 - INFO - root -   Epoch: [226/400][40/346], lr: 0.00000042 	 loss = 0.0537(0.1481)
2023/09/19 00:25:21 - INFO - root -   Epoch: [226/400][60/346], lr: 0.00000042 	 loss = 0.0089(0.1102)
2023/09/19 00:26:21 - INFO - root -   Epoch: [226/400][80/346], lr: 0.00000042 	 loss = 0.0749(0.1186)
2023/09/19 00:27:05 - INFO - root -   Epoch: [226/400][100/346], lr: 0.00000042 	 loss = 0.0136(0.1122)
2023/09/19 00:28:05 - INFO - root -   Epoch: [226/400][120/346], lr: 0.00000042 	 loss = 0.0005(0.1048)
2023/09/19 00:28:49 - INFO - root -   Epoch: [226/400][140/346], lr: 0.00000042 	 loss = 0.0087(0.1170)
2023/09/19 00:29:49 - INFO - root -   Epoch: [226/400][160/346], lr: 0.00000042 	 loss = 0.0018(0.1281)
2023/09/19 00:30:33 - INFO - root -   Epoch: [226/400][180/346], lr: 0.00000042 	 loss = 0.0288(0.1302)
2023/09/19 00:31:33 - INFO - root -   Epoch: [226/400][200/346], lr: 0.00000042 	 loss = 0.0272(0.1302)
2023/09/19 00:32:17 - INFO - root -   Epoch: [226/400][220/346], lr: 0.00000042 	 loss = 0.5803(0.1322)
2023/09/19 00:33:17 - INFO - root -   Epoch: [226/400][240/346], lr: 0.00000042 	 loss = 0.0048(0.1332)
2023/09/19 00:34:02 - INFO - root -   Epoch: [226/400][260/346], lr: 0.00000042 	 loss = 0.7135(0.1300)
2023/09/19 00:35:01 - INFO - root -   Epoch: [226/400][280/346], lr: 0.00000042 	 loss = 0.0023(0.1332)
2023/09/19 00:35:46 - INFO - root -   Epoch: [226/400][300/346], lr: 0.00000042 	 loss = 0.5454(0.1330)
2023/09/19 00:36:45 - INFO - root -   Epoch: [226/400][320/346], lr: 0.00000042 	 loss = 0.0001(0.1304)
2023/09/19 00:37:28 - INFO - root -   Epoch: [226/400][340/346], lr: 0.00000042 	 loss = 0.0048(0.1281)
2023/09/19 00:37:32 - INFO - root -   Epoch: [226/400] 	 loss = 0.1284
2023/09/19 00:37:32 - INFO - root -   train_accuracy = 0.9422
2023/09/19 00:37:54 - INFO - root -   Epoch: [227/400][0/346], lr: 0.00000042 	 loss = 0.0444(0.0444)
2023/09/19 00:38:37 - INFO - root -   Epoch: [227/400][20/346], lr: 0.00000042 	 loss = 0.0069(0.0601)
2023/09/19 00:39:38 - INFO - root -   Epoch: [227/400][40/346], lr: 0.00000042 	 loss = 0.4780(0.0704)
2023/09/19 00:40:21 - INFO - root -   Epoch: [227/400][60/346], lr: 0.00000042 	 loss = 0.0103(0.0629)
2023/09/19 00:41:22 - INFO - root -   Epoch: [227/400][80/346], lr: 0.00000042 	 loss = 0.0010(0.0585)
2023/09/19 00:42:05 - INFO - root -   Epoch: [227/400][100/346], lr: 0.00000042 	 loss = 0.0656(0.0870)
2023/09/19 00:43:06 - INFO - root -   Epoch: [227/400][120/346], lr: 0.00000042 	 loss = 0.0003(0.1206)
2023/09/19 00:43:49 - INFO - root -   Epoch: [227/400][140/346], lr: 0.00000042 	 loss = 0.0014(0.1250)
2023/09/19 00:44:50 - INFO - root -   Epoch: [227/400][160/346], lr: 0.00000042 	 loss = 0.0283(0.1325)
2023/09/19 00:45:33 - INFO - root -   Epoch: [227/400][180/346], lr: 0.00000042 	 loss = 0.0556(0.1338)
2023/09/19 00:46:33 - INFO - root -   Epoch: [227/400][200/346], lr: 0.00000042 	 loss = 0.0029(0.1339)
2023/09/19 00:47:16 - INFO - root -   Epoch: [227/400][220/346], lr: 0.00000042 	 loss = 0.1468(0.1333)
2023/09/19 00:48:17 - INFO - root -   Epoch: [227/400][240/346], lr: 0.00000042 	 loss = 0.0057(0.1397)
2023/09/19 00:49:00 - INFO - root -   Epoch: [227/400][260/346], lr: 0.00000042 	 loss = 0.0096(0.1435)
2023/09/19 00:50:01 - INFO - root -   Epoch: [227/400][280/346], lr: 0.00000042 	 loss = 0.0006(0.1684)
2023/09/19 00:50:44 - INFO - root -   Epoch: [227/400][300/346], lr: 0.00000042 	 loss = 0.0933(0.1785)
2023/09/19 00:51:44 - INFO - root -   Epoch: [227/400][320/346], lr: 0.00000042 	 loss = 0.0223(0.1767)
2023/09/19 00:52:26 - INFO - root -   Epoch: [227/400][340/346], lr: 0.00000042 	 loss = 0.0105(0.1806)
2023/09/19 00:52:30 - INFO - root -   Epoch: [227/400] 	 loss = 0.1866
2023/09/19 00:52:30 - INFO - root -   train_accuracy = 0.9306
2023/09/19 00:52:51 - INFO - root -   Epoch: [228/400][0/346], lr: 0.00000043 	 loss = 0.0106(0.0106)
2023/09/19 00:53:34 - INFO - root -   Epoch: [228/400][20/346], lr: 0.00000043 	 loss = 0.0827(0.1836)
2023/09/19 00:54:35 - INFO - root -   Epoch: [228/400][40/346], lr: 0.00000043 	 loss = 0.0263(0.1669)
2023/09/19 00:55:18 - INFO - root -   Epoch: [228/400][60/346], lr: 0.00000043 	 loss = 0.0116(0.1314)
2023/09/19 00:56:18 - INFO - root -   Epoch: [228/400][80/346], lr: 0.00000043 	 loss = 0.0012(0.1247)
2023/09/19 00:57:01 - INFO - root -   Epoch: [228/400][100/346], lr: 0.00000043 	 loss = 0.6823(0.1338)
2023/09/19 00:58:01 - INFO - root -   Epoch: [228/400][120/346], lr: 0.00000043 	 loss = 0.0007(0.1448)
2023/09/19 00:58:45 - INFO - root -   Epoch: [228/400][140/346], lr: 0.00000043 	 loss = 0.3637(0.1398)
2023/09/19 00:59:45 - INFO - root -   Epoch: [228/400][160/346], lr: 0.00000043 	 loss = 0.0033(0.1390)
2023/09/19 01:00:28 - INFO - root -   Epoch: [228/400][180/346], lr: 0.00000043 	 loss = 0.0114(0.1319)
2023/09/19 01:01:28 - INFO - root -   Epoch: [228/400][200/346], lr: 0.00000043 	 loss = 0.0017(0.1206)
2023/09/19 01:02:12 - INFO - root -   Epoch: [228/400][220/346], lr: 0.00000043 	 loss = 0.0034(0.1245)
2023/09/19 01:03:12 - INFO - root -   Epoch: [228/400][240/346], lr: 0.00000043 	 loss = 0.0019(0.1294)
2023/09/19 01:03:55 - INFO - root -   Epoch: [228/400][260/346], lr: 0.00000043 	 loss = 0.0515(0.1414)
2023/09/19 01:04:55 - INFO - root -   Epoch: [228/400][280/346], lr: 0.00000043 	 loss = 0.0042(0.1585)
2023/09/19 01:05:38 - INFO - root -   Epoch: [228/400][300/346], lr: 0.00000043 	 loss = 0.0056(0.1538)
2023/09/19 01:06:39 - INFO - root -   Epoch: [228/400][320/346], lr: 0.00000043 	 loss = 0.0217(0.1558)
2023/09/19 01:07:20 - INFO - root -   Epoch: [228/400][340/346], lr: 0.00000043 	 loss = 0.4541(0.1575)
2023/09/19 01:07:24 - INFO - root -   Epoch: [228/400] 	 loss = 0.1560
2023/09/19 01:07:24 - INFO - root -   train_accuracy = 0.9364
2023/09/19 01:07:45 - INFO - root -   Epoch: [229/400][0/346], lr: 0.00000043 	 loss = 0.0282(0.0282)
2023/09/19 01:08:29 - INFO - root -   Epoch: [229/400][20/346], lr: 0.00000043 	 loss = 0.0014(0.0807)
2023/09/19 01:09:29 - INFO - root -   Epoch: [229/400][40/346], lr: 0.00000043 	 loss = 0.0068(0.0734)
2023/09/19 01:10:13 - INFO - root -   Epoch: [229/400][60/346], lr: 0.00000043 	 loss = 0.0083(0.0851)
2023/09/19 01:11:13 - INFO - root -   Epoch: [229/400][80/346], lr: 0.00000043 	 loss = 0.0086(0.0791)
2023/09/19 01:11:57 - INFO - root -   Epoch: [229/400][100/346], lr: 0.00000043 	 loss = 0.1963(0.0864)
2023/09/19 01:12:57 - INFO - root -   Epoch: [229/400][120/346], lr: 0.00000043 	 loss = 0.0270(0.0794)
2023/09/19 01:13:40 - INFO - root -   Epoch: [229/400][140/346], lr: 0.00000043 	 loss = 0.0155(0.0819)
2023/09/19 01:14:40 - INFO - root -   Epoch: [229/400][160/346], lr: 0.00000043 	 loss = 0.0069(0.1128)
2023/09/19 01:15:24 - INFO - root -   Epoch: [229/400][180/346], lr: 0.00000043 	 loss = 0.0865(0.1075)
2023/09/19 01:16:24 - INFO - root -   Epoch: [229/400][200/346], lr: 0.00000043 	 loss = 0.0023(0.1052)
2023/09/19 01:17:07 - INFO - root -   Epoch: [229/400][220/346], lr: 0.00000043 	 loss = 0.0058(0.1144)
2023/09/19 01:18:08 - INFO - root -   Epoch: [229/400][240/346], lr: 0.00000043 	 loss = 0.0102(0.1218)
2023/09/19 01:18:51 - INFO - root -   Epoch: [229/400][260/346], lr: 0.00000043 	 loss = 0.6230(0.1257)
2023/09/19 01:19:51 - INFO - root -   Epoch: [229/400][280/346], lr: 0.00000043 	 loss = 0.0005(0.1429)
2023/09/19 01:20:35 - INFO - root -   Epoch: [229/400][300/346], lr: 0.00000043 	 loss = 0.0029(0.1491)
2023/09/19 01:21:35 - INFO - root -   Epoch: [229/400][320/346], lr: 0.00000043 	 loss = 0.0010(0.1456)
2023/09/19 01:22:17 - INFO - root -   Epoch: [229/400][340/346], lr: 0.00000043 	 loss = 0.0439(0.1447)
2023/09/19 01:22:21 - INFO - root -   Epoch: [229/400] 	 loss = 0.1436
2023/09/19 01:26:09 - INFO - root -   precision = 0.6782
2023/09/19 01:26:09 - INFO - root -   eval_loss = 1.1311
2023/09/19 01:26:10 - INFO - root -   train_accuracy = 0.9494
2023/09/19 01:26:32 - INFO - root -   Epoch: [230/400][0/346], lr: 0.00000043 	 loss = 0.0723(0.0723)
2023/09/19 01:27:15 - INFO - root -   Epoch: [230/400][20/346], lr: 0.00000043 	 loss = 0.2806(0.1693)
2023/09/19 01:28:16 - INFO - root -   Epoch: [230/400][40/346], lr: 0.00000043 	 loss = 0.0391(0.1591)
2023/09/19 01:28:59 - INFO - root -   Epoch: [230/400][60/346], lr: 0.00000043 	 loss = 0.0058(0.1521)
2023/09/19 01:29:59 - INFO - root -   Epoch: [230/400][80/346], lr: 0.00000043 	 loss = 0.0631(0.1325)
2023/09/19 01:30:42 - INFO - root -   Epoch: [230/400][100/346], lr: 0.00000043 	 loss = 0.0942(0.1252)
2023/09/19 01:31:43 - INFO - root -   Epoch: [230/400][120/346], lr: 0.00000043 	 loss = 0.0114(0.1194)
2023/09/19 01:32:26 - INFO - root -   Epoch: [230/400][140/346], lr: 0.00000043 	 loss = 0.0044(0.1173)
2023/09/19 01:33:26 - INFO - root -   Epoch: [230/400][160/346], lr: 0.00000043 	 loss = 0.0005(0.1056)
2023/09/19 01:34:09 - INFO - root -   Epoch: [230/400][180/346], lr: 0.00000043 	 loss = 0.0101(0.1053)
2023/09/19 01:35:09 - INFO - root -   Epoch: [230/400][200/346], lr: 0.00000043 	 loss = 0.0010(0.1041)
2023/09/19 01:35:52 - INFO - root -   Epoch: [230/400][220/346], lr: 0.00000043 	 loss = 0.0041(0.1048)
2023/09/19 01:36:53 - INFO - root -   Epoch: [230/400][240/346], lr: 0.00000043 	 loss = 0.0023(0.1026)
2023/09/19 01:37:36 - INFO - root -   Epoch: [230/400][260/346], lr: 0.00000043 	 loss = 0.0226(0.1101)
2023/09/19 01:38:36 - INFO - root -   Epoch: [230/400][280/346], lr: 0.00000043 	 loss = 0.0142(0.1320)
2023/09/19 01:39:19 - INFO - root -   Epoch: [230/400][300/346], lr: 0.00000043 	 loss = 0.1572(0.1305)
2023/09/19 01:40:19 - INFO - root -   Epoch: [230/400][320/346], lr: 0.00000043 	 loss = 0.0144(0.1288)
2023/09/19 01:41:01 - INFO - root -   Epoch: [230/400][340/346], lr: 0.00000043 	 loss = 0.2932(0.1300)
2023/09/19 01:41:05 - INFO - root -   Epoch: [230/400] 	 loss = 0.1354
2023/09/19 01:41:05 - INFO - root -   train_accuracy = 0.9538
2023/09/19 01:41:27 - INFO - root -   Epoch: [231/400][0/346], lr: 0.00000043 	 loss = 0.0044(0.0044)
2023/09/19 01:42:10 - INFO - root -   Epoch: [231/400][20/346], lr: 0.00000043 	 loss = 0.1241(0.1251)
2023/09/19 01:43:10 - INFO - root -   Epoch: [231/400][40/346], lr: 0.00000043 	 loss = 0.1410(0.1582)
2023/09/19 01:43:54 - INFO - root -   Epoch: [231/400][60/346], lr: 0.00000043 	 loss = 0.2492(0.1467)
2023/09/19 01:44:54 - INFO - root -   Epoch: [231/400][80/346], lr: 0.00000043 	 loss = 0.0176(0.2513)
2023/09/19 01:45:37 - INFO - root -   Epoch: [231/400][100/346], lr: 0.00000043 	 loss = 0.0791(0.2545)
2023/09/19 01:46:38 - INFO - root -   Epoch: [231/400][120/346], lr: 0.00000043 	 loss = 0.0092(0.2636)
2023/09/19 01:47:21 - INFO - root -   Epoch: [231/400][140/346], lr: 0.00000043 	 loss = 0.0560(0.2412)
2023/09/19 01:48:22 - INFO - root -   Epoch: [231/400][160/346], lr: 0.00000043 	 loss = 0.0216(0.2374)
2023/09/19 01:49:06 - INFO - root -   Epoch: [231/400][180/346], lr: 0.00000043 	 loss = 0.0051(0.2251)
2023/09/19 01:50:06 - INFO - root -   Epoch: [231/400][200/346], lr: 0.00000043 	 loss = 0.0082(0.2104)
2023/09/19 01:50:49 - INFO - root -   Epoch: [231/400][220/346], lr: 0.00000043 	 loss = 1.9031(0.2192)
2023/09/19 01:51:49 - INFO - root -   Epoch: [231/400][240/346], lr: 0.00000043 	 loss = 0.0071(0.2118)
2023/09/19 01:52:33 - INFO - root -   Epoch: [231/400][260/346], lr: 0.00000043 	 loss = 1.0994(0.2048)
2023/09/19 01:53:33 - INFO - root -   Epoch: [231/400][280/346], lr: 0.00000043 	 loss = 0.0560(0.2100)
2023/09/19 01:54:17 - INFO - root -   Epoch: [231/400][300/346], lr: 0.00000043 	 loss = 0.0200(0.2082)
2023/09/19 01:55:17 - INFO - root -   Epoch: [231/400][320/346], lr: 0.00000043 	 loss = 0.1169(0.2124)
2023/09/19 01:55:59 - INFO - root -   Epoch: [231/400][340/346], lr: 0.00000043 	 loss = 0.0434(0.2127)
2023/09/19 01:56:03 - INFO - root -   Epoch: [231/400] 	 loss = 0.2165
2023/09/19 01:56:03 - INFO - root -   train_accuracy = 0.9205
2023/09/19 01:56:26 - INFO - root -   Epoch: [232/400][0/346], lr: 0.00000043 	 loss = 0.0082(0.0082)
2023/09/19 01:57:09 - INFO - root -   Epoch: [232/400][20/346], lr: 0.00000043 	 loss = 0.0021(0.0411)
2023/09/19 01:58:11 - INFO - root -   Epoch: [232/400][40/346], lr: 0.00000043 	 loss = 0.9298(0.0659)
2023/09/19 01:58:55 - INFO - root -   Epoch: [232/400][60/346], lr: 0.00000043 	 loss = 0.0199(0.0643)
2023/09/19 01:59:56 - INFO - root -   Epoch: [232/400][80/346], lr: 0.00000043 	 loss = 0.0176(0.0981)
2023/09/19 02:00:40 - INFO - root -   Epoch: [232/400][100/346], lr: 0.00000043 	 loss = 0.5141(0.1207)
2023/09/19 02:01:42 - INFO - root -   Epoch: [232/400][120/346], lr: 0.00000043 	 loss = 0.0026(0.1191)
2023/09/19 02:02:25 - INFO - root -   Epoch: [232/400][140/346], lr: 0.00000043 	 loss = 0.0115(0.1196)
2023/09/19 02:03:27 - INFO - root -   Epoch: [232/400][160/346], lr: 0.00000043 	 loss = 0.0018(0.1222)
2023/09/19 02:04:11 - INFO - root -   Epoch: [232/400][180/346], lr: 0.00000043 	 loss = 0.0141(0.1252)
2023/09/19 02:05:11 - INFO - root -   Epoch: [232/400][200/346], lr: 0.00000043 	 loss = 0.0017(0.1159)
2023/09/19 02:05:55 - INFO - root -   Epoch: [232/400][220/346], lr: 0.00000043 	 loss = 0.0162(0.1151)
2023/09/19 02:06:56 - INFO - root -   Epoch: [232/400][240/346], lr: 0.00000043 	 loss = 0.0702(0.1090)
2023/09/19 02:07:40 - INFO - root -   Epoch: [232/400][260/346], lr: 0.00000043 	 loss = 0.0643(0.1038)
2023/09/19 02:08:40 - INFO - root -   Epoch: [232/400][280/346], lr: 0.00000043 	 loss = 0.0014(0.1066)
2023/09/19 02:09:25 - INFO - root -   Epoch: [232/400][300/346], lr: 0.00000043 	 loss = 0.0032(0.1059)
2023/09/19 02:10:25 - INFO - root -   Epoch: [232/400][320/346], lr: 0.00000043 	 loss = 0.0018(0.1081)
2023/09/19 02:11:08 - INFO - root -   Epoch: [232/400][340/346], lr: 0.00000043 	 loss = 0.8653(0.1073)
2023/09/19 02:11:12 - INFO - root -   Epoch: [232/400] 	 loss = 0.1073
2023/09/19 02:11:12 - INFO - root -   train_accuracy = 0.9639
2023/09/19 02:11:34 - INFO - root -   Epoch: [233/400][0/346], lr: 0.00000043 	 loss = 0.1931(0.1931)
2023/09/19 02:12:17 - INFO - root -   Epoch: [233/400][20/346], lr: 0.00000043 	 loss = 0.0004(0.0387)
2023/09/19 02:13:17 - INFO - root -   Epoch: [233/400][40/346], lr: 0.00000043 	 loss = 0.0028(0.0687)
2023/09/19 02:14:00 - INFO - root -   Epoch: [233/400][60/346], lr: 0.00000043 	 loss = 0.0150(0.0708)
2023/09/19 02:15:01 - INFO - root -   Epoch: [233/400][80/346], lr: 0.00000043 	 loss = 0.5932(0.1262)
2023/09/19 02:15:44 - INFO - root -   Epoch: [233/400][100/346], lr: 0.00000043 	 loss = 0.0281(0.1301)
2023/09/19 02:16:45 - INFO - root -   Epoch: [233/400][120/346], lr: 0.00000043 	 loss = 0.0346(0.1237)
2023/09/19 02:17:28 - INFO - root -   Epoch: [233/400][140/346], lr: 0.00000043 	 loss = 0.0079(0.1448)
2023/09/19 02:18:28 - INFO - root -   Epoch: [233/400][160/346], lr: 0.00000043 	 loss = 0.0309(0.1423)
2023/09/19 02:19:11 - INFO - root -   Epoch: [233/400][180/346], lr: 0.00000043 	 loss = 0.0137(0.1352)
2023/09/19 02:20:12 - INFO - root -   Epoch: [233/400][200/346], lr: 0.00000043 	 loss = 0.0003(0.1302)
2023/09/19 02:20:55 - INFO - root -   Epoch: [233/400][220/346], lr: 0.00000043 	 loss = 0.0045(0.1253)
2023/09/19 02:21:55 - INFO - root -   Epoch: [233/400][240/346], lr: 0.00000043 	 loss = 0.0220(0.1203)
2023/09/19 02:22:38 - INFO - root -   Epoch: [233/400][260/346], lr: 0.00000043 	 loss = 0.0178(0.1123)
2023/09/19 02:23:38 - INFO - root -   Epoch: [233/400][280/346], lr: 0.00000043 	 loss = 0.0010(0.1175)
2023/09/19 02:24:21 - INFO - root -   Epoch: [233/400][300/346], lr: 0.00000043 	 loss = 0.0004(0.1120)
2023/09/19 02:25:22 - INFO - root -   Epoch: [233/400][320/346], lr: 0.00000043 	 loss = 0.0038(0.1091)
2023/09/19 02:26:04 - INFO - root -   Epoch: [233/400][340/346], lr: 0.00000043 	 loss = 0.0126(0.1183)
2023/09/19 02:26:07 - INFO - root -   Epoch: [233/400] 	 loss = 0.1215
2023/09/19 02:26:07 - INFO - root -   train_accuracy = 0.9639
2023/09/19 02:26:29 - INFO - root -   Epoch: [234/400][0/346], lr: 0.00000043 	 loss = 0.0081(0.0081)
2023/09/19 02:27:12 - INFO - root -   Epoch: [234/400][20/346], lr: 0.00000043 	 loss = 0.0029(0.2253)
2023/09/19 02:28:13 - INFO - root -   Epoch: [234/400][40/346], lr: 0.00000043 	 loss = 0.2238(0.2385)
2023/09/19 02:28:56 - INFO - root -   Epoch: [234/400][60/346], lr: 0.00000043 	 loss = 0.5024(0.2379)
2023/09/19 02:29:57 - INFO - root -   Epoch: [234/400][80/346], lr: 0.00000043 	 loss = 0.0121(0.2882)
2023/09/19 02:30:40 - INFO - root -   Epoch: [234/400][100/346], lr: 0.00000043 	 loss = 5.4455(0.4455)
2023/09/19 02:31:40 - INFO - root -   Epoch: [234/400][120/346], lr: 0.00000043 	 loss = 0.0002(0.5020)
2023/09/19 02:32:23 - INFO - root -   Epoch: [234/400][140/346], lr: 0.00000043 	 loss = 0.1637(0.4869)
2023/09/19 02:33:24 - INFO - root -   Epoch: [234/400][160/346], lr: 0.00000043 	 loss = 0.0018(0.4506)
2023/09/19 02:34:07 - INFO - root -   Epoch: [234/400][180/346], lr: 0.00000043 	 loss = 0.2923(0.4445)
2023/09/19 02:35:08 - INFO - root -   Epoch: [234/400][200/346], lr: 0.00000043 	 loss = 0.0187(0.4146)
2023/09/19 02:35:51 - INFO - root -   Epoch: [234/400][220/346], lr: 0.00000043 	 loss = 0.0818(0.4087)
2023/09/19 02:36:51 - INFO - root -   Epoch: [234/400][240/346], lr: 0.00000043 	 loss = 0.0465(0.3872)
2023/09/19 02:37:34 - INFO - root -   Epoch: [234/400][260/346], lr: 0.00000043 	 loss = 0.0343(0.3709)
2023/09/19 02:38:35 - INFO - root -   Epoch: [234/400][280/346], lr: 0.00000043 	 loss = 0.4182(0.3666)
2023/09/19 02:39:18 - INFO - root -   Epoch: [234/400][300/346], lr: 0.00000043 	 loss = 0.0069(0.3550)
2023/09/19 02:40:19 - INFO - root -   Epoch: [234/400][320/346], lr: 0.00000043 	 loss = 0.1340(0.3437)
2023/09/19 02:41:01 - INFO - root -   Epoch: [234/400][340/346], lr: 0.00000043 	 loss = 0.0773(0.3283)
2023/09/19 02:41:05 - INFO - root -   Epoch: [234/400] 	 loss = 0.3248
2023/09/19 02:44:53 - INFO - root -   precision = 0.6839
2023/09/19 02:44:53 - INFO - root -   eval_loss = 1.0438
2023/09/19 02:44:54 - INFO - root -   train_accuracy = 0.8858
2023/09/19 02:45:15 - INFO - root -   Epoch: [235/400][0/346], lr: 0.00000044 	 loss = 0.5024(0.5024)
2023/09/19 02:45:58 - INFO - root -   Epoch: [235/400][20/346], lr: 0.00000044 	 loss = 0.0022(0.1320)
2023/09/19 02:46:59 - INFO - root -   Epoch: [235/400][40/346], lr: 0.00000044 	 loss = 0.0184(0.0931)
2023/09/19 02:47:42 - INFO - root -   Epoch: [235/400][60/346], lr: 0.00000044 	 loss = 0.3385(0.0959)
2023/09/19 02:48:42 - INFO - root -   Epoch: [235/400][80/346], lr: 0.00000044 	 loss = 0.0025(0.1021)
2023/09/19 02:49:25 - INFO - root -   Epoch: [235/400][100/346], lr: 0.00000044 	 loss = 0.0443(0.1321)
2023/09/19 02:50:26 - INFO - root -   Epoch: [235/400][120/346], lr: 0.00000044 	 loss = 0.1002(0.1300)
2023/09/19 02:51:09 - INFO - root -   Epoch: [235/400][140/346], lr: 0.00000044 	 loss = 0.1116(0.1283)
2023/09/19 02:52:09 - INFO - root -   Epoch: [235/400][160/346], lr: 0.00000044 	 loss = 0.0036(0.1215)
2023/09/19 02:52:52 - INFO - root -   Epoch: [235/400][180/346], lr: 0.00000044 	 loss = 0.0137(0.1237)
2023/09/19 02:53:53 - INFO - root -   Epoch: [235/400][200/346], lr: 0.00000044 	 loss = 0.0023(0.1271)
2023/09/19 02:54:36 - INFO - root -   Epoch: [235/400][220/346], lr: 0.00000044 	 loss = 0.0427(0.1277)
2023/09/19 02:55:37 - INFO - root -   Epoch: [235/400][240/346], lr: 0.00000044 	 loss = 0.0003(0.1218)
2023/09/19 02:56:20 - INFO - root -   Epoch: [235/400][260/346], lr: 0.00000044 	 loss = 0.0567(0.1156)
2023/09/19 02:57:21 - INFO - root -   Epoch: [235/400][280/346], lr: 0.00000044 	 loss = 0.0102(0.1229)
2023/09/19 02:58:04 - INFO - root -   Epoch: [235/400][300/346], lr: 0.00000044 	 loss = 0.1039(0.1336)
2023/09/19 02:59:04 - INFO - root -   Epoch: [235/400][320/346], lr: 0.00000044 	 loss = 0.0010(0.1277)
2023/09/19 02:59:46 - INFO - root -   Epoch: [235/400][340/346], lr: 0.00000044 	 loss = 0.0639(0.1261)
2023/09/19 02:59:50 - INFO - root -   Epoch: [235/400] 	 loss = 0.1270
2023/09/19 02:59:50 - INFO - root -   train_accuracy = 0.9566
2023/09/19 03:00:11 - INFO - root -   Epoch: [236/400][0/346], lr: 0.00000044 	 loss = 0.3645(0.3645)
2023/09/19 03:00:55 - INFO - root -   Epoch: [236/400][20/346], lr: 0.00000044 	 loss = 0.0011(0.1343)
2023/09/19 03:01:55 - INFO - root -   Epoch: [236/400][40/346], lr: 0.00000044 	 loss = 0.0125(0.0904)
2023/09/19 03:02:39 - INFO - root -   Epoch: [236/400][60/346], lr: 0.00000044 	 loss = 0.0081(0.0745)
2023/09/19 03:03:39 - INFO - root -   Epoch: [236/400][80/346], lr: 0.00000044 	 loss = 0.1076(0.1017)
2023/09/19 03:04:23 - INFO - root -   Epoch: [236/400][100/346], lr: 0.00000044 	 loss = 0.0096(0.1103)
2023/09/19 03:05:24 - INFO - root -   Epoch: [236/400][120/346], lr: 0.00000044 	 loss = 0.0338(0.1236)
2023/09/19 03:06:07 - INFO - root -   Epoch: [236/400][140/346], lr: 0.00000044 	 loss = 0.3691(0.1297)
2023/09/19 03:07:08 - INFO - root -   Epoch: [236/400][160/346], lr: 0.00000044 	 loss = 0.0619(0.1624)
2023/09/19 03:07:51 - INFO - root -   Epoch: [236/400][180/346], lr: 0.00000044 	 loss = 0.0924(0.1545)
2023/09/19 03:08:52 - INFO - root -   Epoch: [236/400][200/346], lr: 0.00000044 	 loss = 0.0012(0.1484)
2023/09/19 03:09:35 - INFO - root -   Epoch: [236/400][220/346], lr: 0.00000044 	 loss = 0.0903(0.1744)
2023/09/19 03:10:36 - INFO - root -   Epoch: [236/400][240/346], lr: 0.00000044 	 loss = 0.0673(0.1752)
2023/09/19 03:11:19 - INFO - root -   Epoch: [236/400][260/346], lr: 0.00000044 	 loss = 0.0386(0.1697)
2023/09/19 03:12:20 - INFO - root -   Epoch: [236/400][280/346], lr: 0.00000044 	 loss = 0.0197(0.1645)
2023/09/19 03:13:03 - INFO - root -   Epoch: [236/400][300/346], lr: 0.00000044 	 loss = 0.0057(0.1679)
2023/09/19 03:14:03 - INFO - root -   Epoch: [236/400][320/346], lr: 0.00000044 	 loss = 0.0232(0.1733)
2023/09/19 03:14:45 - INFO - root -   Epoch: [236/400][340/346], lr: 0.00000044 	 loss = 0.3590(0.1703)
2023/09/19 03:14:50 - INFO - root -   Epoch: [236/400] 	 loss = 0.1706
2023/09/19 03:14:50 - INFO - root -   train_accuracy = 0.9220
2023/09/19 03:15:11 - INFO - root -   Epoch: [237/400][0/346], lr: 0.00000044 	 loss = 0.0069(0.0069)
2023/09/19 03:15:54 - INFO - root -   Epoch: [237/400][20/346], lr: 0.00000044 	 loss = 0.0007(0.1004)
2023/09/19 03:16:55 - INFO - root -   Epoch: [237/400][40/346], lr: 0.00000044 	 loss = 0.1527(0.1705)
2023/09/19 03:17:38 - INFO - root -   Epoch: [237/400][60/346], lr: 0.00000044 	 loss = 0.0475(0.1263)
2023/09/19 03:18:39 - INFO - root -   Epoch: [237/400][80/346], lr: 0.00000044 	 loss = 0.0065(0.1274)
2023/09/19 03:19:22 - INFO - root -   Epoch: [237/400][100/346], lr: 0.00000044 	 loss = 0.0230(0.1207)
2023/09/19 03:20:22 - INFO - root -   Epoch: [237/400][120/346], lr: 0.00000044 	 loss = 0.0050(0.1126)
2023/09/19 03:21:06 - INFO - root -   Epoch: [237/400][140/346], lr: 0.00000044 	 loss = 0.0041(0.1254)
2023/09/19 03:22:06 - INFO - root -   Epoch: [237/400][160/346], lr: 0.00000044 	 loss = 0.0090(0.1479)
2023/09/19 03:22:49 - INFO - root -   Epoch: [237/400][180/346], lr: 0.00000044 	 loss = 0.0046(0.1523)
2023/09/19 03:23:50 - INFO - root -   Epoch: [237/400][200/346], lr: 0.00000044 	 loss = 0.0064(0.1458)
2023/09/19 03:24:33 - INFO - root -   Epoch: [237/400][220/346], lr: 0.00000044 	 loss = 0.0263(0.1442)
2023/09/19 03:25:33 - INFO - root -   Epoch: [237/400][240/346], lr: 0.00000044 	 loss = 0.0035(0.1426)
2023/09/19 03:26:18 - INFO - root -   Epoch: [237/400][260/346], lr: 0.00000044 	 loss = 0.0706(0.1433)
2023/09/19 03:27:18 - INFO - root -   Epoch: [237/400][280/346], lr: 0.00000044 	 loss = 0.0045(0.1501)
2023/09/19 03:28:01 - INFO - root -   Epoch: [237/400][300/346], lr: 0.00000044 	 loss = 0.0006(0.1441)
2023/09/19 03:29:02 - INFO - root -   Epoch: [237/400][320/346], lr: 0.00000044 	 loss = 0.0002(0.1413)
2023/09/19 03:29:42 - INFO - root -   Epoch: [237/400][340/346], lr: 0.00000044 	 loss = 0.0200(0.1401)
2023/09/19 03:29:46 - INFO - root -   Epoch: [237/400] 	 loss = 0.1450
2023/09/19 03:29:46 - INFO - root -   train_accuracy = 0.9494
2023/09/19 03:30:08 - INFO - root -   Epoch: [238/400][0/346], lr: 0.00000044 	 loss = 0.0068(0.0068)
2023/09/19 03:30:51 - INFO - root -   Epoch: [238/400][20/346], lr: 0.00000044 	 loss = 0.0035(0.1259)
2023/09/19 03:31:52 - INFO - root -   Epoch: [238/400][40/346], lr: 0.00000044 	 loss = 0.0102(0.2155)
2023/09/19 03:32:34 - INFO - root -   Epoch: [238/400][60/346], lr: 0.00000044 	 loss = 0.0459(0.2492)
2023/09/19 03:33:35 - INFO - root -   Epoch: [238/400][80/346], lr: 0.00000044 	 loss = 0.0010(0.2301)
2023/09/19 03:34:18 - INFO - root -   Epoch: [238/400][100/346], lr: 0.00000044 	 loss = 0.0606(0.2100)
2023/09/19 03:35:19 - INFO - root -   Epoch: [238/400][120/346], lr: 0.00000044 	 loss = 0.0043(0.2112)
2023/09/19 03:36:02 - INFO - root -   Epoch: [238/400][140/346], lr: 0.00000044 	 loss = 0.0040(0.2039)
2023/09/19 03:37:02 - INFO - root -   Epoch: [238/400][160/346], lr: 0.00000044 	 loss = 0.0022(0.1978)
2023/09/19 03:37:45 - INFO - root -   Epoch: [238/400][180/346], lr: 0.00000044 	 loss = 0.0009(0.1864)
2023/09/19 03:38:46 - INFO - root -   Epoch: [238/400][200/346], lr: 0.00000044 	 loss = 0.0017(0.1783)
2023/09/19 03:39:29 - INFO - root -   Epoch: [238/400][220/346], lr: 0.00000044 	 loss = 0.0054(0.1709)
2023/09/19 03:40:29 - INFO - root -   Epoch: [238/400][240/346], lr: 0.00000044 	 loss = 0.0011(0.1661)
2023/09/19 03:41:12 - INFO - root -   Epoch: [238/400][260/346], lr: 0.00000044 	 loss = 0.0691(0.1618)
2023/09/19 03:42:13 - INFO - root -   Epoch: [238/400][280/346], lr: 0.00000044 	 loss = 0.0248(0.1785)
2023/09/19 03:42:56 - INFO - root -   Epoch: [238/400][300/346], lr: 0.00000044 	 loss = 0.1009(0.1706)
2023/09/19 03:43:56 - INFO - root -   Epoch: [238/400][320/346], lr: 0.00000044 	 loss = 0.0030(0.1765)
2023/09/19 03:44:38 - INFO - root -   Epoch: [238/400][340/346], lr: 0.00000044 	 loss = 0.0320(0.1702)
2023/09/19 03:44:42 - INFO - root -   Epoch: [238/400] 	 loss = 0.1724
2023/09/19 03:44:42 - INFO - root -   train_accuracy = 0.9277
2023/09/19 03:45:04 - INFO - root -   Epoch: [239/400][0/346], lr: 0.00000044 	 loss = 0.0177(0.0177)
2023/09/19 03:45:47 - INFO - root -   Epoch: [239/400][20/346], lr: 0.00000044 	 loss = 0.0014(0.0446)
2023/09/19 03:46:48 - INFO - root -   Epoch: [239/400][40/346], lr: 0.00000044 	 loss = 0.0286(0.0497)
2023/09/19 03:47:31 - INFO - root -   Epoch: [239/400][60/346], lr: 0.00000044 	 loss = 0.0140(0.0440)
2023/09/19 03:48:31 - INFO - root -   Epoch: [239/400][80/346], lr: 0.00000044 	 loss = 0.0036(0.0479)
2023/09/19 03:49:15 - INFO - root -   Epoch: [239/400][100/346], lr: 0.00000044 	 loss = 0.0342(0.0441)
2023/09/19 03:50:15 - INFO - root -   Epoch: [239/400][120/346], lr: 0.00000044 	 loss = 0.0019(0.0596)
2023/09/19 03:50:59 - INFO - root -   Epoch: [239/400][140/346], lr: 0.00000044 	 loss = 0.1946(0.0655)
2023/09/19 03:51:59 - INFO - root -   Epoch: [239/400][160/346], lr: 0.00000044 	 loss = 0.0097(0.0686)
2023/09/19 03:52:43 - INFO - root -   Epoch: [239/400][180/346], lr: 0.00000044 	 loss = 0.0032(0.0787)
2023/09/19 03:53:43 - INFO - root -   Epoch: [239/400][200/346], lr: 0.00000044 	 loss = 0.0011(0.0807)
2023/09/19 03:54:27 - INFO - root -   Epoch: [239/400][220/346], lr: 0.00000044 	 loss = 0.0057(0.0840)
2023/09/19 03:55:26 - INFO - root -   Epoch: [239/400][240/346], lr: 0.00000044 	 loss = 0.0002(0.0874)
2023/09/19 03:56:11 - INFO - root -   Epoch: [239/400][260/346], lr: 0.00000044 	 loss = 0.1265(0.0843)
2023/09/19 03:57:10 - INFO - root -   Epoch: [239/400][280/346], lr: 0.00000044 	 loss = 0.0034(0.0846)
2023/09/19 03:57:55 - INFO - root -   Epoch: [239/400][300/346], lr: 0.00000044 	 loss = 0.0107(0.0874)
2023/09/19 03:58:53 - INFO - root -   Epoch: [239/400][320/346], lr: 0.00000044 	 loss = 0.0404(0.0990)
2023/09/19 03:59:37 - INFO - root -   Epoch: [239/400][340/346], lr: 0.00000044 	 loss = 0.1202(0.0955)
2023/09/19 03:59:41 - INFO - root -   Epoch: [239/400] 	 loss = 0.0958
2023/09/19 04:03:28 - INFO - root -   precision = 0.6782
2023/09/19 04:03:28 - INFO - root -   eval_loss = 1.2552
2023/09/19 04:03:29 - INFO - root -   train_accuracy = 0.9639
2023/09/19 04:03:50 - INFO - root -   Epoch: [240/400][0/346], lr: 0.00000044 	 loss = 0.0046(0.0046)
2023/09/19 04:04:34 - INFO - root -   Epoch: [240/400][20/346], lr: 0.00000044 	 loss = 0.0017(0.1128)
2023/09/19 04:05:35 - INFO - root -   Epoch: [240/400][40/346], lr: 0.00000044 	 loss = 0.0113(0.1154)
2023/09/19 04:06:18 - INFO - root -   Epoch: [240/400][60/346], lr: 0.00000044 	 loss = 0.0092(0.1433)
2023/09/19 04:07:18 - INFO - root -   Epoch: [240/400][80/346], lr: 0.00000044 	 loss = 0.0563(0.1177)
2023/09/19 04:08:01 - INFO - root -   Epoch: [240/400][100/346], lr: 0.00000044 	 loss = 0.5293(0.1118)
2023/09/19 04:09:02 - INFO - root -   Epoch: [240/400][120/346], lr: 0.00000044 	 loss = 0.0010(0.1217)
2023/09/19 04:09:45 - INFO - root -   Epoch: [240/400][140/346], lr: 0.00000044 	 loss = 0.0014(0.1230)
2023/09/19 04:10:45 - INFO - root -   Epoch: [240/400][160/346], lr: 0.00000044 	 loss = 0.0332(0.1143)
2023/09/19 04:11:28 - INFO - root -   Epoch: [240/400][180/346], lr: 0.00000044 	 loss = 0.0662(0.1098)
2023/09/19 04:12:28 - INFO - root -   Epoch: [240/400][200/346], lr: 0.00000044 	 loss = 0.0016(0.1073)
2023/09/19 04:13:11 - INFO - root -   Epoch: [240/400][220/346], lr: 0.00000044 	 loss = 0.0077(0.1237)
2023/09/19 04:14:12 - INFO - root -   Epoch: [240/400][240/346], lr: 0.00000044 	 loss = 0.4364(0.1243)
2023/09/19 04:14:55 - INFO - root -   Epoch: [240/400][260/346], lr: 0.00000044 	 loss = 0.0043(0.1290)
2023/09/19 04:15:56 - INFO - root -   Epoch: [240/400][280/346], lr: 0.00000044 	 loss = 0.0099(0.1389)
2023/09/19 04:16:39 - INFO - root -   Epoch: [240/400][300/346], lr: 0.00000044 	 loss = 0.0216(0.1415)
2023/09/19 04:17:39 - INFO - root -   Epoch: [240/400][320/346], lr: 0.00000044 	 loss = 0.0011(0.1373)
2023/09/19 04:18:21 - INFO - root -   Epoch: [240/400][340/346], lr: 0.00000044 	 loss = 0.4682(0.1489)
2023/09/19 04:18:24 - INFO - root -   Epoch: [240/400] 	 loss = 0.1530
2023/09/19 04:18:24 - INFO - root -   train_accuracy = 0.9292
2023/09/19 04:18:46 - INFO - root -   Epoch: [241/400][0/346], lr: 0.00000044 	 loss = 0.0043(0.0043)
2023/09/19 04:19:29 - INFO - root -   Epoch: [241/400][20/346], lr: 0.00000044 	 loss = 0.0044(0.1981)
2023/09/19 04:20:30 - INFO - root -   Epoch: [241/400][40/346], lr: 0.00000044 	 loss = 0.0043(0.2117)
2023/09/19 04:21:13 - INFO - root -   Epoch: [241/400][60/346], lr: 0.00000044 	 loss = 0.3783(0.1893)
2023/09/19 04:22:14 - INFO - root -   Epoch: [241/400][80/346], lr: 0.00000044 	 loss = 0.0090(0.1792)
2023/09/19 04:22:57 - INFO - root -   Epoch: [241/400][100/346], lr: 0.00000044 	 loss = 0.0413(0.1581)
2023/09/19 04:23:58 - INFO - root -   Epoch: [241/400][120/346], lr: 0.00000044 	 loss = 0.1128(0.1522)
2023/09/19 04:24:41 - INFO - root -   Epoch: [241/400][140/346], lr: 0.00000044 	 loss = 0.0005(0.1470)
2023/09/19 04:25:42 - INFO - root -   Epoch: [241/400][160/346], lr: 0.00000044 	 loss = 0.0276(0.1420)
2023/09/19 04:26:25 - INFO - root -   Epoch: [241/400][180/346], lr: 0.00000044 	 loss = 0.0050(0.1459)
2023/09/19 04:27:26 - INFO - root -   Epoch: [241/400][200/346], lr: 0.00000044 	 loss = 0.0003(0.1394)
2023/09/19 04:28:09 - INFO - root -   Epoch: [241/400][220/346], lr: 0.00000044 	 loss = 0.5545(0.1356)
2023/09/19 04:29:09 - INFO - root -   Epoch: [241/400][240/346], lr: 0.00000044 	 loss = 0.0002(0.1281)
2023/09/19 04:29:52 - INFO - root -   Epoch: [241/400][260/346], lr: 0.00000044 	 loss = 0.0140(0.1317)
2023/09/19 04:30:53 - INFO - root -   Epoch: [241/400][280/346], lr: 0.00000044 	 loss = 0.0043(0.1404)
2023/09/19 04:31:36 - INFO - root -   Epoch: [241/400][300/346], lr: 0.00000044 	 loss = 0.0008(0.1408)
2023/09/19 04:32:36 - INFO - root -   Epoch: [241/400][320/346], lr: 0.00000044 	 loss = 0.0063(0.1426)
2023/09/19 04:33:18 - INFO - root -   Epoch: [241/400][340/346], lr: 0.00000044 	 loss = 0.0542(0.1370)
2023/09/19 04:33:22 - INFO - root -   Epoch: [241/400] 	 loss = 0.1353
2023/09/19 04:33:22 - INFO - root -   train_accuracy = 0.9436
2023/09/19 04:33:44 - INFO - root -   Epoch: [242/400][0/346], lr: 0.00000045 	 loss = 0.0130(0.0130)
2023/09/19 04:34:27 - INFO - root -   Epoch: [242/400][20/346], lr: 0.00000045 	 loss = 0.0035(0.1237)
2023/09/19 04:35:28 - INFO - root -   Epoch: [242/400][40/346], lr: 0.00000045 	 loss = 0.2967(0.1732)
2023/09/19 04:36:11 - INFO - root -   Epoch: [242/400][60/346], lr: 0.00000045 	 loss = 1.7386(0.2302)
2023/09/19 04:37:12 - INFO - root -   Epoch: [242/400][80/346], lr: 0.00000045 	 loss = 0.0110(0.3735)
2023/09/19 04:37:55 - INFO - root -   Epoch: [242/400][100/346], lr: 0.00000045 	 loss = 0.0129(0.4302)
2023/09/19 04:38:56 - INFO - root -   Epoch: [242/400][120/346], lr: 0.00000045 	 loss = 0.0023(0.4554)
2023/09/19 04:39:39 - INFO - root -   Epoch: [242/400][140/346], lr: 0.00000045 	 loss = 0.0366(0.4173)
2023/09/19 04:40:39 - INFO - root -   Epoch: [242/400][160/346], lr: 0.00000045 	 loss = 0.0082(0.3859)
2023/09/19 04:41:22 - INFO - root -   Epoch: [242/400][180/346], lr: 0.00000045 	 loss = 0.0489(0.3535)
2023/09/19 04:42:23 - INFO - root -   Epoch: [242/400][200/346], lr: 0.00000045 	 loss = 0.0015(0.3363)
2023/09/19 04:43:06 - INFO - root -   Epoch: [242/400][220/346], lr: 0.00000045 	 loss = 0.3348(0.3359)
2023/09/19 04:44:07 - INFO - root -   Epoch: [242/400][240/346], lr: 0.00000045 	 loss = 0.0006(0.3209)
2023/09/19 04:44:50 - INFO - root -   Epoch: [242/400][260/346], lr: 0.00000045 	 loss = 1.3279(0.3075)
2023/09/19 04:45:50 - INFO - root -   Epoch: [242/400][280/346], lr: 0.00000045 	 loss = 0.0721(0.2982)
2023/09/19 04:46:33 - INFO - root -   Epoch: [242/400][300/346], lr: 0.00000045 	 loss = 0.0029(0.2860)
2023/09/19 04:47:34 - INFO - root -   Epoch: [242/400][320/346], lr: 0.00000045 	 loss = 0.0008(0.2808)
2023/09/19 04:48:15 - INFO - root -   Epoch: [242/400][340/346], lr: 0.00000045 	 loss = 0.0551(0.2697)
2023/09/19 04:48:19 - INFO - root -   Epoch: [242/400] 	 loss = 0.2672
2023/09/19 04:48:19 - INFO - root -   train_accuracy = 0.9046
2023/09/19 04:48:41 - INFO - root -   Epoch: [243/400][0/346], lr: 0.00000045 	 loss = 0.6759(0.6759)
2023/09/19 04:49:24 - INFO - root -   Epoch: [243/400][20/346], lr: 0.00000045 	 loss = 0.0078(0.1045)
2023/09/19 04:50:25 - INFO - root -   Epoch: [243/400][40/346], lr: 0.00000045 	 loss = 0.0294(0.1138)
2023/09/19 04:51:08 - INFO - root -   Epoch: [243/400][60/346], lr: 0.00000045 	 loss = 0.5757(0.1108)
2023/09/19 04:52:09 - INFO - root -   Epoch: [243/400][80/346], lr: 0.00000045 	 loss = 0.0059(0.1176)
2023/09/19 04:52:52 - INFO - root -   Epoch: [243/400][100/346], lr: 0.00000045 	 loss = 0.0421(0.1341)
2023/09/19 04:53:53 - INFO - root -   Epoch: [243/400][120/346], lr: 0.00000045 	 loss = 0.0420(0.1223)
2023/09/19 04:54:36 - INFO - root -   Epoch: [243/400][140/346], lr: 0.00000045 	 loss = 0.0069(0.1158)
2023/09/19 04:55:36 - INFO - root -   Epoch: [243/400][160/346], lr: 0.00000045 	 loss = 0.0076(0.1231)
2023/09/19 04:56:19 - INFO - root -   Epoch: [243/400][180/346], lr: 0.00000045 	 loss = 0.1128(0.1235)
2023/09/19 04:57:20 - INFO - root -   Epoch: [243/400][200/346], lr: 0.00000045 	 loss = 0.0007(0.1204)
2023/09/19 04:58:03 - INFO - root -   Epoch: [243/400][220/346], lr: 0.00000045 	 loss = 1.1747(0.1291)
2023/09/19 04:59:04 - INFO - root -   Epoch: [243/400][240/346], lr: 0.00000045 	 loss = 0.0010(0.1463)
2023/09/19 04:59:47 - INFO - root -   Epoch: [243/400][260/346], lr: 0.00000045 	 loss = 0.0028(0.1463)
2023/09/19 05:00:47 - INFO - root -   Epoch: [243/400][280/346], lr: 0.00000045 	 loss = 0.0045(0.1582)
2023/09/19 05:01:31 - INFO - root -   Epoch: [243/400][300/346], lr: 0.00000045 	 loss = 0.0451(0.1562)
2023/09/19 05:02:31 - INFO - root -   Epoch: [243/400][320/346], lr: 0.00000045 	 loss = 0.0310(0.1556)
2023/09/19 05:03:13 - INFO - root -   Epoch: [243/400][340/346], lr: 0.00000045 	 loss = 0.0354(0.1549)
2023/09/19 05:03:17 - INFO - root -   Epoch: [243/400] 	 loss = 0.1569
2023/09/19 05:03:17 - INFO - root -   train_accuracy = 0.9364
2023/09/19 05:03:39 - INFO - root -   Epoch: [244/400][0/346], lr: 0.00000045 	 loss = 0.1553(0.1553)
2023/09/19 05:04:23 - INFO - root -   Epoch: [244/400][20/346], lr: 0.00000045 	 loss = 0.0028(0.1010)
2023/09/19 05:05:24 - INFO - root -   Epoch: [244/400][40/346], lr: 0.00000045 	 loss = 0.0742(0.1248)
2023/09/19 05:06:07 - INFO - root -   Epoch: [244/400][60/346], lr: 0.00000045 	 loss = 0.0095(0.1002)
2023/09/19 05:07:08 - INFO - root -   Epoch: [244/400][80/346], lr: 0.00000045 	 loss = 0.0136(0.1091)
2023/09/19 05:07:52 - INFO - root -   Epoch: [244/400][100/346], lr: 0.00000045 	 loss = 0.7447(0.1197)
2023/09/19 05:08:53 - INFO - root -   Epoch: [244/400][120/346], lr: 0.00000045 	 loss = 0.0173(0.1128)
2023/09/19 05:09:38 - INFO - root -   Epoch: [244/400][140/346], lr: 0.00000045 	 loss = 0.0346(0.1151)
2023/09/19 05:10:39 - INFO - root -   Epoch: [244/400][160/346], lr: 0.00000045 	 loss = 0.0014(0.1041)
2023/09/19 05:11:22 - INFO - root -   Epoch: [244/400][180/346], lr: 0.00000045 	 loss = 0.0075(0.1018)
2023/09/19 05:12:23 - INFO - root -   Epoch: [244/400][200/346], lr: 0.00000045 	 loss = 0.0031(0.0946)
2023/09/19 05:13:06 - INFO - root -   Epoch: [244/400][220/346], lr: 0.00000045 	 loss = 0.0550(0.0950)
2023/09/19 05:14:07 - INFO - root -   Epoch: [244/400][240/346], lr: 0.00000045 	 loss = 0.0007(0.0988)
2023/09/19 05:14:50 - INFO - root -   Epoch: [244/400][260/346], lr: 0.00000045 	 loss = 0.0190(0.1017)
2023/09/19 05:15:51 - INFO - root -   Epoch: [244/400][280/346], lr: 0.00000045 	 loss = 0.0033(0.1121)
2023/09/19 05:16:34 - INFO - root -   Epoch: [244/400][300/346], lr: 0.00000045 	 loss = 0.0350(0.1074)
2023/09/19 05:17:35 - INFO - root -   Epoch: [244/400][320/346], lr: 0.00000045 	 loss = 0.0002(0.1069)
2023/09/19 05:18:16 - INFO - root -   Epoch: [244/400][340/346], lr: 0.00000045 	 loss = 0.6233(0.1087)
2023/09/19 05:18:20 - INFO - root -   Epoch: [244/400] 	 loss = 0.1080
2023/09/19 05:22:08 - INFO - root -   precision = 0.7069
2023/09/19 05:22:08 - INFO - root -   eval_loss = 1.2471
2023/09/19 05:22:09 - INFO - root -   train_accuracy = 0.9523
2023/09/19 05:22:31 - INFO - root -   Epoch: [245/400][0/346], lr: 0.00000045 	 loss = 0.0085(0.0085)
2023/09/19 05:23:14 - INFO - root -   Epoch: [245/400][20/346], lr: 0.00000045 	 loss = 0.0038(0.0299)
2023/09/19 05:24:14 - INFO - root -   Epoch: [245/400][40/346], lr: 0.00000045 	 loss = 0.0483(0.1218)
2023/09/19 05:24:57 - INFO - root -   Epoch: [245/400][60/346], lr: 0.00000045 	 loss = 0.6424(0.1169)
2023/09/19 05:25:57 - INFO - root -   Epoch: [245/400][80/346], lr: 0.00000045 	 loss = 0.0210(0.1293)
2023/09/19 05:26:41 - INFO - root -   Epoch: [245/400][100/346], lr: 0.00000045 	 loss = 0.0330(0.1201)
2023/09/19 05:27:41 - INFO - root -   Epoch: [245/400][120/346], lr: 0.00000045 	 loss = 0.0020(0.1235)
2023/09/19 05:28:24 - INFO - root -   Epoch: [245/400][140/346], lr: 0.00000045 	 loss = 0.0303(0.1303)
2023/09/19 05:29:24 - INFO - root -   Epoch: [245/400][160/346], lr: 0.00000045 	 loss = 1.0827(0.1676)
2023/09/19 05:30:07 - INFO - root -   Epoch: [245/400][180/346], lr: 0.00000045 	 loss = 0.0082(0.1699)
2023/09/19 05:31:08 - INFO - root -   Epoch: [245/400][200/346], lr: 0.00000045 	 loss = 0.0182(0.1634)
2023/09/19 05:31:50 - INFO - root -   Epoch: [245/400][220/346], lr: 0.00000045 	 loss = 0.0973(0.1756)
2023/09/19 05:32:51 - INFO - root -   Epoch: [245/400][240/346], lr: 0.00000045 	 loss = 0.0014(0.1685)
2023/09/19 05:33:34 - INFO - root -   Epoch: [245/400][260/346], lr: 0.00000045 	 loss = 0.5257(0.1758)
2023/09/19 05:34:34 - INFO - root -   Epoch: [245/400][280/346], lr: 0.00000045 	 loss = 0.0316(0.1849)
2023/09/19 05:35:17 - INFO - root -   Epoch: [245/400][300/346], lr: 0.00000045 	 loss = 0.0106(0.1871)
2023/09/19 05:36:17 - INFO - root -   Epoch: [245/400][320/346], lr: 0.00000045 	 loss = 0.0030(0.1894)
2023/09/19 05:36:59 - INFO - root -   Epoch: [245/400][340/346], lr: 0.00000045 	 loss = 0.0051(0.1835)
2023/09/19 05:37:03 - INFO - root -   Epoch: [245/400] 	 loss = 0.1849
2023/09/19 05:37:03 - INFO - root -   train_accuracy = 0.9191
2023/09/19 05:37:25 - INFO - root -   Epoch: [246/400][0/346], lr: 0.00000045 	 loss = 0.2048(0.2048)
2023/09/19 05:38:08 - INFO - root -   Epoch: [246/400][20/346], lr: 0.00000045 	 loss = 0.0074(0.1067)
2023/09/19 05:39:08 - INFO - root -   Epoch: [246/400][40/346], lr: 0.00000045 	 loss = 0.0274(0.2286)
2023/09/19 05:39:51 - INFO - root -   Epoch: [246/400][60/346], lr: 0.00000045 	 loss = 0.2400(0.1755)
2023/09/19 05:40:52 - INFO - root -   Epoch: [246/400][80/346], lr: 0.00000045 	 loss = 0.0263(0.1593)
2023/09/19 05:41:35 - INFO - root -   Epoch: [246/400][100/346], lr: 0.00000045 	 loss = 0.1192(0.1407)
2023/09/19 05:42:35 - INFO - root -   Epoch: [246/400][120/346], lr: 0.00000045 	 loss = 0.0009(0.1398)
2023/09/19 05:43:18 - INFO - root -   Epoch: [246/400][140/346], lr: 0.00000045 	 loss = 0.4124(0.1461)
2023/09/19 05:44:18 - INFO - root -   Epoch: [246/400][160/346], lr: 0.00000045 	 loss = 0.0006(0.1370)
2023/09/19 05:45:02 - INFO - root -   Epoch: [246/400][180/346], lr: 0.00000045 	 loss = 0.0060(0.1330)
2023/09/19 05:46:02 - INFO - root -   Epoch: [246/400][200/346], lr: 0.00000045 	 loss = 0.0004(0.1299)
2023/09/19 05:46:45 - INFO - root -   Epoch: [246/400][220/346], lr: 0.00000045 	 loss = 0.0020(0.1221)
2023/09/19 05:47:46 - INFO - root -   Epoch: [246/400][240/346], lr: 0.00000045 	 loss = 0.0296(0.1159)
2023/09/19 05:48:29 - INFO - root -   Epoch: [246/400][260/346], lr: 0.00000045 	 loss = 0.1001(0.1135)
2023/09/19 05:49:29 - INFO - root -   Epoch: [246/400][280/346], lr: 0.00000045 	 loss = 0.0292(0.1184)
2023/09/19 05:50:12 - INFO - root -   Epoch: [246/400][300/346], lr: 0.00000045 	 loss = 0.0469(0.1132)
2023/09/19 05:51:12 - INFO - root -   Epoch: [246/400][320/346], lr: 0.00000045 	 loss = 0.0100(0.1138)
2023/09/19 05:51:55 - INFO - root -   Epoch: [246/400][340/346], lr: 0.00000045 	 loss = 0.0679(0.1150)
2023/09/19 05:51:59 - INFO - root -   Epoch: [246/400] 	 loss = 0.1136
2023/09/19 05:51:59 - INFO - root -   train_accuracy = 0.9610
2023/09/19 05:52:20 - INFO - root -   Epoch: [247/400][0/346], lr: 0.00000045 	 loss = 0.0037(0.0037)
2023/09/19 05:53:04 - INFO - root -   Epoch: [247/400][20/346], lr: 0.00000045 	 loss = 0.0093(0.0458)
2023/09/19 05:54:05 - INFO - root -   Epoch: [247/400][40/346], lr: 0.00000045 	 loss = 0.0017(0.0988)
2023/09/19 05:54:50 - INFO - root -   Epoch: [247/400][60/346], lr: 0.00000045 	 loss = 0.0153(0.0852)
2023/09/19 05:55:51 - INFO - root -   Epoch: [247/400][80/346], lr: 0.00000045 	 loss = 0.2118(0.0806)
2023/09/19 05:56:35 - INFO - root -   Epoch: [247/400][100/346], lr: 0.00000045 	 loss = 0.0518(0.1017)
2023/09/19 05:57:36 - INFO - root -   Epoch: [247/400][120/346], lr: 0.00000045 	 loss = 0.0274(0.1554)
2023/09/19 05:58:21 - INFO - root -   Epoch: [247/400][140/346], lr: 0.00000045 	 loss = 0.2222(0.1470)
2023/09/19 05:59:22 - INFO - root -   Epoch: [247/400][160/346], lr: 0.00000045 	 loss = 0.0010(0.1372)
2023/09/19 06:00:07 - INFO - root -   Epoch: [247/400][180/346], lr: 0.00000045 	 loss = 0.0038(0.1363)
2023/09/19 06:01:07 - INFO - root -   Epoch: [247/400][200/346], lr: 0.00000045 	 loss = 0.0001(0.1363)
2023/09/19 06:01:52 - INFO - root -   Epoch: [247/400][220/346], lr: 0.00000045 	 loss = 0.0016(0.1370)
2023/09/19 06:02:52 - INFO - root -   Epoch: [247/400][240/346], lr: 0.00000045 	 loss = 0.0019(0.1400)
2023/09/19 06:03:37 - INFO - root -   Epoch: [247/400][260/346], lr: 0.00000045 	 loss = 0.0099(0.1333)
2023/09/19 06:04:37 - INFO - root -   Epoch: [247/400][280/346], lr: 0.00000045 	 loss = 0.0019(0.1327)
2023/09/19 06:05:23 - INFO - root -   Epoch: [247/400][300/346], lr: 0.00000045 	 loss = 0.0192(0.1324)
2023/09/19 06:06:22 - INFO - root -   Epoch: [247/400][320/346], lr: 0.00000045 	 loss = 0.2451(0.1324)
2023/09/19 06:07:06 - INFO - root -   Epoch: [247/400][340/346], lr: 0.00000045 	 loss = 0.0665(0.1312)
2023/09/19 06:07:10 - INFO - root -   Epoch: [247/400] 	 loss = 0.1360
2023/09/19 06:07:10 - INFO - root -   train_accuracy = 0.9523
2023/09/19 06:07:31 - INFO - root -   Epoch: [248/400][0/346], lr: 0.00000045 	 loss = 0.0075(0.0075)
2023/09/19 06:08:14 - INFO - root -   Epoch: [248/400][20/346], lr: 0.00000045 	 loss = 0.0052(0.2444)
2023/09/19 06:09:15 - INFO - root -   Epoch: [248/400][40/346], lr: 0.00000045 	 loss = 0.7569(0.2169)
2023/09/19 06:09:58 - INFO - root -   Epoch: [248/400][60/346], lr: 0.00000045 	 loss = 0.0089(0.1785)
2023/09/19 06:10:58 - INFO - root -   Epoch: [248/400][80/346], lr: 0.00000045 	 loss = 0.0087(0.1512)
2023/09/19 06:11:41 - INFO - root -   Epoch: [248/400][100/346], lr: 0.00000045 	 loss = 1.7909(0.1634)
2023/09/19 06:12:42 - INFO - root -   Epoch: [248/400][120/346], lr: 0.00000045 	 loss = 0.0010(0.1602)
2023/09/19 06:13:25 - INFO - root -   Epoch: [248/400][140/346], lr: 0.00000045 	 loss = 0.0231(0.1728)
2023/09/19 06:14:25 - INFO - root -   Epoch: [248/400][160/346], lr: 0.00000045 	 loss = 0.0003(0.1615)
2023/09/19 06:15:08 - INFO - root -   Epoch: [248/400][180/346], lr: 0.00000045 	 loss = 0.0247(0.1519)
2023/09/19 06:16:08 - INFO - root -   Epoch: [248/400][200/346], lr: 0.00000045 	 loss = 0.0037(0.1465)
2023/09/19 06:16:52 - INFO - root -   Epoch: [248/400][220/346], lr: 0.00000045 	 loss = 0.0092(0.1462)
2023/09/19 06:17:51 - INFO - root -   Epoch: [248/400][240/346], lr: 0.00000045 	 loss = 0.0003(0.1440)
2023/09/19 06:18:35 - INFO - root -   Epoch: [248/400][260/346], lr: 0.00000045 	 loss = 0.1699(0.1369)
2023/09/19 06:19:34 - INFO - root -   Epoch: [248/400][280/346], lr: 0.00000045 	 loss = 0.0011(0.1414)
2023/09/19 06:20:19 - INFO - root -   Epoch: [248/400][300/346], lr: 0.00000045 	 loss = 0.0102(0.1349)
2023/09/19 06:21:18 - INFO - root -   Epoch: [248/400][320/346], lr: 0.00000045 	 loss = 0.0048(0.1282)
2023/09/19 06:22:00 - INFO - root -   Epoch: [248/400][340/346], lr: 0.00000045 	 loss = 0.0586(0.1263)
2023/09/19 06:22:04 - INFO - root -   Epoch: [248/400] 	 loss = 0.1246
2023/09/19 06:22:04 - INFO - root -   train_accuracy = 0.9480
2023/09/19 06:22:26 - INFO - root -   Epoch: [249/400][0/346], lr: 0.00000046 	 loss = 0.0024(0.0024)
2023/09/19 06:23:09 - INFO - root -   Epoch: [249/400][20/346], lr: 0.00000046 	 loss = 0.0027(0.0554)
2023/09/19 06:24:10 - INFO - root -   Epoch: [249/400][40/346], lr: 0.00000046 	 loss = 0.0063(0.0771)
2023/09/19 06:24:54 - INFO - root -   Epoch: [249/400][60/346], lr: 0.00000046 	 loss = 0.0837(0.0623)
2023/09/19 06:25:55 - INFO - root -   Epoch: [249/400][80/346], lr: 0.00000046 	 loss = 0.0122(0.1111)
2023/09/19 06:26:38 - INFO - root -   Epoch: [249/400][100/346], lr: 0.00000046 	 loss = 0.5953(0.1071)
2023/09/19 06:27:39 - INFO - root -   Epoch: [249/400][120/346], lr: 0.00000046 	 loss = 0.0105(0.1167)
2023/09/19 06:28:22 - INFO - root -   Epoch: [249/400][140/346], lr: 0.00000046 	 loss = 0.0072(0.1135)
2023/09/19 06:29:23 - INFO - root -   Epoch: [249/400][160/346], lr: 0.00000046 	 loss = 0.0005(0.1211)
2023/09/19 06:30:06 - INFO - root -   Epoch: [249/400][180/346], lr: 0.00000046 	 loss = 0.0183(0.1285)
2023/09/19 06:31:07 - INFO - root -   Epoch: [249/400][200/346], lr: 0.00000046 	 loss = 0.0016(0.1241)
2023/09/19 06:31:51 - INFO - root -   Epoch: [249/400][220/346], lr: 0.00000046 	 loss = 0.0036(0.1259)
2023/09/19 06:32:51 - INFO - root -   Epoch: [249/400][240/346], lr: 0.00000046 	 loss = 0.1335(0.1198)
2023/09/19 06:33:35 - INFO - root -   Epoch: [249/400][260/346], lr: 0.00000046 	 loss = 0.0079(0.1149)
2023/09/19 06:34:35 - INFO - root -   Epoch: [249/400][280/346], lr: 0.00000046 	 loss = 0.0095(0.1216)
2023/09/19 06:35:19 - INFO - root -   Epoch: [249/400][300/346], lr: 0.00000046 	 loss = 0.0044(0.1461)
2023/09/19 06:36:19 - INFO - root -   Epoch: [249/400][320/346], lr: 0.00000046 	 loss = 0.0259(0.1616)
2023/09/19 06:37:01 - INFO - root -   Epoch: [249/400][340/346], lr: 0.00000046 	 loss = 0.7582(0.1750)
2023/09/19 06:37:05 - INFO - root -   Epoch: [249/400] 	 loss = 0.1800
2023/09/19 06:40:53 - INFO - root -   precision = 0.6609
2023/09/19 06:40:53 - INFO - root -   eval_loss = 1.1468
2023/09/19 06:40:54 - INFO - root -   train_accuracy = 0.9191
2023/09/19 06:41:15 - INFO - root -   Epoch: [250/400][0/346], lr: 0.00000046 	 loss = 0.1389(0.1389)
2023/09/19 06:41:58 - INFO - root -   Epoch: [250/400][20/346], lr: 0.00000046 	 loss = 0.0473(0.2754)
2023/09/19 06:42:58 - INFO - root -   Epoch: [250/400][40/346], lr: 0.00000046 	 loss = 0.3568(0.3100)
2023/09/19 06:43:41 - INFO - root -   Epoch: [250/400][60/346], lr: 0.00000046 	 loss = 0.0821(0.2516)
2023/09/19 06:44:41 - INFO - root -   Epoch: [250/400][80/346], lr: 0.00000046 	 loss = 0.0258(0.2331)
2023/09/19 06:45:24 - INFO - root -   Epoch: [250/400][100/346], lr: 0.00000046 	 loss = 0.4603(0.2165)
2023/09/19 06:46:24 - INFO - root -   Epoch: [250/400][120/346], lr: 0.00000046 	 loss = 0.0003(0.1967)
2023/09/19 06:47:07 - INFO - root -   Epoch: [250/400][140/346], lr: 0.00000046 	 loss = 0.0456(0.1824)
2023/09/19 06:48:08 - INFO - root -   Epoch: [250/400][160/346], lr: 0.00000046 	 loss = 0.0001(0.1716)
2023/09/19 06:48:50 - INFO - root -   Epoch: [250/400][180/346], lr: 0.00000046 	 loss = 0.0310(0.1649)
2023/09/19 06:49:51 - INFO - root -   Epoch: [250/400][200/346], lr: 0.00000046 	 loss = 0.0057(0.1598)
2023/09/19 06:50:33 - INFO - root -   Epoch: [250/400][220/346], lr: 0.00000046 	 loss = 0.0028(0.1544)
2023/09/19 06:51:34 - INFO - root -   Epoch: [250/400][240/346], lr: 0.00000046 	 loss = 0.0005(0.1456)
2023/09/19 06:52:17 - INFO - root -   Epoch: [250/400][260/346], lr: 0.00000046 	 loss = 0.4797(0.1395)
2023/09/19 06:53:17 - INFO - root -   Epoch: [250/400][280/346], lr: 0.00000046 	 loss = 0.0068(0.1483)
2023/09/19 06:54:00 - INFO - root -   Epoch: [250/400][300/346], lr: 0.00000046 	 loss = 0.0019(0.1439)
2023/09/19 06:55:00 - INFO - root -   Epoch: [250/400][320/346], lr: 0.00000046 	 loss = 0.0570(0.1395)
2023/09/19 06:55:41 - INFO - root -   Epoch: [250/400][340/346], lr: 0.00000046 	 loss = 0.0041(0.1409)
2023/09/19 06:55:45 - INFO - root -   Epoch: [250/400] 	 loss = 0.1391
2023/09/19 06:55:45 - INFO - root -   train_accuracy = 0.9465
2023/09/19 06:56:07 - INFO - root -   Epoch: [251/400][0/346], lr: 0.00000046 	 loss = 0.0151(0.0151)
2023/09/19 06:56:50 - INFO - root -   Epoch: [251/400][20/346], lr: 0.00000046 	 loss = 0.0012(0.0465)
2023/09/19 06:57:51 - INFO - root -   Epoch: [251/400][40/346], lr: 0.00000046 	 loss = 0.0021(0.0467)
2023/09/19 06:58:35 - INFO - root -   Epoch: [251/400][60/346], lr: 0.00000046 	 loss = 0.0008(0.0638)
2023/09/19 06:59:36 - INFO - root -   Epoch: [251/400][80/346], lr: 0.00000046 	 loss = 0.0177(0.0717)
2023/09/19 07:00:19 - INFO - root -   Epoch: [251/400][100/346], lr: 0.00000046 	 loss = 0.5491(0.0820)
2023/09/19 07:01:20 - INFO - root -   Epoch: [251/400][120/346], lr: 0.00000046 	 loss = 0.0008(0.0852)
2023/09/19 07:02:03 - INFO - root -   Epoch: [251/400][140/346], lr: 0.00000046 	 loss = 0.0102(0.0920)
2023/09/19 07:03:04 - INFO - root -   Epoch: [251/400][160/346], lr: 0.00000046 	 loss = 0.1192(0.0987)
2023/09/19 07:03:48 - INFO - root -   Epoch: [251/400][180/346], lr: 0.00000046 	 loss = 0.0094(0.0941)
2023/09/19 07:04:48 - INFO - root -   Epoch: [251/400][200/346], lr: 0.00000046 	 loss = 0.0002(0.0911)
2023/09/19 07:05:32 - INFO - root -   Epoch: [251/400][220/346], lr: 0.00000046 	 loss = 0.0080(0.0941)
2023/09/19 07:06:32 - INFO - root -   Epoch: [251/400][240/346], lr: 0.00000046 	 loss = 0.0008(0.0945)
2023/09/19 07:07:17 - INFO - root -   Epoch: [251/400][260/346], lr: 0.00000046 	 loss = 0.0063(0.0893)
2023/09/19 07:08:16 - INFO - root -   Epoch: [251/400][280/346], lr: 0.00000046 	 loss = 0.0003(0.0887)
2023/09/19 07:09:01 - INFO - root -   Epoch: [251/400][300/346], lr: 0.00000046 	 loss = 0.0118(0.1022)
2023/09/19 07:10:00 - INFO - root -   Epoch: [251/400][320/346], lr: 0.00000046 	 loss = 0.0001(0.1036)
2023/09/19 07:10:44 - INFO - root -   Epoch: [251/400][340/346], lr: 0.00000046 	 loss = 0.0163(0.1011)
2023/09/19 07:10:48 - INFO - root -   Epoch: [251/400] 	 loss = 0.1056
2023/09/19 07:10:48 - INFO - root -   train_accuracy = 0.9653
2023/09/19 07:11:09 - INFO - root -   Epoch: [252/400][0/346], lr: 0.00000046 	 loss = 0.0011(0.0011)
2023/09/19 07:11:52 - INFO - root -   Epoch: [252/400][20/346], lr: 0.00000046 	 loss = 0.0045(0.1043)
2023/09/19 07:12:53 - INFO - root -   Epoch: [252/400][40/346], lr: 0.00000046 	 loss = 0.0009(0.0677)
2023/09/19 07:13:36 - INFO - root -   Epoch: [252/400][60/346], lr: 0.00000046 	 loss = 0.0210(0.0521)
2023/09/19 07:14:37 - INFO - root -   Epoch: [252/400][80/346], lr: 0.00000046 	 loss = 0.0032(0.0591)
2023/09/19 07:15:20 - INFO - root -   Epoch: [252/400][100/346], lr: 0.00000046 	 loss = 0.0094(0.0686)
2023/09/19 07:16:20 - INFO - root -   Epoch: [252/400][120/346], lr: 0.00000046 	 loss = 0.0061(0.0849)
2023/09/19 07:17:03 - INFO - root -   Epoch: [252/400][140/346], lr: 0.00000046 	 loss = 0.0004(0.0784)
2023/09/19 07:18:04 - INFO - root -   Epoch: [252/400][160/346], lr: 0.00000046 	 loss = 0.0001(0.0854)
2023/09/19 07:18:46 - INFO - root -   Epoch: [252/400][180/346], lr: 0.00000046 	 loss = 0.0014(0.0858)
2023/09/19 07:19:47 - INFO - root -   Epoch: [252/400][200/346], lr: 0.00000046 	 loss = 0.0027(0.0808)
2023/09/19 07:20:30 - INFO - root -   Epoch: [252/400][220/346], lr: 0.00000046 	 loss = 0.0187(0.0793)
2023/09/19 07:21:30 - INFO - root -   Epoch: [252/400][240/346], lr: 0.00000046 	 loss = 0.0010(0.0780)
2023/09/19 07:22:14 - INFO - root -   Epoch: [252/400][260/346], lr: 0.00000046 	 loss = 0.0182(0.0771)
2023/09/19 07:23:13 - INFO - root -   Epoch: [252/400][280/346], lr: 0.00000046 	 loss = 0.0027(0.0882)
2023/09/19 07:23:57 - INFO - root -   Epoch: [252/400][300/346], lr: 0.00000046 	 loss = 0.2715(0.0915)
2023/09/19 07:24:57 - INFO - root -   Epoch: [252/400][320/346], lr: 0.00000046 	 loss = 0.0183(0.0929)
2023/09/19 07:25:40 - INFO - root -   Epoch: [252/400][340/346], lr: 0.00000046 	 loss = 0.0028(0.0986)
2023/09/19 07:25:44 - INFO - root -   Epoch: [252/400] 	 loss = 0.1017
2023/09/19 07:25:44 - INFO - root -   train_accuracy = 0.9639
2023/09/19 07:26:05 - INFO - root -   Epoch: [253/400][0/346], lr: 0.00000046 	 loss = 0.0039(0.0039)
2023/09/19 07:26:48 - INFO - root -   Epoch: [253/400][20/346], lr: 0.00000046 	 loss = 0.0391(0.0608)
2023/09/19 07:27:49 - INFO - root -   Epoch: [253/400][40/346], lr: 0.00000046 	 loss = 0.0233(0.1065)
2023/09/19 07:28:32 - INFO - root -   Epoch: [253/400][60/346], lr: 0.00000046 	 loss = 0.3774(0.1037)
2023/09/19 07:29:32 - INFO - root -   Epoch: [253/400][80/346], lr: 0.00000046 	 loss = 0.0011(0.0826)
2023/09/19 07:30:15 - INFO - root -   Epoch: [253/400][100/346], lr: 0.00000046 	 loss = 0.5428(0.0893)
2023/09/19 07:31:16 - INFO - root -   Epoch: [253/400][120/346], lr: 0.00000046 	 loss = 0.0306(0.1385)
2023/09/19 07:31:59 - INFO - root -   Epoch: [253/400][140/346], lr: 0.00000046 	 loss = 0.1830(0.1678)
2023/09/19 07:32:59 - INFO - root -   Epoch: [253/400][160/346], lr: 0.00000046 	 loss = 0.0668(0.1741)
2023/09/19 07:33:42 - INFO - root -   Epoch: [253/400][180/346], lr: 0.00000046 	 loss = 0.1913(0.1769)
2023/09/19 07:34:42 - INFO - root -   Epoch: [253/400][200/346], lr: 0.00000046 	 loss = 0.0004(0.1753)
2023/09/19 07:35:25 - INFO - root -   Epoch: [253/400][220/346], lr: 0.00000046 	 loss = 0.0065(0.1708)
2023/09/19 07:36:25 - INFO - root -   Epoch: [253/400][240/346], lr: 0.00000046 	 loss = 0.0022(0.1737)
2023/09/19 07:37:08 - INFO - root -   Epoch: [253/400][260/346], lr: 0.00000046 	 loss = 0.1887(0.1646)
2023/09/19 07:38:08 - INFO - root -   Epoch: [253/400][280/346], lr: 0.00000046 	 loss = 0.0906(0.1665)
2023/09/19 07:38:52 - INFO - root -   Epoch: [253/400][300/346], lr: 0.00000046 	 loss = 0.0007(0.1685)
2023/09/19 07:39:52 - INFO - root -   Epoch: [253/400][320/346], lr: 0.00000046 	 loss = 0.0011(0.1682)
2023/09/19 07:40:34 - INFO - root -   Epoch: [253/400][340/346], lr: 0.00000046 	 loss = 1.1639(0.1729)
2023/09/19 07:40:38 - INFO - root -   Epoch: [253/400] 	 loss = 0.1705
2023/09/19 07:40:38 - INFO - root -   train_accuracy = 0.9306
2023/09/19 07:40:59 - INFO - root -   Epoch: [254/400][0/346], lr: 0.00000046 	 loss = 0.0245(0.0245)
2023/09/19 07:41:42 - INFO - root -   Epoch: [254/400][20/346], lr: 0.00000046 	 loss = 0.0087(0.0734)
2023/09/19 07:42:43 - INFO - root -   Epoch: [254/400][40/346], lr: 0.00000046 	 loss = 0.0037(0.1900)
2023/09/19 07:43:26 - INFO - root -   Epoch: [254/400][60/346], lr: 0.00000046 	 loss = 0.0247(0.2494)
2023/09/19 07:44:26 - INFO - root -   Epoch: [254/400][80/346], lr: 0.00000046 	 loss = 0.0388(0.2299)
2023/09/19 07:45:09 - INFO - root -   Epoch: [254/400][100/346], lr: 0.00000046 	 loss = 0.0111(0.2086)
2023/09/19 07:46:10 - INFO - root -   Epoch: [254/400][120/346], lr: 0.00000046 	 loss = 0.0027(0.2053)
2023/09/19 07:46:52 - INFO - root -   Epoch: [254/400][140/346], lr: 0.00000046 	 loss = 0.0071(0.1874)
2023/09/19 07:47:53 - INFO - root -   Epoch: [254/400][160/346], lr: 0.00000046 	 loss = 0.0004(0.1753)
2023/09/19 07:48:36 - INFO - root -   Epoch: [254/400][180/346], lr: 0.00000046 	 loss = 0.0068(0.1822)
2023/09/19 07:49:36 - INFO - root -   Epoch: [254/400][200/346], lr: 0.00000046 	 loss = 0.0017(0.1826)
2023/09/19 07:50:19 - INFO - root -   Epoch: [254/400][220/346], lr: 0.00000046 	 loss = 0.0222(0.1746)
2023/09/19 07:51:19 - INFO - root -   Epoch: [254/400][240/346], lr: 0.00000046 	 loss = 0.1550(0.1693)
2023/09/19 07:52:02 - INFO - root -   Epoch: [254/400][260/346], lr: 0.00000046 	 loss = 0.0686(0.1640)
2023/09/19 07:53:02 - INFO - root -   Epoch: [254/400][280/346], lr: 0.00000046 	 loss = 0.0002(0.1600)
2023/09/19 07:53:45 - INFO - root -   Epoch: [254/400][300/346], lr: 0.00000046 	 loss = 0.0006(0.1545)
2023/09/19 07:54:46 - INFO - root -   Epoch: [254/400][320/346], lr: 0.00000046 	 loss = 0.0039(0.1468)
2023/09/19 07:55:27 - INFO - root -   Epoch: [254/400][340/346], lr: 0.00000046 	 loss = 0.1471(0.1420)
2023/09/19 07:55:31 - INFO - root -   Epoch: [254/400] 	 loss = 0.1440
2023/09/19 07:59:19 - INFO - root -   precision = 0.7011
2023/09/19 07:59:19 - INFO - root -   eval_loss = 1.2601
2023/09/19 07:59:20 - INFO - root -   train_accuracy = 0.9379
2023/09/19 07:59:41 - INFO - root -   Epoch: [255/400][0/346], lr: 0.00000046 	 loss = 0.3751(0.3751)
2023/09/19 08:00:24 - INFO - root -   Epoch: [255/400][20/346], lr: 0.00000046 	 loss = 0.0311(0.0504)
2023/09/19 08:01:25 - INFO - root -   Epoch: [255/400][40/346], lr: 0.00000046 	 loss = 0.0032(0.0430)
2023/09/19 08:02:08 - INFO - root -   Epoch: [255/400][60/346], lr: 0.00000046 	 loss = 0.0109(0.0566)
2023/09/19 08:03:08 - INFO - root -   Epoch: [255/400][80/346], lr: 0.00000046 	 loss = 0.0062(0.0633)
2023/09/19 08:03:51 - INFO - root -   Epoch: [255/400][100/346], lr: 0.00000046 	 loss = 0.0149(0.0662)
2023/09/19 08:04:52 - INFO - root -   Epoch: [255/400][120/346], lr: 0.00000046 	 loss = 0.0022(0.1120)
2023/09/19 08:05:34 - INFO - root -   Epoch: [255/400][140/346], lr: 0.00000046 	 loss = 0.3718(0.1301)
2023/09/19 08:06:35 - INFO - root -   Epoch: [255/400][160/346], lr: 0.00000046 	 loss = 0.0025(0.1533)
2023/09/19 08:07:18 - INFO - root -   Epoch: [255/400][180/346], lr: 0.00000046 	 loss = 0.0058(0.1535)
2023/09/19 08:08:18 - INFO - root -   Epoch: [255/400][200/346], lr: 0.00000046 	 loss = 0.0004(0.1419)
2023/09/19 08:09:01 - INFO - root -   Epoch: [255/400][220/346], lr: 0.00000046 	 loss = 0.1025(0.1358)
2023/09/19 08:10:01 - INFO - root -   Epoch: [255/400][240/346], lr: 0.00000046 	 loss = 0.0168(0.1360)
2023/09/19 08:10:44 - INFO - root -   Epoch: [255/400][260/346], lr: 0.00000046 	 loss = 0.0050(0.1277)
2023/09/19 08:11:44 - INFO - root -   Epoch: [255/400][280/346], lr: 0.00000046 	 loss = 0.0011(0.1307)
2023/09/19 08:12:27 - INFO - root -   Epoch: [255/400][300/346], lr: 0.00000046 	 loss = 0.0011(0.1345)
2023/09/19 08:13:27 - INFO - root -   Epoch: [255/400][320/346], lr: 0.00000046 	 loss = 0.0002(0.1292)
2023/09/19 08:14:09 - INFO - root -   Epoch: [255/400][340/346], lr: 0.00000046 	 loss = 0.0505(0.1247)
2023/09/19 08:14:13 - INFO - root -   Epoch: [255/400] 	 loss = 0.1248
2023/09/19 08:14:13 - INFO - root -   train_accuracy = 0.9523
2023/09/19 08:14:35 - INFO - root -   Epoch: [256/400][0/346], lr: 0.00000047 	 loss = 0.0022(0.0022)
2023/09/19 08:15:18 - INFO - root -   Epoch: [256/400][20/346], lr: 0.00000047 	 loss = 0.0006(0.0094)
2023/09/19 08:16:18 - INFO - root -   Epoch: [256/400][40/346], lr: 0.00000047 	 loss = 0.0035(0.0553)
2023/09/19 08:17:01 - INFO - root -   Epoch: [256/400][60/346], lr: 0.00000047 	 loss = 0.0012(0.0611)
2023/09/19 08:18:01 - INFO - root -   Epoch: [256/400][80/346], lr: 0.00000047 	 loss = 0.0003(0.0711)
2023/09/19 08:18:44 - INFO - root -   Epoch: [256/400][100/346], lr: 0.00000047 	 loss = 1.8691(0.1035)
2023/09/19 08:19:45 - INFO - root -   Epoch: [256/400][120/346], lr: 0.00000047 	 loss = 0.0495(0.1263)
2023/09/19 08:20:28 - INFO - root -   Epoch: [256/400][140/346], lr: 0.00000047 	 loss = 0.0114(0.1237)
2023/09/19 08:21:28 - INFO - root -   Epoch: [256/400][160/346], lr: 0.00000047 	 loss = 0.0011(0.1191)
2023/09/19 08:22:11 - INFO - root -   Epoch: [256/400][180/346], lr: 0.00000047 	 loss = 0.0778(0.1270)
2023/09/19 08:23:11 - INFO - root -   Epoch: [256/400][200/346], lr: 0.00000047 	 loss = 0.0002(0.1176)
2023/09/19 08:23:54 - INFO - root -   Epoch: [256/400][220/346], lr: 0.00000047 	 loss = 0.0140(0.1227)
2023/09/19 08:24:54 - INFO - root -   Epoch: [256/400][240/346], lr: 0.00000047 	 loss = 0.0077(0.1332)
2023/09/19 08:25:37 - INFO - root -   Epoch: [256/400][260/346], lr: 0.00000047 	 loss = 0.0391(0.1359)
2023/09/19 08:26:37 - INFO - root -   Epoch: [256/400][280/346], lr: 0.00000047 	 loss = 0.0204(0.1415)
2023/09/19 08:27:21 - INFO - root -   Epoch: [256/400][300/346], lr: 0.00000047 	 loss = 0.0007(0.1436)
2023/09/19 08:28:20 - INFO - root -   Epoch: [256/400][320/346], lr: 0.00000047 	 loss = 0.0001(0.1395)
2023/09/19 08:29:03 - INFO - root -   Epoch: [256/400][340/346], lr: 0.00000047 	 loss = 0.0026(0.1480)
2023/09/19 08:29:07 - INFO - root -   Epoch: [256/400] 	 loss = 0.1473
2023/09/19 08:29:07 - INFO - root -   train_accuracy = 0.9408
2023/09/19 08:29:28 - INFO - root -   Epoch: [257/400][0/346], lr: 0.00000047 	 loss = 0.0286(0.0286)
2023/09/19 08:30:11 - INFO - root -   Epoch: [257/400][20/346], lr: 0.00000047 	 loss = 0.0010(0.0969)
2023/09/19 08:31:12 - INFO - root -   Epoch: [257/400][40/346], lr: 0.00000047 	 loss = 0.7856(0.1739)
2023/09/19 08:31:55 - INFO - root -   Epoch: [257/400][60/346], lr: 0.00000047 	 loss = 0.0042(0.1298)
2023/09/19 08:32:57 - INFO - root -   Epoch: [257/400][80/346], lr: 0.00000047 	 loss = 0.0156(0.1289)
2023/09/19 08:33:40 - INFO - root -   Epoch: [257/400][100/346], lr: 0.00000047 	 loss = 0.0197(0.1180)
2023/09/19 08:34:40 - INFO - root -   Epoch: [257/400][120/346], lr: 0.00000047 	 loss = 0.0007(0.1114)
2023/09/19 08:35:23 - INFO - root -   Epoch: [257/400][140/346], lr: 0.00000047 	 loss = 0.0018(0.1110)
2023/09/19 08:36:24 - INFO - root -   Epoch: [257/400][160/346], lr: 0.00000047 	 loss = 0.0004(0.1156)
2023/09/19 08:37:07 - INFO - root -   Epoch: [257/400][180/346], lr: 0.00000047 	 loss = 0.0559(0.1298)
2023/09/19 08:38:07 - INFO - root -   Epoch: [257/400][200/346], lr: 0.00000047 	 loss = 0.0059(0.1207)
2023/09/19 08:38:51 - INFO - root -   Epoch: [257/400][220/346], lr: 0.00000047 	 loss = 0.0024(0.1224)
2023/09/19 08:39:51 - INFO - root -   Epoch: [257/400][240/346], lr: 0.00000047 	 loss = 0.0034(0.1200)
2023/09/19 08:40:35 - INFO - root -   Epoch: [257/400][260/346], lr: 0.00000047 	 loss = 0.0165(0.1167)
2023/09/19 08:41:34 - INFO - root -   Epoch: [257/400][280/346], lr: 0.00000047 	 loss = 0.0001(0.1206)
2023/09/19 08:42:19 - INFO - root -   Epoch: [257/400][300/346], lr: 0.00000047 	 loss = 0.0002(0.1189)
2023/09/19 08:43:17 - INFO - root -   Epoch: [257/400][320/346], lr: 0.00000047 	 loss = 0.0653(0.1132)
2023/09/19 08:44:01 - INFO - root -   Epoch: [257/400][340/346], lr: 0.00000047 	 loss = 0.0021(0.1112)
2023/09/19 08:44:05 - INFO - root -   Epoch: [257/400] 	 loss = 0.1133
2023/09/19 08:44:05 - INFO - root -   train_accuracy = 0.9552
2023/09/19 08:44:27 - INFO - root -   Epoch: [258/400][0/346], lr: 0.00000047 	 loss = 0.0481(0.0481)
2023/09/19 08:45:10 - INFO - root -   Epoch: [258/400][20/346], lr: 0.00000047 	 loss = 0.0138(0.0947)
2023/09/19 08:46:11 - INFO - root -   Epoch: [258/400][40/346], lr: 0.00000047 	 loss = 0.0671(0.1690)
2023/09/19 08:46:54 - INFO - root -   Epoch: [258/400][60/346], lr: 0.00000047 	 loss = 0.2051(0.1441)
2023/09/19 08:47:54 - INFO - root -   Epoch: [258/400][80/346], lr: 0.00000047 	 loss = 0.0009(0.1183)
2023/09/19 08:48:38 - INFO - root -   Epoch: [258/400][100/346], lr: 0.00000047 	 loss = 0.3560(0.1056)
2023/09/19 08:49:38 - INFO - root -   Epoch: [258/400][120/346], lr: 0.00000047 	 loss = 0.0011(0.0968)
2023/09/19 08:50:21 - INFO - root -   Epoch: [258/400][140/346], lr: 0.00000047 	 loss = 0.0013(0.1074)
2023/09/19 08:51:22 - INFO - root -   Epoch: [258/400][160/346], lr: 0.00000047 	 loss = 0.0005(0.0964)
2023/09/19 08:52:05 - INFO - root -   Epoch: [258/400][180/346], lr: 0.00000047 	 loss = 0.0024(0.0987)
2023/09/19 08:53:05 - INFO - root -   Epoch: [258/400][200/346], lr: 0.00000047 	 loss = 0.0006(0.1273)
2023/09/19 08:53:49 - INFO - root -   Epoch: [258/400][220/346], lr: 0.00000047 	 loss = 0.0062(0.1352)
2023/09/19 08:54:49 - INFO - root -   Epoch: [258/400][240/346], lr: 0.00000047 	 loss = 0.0050(0.1410)
2023/09/19 08:55:33 - INFO - root -   Epoch: [258/400][260/346], lr: 0.00000047 	 loss = 0.7273(0.1570)
2023/09/19 08:56:33 - INFO - root -   Epoch: [258/400][280/346], lr: 0.00000047 	 loss = 0.0923(0.1731)
2023/09/19 08:57:17 - INFO - root -   Epoch: [258/400][300/346], lr: 0.00000047 	 loss = 0.0777(0.1664)
2023/09/19 08:58:16 - INFO - root -   Epoch: [258/400][320/346], lr: 0.00000047 	 loss = 0.0152(0.1577)
2023/09/19 08:58:59 - INFO - root -   Epoch: [258/400][340/346], lr: 0.00000047 	 loss = 0.0535(0.1548)
2023/09/19 08:59:03 - INFO - root -   Epoch: [258/400] 	 loss = 0.1559
2023/09/19 08:59:03 - INFO - root -   train_accuracy = 0.9436
2023/09/19 08:59:24 - INFO - root -   Epoch: [259/400][0/346], lr: 0.00000047 	 loss = 0.0665(0.0665)
2023/09/19 09:00:07 - INFO - root -   Epoch: [259/400][20/346], lr: 0.00000047 	 loss = 0.0009(0.0620)
2023/09/19 09:01:09 - INFO - root -   Epoch: [259/400][40/346], lr: 0.00000047 	 loss = 0.0068(0.0751)
2023/09/19 09:01:52 - INFO - root -   Epoch: [259/400][60/346], lr: 0.00000047 	 loss = 0.0044(0.0861)
2023/09/19 09:02:53 - INFO - root -   Epoch: [259/400][80/346], lr: 0.00000047 	 loss = 0.0400(0.0695)
2023/09/19 09:03:36 - INFO - root -   Epoch: [259/400][100/346], lr: 0.00000047 	 loss = 0.0037(0.0707)
2023/09/19 09:04:37 - INFO - root -   Epoch: [259/400][120/346], lr: 0.00000047 	 loss = 0.0743(0.0806)
2023/09/19 09:05:20 - INFO - root -   Epoch: [259/400][140/346], lr: 0.00000047 	 loss = 0.4687(0.0786)
2023/09/19 09:06:20 - INFO - root -   Epoch: [259/400][160/346], lr: 0.00000047 	 loss = 0.1258(0.0810)
2023/09/19 09:07:04 - INFO - root -   Epoch: [259/400][180/346], lr: 0.00000047 	 loss = 0.0067(0.0848)
2023/09/19 09:08:04 - INFO - root -   Epoch: [259/400][200/346], lr: 0.00000047 	 loss = 0.0000(0.0851)
2023/09/19 09:08:48 - INFO - root -   Epoch: [259/400][220/346], lr: 0.00000047 	 loss = 0.0235(0.0943)
2023/09/19 09:09:48 - INFO - root -   Epoch: [259/400][240/346], lr: 0.00000047 	 loss = 0.0029(0.0876)
2023/09/19 09:10:32 - INFO - root -   Epoch: [259/400][260/346], lr: 0.00000047 	 loss = 0.0815(0.0847)
2023/09/19 09:11:32 - INFO - root -   Epoch: [259/400][280/346], lr: 0.00000047 	 loss = 0.0001(0.0818)
2023/09/19 09:12:16 - INFO - root -   Epoch: [259/400][300/346], lr: 0.00000047 	 loss = 0.0071(0.0806)
2023/09/19 09:13:15 - INFO - root -   Epoch: [259/400][320/346], lr: 0.00000047 	 loss = 0.0003(0.0778)
2023/09/19 09:13:58 - INFO - root -   Epoch: [259/400][340/346], lr: 0.00000047 	 loss = 0.0022(0.0859)
2023/09/19 09:14:02 - INFO - root -   Epoch: [259/400] 	 loss = 0.0886
2023/09/19 09:17:52 - INFO - root -   precision = 0.6437
2023/09/19 09:17:52 - INFO - root -   eval_loss = 1.4389
2023/09/19 09:17:53 - INFO - root -   train_accuracy = 0.9682
2023/09/19 09:18:15 - INFO - root -   Epoch: [260/400][0/346], lr: 0.00000047 	 loss = 0.3346(0.3346)
2023/09/19 09:18:58 - INFO - root -   Epoch: [260/400][20/346], lr: 0.00000047 	 loss = 0.0057(0.2988)
2023/09/19 09:19:58 - INFO - root -   Epoch: [260/400][40/346], lr: 0.00000047 	 loss = 0.0091(0.1882)
2023/09/19 09:20:41 - INFO - root -   Epoch: [260/400][60/346], lr: 0.00000047 	 loss = 0.0050(0.1637)
2023/09/19 09:21:42 - INFO - root -   Epoch: [260/400][80/346], lr: 0.00000047 	 loss = 0.0023(0.1378)
2023/09/19 09:22:25 - INFO - root -   Epoch: [260/400][100/346], lr: 0.00000047 	 loss = 0.0050(0.1637)
2023/09/19 09:23:25 - INFO - root -   Epoch: [260/400][120/346], lr: 0.00000047 	 loss = 0.0002(0.1609)
2023/09/19 09:24:09 - INFO - root -   Epoch: [260/400][140/346], lr: 0.00000047 	 loss = 0.0011(0.1515)
2023/09/19 09:25:09 - INFO - root -   Epoch: [260/400][160/346], lr: 0.00000047 	 loss = 0.0019(0.1572)
2023/09/19 09:25:52 - INFO - root -   Epoch: [260/400][180/346], lr: 0.00000047 	 loss = 0.2745(0.1550)
2023/09/19 09:26:52 - INFO - root -   Epoch: [260/400][200/346], lr: 0.00000047 	 loss = 0.0015(0.1439)
2023/09/19 09:27:35 - INFO - root -   Epoch: [260/400][220/346], lr: 0.00000047 	 loss = 0.0003(0.1483)
2023/09/19 09:28:36 - INFO - root -   Epoch: [260/400][240/346], lr: 0.00000047 	 loss = 0.0008(0.1468)
2023/09/19 09:29:18 - INFO - root -   Epoch: [260/400][260/346], lr: 0.00000047 	 loss = 0.6333(0.1403)
2023/09/19 09:30:19 - INFO - root -   Epoch: [260/400][280/346], lr: 0.00000047 	 loss = 0.0006(0.1365)
2023/09/19 09:31:01 - INFO - root -   Epoch: [260/400][300/346], lr: 0.00000047 	 loss = 0.0028(0.1386)
2023/09/19 09:32:02 - INFO - root -   Epoch: [260/400][320/346], lr: 0.00000047 	 loss = 0.6854(0.1453)
2023/09/19 09:32:44 - INFO - root -   Epoch: [260/400][340/346], lr: 0.00000047 	 loss = 0.0996(0.1412)
2023/09/19 09:32:48 - INFO - root -   Epoch: [260/400] 	 loss = 0.1413
2023/09/19 09:32:48 - INFO - root -   train_accuracy = 0.9422
2023/09/19 09:33:10 - INFO - root -   Epoch: [261/400][0/346], lr: 0.00000047 	 loss = 0.0072(0.0072)
2023/09/19 09:33:52 - INFO - root -   Epoch: [261/400][20/346], lr: 0.00000047 	 loss = 0.0028(0.0323)
2023/09/19 09:34:53 - INFO - root -   Epoch: [261/400][40/346], lr: 0.00000047 	 loss = 0.3416(0.0524)
2023/09/19 09:35:36 - INFO - root -   Epoch: [261/400][60/346], lr: 0.00000047 	 loss = 0.0343(0.0934)
2023/09/19 09:36:37 - INFO - root -   Epoch: [261/400][80/346], lr: 0.00000047 	 loss = 0.1741(0.0941)
2023/09/19 09:37:20 - INFO - root -   Epoch: [261/400][100/346], lr: 0.00000047 	 loss = 0.0815(0.1178)
2023/09/19 09:38:20 - INFO - root -   Epoch: [261/400][120/346], lr: 0.00000047 	 loss = 0.0003(0.1101)
2023/09/19 09:39:03 - INFO - root -   Epoch: [261/400][140/346], lr: 0.00000047 	 loss = 0.0180(0.0975)
2023/09/19 09:40:03 - INFO - root -   Epoch: [261/400][160/346], lr: 0.00000047 	 loss = 0.0018(0.0906)
2023/09/19 09:40:46 - INFO - root -   Epoch: [261/400][180/346], lr: 0.00000047 	 loss = 0.0087(0.1038)
2023/09/19 09:41:46 - INFO - root -   Epoch: [261/400][200/346], lr: 0.00000047 	 loss = 0.0041(0.1039)
2023/09/19 09:42:29 - INFO - root -   Epoch: [261/400][220/346], lr: 0.00000047 	 loss = 0.4068(0.1276)
2023/09/19 09:43:29 - INFO - root -   Epoch: [261/400][240/346], lr: 0.00000047 	 loss = 0.0423(0.1269)
2023/09/19 09:44:12 - INFO - root -   Epoch: [261/400][260/346], lr: 0.00000047 	 loss = 0.0025(0.1252)
2023/09/19 09:45:13 - INFO - root -   Epoch: [261/400][280/346], lr: 0.00000047 	 loss = 0.0002(0.1430)
2023/09/19 09:45:56 - INFO - root -   Epoch: [261/400][300/346], lr: 0.00000047 	 loss = 0.0108(0.1423)
2023/09/19 09:46:56 - INFO - root -   Epoch: [261/400][320/346], lr: 0.00000047 	 loss = 0.0017(0.1416)
2023/09/19 09:47:39 - INFO - root -   Epoch: [261/400][340/346], lr: 0.00000047 	 loss = 0.0086(0.1485)
2023/09/19 09:47:43 - INFO - root -   Epoch: [261/400] 	 loss = 0.1484
2023/09/19 09:47:43 - INFO - root -   train_accuracy = 0.9350
2023/09/19 09:48:05 - INFO - root -   Epoch: [262/400][0/346], lr: 0.00000047 	 loss = 0.0053(0.0053)
2023/09/19 09:48:48 - INFO - root -   Epoch: [262/400][20/346], lr: 0.00000047 	 loss = 0.0003(0.0391)
2023/09/19 09:49:49 - INFO - root -   Epoch: [262/400][40/346], lr: 0.00000047 	 loss = 0.0372(0.0363)
2023/09/19 09:50:32 - INFO - root -   Epoch: [262/400][60/346], lr: 0.00000047 	 loss = 0.0135(0.0384)
2023/09/19 09:51:33 - INFO - root -   Epoch: [262/400][80/346], lr: 0.00000047 	 loss = 0.0132(0.0424)
2023/09/19 09:52:17 - INFO - root -   Epoch: [262/400][100/346], lr: 0.00000047 	 loss = 0.0046(0.0570)
2023/09/19 09:53:17 - INFO - root -   Epoch: [262/400][120/346], lr: 0.00000047 	 loss = 0.0003(0.0554)
2023/09/19 09:54:00 - INFO - root -   Epoch: [262/400][140/346], lr: 0.00000047 	 loss = 0.0016(0.0648)
2023/09/19 09:55:01 - INFO - root -   Epoch: [262/400][160/346], lr: 0.00000047 	 loss = 0.0050(0.0858)
2023/09/19 09:55:44 - INFO - root -   Epoch: [262/400][180/346], lr: 0.00000047 	 loss = 0.1438(0.1018)
2023/09/19 09:56:45 - INFO - root -   Epoch: [262/400][200/346], lr: 0.00000047 	 loss = 0.0089(0.1012)
2023/09/19 09:57:28 - INFO - root -   Epoch: [262/400][220/346], lr: 0.00000047 	 loss = 0.0028(0.1165)
2023/09/19 09:58:28 - INFO - root -   Epoch: [262/400][240/346], lr: 0.00000047 	 loss = 0.0127(0.1276)
2023/09/19 09:59:12 - INFO - root -   Epoch: [262/400][260/346], lr: 0.00000047 	 loss = 0.0836(0.1260)
2023/09/19 10:00:12 - INFO - root -   Epoch: [262/400][280/346], lr: 0.00000047 	 loss = 0.0017(0.1365)
2023/09/19 10:00:56 - INFO - root -   Epoch: [262/400][300/346], lr: 0.00000047 	 loss = 0.2387(0.1304)
2023/09/19 10:01:56 - INFO - root -   Epoch: [262/400][320/346], lr: 0.00000047 	 loss = 0.0001(0.1348)
2023/09/19 10:02:39 - INFO - root -   Epoch: [262/400][340/346], lr: 0.00000047 	 loss = 0.0264(0.1338)
2023/09/19 10:02:43 - INFO - root -   Epoch: [262/400] 	 loss = 0.1357
2023/09/19 10:02:43 - INFO - root -   train_accuracy = 0.9523
2023/09/19 10:03:05 - INFO - root -   Epoch: [263/400][0/346], lr: 0.00000048 	 loss = 0.0014(0.0014)
2023/09/19 10:03:48 - INFO - root -   Epoch: [263/400][20/346], lr: 0.00000048 	 loss = 0.0008(0.0381)
2023/09/19 10:04:49 - INFO - root -   Epoch: [263/400][40/346], lr: 0.00000048 	 loss = 0.9608(0.1086)
2023/09/19 10:05:32 - INFO - root -   Epoch: [263/400][60/346], lr: 0.00000048 	 loss = 0.0016(0.0847)
2023/09/19 10:06:33 - INFO - root -   Epoch: [263/400][80/346], lr: 0.00000048 	 loss = 1.1146(0.1199)
2023/09/19 10:07:16 - INFO - root -   Epoch: [263/400][100/346], lr: 0.00000048 	 loss = 0.1443(0.1737)
2023/09/19 10:08:16 - INFO - root -   Epoch: [263/400][120/346], lr: 0.00000048 	 loss = 0.0009(0.1716)
2023/09/19 10:08:59 - INFO - root -   Epoch: [263/400][140/346], lr: 0.00000048 	 loss = 0.0826(0.1776)
2023/09/19 10:10:00 - INFO - root -   Epoch: [263/400][160/346], lr: 0.00000048 	 loss = 0.0007(0.1835)
2023/09/19 10:10:43 - INFO - root -   Epoch: [263/400][180/346], lr: 0.00000048 	 loss = 0.0035(0.1758)
2023/09/19 10:11:43 - INFO - root -   Epoch: [263/400][200/346], lr: 0.00000048 	 loss = 0.0002(0.1641)
2023/09/19 10:12:27 - INFO - root -   Epoch: [263/400][220/346], lr: 0.00000048 	 loss = 0.0041(0.1673)
2023/09/19 10:13:27 - INFO - root -   Epoch: [263/400][240/346], lr: 0.00000048 	 loss = 0.0084(0.1593)
2023/09/19 10:14:10 - INFO - root -   Epoch: [263/400][260/346], lr: 0.00000048 	 loss = 0.0467(0.1513)
2023/09/19 10:15:11 - INFO - root -   Epoch: [263/400][280/346], lr: 0.00000048 	 loss = 0.0009(0.1470)
2023/09/19 10:15:54 - INFO - root -   Epoch: [263/400][300/346], lr: 0.00000048 	 loss = 0.1972(0.1421)
2023/09/19 10:16:54 - INFO - root -   Epoch: [263/400][320/346], lr: 0.00000048 	 loss = 0.0027(0.1381)
2023/09/19 10:17:36 - INFO - root -   Epoch: [263/400][340/346], lr: 0.00000048 	 loss = 0.0043(0.1331)
2023/09/19 10:17:40 - INFO - root -   Epoch: [263/400] 	 loss = 0.1314
2023/09/19 10:17:40 - INFO - root -   train_accuracy = 0.9494
2023/09/19 10:18:01 - INFO - root -   Epoch: [264/400][0/346], lr: 0.00000048 	 loss = 0.0023(0.0023)
2023/09/19 10:18:44 - INFO - root -   Epoch: [264/400][20/346], lr: 0.00000048 	 loss = 0.0019(0.0629)
2023/09/19 10:19:45 - INFO - root -   Epoch: [264/400][40/346], lr: 0.00000048 	 loss = 0.7495(0.1304)
2023/09/19 10:20:28 - INFO - root -   Epoch: [264/400][60/346], lr: 0.00000048 	 loss = 0.0257(0.1038)
2023/09/19 10:21:28 - INFO - root -   Epoch: [264/400][80/346], lr: 0.00000048 	 loss = 0.0026(0.1341)
2023/09/19 10:22:12 - INFO - root -   Epoch: [264/400][100/346], lr: 0.00000048 	 loss = 0.1534(0.1163)
2023/09/19 10:23:12 - INFO - root -   Epoch: [264/400][120/346], lr: 0.00000048 	 loss = 0.0002(0.1109)
2023/09/19 10:23:55 - INFO - root -   Epoch: [264/400][140/346], lr: 0.00000048 	 loss = 0.0031(0.1070)
2023/09/19 10:24:55 - INFO - root -   Epoch: [264/400][160/346], lr: 0.00000048 	 loss = 0.0007(0.1102)
2023/09/19 10:25:38 - INFO - root -   Epoch: [264/400][180/346], lr: 0.00000048 	 loss = 0.0161(0.1033)
2023/09/19 10:26:39 - INFO - root -   Epoch: [264/400][200/346], lr: 0.00000048 	 loss = 0.0002(0.0963)
2023/09/19 10:27:22 - INFO - root -   Epoch: [264/400][220/346], lr: 0.00000048 	 loss = 0.0019(0.0954)
2023/09/19 10:28:22 - INFO - root -   Epoch: [264/400][240/346], lr: 0.00000048 	 loss = 0.0011(0.0919)
2023/09/19 10:29:05 - INFO - root -   Epoch: [264/400][260/346], lr: 0.00000048 	 loss = 0.0093(0.0867)
2023/09/19 10:30:05 - INFO - root -   Epoch: [264/400][280/346], lr: 0.00000048 	 loss = 0.0559(0.0868)
2023/09/19 10:30:48 - INFO - root -   Epoch: [264/400][300/346], lr: 0.00000048 	 loss = 0.0131(0.0823)
2023/09/19 10:31:49 - INFO - root -   Epoch: [264/400][320/346], lr: 0.00000048 	 loss = 0.0001(0.0783)
2023/09/19 10:32:31 - INFO - root -   Epoch: [264/400][340/346], lr: 0.00000048 	 loss = 0.0047(0.0771)
2023/09/19 10:32:35 - INFO - root -   Epoch: [264/400] 	 loss = 0.0764
2023/09/19 10:36:22 - INFO - root -   precision = 0.7069
2023/09/19 10:36:22 - INFO - root -   eval_loss = 1.4044
2023/09/19 10:36:23 - INFO - root -   train_accuracy = 0.9783
2023/09/19 10:36:44 - INFO - root -   Epoch: [265/400][0/346], lr: 0.00000048 	 loss = 0.0012(0.0012)
2023/09/19 10:37:28 - INFO - root -   Epoch: [265/400][20/346], lr: 0.00000048 	 loss = 0.0001(0.0583)
2023/09/19 10:38:29 - INFO - root -   Epoch: [265/400][40/346], lr: 0.00000048 	 loss = 0.0140(0.0586)
2023/09/19 10:39:12 - INFO - root -   Epoch: [265/400][60/346], lr: 0.00000048 	 loss = 0.0108(0.0468)
2023/09/19 10:40:12 - INFO - root -   Epoch: [265/400][80/346], lr: 0.00000048 	 loss = 0.0021(0.0458)
2023/09/19 10:40:55 - INFO - root -   Epoch: [265/400][100/346], lr: 0.00000048 	 loss = 0.3177(0.0534)
2023/09/19 10:41:56 - INFO - root -   Epoch: [265/400][120/346], lr: 0.00000048 	 loss = 0.2385(0.0686)
2023/09/19 10:42:39 - INFO - root -   Epoch: [265/400][140/346], lr: 0.00000048 	 loss = 0.0048(0.0769)
2023/09/19 10:43:39 - INFO - root -   Epoch: [265/400][160/346], lr: 0.00000048 	 loss = 0.0324(0.0751)
2023/09/19 10:44:22 - INFO - root -   Epoch: [265/400][180/346], lr: 0.00000048 	 loss = 0.0185(0.0739)
2023/09/19 10:45:23 - INFO - root -   Epoch: [265/400][200/346], lr: 0.00000048 	 loss = 0.0001(0.0751)
2023/09/19 10:46:06 - INFO - root -   Epoch: [265/400][220/346], lr: 0.00000048 	 loss = 0.0314(0.0717)
2023/09/19 10:47:06 - INFO - root -   Epoch: [265/400][240/346], lr: 0.00000048 	 loss = 0.0092(0.0780)
2023/09/19 10:47:49 - INFO - root -   Epoch: [265/400][260/346], lr: 0.00000048 	 loss = 0.4345(0.0787)
2023/09/19 10:48:49 - INFO - root -   Epoch: [265/400][280/346], lr: 0.00000048 	 loss = 0.0003(0.0772)
2023/09/19 10:49:32 - INFO - root -   Epoch: [265/400][300/346], lr: 0.00000048 	 loss = 0.0046(0.0847)
2023/09/19 10:50:33 - INFO - root -   Epoch: [265/400][320/346], lr: 0.00000048 	 loss = 0.0011(0.1068)
2023/09/19 10:51:15 - INFO - root -   Epoch: [265/400][340/346], lr: 0.00000048 	 loss = 0.0549(0.1086)
2023/09/19 10:51:19 - INFO - root -   Epoch: [265/400] 	 loss = 0.1216
2023/09/19 10:51:19 - INFO - root -   train_accuracy = 0.9566
2023/09/19 10:51:41 - INFO - root -   Epoch: [266/400][0/346], lr: 0.00000048 	 loss = 0.0090(0.0090)
2023/09/19 10:52:24 - INFO - root -   Epoch: [266/400][20/346], lr: 0.00000048 	 loss = 0.0025(0.2627)
2023/09/19 10:53:24 - INFO - root -   Epoch: [266/400][40/346], lr: 0.00000048 	 loss = 0.0006(0.2361)
2023/09/19 10:54:08 - INFO - root -   Epoch: [266/400][60/346], lr: 0.00000048 	 loss = 0.2958(0.1793)
2023/09/19 10:55:08 - INFO - root -   Epoch: [266/400][80/346], lr: 0.00000048 	 loss = 0.0507(0.1625)
2023/09/19 10:55:51 - INFO - root -   Epoch: [266/400][100/346], lr: 0.00000048 	 loss = 0.0207(0.1414)
2023/09/19 10:56:52 - INFO - root -   Epoch: [266/400][120/346], lr: 0.00000048 	 loss = 0.0004(0.1276)
2023/09/19 10:57:35 - INFO - root -   Epoch: [266/400][140/346], lr: 0.00000048 	 loss = 0.0177(0.1189)
2023/09/19 10:58:36 - INFO - root -   Epoch: [266/400][160/346], lr: 0.00000048 	 loss = 0.0002(0.1101)
2023/09/19 10:59:19 - INFO - root -   Epoch: [266/400][180/346], lr: 0.00000048 	 loss = 0.0147(0.1159)
2023/09/19 11:00:20 - INFO - root -   Epoch: [266/400][200/346], lr: 0.00000048 	 loss = 0.0001(0.1142)
2023/09/19 11:01:03 - INFO - root -   Epoch: [266/400][220/346], lr: 0.00000048 	 loss = 0.0009(0.1130)
2023/09/19 11:02:03 - INFO - root -   Epoch: [266/400][240/346], lr: 0.00000048 	 loss = 0.0013(0.1140)
2023/09/19 11:02:47 - INFO - root -   Epoch: [266/400][260/346], lr: 0.00000048 	 loss = 0.1288(0.1093)
2023/09/19 11:03:47 - INFO - root -   Epoch: [266/400][280/346], lr: 0.00000048 	 loss = 0.0003(0.1235)
2023/09/19 11:04:30 - INFO - root -   Epoch: [266/400][300/346], lr: 0.00000048 	 loss = 0.0147(0.1392)
2023/09/19 11:05:30 - INFO - root -   Epoch: [266/400][320/346], lr: 0.00000048 	 loss = 0.0092(0.1399)
2023/09/19 11:06:13 - INFO - root -   Epoch: [266/400][340/346], lr: 0.00000048 	 loss = 0.8775(0.1460)
2023/09/19 11:06:17 - INFO - root -   Epoch: [266/400] 	 loss = 0.1444
2023/09/19 11:06:17 - INFO - root -   train_accuracy = 0.9408
2023/09/19 11:06:39 - INFO - root -   Epoch: [267/400][0/346], lr: 0.00000048 	 loss = 0.0010(0.0010)
2023/09/19 11:07:22 - INFO - root -   Epoch: [267/400][20/346], lr: 0.00000048 	 loss = 0.0033(0.0683)
2023/09/19 11:08:23 - INFO - root -   Epoch: [267/400][40/346], lr: 0.00000048 	 loss = 0.0354(0.0870)
2023/09/19 11:09:07 - INFO - root -   Epoch: [267/400][60/346], lr: 0.00000048 	 loss = 0.2221(0.0876)
2023/09/19 11:10:08 - INFO - root -   Epoch: [267/400][80/346], lr: 0.00000048 	 loss = 0.0005(0.1088)
2023/09/19 11:10:51 - INFO - root -   Epoch: [267/400][100/346], lr: 0.00000048 	 loss = 0.0108(0.1464)
2023/09/19 11:11:52 - INFO - root -   Epoch: [267/400][120/346], lr: 0.00000048 	 loss = 0.0004(0.1366)
2023/09/19 11:12:36 - INFO - root -   Epoch: [267/400][140/346], lr: 0.00000048 	 loss = 0.0113(0.1306)
2023/09/19 11:13:36 - INFO - root -   Epoch: [267/400][160/346], lr: 0.00000048 	 loss = 0.0021(0.1227)
2023/09/19 11:14:20 - INFO - root -   Epoch: [267/400][180/346], lr: 0.00000048 	 loss = 0.0959(0.1397)
2023/09/19 11:15:20 - INFO - root -   Epoch: [267/400][200/346], lr: 0.00000048 	 loss = 0.0038(0.1327)
2023/09/19 11:16:04 - INFO - root -   Epoch: [267/400][220/346], lr: 0.00000048 	 loss = 0.1816(0.1306)
2023/09/19 11:17:05 - INFO - root -   Epoch: [267/400][240/346], lr: 0.00000048 	 loss = 0.0005(0.1221)
2023/09/19 11:17:48 - INFO - root -   Epoch: [267/400][260/346], lr: 0.00000048 	 loss = 0.3542(0.1176)
2023/09/19 11:18:49 - INFO - root -   Epoch: [267/400][280/346], lr: 0.00000048 	 loss = 0.0001(0.1147)
2023/09/19 11:19:32 - INFO - root -   Epoch: [267/400][300/346], lr: 0.00000048 	 loss = 0.1196(0.1101)
2023/09/19 11:20:33 - INFO - root -   Epoch: [267/400][320/346], lr: 0.00000048 	 loss = 0.0219(0.1077)
2023/09/19 11:21:15 - INFO - root -   Epoch: [267/400][340/346], lr: 0.00000048 	 loss = 0.0050(0.1044)
2023/09/19 11:21:19 - INFO - root -   Epoch: [267/400] 	 loss = 0.1030
2023/09/19 11:21:19 - INFO - root -   train_accuracy = 0.9639
2023/09/19 11:21:41 - INFO - root -   Epoch: [268/400][0/346], lr: 0.00000048 	 loss = 0.4447(0.4447)
2023/09/19 11:22:25 - INFO - root -   Epoch: [268/400][20/346], lr: 0.00000048 	 loss = 0.0304(0.0704)
2023/09/19 11:23:26 - INFO - root -   Epoch: [268/400][40/346], lr: 0.00000048 	 loss = 0.9166(0.1188)
2023/09/19 11:24:09 - INFO - root -   Epoch: [268/400][60/346], lr: 0.00000048 	 loss = 0.0127(0.1078)
2023/09/19 11:25:10 - INFO - root -   Epoch: [268/400][80/346], lr: 0.00000048 	 loss = 0.0005(0.0911)
2023/09/19 11:25:54 - INFO - root -   Epoch: [268/400][100/346], lr: 0.00000048 	 loss = 0.0461(0.0918)
2023/09/19 11:26:55 - INFO - root -   Epoch: [268/400][120/346], lr: 0.00000048 	 loss = 0.2785(0.1244)
2023/09/19 11:27:39 - INFO - root -   Epoch: [268/400][140/346], lr: 0.00000048 	 loss = 0.0051(0.1130)
2023/09/19 11:28:40 - INFO - root -   Epoch: [268/400][160/346], lr: 0.00000048 	 loss = 0.0002(0.1084)
2023/09/19 11:29:23 - INFO - root -   Epoch: [268/400][180/346], lr: 0.00000048 	 loss = 0.0012(0.0981)
2023/09/19 11:30:24 - INFO - root -   Epoch: [268/400][200/346], lr: 0.00000048 	 loss = 0.0015(0.0934)
2023/09/19 11:31:08 - INFO - root -   Epoch: [268/400][220/346], lr: 0.00000048 	 loss = 0.0039(0.1030)
2023/09/19 11:32:08 - INFO - root -   Epoch: [268/400][240/346], lr: 0.00000048 	 loss = 0.0037(0.0975)
2023/09/19 11:32:52 - INFO - root -   Epoch: [268/400][260/346], lr: 0.00000048 	 loss = 0.0087(0.0952)
2023/09/19 11:33:52 - INFO - root -   Epoch: [268/400][280/346], lr: 0.00000048 	 loss = 0.0005(0.0942)
2023/09/19 11:34:36 - INFO - root -   Epoch: [268/400][300/346], lr: 0.00000048 	 loss = 0.0004(0.0945)
2023/09/19 11:35:37 - INFO - root -   Epoch: [268/400][320/346], lr: 0.00000048 	 loss = 0.1211(0.0994)
2023/09/19 11:36:19 - INFO - root -   Epoch: [268/400][340/346], lr: 0.00000048 	 loss = 0.0047(0.0949)
2023/09/19 11:36:23 - INFO - root -   Epoch: [268/400] 	 loss = 0.0938
2023/09/19 11:36:23 - INFO - root -   train_accuracy = 0.9668
2023/09/19 11:36:44 - INFO - root -   Epoch: [269/400][0/346], lr: 0.00000048 	 loss = 0.0082(0.0082)
2023/09/19 11:37:27 - INFO - root -   Epoch: [269/400][20/346], lr: 0.00000048 	 loss = 0.0002(0.0349)
2023/09/19 11:38:29 - INFO - root -   Epoch: [269/400][40/346], lr: 0.00000048 	 loss = 0.0041(0.1228)
2023/09/19 11:39:13 - INFO - root -   Epoch: [269/400][60/346], lr: 0.00000048 	 loss = 0.2278(0.1201)
2023/09/19 11:40:14 - INFO - root -   Epoch: [269/400][80/346], lr: 0.00000048 	 loss = 0.0024(0.1277)
2023/09/19 11:40:58 - INFO - root -   Epoch: [269/400][100/346], lr: 0.00000048 	 loss = 0.2022(0.1104)
2023/09/19 11:41:59 - INFO - root -   Epoch: [269/400][120/346], lr: 0.00000048 	 loss = 0.0318(0.1135)
2023/09/19 11:42:42 - INFO - root -   Epoch: [269/400][140/346], lr: 0.00000048 	 loss = 0.0382(0.1073)
2023/09/19 11:43:43 - INFO - root -   Epoch: [269/400][160/346], lr: 0.00000048 	 loss = 0.0005(0.1228)
2023/09/19 11:44:27 - INFO - root -   Epoch: [269/400][180/346], lr: 0.00000048 	 loss = 0.1027(0.1320)
2023/09/19 11:45:26 - INFO - root -   Epoch: [269/400][200/346], lr: 0.00000048 	 loss = 0.0004(0.1335)
2023/09/19 11:46:12 - INFO - root -   Epoch: [269/400][220/346], lr: 0.00000048 	 loss = 0.0121(0.1264)
2023/09/19 11:47:10 - INFO - root -   Epoch: [269/400][240/346], lr: 0.00000048 	 loss = 0.0107(0.1430)
2023/09/19 11:47:56 - INFO - root -   Epoch: [269/400][260/346], lr: 0.00000048 	 loss = 0.6144(0.1479)
2023/09/19 11:48:54 - INFO - root -   Epoch: [269/400][280/346], lr: 0.00000048 	 loss = 0.0057(0.1536)
2023/09/19 11:49:41 - INFO - root -   Epoch: [269/400][300/346], lr: 0.00000048 	 loss = 0.0002(0.1582)
2023/09/19 11:50:38 - INFO - root -   Epoch: [269/400][320/346], lr: 0.00000048 	 loss = 0.0011(0.1505)
2023/09/19 11:51:23 - INFO - root -   Epoch: [269/400][340/346], lr: 0.00000048 	 loss = 0.0041(0.1435)
2023/09/19 11:51:26 - INFO - root -   Epoch: [269/400] 	 loss = 0.1417
2023/09/19 11:55:14 - INFO - root -   precision = 0.7011
2023/09/19 11:55:14 - INFO - root -   eval_loss = 1.4313
2023/09/19 11:55:15 - INFO - root -   train_accuracy = 0.9509
2023/09/19 11:55:36 - INFO - root -   Epoch: [270/400][0/346], lr: 0.00000049 	 loss = 0.0983(0.0983)
2023/09/19 11:56:19 - INFO - root -   Epoch: [270/400][20/346], lr: 0.00000049 	 loss = 0.0018(0.1339)
2023/09/19 11:57:20 - INFO - root -   Epoch: [270/400][40/346], lr: 0.00000049 	 loss = 0.1626(0.1328)
2023/09/19 11:58:03 - INFO - root -   Epoch: [270/400][60/346], lr: 0.00000049 	 loss = 0.4023(0.1310)
2023/09/19 11:59:03 - INFO - root -   Epoch: [270/400][80/346], lr: 0.00000049 	 loss = 0.0560(0.1824)
2023/09/19 11:59:47 - INFO - root -   Epoch: [270/400][100/346], lr: 0.00000049 	 loss = 0.0059(0.1951)
2023/09/19 12:00:47 - INFO - root -   Epoch: [270/400][120/346], lr: 0.00000049 	 loss = 0.0075(0.1762)
2023/09/19 12:01:30 - INFO - root -   Epoch: [270/400][140/346], lr: 0.00000049 	 loss = 0.4954(0.1746)
2023/09/19 12:02:30 - INFO - root -   Epoch: [270/400][160/346], lr: 0.00000049 	 loss = 0.0015(0.1615)
2023/09/19 12:03:14 - INFO - root -   Epoch: [270/400][180/346], lr: 0.00000049 	 loss = 0.0642(0.1600)
2023/09/19 12:04:13 - INFO - root -   Epoch: [270/400][200/346], lr: 0.00000049 	 loss = 0.0013(0.1488)
2023/09/19 12:04:58 - INFO - root -   Epoch: [270/400][220/346], lr: 0.00000049 	 loss = 0.2284(0.1522)
2023/09/19 12:05:56 - INFO - root -   Epoch: [270/400][240/346], lr: 0.00000049 	 loss = 0.0093(0.1430)
2023/09/19 12:06:41 - INFO - root -   Epoch: [270/400][260/346], lr: 0.00000049 	 loss = 0.0018(0.1405)
2023/09/19 12:07:39 - INFO - root -   Epoch: [270/400][280/346], lr: 0.00000049 	 loss = 0.0070(0.1383)
2023/09/19 12:08:25 - INFO - root -   Epoch: [270/400][300/346], lr: 0.00000049 	 loss = 0.0016(0.1304)
2023/09/19 12:09:22 - INFO - root -   Epoch: [270/400][320/346], lr: 0.00000049 	 loss = 0.1692(0.1256)
2023/09/19 12:10:06 - INFO - root -   Epoch: [270/400][340/346], lr: 0.00000049 	 loss = 0.0446(0.1221)
2023/09/19 12:10:09 - INFO - root -   Epoch: [270/400] 	 loss = 0.1209
2023/09/19 12:10:09 - INFO - root -   train_accuracy = 0.9566
2023/09/19 12:10:31 - INFO - root -   Epoch: [271/400][0/346], lr: 0.00000049 	 loss = 0.0218(0.0218)
2023/09/19 12:11:14 - INFO - root -   Epoch: [271/400][20/346], lr: 0.00000049 	 loss = 0.0007(0.0532)
2023/09/19 12:12:15 - INFO - root -   Epoch: [271/400][40/346], lr: 0.00000049 	 loss = 0.0010(0.0773)
2023/09/19 12:12:58 - INFO - root -   Epoch: [271/400][60/346], lr: 0.00000049 	 loss = 0.0005(0.0642)
2023/09/19 12:13:59 - INFO - root -   Epoch: [271/400][80/346], lr: 0.00000049 	 loss = 0.0005(0.0958)
2023/09/19 12:14:43 - INFO - root -   Epoch: [271/400][100/346], lr: 0.00000049 	 loss = 0.0117(0.0936)
2023/09/19 12:15:42 - INFO - root -   Epoch: [271/400][120/346], lr: 0.00000049 	 loss = 0.0046(0.0957)
2023/09/19 12:16:27 - INFO - root -   Epoch: [271/400][140/346], lr: 0.00000049 	 loss = 0.0047(0.0964)
2023/09/19 12:17:26 - INFO - root -   Epoch: [271/400][160/346], lr: 0.00000049 	 loss = 0.0012(0.0886)
2023/09/19 12:18:11 - INFO - root -   Epoch: [271/400][180/346], lr: 0.00000049 	 loss = 0.0139(0.0973)
2023/09/19 12:19:10 - INFO - root -   Epoch: [271/400][200/346], lr: 0.00000049 	 loss = 0.0005(0.0986)
2023/09/19 12:19:56 - INFO - root -   Epoch: [271/400][220/346], lr: 0.00000049 	 loss = 0.0139(0.1040)
2023/09/19 12:20:54 - INFO - root -   Epoch: [271/400][240/346], lr: 0.00000049 	 loss = 0.0139(0.1011)
2023/09/19 12:21:40 - INFO - root -   Epoch: [271/400][260/346], lr: 0.00000049 	 loss = 0.0137(0.0980)
2023/09/19 12:22:37 - INFO - root -   Epoch: [271/400][280/346], lr: 0.00000049 	 loss = 0.0424(0.1021)
2023/09/19 12:23:24 - INFO - root -   Epoch: [271/400][300/346], lr: 0.00000049 	 loss = 0.0011(0.1029)
2023/09/19 12:24:21 - INFO - root -   Epoch: [271/400][320/346], lr: 0.00000049 	 loss = 0.0032(0.1092)
2023/09/19 12:25:06 - INFO - root -   Epoch: [271/400][340/346], lr: 0.00000049 	 loss = 0.1104(0.1049)
2023/09/19 12:25:10 - INFO - root -   Epoch: [271/400] 	 loss = 0.1136
2023/09/19 12:25:10 - INFO - root -   train_accuracy = 0.9595
2023/09/19 12:25:32 - INFO - root -   Epoch: [272/400][0/346], lr: 0.00000049 	 loss = 0.0082(0.0082)
2023/09/19 12:26:15 - INFO - root -   Epoch: [272/400][20/346], lr: 0.00000049 	 loss = 0.0004(0.0941)
2023/09/19 12:27:15 - INFO - root -   Epoch: [272/400][40/346], lr: 0.00000049 	 loss = 0.0141(0.1616)
2023/09/19 12:27:58 - INFO - root -   Epoch: [272/400][60/346], lr: 0.00000049 	 loss = 0.0063(0.1316)
2023/09/19 12:28:59 - INFO - root -   Epoch: [272/400][80/346], lr: 0.00000049 	 loss = 0.0029(0.1330)
2023/09/19 12:29:42 - INFO - root -   Epoch: [272/400][100/346], lr: 0.00000049 	 loss = 0.1588(0.1199)
2023/09/19 12:30:42 - INFO - root -   Epoch: [272/400][120/346], lr: 0.00000049 	 loss = 0.0005(0.1112)
2023/09/19 12:31:25 - INFO - root -   Epoch: [272/400][140/346], lr: 0.00000049 	 loss = 0.1347(0.1003)
2023/09/19 12:32:26 - INFO - root -   Epoch: [272/400][160/346], lr: 0.00000049 	 loss = 0.0007(0.0909)
2023/09/19 12:33:09 - INFO - root -   Epoch: [272/400][180/346], lr: 0.00000049 	 loss = 0.0014(0.0936)
2023/09/19 12:34:09 - INFO - root -   Epoch: [272/400][200/346], lr: 0.00000049 	 loss = 0.0002(0.0892)
2023/09/19 12:34:52 - INFO - root -   Epoch: [272/400][220/346], lr: 0.00000049 	 loss = 0.2909(0.0924)
2023/09/19 12:35:52 - INFO - root -   Epoch: [272/400][240/346], lr: 0.00000049 	 loss = 0.0000(0.0929)
2023/09/19 12:36:36 - INFO - root -   Epoch: [272/400][260/346], lr: 0.00000049 	 loss = 0.0067(0.0895)
2023/09/19 12:37:35 - INFO - root -   Epoch: [272/400][280/346], lr: 0.00000049 	 loss = 0.0003(0.1124)
2023/09/19 12:38:19 - INFO - root -   Epoch: [272/400][300/346], lr: 0.00000049 	 loss = 0.0044(0.1123)
2023/09/19 12:39:18 - INFO - root -   Epoch: [272/400][320/346], lr: 0.00000049 	 loss = 0.0006(0.1067)
2023/09/19 12:40:02 - INFO - root -   Epoch: [272/400][340/346], lr: 0.00000049 	 loss = 0.7796(0.1068)
2023/09/19 12:40:06 - INFO - root -   Epoch: [272/400] 	 loss = 0.1067
2023/09/19 12:40:06 - INFO - root -   train_accuracy = 0.9552
2023/09/19 12:40:28 - INFO - root -   Epoch: [273/400][0/346], lr: 0.00000049 	 loss = 0.0046(0.0046)
2023/09/19 12:41:11 - INFO - root -   Epoch: [273/400][20/346], lr: 0.00000049 	 loss = 0.0011(0.0764)
2023/09/19 12:42:11 - INFO - root -   Epoch: [273/400][40/346], lr: 0.00000049 	 loss = 0.0130(0.1504)
2023/09/19 12:42:55 - INFO - root -   Epoch: [273/400][60/346], lr: 0.00000049 	 loss = 0.0016(0.1216)
2023/09/19 12:43:55 - INFO - root -   Epoch: [273/400][80/346], lr: 0.00000049 	 loss = 0.0015(0.1160)
2023/09/19 12:44:39 - INFO - root -   Epoch: [273/400][100/346], lr: 0.00000049 	 loss = 0.0230(0.1329)
2023/09/19 12:45:39 - INFO - root -   Epoch: [273/400][120/346], lr: 0.00000049 	 loss = 0.0004(0.1277)
2023/09/19 12:46:22 - INFO - root -   Epoch: [273/400][140/346], lr: 0.00000049 	 loss = 0.0017(0.1178)
2023/09/19 12:47:23 - INFO - root -   Epoch: [273/400][160/346], lr: 0.00000049 	 loss = 0.0038(0.1106)
2023/09/19 12:48:06 - INFO - root -   Epoch: [273/400][180/346], lr: 0.00000049 	 loss = 0.0051(0.1095)
2023/09/19 12:49:07 - INFO - root -   Epoch: [273/400][200/346], lr: 0.00000049 	 loss = 0.0001(0.1159)
2023/09/19 12:49:50 - INFO - root -   Epoch: [273/400][220/346], lr: 0.00000049 	 loss = 0.0008(0.1164)
2023/09/19 12:50:50 - INFO - root -   Epoch: [273/400][240/346], lr: 0.00000049 	 loss = 0.0007(0.1122)
2023/09/19 12:51:34 - INFO - root -   Epoch: [273/400][260/346], lr: 0.00000049 	 loss = 0.5112(0.1112)
2023/09/19 12:52:34 - INFO - root -   Epoch: [273/400][280/346], lr: 0.00000049 	 loss = 0.0002(0.1112)
2023/09/19 12:53:18 - INFO - root -   Epoch: [273/400][300/346], lr: 0.00000049 	 loss = 0.0013(0.1104)
2023/09/19 12:54:18 - INFO - root -   Epoch: [273/400][320/346], lr: 0.00000049 	 loss = 0.0002(0.1152)
2023/09/19 12:55:01 - INFO - root -   Epoch: [273/400][340/346], lr: 0.00000049 	 loss = 0.3637(0.1174)
2023/09/19 12:55:05 - INFO - root -   Epoch: [273/400] 	 loss = 0.1262
2023/09/19 12:55:05 - INFO - root -   train_accuracy = 0.9509
2023/09/19 12:55:27 - INFO - root -   Epoch: [274/400][0/346], lr: 0.00000049 	 loss = 0.0008(0.0008)
2023/09/19 12:56:10 - INFO - root -   Epoch: [274/400][20/346], lr: 0.00000049 	 loss = 0.0434(0.2172)
2023/09/19 12:57:11 - INFO - root -   Epoch: [274/400][40/346], lr: 0.00000049 	 loss = 0.0057(0.1738)
2023/09/19 12:57:54 - INFO - root -   Epoch: [274/400][60/346], lr: 0.00000049 	 loss = 0.0547(0.1337)
2023/09/19 12:58:55 - INFO - root -   Epoch: [274/400][80/346], lr: 0.00000049 	 loss = 0.0006(0.1361)
2023/09/19 12:59:38 - INFO - root -   Epoch: [274/400][100/346], lr: 0.00000049 	 loss = 0.0160(0.1384)
2023/09/19 13:00:39 - INFO - root -   Epoch: [274/400][120/346], lr: 0.00000049 	 loss = 0.0020(0.1324)
2023/09/19 13:01:22 - INFO - root -   Epoch: [274/400][140/346], lr: 0.00000049 	 loss = 0.0012(0.1246)
2023/09/19 13:02:23 - INFO - root -   Epoch: [274/400][160/346], lr: 0.00000049 	 loss = 0.0006(0.1186)
2023/09/19 13:03:06 - INFO - root -   Epoch: [274/400][180/346], lr: 0.00000049 	 loss = 0.0386(0.1193)
2023/09/19 13:04:07 - INFO - root -   Epoch: [274/400][200/346], lr: 0.00000049 	 loss = 0.0003(0.1186)
2023/09/19 13:04:50 - INFO - root -   Epoch: [274/400][220/346], lr: 0.00000049 	 loss = 0.2277(0.1294)
2023/09/19 13:05:51 - INFO - root -   Epoch: [274/400][240/346], lr: 0.00000049 	 loss = 0.0006(0.1216)
2023/09/19 13:06:34 - INFO - root -   Epoch: [274/400][260/346], lr: 0.00000049 	 loss = 0.0222(0.1223)
2023/09/19 13:07:34 - INFO - root -   Epoch: [274/400][280/346], lr: 0.00000049 	 loss = 0.0029(0.1153)
2023/09/19 13:08:18 - INFO - root -   Epoch: [274/400][300/346], lr: 0.00000049 	 loss = 0.0019(0.1178)
2023/09/19 13:09:18 - INFO - root -   Epoch: [274/400][320/346], lr: 0.00000049 	 loss = 0.0011(0.1120)
2023/09/19 13:09:59 - INFO - root -   Epoch: [274/400][340/346], lr: 0.00000049 	 loss = 0.0086(0.1135)
2023/09/19 13:10:03 - INFO - root -   Epoch: [274/400] 	 loss = 0.1126
2023/09/19 13:13:50 - INFO - root -   precision = 0.6667
2023/09/19 13:13:50 - INFO - root -   eval_loss = 1.2981
2023/09/19 13:13:51 - INFO - root -   train_accuracy = 0.9509
2023/09/19 13:14:13 - INFO - root -   Epoch: [275/400][0/346], lr: 0.00000049 	 loss = 0.1500(0.1500)
2023/09/19 13:14:56 - INFO - root -   Epoch: [275/400][20/346], lr: 0.00000049 	 loss = 0.0007(0.0390)
2023/09/19 13:15:57 - INFO - root -   Epoch: [275/400][40/346], lr: 0.00000049 	 loss = 0.0032(0.0608)
2023/09/19 13:16:40 - INFO - root -   Epoch: [275/400][60/346], lr: 0.00000049 	 loss = 0.0022(0.0673)
2023/09/19 13:17:40 - INFO - root -   Epoch: [275/400][80/346], lr: 0.00000049 	 loss = 0.0003(0.0617)
2023/09/19 13:18:23 - INFO - root -   Epoch: [275/400][100/346], lr: 0.00000049 	 loss = 0.0044(0.0736)
2023/09/19 13:19:24 - INFO - root -   Epoch: [275/400][120/346], lr: 0.00000049 	 loss = 0.0367(0.0757)
2023/09/19 13:20:07 - INFO - root -   Epoch: [275/400][140/346], lr: 0.00000049 	 loss = 0.0015(0.0753)
2023/09/19 13:21:07 - INFO - root -   Epoch: [275/400][160/346], lr: 0.00000049 	 loss = 0.0024(0.0695)
2023/09/19 13:21:50 - INFO - root -   Epoch: [275/400][180/346], lr: 0.00000049 	 loss = 0.1262(0.0706)
2023/09/19 13:22:51 - INFO - root -   Epoch: [275/400][200/346], lr: 0.00000049 	 loss = 0.0000(0.0679)
2023/09/19 13:23:34 - INFO - root -   Epoch: [275/400][220/346], lr: 0.00000049 	 loss = 0.0008(0.0713)
2023/09/19 13:24:34 - INFO - root -   Epoch: [275/400][240/346], lr: 0.00000049 	 loss = 0.0001(0.0661)
2023/09/19 13:25:17 - INFO - root -   Epoch: [275/400][260/346], lr: 0.00000049 	 loss = 0.0090(0.0659)
2023/09/19 13:26:18 - INFO - root -   Epoch: [275/400][280/346], lr: 0.00000049 	 loss = 0.0009(0.0796)
2023/09/19 13:27:01 - INFO - root -   Epoch: [275/400][300/346], lr: 0.00000049 	 loss = 0.0008(0.0756)
2023/09/19 13:28:02 - INFO - root -   Epoch: [275/400][320/346], lr: 0.00000049 	 loss = 0.0002(0.0735)
2023/09/19 13:28:44 - INFO - root -   Epoch: [275/400][340/346], lr: 0.00000049 	 loss = 0.0275(0.0716)
2023/09/19 13:28:47 - INFO - root -   Epoch: [275/400] 	 loss = 0.0744
2023/09/19 13:28:47 - INFO - root -   train_accuracy = 0.9740
2023/09/19 13:29:09 - INFO - root -   Epoch: [276/400][0/346], lr: 0.00000049 	 loss = 0.0758(0.0758)
2023/09/19 13:29:52 - INFO - root -   Epoch: [276/400][20/346], lr: 0.00000049 	 loss = 0.0001(0.1006)
2023/09/19 13:30:53 - INFO - root -   Epoch: [276/400][40/346], lr: 0.00000049 	 loss = 0.0007(0.1205)
2023/09/19 13:31:36 - INFO - root -   Epoch: [276/400][60/346], lr: 0.00000049 	 loss = 0.0003(0.0917)
2023/09/19 13:32:37 - INFO - root -   Epoch: [276/400][80/346], lr: 0.00000049 	 loss = 0.0343(0.0762)
2023/09/19 13:33:20 - INFO - root -   Epoch: [276/400][100/346], lr: 0.00000049 	 loss = 0.0029(0.0804)
2023/09/19 13:34:20 - INFO - root -   Epoch: [276/400][120/346], lr: 0.00000049 	 loss = 0.0002(0.0697)
2023/09/19 13:35:03 - INFO - root -   Epoch: [276/400][140/346], lr: 0.00000049 	 loss = 0.0008(0.0696)
2023/09/19 13:36:04 - INFO - root -   Epoch: [276/400][160/346], lr: 0.00000049 	 loss = 0.0490(0.0678)
2023/09/19 13:36:47 - INFO - root -   Epoch: [276/400][180/346], lr: 0.00000049 	 loss = 0.0012(0.0664)
2023/09/19 13:37:48 - INFO - root -   Epoch: [276/400][200/346], lr: 0.00000049 	 loss = 0.0017(0.0630)
2023/09/19 13:38:31 - INFO - root -   Epoch: [276/400][220/346], lr: 0.00000049 	 loss = 0.0864(0.0620)
2023/09/19 13:39:31 - INFO - root -   Epoch: [276/400][240/346], lr: 0.00000049 	 loss = 0.0003(0.0620)
2023/09/19 13:40:15 - INFO - root -   Epoch: [276/400][260/346], lr: 0.00000049 	 loss = 0.0065(0.0689)
2023/09/19 13:41:14 - INFO - root -   Epoch: [276/400][280/346], lr: 0.00000049 	 loss = 0.0010(0.0917)
2023/09/19 13:41:59 - INFO - root -   Epoch: [276/400][300/346], lr: 0.00000049 	 loss = 0.0005(0.0910)
2023/09/19 13:42:58 - INFO - root -   Epoch: [276/400][320/346], lr: 0.00000049 	 loss = 0.0002(0.1052)
2023/09/19 13:43:42 - INFO - root -   Epoch: [276/400][340/346], lr: 0.00000049 	 loss = 0.3454(0.1126)
2023/09/19 13:43:46 - INFO - root -   Epoch: [276/400] 	 loss = 0.1168
2023/09/19 13:43:46 - INFO - root -   train_accuracy = 0.9566
2023/09/19 13:44:08 - INFO - root -   Epoch: [277/400][0/346], lr: 0.00000050 	 loss = 0.0016(0.0016)
2023/09/19 13:44:51 - INFO - root -   Epoch: [277/400][20/346], lr: 0.00000050 	 loss = 0.0264(0.0487)
2023/09/19 13:45:52 - INFO - root -   Epoch: [277/400][40/346], lr: 0.00000050 	 loss = 0.3398(0.0905)
2023/09/19 13:46:35 - INFO - root -   Epoch: [277/400][60/346], lr: 0.00000050 	 loss = 0.0034(0.0665)
2023/09/19 13:47:36 - INFO - root -   Epoch: [277/400][80/346], lr: 0.00000050 	 loss = 0.0012(0.0652)
2023/09/19 13:48:19 - INFO - root -   Epoch: [277/400][100/346], lr: 0.00000050 	 loss = 0.0039(0.0573)
2023/09/19 13:49:20 - INFO - root -   Epoch: [277/400][120/346], lr: 0.00000050 	 loss = 0.0003(0.0720)
2023/09/19 13:50:03 - INFO - root -   Epoch: [277/400][140/346], lr: 0.00000050 	 loss = 0.1807(0.0663)
2023/09/19 13:51:04 - INFO - root -   Epoch: [277/400][160/346], lr: 0.00000050 	 loss = 0.0265(0.0980)
2023/09/19 13:51:47 - INFO - root -   Epoch: [277/400][180/346], lr: 0.00000050 	 loss = 0.0120(0.0940)
2023/09/19 13:52:48 - INFO - root -   Epoch: [277/400][200/346], lr: 0.00000050 	 loss = 0.0001(0.1005)
2023/09/19 13:53:31 - INFO - root -   Epoch: [277/400][220/346], lr: 0.00000050 	 loss = 0.0017(0.1123)
2023/09/19 13:54:32 - INFO - root -   Epoch: [277/400][240/346], lr: 0.00000050 	 loss = 0.0109(0.1091)
2023/09/19 13:55:15 - INFO - root -   Epoch: [277/400][260/346], lr: 0.00000050 	 loss = 0.0150(0.1031)
2023/09/19 13:56:16 - INFO - root -   Epoch: [277/400][280/346], lr: 0.00000050 	 loss = 0.0002(0.1043)
2023/09/19 13:56:59 - INFO - root -   Epoch: [277/400][300/346], lr: 0.00000050 	 loss = 0.0310(0.1013)
2023/09/19 13:57:59 - INFO - root -   Epoch: [277/400][320/346], lr: 0.00000050 	 loss = 0.0000(0.1063)
2023/09/19 13:58:40 - INFO - root -   Epoch: [277/400][340/346], lr: 0.00000050 	 loss = 0.0082(0.1174)
2023/09/19 13:58:44 - INFO - root -   Epoch: [277/400] 	 loss = 0.1168
2023/09/19 13:58:44 - INFO - root -   train_accuracy = 0.9523
2023/09/19 13:59:06 - INFO - root -   Epoch: [278/400][0/346], lr: 0.00000050 	 loss = 0.0035(0.0035)
2023/09/19 13:59:49 - INFO - root -   Epoch: [278/400][20/346], lr: 0.00000050 	 loss = 0.0048(0.2020)
2023/09/19 14:00:50 - INFO - root -   Epoch: [278/400][40/346], lr: 0.00000050 	 loss = 0.0024(0.1237)
2023/09/19 14:01:33 - INFO - root -   Epoch: [278/400][60/346], lr: 0.00000050 	 loss = 0.0005(0.0874)
2023/09/19 14:02:34 - INFO - root -   Epoch: [278/400][80/346], lr: 0.00000050 	 loss = 0.0151(0.0798)
2023/09/19 14:03:17 - INFO - root -   Epoch: [278/400][100/346], lr: 0.00000050 	 loss = 0.2098(0.0972)
2023/09/19 14:04:18 - INFO - root -   Epoch: [278/400][120/346], lr: 0.00000050 	 loss = 0.0001(0.1025)
2023/09/19 14:05:01 - INFO - root -   Epoch: [278/400][140/346], lr: 0.00000050 	 loss = 0.0019(0.0936)
2023/09/19 14:06:01 - INFO - root -   Epoch: [278/400][160/346], lr: 0.00000050 	 loss = 0.0004(0.0870)
2023/09/19 14:06:45 - INFO - root -   Epoch: [278/400][180/346], lr: 0.00000050 	 loss = 0.0071(0.0852)
2023/09/19 14:07:45 - INFO - root -   Epoch: [278/400][200/346], lr: 0.00000050 	 loss = 0.0001(0.0815)
2023/09/19 14:08:29 - INFO - root -   Epoch: [278/400][220/346], lr: 0.00000050 	 loss = 0.0017(0.0820)
2023/09/19 14:09:29 - INFO - root -   Epoch: [278/400][240/346], lr: 0.00000050 	 loss = 0.0023(0.0858)
2023/09/19 14:10:13 - INFO - root -   Epoch: [278/400][260/346], lr: 0.00000050 	 loss = 0.0075(0.0807)
2023/09/19 14:11:12 - INFO - root -   Epoch: [278/400][280/346], lr: 0.00000050 	 loss = 0.0009(0.0952)
2023/09/19 14:11:58 - INFO - root -   Epoch: [278/400][300/346], lr: 0.00000050 	 loss = 0.0006(0.0948)
2023/09/19 14:12:56 - INFO - root -   Epoch: [278/400][320/346], lr: 0.00000050 	 loss = 0.0006(0.1008)
2023/09/19 14:13:39 - INFO - root -   Epoch: [278/400][340/346], lr: 0.00000050 	 loss = 0.0029(0.0984)
2023/09/19 14:13:42 - INFO - root -   Epoch: [278/400] 	 loss = 0.0978
2023/09/19 14:13:42 - INFO - root -   train_accuracy = 0.9624
2023/09/19 14:14:04 - INFO - root -   Epoch: [279/400][0/346], lr: 0.00000050 	 loss = 0.0015(0.0015)
2023/09/19 14:14:47 - INFO - root -   Epoch: [279/400][20/346], lr: 0.00000050 	 loss = 0.0011(0.0167)
2023/09/19 14:15:49 - INFO - root -   Epoch: [279/400][40/346], lr: 0.00000050 	 loss = 0.7647(0.0623)
2023/09/19 14:16:32 - INFO - root -   Epoch: [279/400][60/346], lr: 0.00000050 	 loss = 0.1404(0.0483)
2023/09/19 14:17:33 - INFO - root -   Epoch: [279/400][80/346], lr: 0.00000050 	 loss = 0.0004(0.0447)
2023/09/19 14:18:17 - INFO - root -   Epoch: [279/400][100/346], lr: 0.00000050 	 loss = 0.0022(0.0404)
2023/09/19 14:19:17 - INFO - root -   Epoch: [279/400][120/346], lr: 0.00000050 	 loss = 0.0166(0.0667)
2023/09/19 14:20:01 - INFO - root -   Epoch: [279/400][140/346], lr: 0.00000050 	 loss = 0.0167(0.0782)
2023/09/19 14:21:02 - INFO - root -   Epoch: [279/400][160/346], lr: 0.00000050 	 loss = 0.0040(0.1009)
2023/09/19 14:21:45 - INFO - root -   Epoch: [279/400][180/346], lr: 0.00000050 	 loss = 0.0058(0.0943)
2023/09/19 14:22:47 - INFO - root -   Epoch: [279/400][200/346], lr: 0.00000050 	 loss = 0.0005(0.0974)
2023/09/19 14:23:30 - INFO - root -   Epoch: [279/400][220/346], lr: 0.00000050 	 loss = 0.0049(0.1224)
2023/09/19 14:24:31 - INFO - root -   Epoch: [279/400][240/346], lr: 0.00000050 	 loss = 0.0003(0.1136)
2023/09/19 14:25:15 - INFO - root -   Epoch: [279/400][260/346], lr: 0.00000050 	 loss = 0.3833(0.1166)
2023/09/19 14:26:16 - INFO - root -   Epoch: [279/400][280/346], lr: 0.00000050 	 loss = 0.0186(0.1126)
2023/09/19 14:26:59 - INFO - root -   Epoch: [279/400][300/346], lr: 0.00000050 	 loss = 0.0008(0.1060)
2023/09/19 14:28:00 - INFO - root -   Epoch: [279/400][320/346], lr: 0.00000050 	 loss = 0.0003(0.1005)
2023/09/19 14:28:41 - INFO - root -   Epoch: [279/400][340/346], lr: 0.00000050 	 loss = 0.0028(0.1003)
2023/09/19 14:28:45 - INFO - root -   Epoch: [279/400] 	 loss = 0.1010
2023/09/19 14:32:33 - INFO - root -   precision = 0.7126
2023/09/19 14:32:33 - INFO - root -   eval_loss = 1.3055
2023/09/19 14:32:34 - INFO - root -   train_accuracy = 0.9639
2023/09/19 14:32:55 - INFO - root -   Epoch: [280/400][0/346], lr: 0.00000050 	 loss = 0.0009(0.0009)
2023/09/19 14:33:38 - INFO - root -   Epoch: [280/400][20/346], lr: 0.00000050 	 loss = 0.0003(0.0561)
2023/09/19 14:34:38 - INFO - root -   Epoch: [280/400][40/346], lr: 0.00000050 	 loss = 0.0031(0.0784)
2023/09/19 14:35:21 - INFO - root -   Epoch: [280/400][60/346], lr: 0.00000050 	 loss = 0.0042(0.0540)
2023/09/19 14:36:21 - INFO - root -   Epoch: [280/400][80/346], lr: 0.00000050 	 loss = 0.0002(0.0527)
2023/09/19 14:37:04 - INFO - root -   Epoch: [280/400][100/346], lr: 0.00000050 	 loss = 0.0189(0.0484)
2023/09/19 14:38:04 - INFO - root -   Epoch: [280/400][120/346], lr: 0.00000050 	 loss = 0.0002(0.0502)
2023/09/19 14:38:48 - INFO - root -   Epoch: [280/400][140/346], lr: 0.00000050 	 loss = 0.0005(0.0458)
2023/09/19 14:39:48 - INFO - root -   Epoch: [280/400][160/346], lr: 0.00000050 	 loss = 0.0004(0.0614)
2023/09/19 14:40:31 - INFO - root -   Epoch: [280/400][180/346], lr: 0.00000050 	 loss = 0.0193(0.0691)
2023/09/19 14:41:32 - INFO - root -   Epoch: [280/400][200/346], lr: 0.00000050 	 loss = 0.0008(0.0663)
2023/09/19 14:42:14 - INFO - root -   Epoch: [280/400][220/346], lr: 0.00000050 	 loss = 0.0133(0.0729)
2023/09/19 14:43:15 - INFO - root -   Epoch: [280/400][240/346], lr: 0.00000050 	 loss = 0.0008(0.0836)
2023/09/19 14:43:58 - INFO - root -   Epoch: [280/400][260/346], lr: 0.00000050 	 loss = 0.0061(0.0779)
2023/09/19 14:44:57 - INFO - root -   Epoch: [280/400][280/346], lr: 0.00000050 	 loss = 0.0001(0.0941)
2023/09/19 14:45:41 - INFO - root -   Epoch: [280/400][300/346], lr: 0.00000050 	 loss = 0.0016(0.1053)
2023/09/19 14:46:40 - INFO - root -   Epoch: [280/400][320/346], lr: 0.00000050 	 loss = 0.0329(0.1082)
2023/09/19 14:47:23 - INFO - root -   Epoch: [280/400][340/346], lr: 0.00000050 	 loss = 0.0199(0.1054)
2023/09/19 14:47:27 - INFO - root -   Epoch: [280/400] 	 loss = 0.1074
2023/09/19 14:47:27 - INFO - root -   train_accuracy = 0.9581
2023/09/19 14:47:48 - INFO - root -   Epoch: [281/400][0/346], lr: 0.00000050 	 loss = 0.0089(0.0089)
2023/09/19 14:48:31 - INFO - root -   Epoch: [281/400][20/346], lr: 0.00000050 	 loss = 0.0005(0.0239)
2023/09/19 14:49:32 - INFO - root -   Epoch: [281/400][40/346], lr: 0.00000050 	 loss = 0.7612(0.1309)
2023/09/19 14:50:15 - INFO - root -   Epoch: [281/400][60/346], lr: 0.00000050 	 loss = 0.0176(0.1338)
2023/09/19 14:51:16 - INFO - root -   Epoch: [281/400][80/346], lr: 0.00000050 	 loss = 0.0555(0.1733)
2023/09/19 14:51:59 - INFO - root -   Epoch: [281/400][100/346], lr: 0.00000050 	 loss = 0.0140(0.1642)
2023/09/19 14:53:00 - INFO - root -   Epoch: [281/400][120/346], lr: 0.00000050 	 loss = 0.0004(0.1482)
2023/09/19 14:53:43 - INFO - root -   Epoch: [281/400][140/346], lr: 0.00000050 	 loss = 0.0136(0.1379)
2023/09/19 14:54:43 - INFO - root -   Epoch: [281/400][160/346], lr: 0.00000050 	 loss = 0.0228(0.1485)
2023/09/19 14:55:28 - INFO - root -   Epoch: [281/400][180/346], lr: 0.00000050 	 loss = 0.0015(0.1336)
2023/09/19 14:56:27 - INFO - root -   Epoch: [281/400][200/346], lr: 0.00000050 	 loss = 0.0002(0.1281)
2023/09/19 14:57:12 - INFO - root -   Epoch: [281/400][220/346], lr: 0.00000050 	 loss = 0.0201(0.1355)
2023/09/19 14:58:11 - INFO - root -   Epoch: [281/400][240/346], lr: 0.00000050 	 loss = 0.0165(0.1363)
2023/09/19 14:58:56 - INFO - root -   Epoch: [281/400][260/346], lr: 0.00000050 	 loss = 0.0442(0.1321)
2023/09/19 14:59:54 - INFO - root -   Epoch: [281/400][280/346], lr: 0.00000050 	 loss = 0.1045(0.1355)
2023/09/19 15:00:40 - INFO - root -   Epoch: [281/400][300/346], lr: 0.00000050 	 loss = 0.0055(0.1293)
2023/09/19 15:01:38 - INFO - root -   Epoch: [281/400][320/346], lr: 0.00000050 	 loss = 0.0000(0.1266)
2023/09/19 15:02:23 - INFO - root -   Epoch: [281/400][340/346], lr: 0.00000050 	 loss = 0.0044(0.1270)
2023/09/19 15:02:27 - INFO - root -   Epoch: [281/400] 	 loss = 0.1254
2023/09/19 15:02:27 - INFO - root -   train_accuracy = 0.9480
2023/09/19 15:02:49 - INFO - root -   Epoch: [282/400][0/346], lr: 0.00000050 	 loss = 0.0003(0.0003)
2023/09/19 15:03:32 - INFO - root -   Epoch: [282/400][20/346], lr: 0.00000050 	 loss = 0.0003(0.0765)
2023/09/19 15:04:33 - INFO - root -   Epoch: [282/400][40/346], lr: 0.00000050 	 loss = 0.0104(0.1069)
2023/09/19 15:05:16 - INFO - root -   Epoch: [282/400][60/346], lr: 0.00000050 	 loss = 0.0017(0.0918)
2023/09/19 15:06:16 - INFO - root -   Epoch: [282/400][80/346], lr: 0.00000050 	 loss = 0.0972(0.1009)
2023/09/19 15:07:00 - INFO - root -   Epoch: [282/400][100/346], lr: 0.00000050 	 loss = 0.1152(0.1150)
2023/09/19 15:08:00 - INFO - root -   Epoch: [282/400][120/346], lr: 0.00000050 	 loss = 0.0011(0.1057)
2023/09/19 15:08:43 - INFO - root -   Epoch: [282/400][140/346], lr: 0.00000050 	 loss = 0.0168(0.1099)
2023/09/19 15:09:44 - INFO - root -   Epoch: [282/400][160/346], lr: 0.00000050 	 loss = 0.0797(0.1035)
2023/09/19 15:10:26 - INFO - root -   Epoch: [282/400][180/346], lr: 0.00000050 	 loss = 0.1024(0.0960)
2023/09/19 15:11:27 - INFO - root -   Epoch: [282/400][200/346], lr: 0.00000050 	 loss = 0.0051(0.0928)
2023/09/19 15:12:09 - INFO - root -   Epoch: [282/400][220/346], lr: 0.00000050 	 loss = 0.0049(0.0937)
2023/09/19 15:13:10 - INFO - root -   Epoch: [282/400][240/346], lr: 0.00000050 	 loss = 0.0084(0.1118)
2023/09/19 15:13:53 - INFO - root -   Epoch: [282/400][260/346], lr: 0.00000050 	 loss = 0.0040(0.1070)
2023/09/19 15:14:53 - INFO - root -   Epoch: [282/400][280/346], lr: 0.00000050 	 loss = 0.0002(0.1104)
2023/09/19 15:15:36 - INFO - root -   Epoch: [282/400][300/346], lr: 0.00000050 	 loss = 0.0009(0.1084)
2023/09/19 15:16:37 - INFO - root -   Epoch: [282/400][320/346], lr: 0.00000050 	 loss = 0.0157(0.1059)
2023/09/19 15:17:19 - INFO - root -   Epoch: [282/400][340/346], lr: 0.00000050 	 loss = 0.0126(0.1077)
2023/09/19 15:17:25 - INFO - root -   Epoch: [282/400] 	 loss = 0.1066
2023/09/19 15:17:25 - INFO - root -   train_accuracy = 0.9595
2023/09/19 15:17:46 - INFO - root -   Epoch: [283/400][0/346], lr: 0.00000050 	 loss = 0.0165(0.0165)
2023/09/19 15:18:29 - INFO - root -   Epoch: [283/400][20/346], lr: 0.00000050 	 loss = 0.0005(0.1577)
2023/09/19 15:19:30 - INFO - root -   Epoch: [283/400][40/346], lr: 0.00000050 	 loss = 0.0087(0.2174)
2023/09/19 15:20:14 - INFO - root -   Epoch: [283/400][60/346], lr: 0.00000050 	 loss = 0.0862(0.1594)
2023/09/19 15:21:15 - INFO - root -   Epoch: [283/400][80/346], lr: 0.00000050 	 loss = 0.0043(0.1492)
2023/09/19 15:21:58 - INFO - root -   Epoch: [283/400][100/346], lr: 0.00000050 	 loss = 0.0442(0.1370)
2023/09/19 15:23:00 - INFO - root -   Epoch: [283/400][120/346], lr: 0.00000050 	 loss = 0.0006(0.1310)
2023/09/19 15:23:44 - INFO - root -   Epoch: [283/400][140/346], lr: 0.00000050 	 loss = 0.4178(0.1214)
2023/09/19 15:24:44 - INFO - root -   Epoch: [283/400][160/346], lr: 0.00000050 	 loss = 0.0022(0.1127)
2023/09/19 15:25:27 - INFO - root -   Epoch: [283/400][180/346], lr: 0.00000050 	 loss = 0.0296(0.1054)
2023/09/19 15:26:27 - INFO - root -   Epoch: [283/400][200/346], lr: 0.00000050 	 loss = 0.0002(0.0963)
2023/09/19 15:27:10 - INFO - root -   Epoch: [283/400][220/346], lr: 0.00000050 	 loss = 0.0006(0.0980)
2023/09/19 15:28:11 - INFO - root -   Epoch: [283/400][240/346], lr: 0.00000050 	 loss = 0.0071(0.0941)
2023/09/19 15:28:54 - INFO - root -   Epoch: [283/400][260/346], lr: 0.00000050 	 loss = 0.0133(0.0917)
2023/09/19 15:29:55 - INFO - root -   Epoch: [283/400][280/346], lr: 0.00000050 	 loss = 0.0007(0.0978)
2023/09/19 15:30:38 - INFO - root -   Epoch: [283/400][300/346], lr: 0.00000050 	 loss = 0.0003(0.1092)
2023/09/19 15:31:38 - INFO - root -   Epoch: [283/400][320/346], lr: 0.00000050 	 loss = 0.0012(0.1103)
2023/09/19 15:32:21 - INFO - root -   Epoch: [283/400][340/346], lr: 0.00000050 	 loss = 0.0075(0.1105)
2023/09/19 15:32:24 - INFO - root -   Epoch: [283/400] 	 loss = 0.1125
2023/09/19 15:32:24 - INFO - root -   train_accuracy = 0.9523
2023/09/19 15:32:46 - INFO - root -   Epoch: [284/400][0/346], lr: 0.00000051 	 loss = 0.0006(0.0006)
2023/09/19 15:33:29 - INFO - root -   Epoch: [284/400][20/346], lr: 0.00000051 	 loss = 0.0285(0.0415)
2023/09/19 15:34:30 - INFO - root -   Epoch: [284/400][40/346], lr: 0.00000051 	 loss = 0.0038(0.0360)
2023/09/19 15:35:13 - INFO - root -   Epoch: [284/400][60/346], lr: 0.00000051 	 loss = 0.0006(0.0396)
2023/09/19 15:36:13 - INFO - root -   Epoch: [284/400][80/346], lr: 0.00000051 	 loss = 0.0007(0.0463)
2023/09/19 15:36:57 - INFO - root -   Epoch: [284/400][100/346], lr: 0.00000051 	 loss = 0.0011(0.0685)
2023/09/19 15:37:57 - INFO - root -   Epoch: [284/400][120/346], lr: 0.00000051 	 loss = 0.0002(0.0650)
2023/09/19 15:38:40 - INFO - root -   Epoch: [284/400][140/346], lr: 0.00000051 	 loss = 0.0048(0.0592)
2023/09/19 15:39:41 - INFO - root -   Epoch: [284/400][160/346], lr: 0.00000051 	 loss = 0.0002(0.0625)
2023/09/19 15:40:24 - INFO - root -   Epoch: [284/400][180/346], lr: 0.00000051 	 loss = 0.0009(0.0627)
2023/09/19 15:41:24 - INFO - root -   Epoch: [284/400][200/346], lr: 0.00000051 	 loss = 0.0452(0.0784)
2023/09/19 15:42:07 - INFO - root -   Epoch: [284/400][220/346], lr: 0.00000051 	 loss = 0.0051(0.0857)
2023/09/19 15:43:08 - INFO - root -   Epoch: [284/400][240/346], lr: 0.00000051 	 loss = 0.0003(0.0827)
2023/09/19 15:43:51 - INFO - root -   Epoch: [284/400][260/346], lr: 0.00000051 	 loss = 0.0227(0.0783)
2023/09/19 15:44:52 - INFO - root -   Epoch: [284/400][280/346], lr: 0.00000051 	 loss = 0.0018(0.0769)
2023/09/19 15:45:35 - INFO - root -   Epoch: [284/400][300/346], lr: 0.00000051 	 loss = 0.1624(0.0819)
2023/09/19 15:46:36 - INFO - root -   Epoch: [284/400][320/346], lr: 0.00000051 	 loss = 0.0005(0.0781)
2023/09/19 15:47:17 - INFO - root -   Epoch: [284/400][340/346], lr: 0.00000051 	 loss = 0.0291(0.0816)
2023/09/19 15:47:21 - INFO - root -   Epoch: [284/400] 	 loss = 0.0820
2023/09/19 15:51:09 - INFO - root -   precision = 0.6724
2023/09/19 15:51:09 - INFO - root -   eval_loss = 1.5329
2023/09/19 15:51:10 - INFO - root -   train_accuracy = 0.9711
2023/09/19 15:51:32 - INFO - root -   Epoch: [285/400][0/346], lr: 0.00000051 	 loss = 0.0085(0.0085)
2023/09/19 15:52:15 - INFO - root -   Epoch: [285/400][20/346], lr: 0.00000051 	 loss = 0.0021(0.1624)
2023/09/19 15:53:16 - INFO - root -   Epoch: [285/400][40/346], lr: 0.00000051 	 loss = 0.0006(0.1154)
2023/09/19 15:53:59 - INFO - root -   Epoch: [285/400][60/346], lr: 0.00000051 	 loss = 0.0010(0.1143)
2023/09/19 15:54:59 - INFO - root -   Epoch: [285/400][80/346], lr: 0.00000051 	 loss = 0.4209(0.1315)
2023/09/19 15:55:43 - INFO - root -   Epoch: [285/400][100/346], lr: 0.00000051 	 loss = 0.0133(0.1191)
2023/09/19 15:56:43 - INFO - root -   Epoch: [285/400][120/346], lr: 0.00000051 	 loss = 0.0002(0.1264)
2023/09/19 15:57:26 - INFO - root -   Epoch: [285/400][140/346], lr: 0.00000051 	 loss = 0.0065(0.1266)
2023/09/19 15:58:27 - INFO - root -   Epoch: [285/400][160/346], lr: 0.00000051 	 loss = 0.0000(0.1269)
2023/09/19 15:59:10 - INFO - root -   Epoch: [285/400][180/346], lr: 0.00000051 	 loss = 0.0452(0.1223)
2023/09/19 16:00:11 - INFO - root -   Epoch: [285/400][200/346], lr: 0.00000051 	 loss = 0.0001(0.1353)
2023/09/19 16:00:53 - INFO - root -   Epoch: [285/400][220/346], lr: 0.00000051 	 loss = 0.0017(0.1367)
2023/09/19 16:01:54 - INFO - root -   Epoch: [285/400][240/346], lr: 0.00000051 	 loss = 0.0008(0.1282)
2023/09/19 16:02:37 - INFO - root -   Epoch: [285/400][260/346], lr: 0.00000051 	 loss = 0.0059(0.1243)
2023/09/19 16:03:37 - INFO - root -   Epoch: [285/400][280/346], lr: 0.00000051 	 loss = 0.0035(0.1317)
2023/09/19 16:04:20 - INFO - root -   Epoch: [285/400][300/346], lr: 0.00000051 	 loss = 0.0021(0.1292)
2023/09/19 16:05:21 - INFO - root -   Epoch: [285/400][320/346], lr: 0.00000051 	 loss = 0.0001(0.1250)
2023/09/19 16:06:03 - INFO - root -   Epoch: [285/400][340/346], lr: 0.00000051 	 loss = 0.0011(0.1202)
2023/09/19 16:06:07 - INFO - root -   Epoch: [285/400] 	 loss = 0.1216
2023/09/19 16:06:07 - INFO - root -   train_accuracy = 0.9523
2023/09/19 16:06:28 - INFO - root -   Epoch: [286/400][0/346], lr: 0.00000051 	 loss = 0.0077(0.0077)
2023/09/19 16:07:11 - INFO - root -   Epoch: [286/400][20/346], lr: 0.00000051 	 loss = 0.0008(0.0515)
2023/09/19 16:08:12 - INFO - root -   Epoch: [286/400][40/346], lr: 0.00000051 	 loss = 0.0356(0.0842)
2023/09/19 16:08:55 - INFO - root -   Epoch: [286/400][60/346], lr: 0.00000051 	 loss = 0.0002(0.0911)
2023/09/19 16:09:56 - INFO - root -   Epoch: [286/400][80/346], lr: 0.00000051 	 loss = 0.0013(0.0799)
2023/09/19 16:10:39 - INFO - root -   Epoch: [286/400][100/346], lr: 0.00000051 	 loss = 0.0400(0.0709)
2023/09/19 16:11:39 - INFO - root -   Epoch: [286/400][120/346], lr: 0.00000051 	 loss = 0.0001(0.0828)
2023/09/19 16:12:22 - INFO - root -   Epoch: [286/400][140/346], lr: 0.00000051 	 loss = 0.0142(0.0844)
2023/09/19 16:13:22 - INFO - root -   Epoch: [286/400][160/346], lr: 0.00000051 	 loss = 0.0002(0.0939)
2023/09/19 16:14:06 - INFO - root -   Epoch: [286/400][180/346], lr: 0.00000051 	 loss = 0.0007(0.0911)
2023/09/19 16:15:06 - INFO - root -   Epoch: [286/400][200/346], lr: 0.00000051 	 loss = 0.0004(0.1068)
2023/09/19 16:15:50 - INFO - root -   Epoch: [286/400][220/346], lr: 0.00000051 	 loss = 0.0002(0.1298)
2023/09/19 16:16:49 - INFO - root -   Epoch: [286/400][240/346], lr: 0.00000051 	 loss = 0.0004(0.1387)
2023/09/19 16:17:33 - INFO - root -   Epoch: [286/400][260/346], lr: 0.00000051 	 loss = 0.0134(0.1432)
2023/09/19 16:18:33 - INFO - root -   Epoch: [286/400][280/346], lr: 0.00000051 	 loss = 0.0001(0.1485)
2023/09/19 16:19:17 - INFO - root -   Epoch: [286/400][300/346], lr: 0.00000051 	 loss = 0.0002(0.1456)
2023/09/19 16:20:16 - INFO - root -   Epoch: [286/400][320/346], lr: 0.00000051 	 loss = 0.0003(0.1434)
2023/09/19 16:21:00 - INFO - root -   Epoch: [286/400][340/346], lr: 0.00000051 	 loss = 0.0057(0.1476)
2023/09/19 16:21:04 - INFO - root -   Epoch: [286/400] 	 loss = 0.1489
2023/09/19 16:21:04 - INFO - root -   train_accuracy = 0.9408
2023/09/19 16:21:26 - INFO - root -   Epoch: [287/400][0/346], lr: 0.00000051 	 loss = 0.0031(0.0031)
2023/09/19 16:22:09 - INFO - root -   Epoch: [287/400][20/346], lr: 0.00000051 	 loss = 0.0003(0.1172)
2023/09/19 16:23:09 - INFO - root -   Epoch: [287/400][40/346], lr: 0.00000051 	 loss = 0.0860(0.1252)
2023/09/19 16:23:53 - INFO - root -   Epoch: [287/400][60/346], lr: 0.00000051 	 loss = 0.0294(0.0981)
2023/09/19 16:24:53 - INFO - root -   Epoch: [287/400][80/346], lr: 0.00000051 	 loss = 0.0003(0.0821)
2023/09/19 16:25:36 - INFO - root -   Epoch: [287/400][100/346], lr: 0.00000051 	 loss = 0.0211(0.0969)
2023/09/19 16:26:37 - INFO - root -   Epoch: [287/400][120/346], lr: 0.00000051 	 loss = 0.0008(0.0890)
2023/09/19 16:27:20 - INFO - root -   Epoch: [287/400][140/346], lr: 0.00000051 	 loss = 0.0013(0.0862)
2023/09/19 16:28:20 - INFO - root -   Epoch: [287/400][160/346], lr: 0.00000051 	 loss = 0.0005(0.0847)
2023/09/19 16:29:04 - INFO - root -   Epoch: [287/400][180/346], lr: 0.00000051 	 loss = 0.0757(0.0865)
2023/09/19 16:30:04 - INFO - root -   Epoch: [287/400][200/346], lr: 0.00000051 	 loss = 0.0004(0.0806)
2023/09/19 16:30:48 - INFO - root -   Epoch: [287/400][220/346], lr: 0.00000051 	 loss = 0.0027(0.0763)
2023/09/19 16:31:47 - INFO - root -   Epoch: [287/400][240/346], lr: 0.00000051 	 loss = 0.0002(0.0709)
2023/09/19 16:32:31 - INFO - root -   Epoch: [287/400][260/346], lr: 0.00000051 	 loss = 0.1732(0.0697)
2023/09/19 16:33:30 - INFO - root -   Epoch: [287/400][280/346], lr: 0.00000051 	 loss = 0.0003(0.0715)
2023/09/19 16:34:15 - INFO - root -   Epoch: [287/400][300/346], lr: 0.00000051 	 loss = 0.0002(0.0710)
2023/09/19 16:35:13 - INFO - root -   Epoch: [287/400][320/346], lr: 0.00000051 	 loss = 0.0002(0.0679)
2023/09/19 16:35:57 - INFO - root -   Epoch: [287/400][340/346], lr: 0.00000051 	 loss = 0.2070(0.0686)
2023/09/19 16:36:01 - INFO - root -   Epoch: [287/400] 	 loss = 0.0678
2023/09/19 16:36:01 - INFO - root -   train_accuracy = 0.9740
2023/09/19 16:36:23 - INFO - root -   Epoch: [288/400][0/346], lr: 0.00000051 	 loss = 0.0076(0.0076)
2023/09/19 16:37:06 - INFO - root -   Epoch: [288/400][20/346], lr: 0.00000051 	 loss = 0.0017(0.0230)
2023/09/19 16:38:07 - INFO - root -   Epoch: [288/400][40/346], lr: 0.00000051 	 loss = 0.0036(0.0613)
2023/09/19 16:38:50 - INFO - root -   Epoch: [288/400][60/346], lr: 0.00000051 	 loss = 0.0018(0.0523)
2023/09/19 16:39:51 - INFO - root -   Epoch: [288/400][80/346], lr: 0.00000051 	 loss = 0.0027(0.0498)
2023/09/19 16:40:34 - INFO - root -   Epoch: [288/400][100/346], lr: 0.00000051 	 loss = 0.0036(0.0515)
2023/09/19 16:41:34 - INFO - root -   Epoch: [288/400][120/346], lr: 0.00000051 	 loss = 0.0001(0.0545)
2023/09/19 16:42:18 - INFO - root -   Epoch: [288/400][140/346], lr: 0.00000051 	 loss = 0.0015(0.0587)
2023/09/19 16:43:18 - INFO - root -   Epoch: [288/400][160/346], lr: 0.00000051 	 loss = 0.0001(0.0848)
2023/09/19 16:44:01 - INFO - root -   Epoch: [288/400][180/346], lr: 0.00000051 	 loss = 0.0004(0.0904)
2023/09/19 16:45:02 - INFO - root -   Epoch: [288/400][200/346], lr: 0.00000051 	 loss = 0.0005(0.1117)
2023/09/19 16:45:45 - INFO - root -   Epoch: [288/400][220/346], lr: 0.00000051 	 loss = 0.1356(0.1129)
2023/09/19 16:46:45 - INFO - root -   Epoch: [288/400][240/346], lr: 0.00000051 	 loss = 0.0259(0.1125)
2023/09/19 16:47:28 - INFO - root -   Epoch: [288/400][260/346], lr: 0.00000051 	 loss = 0.0113(0.1057)
2023/09/19 16:48:29 - INFO - root -   Epoch: [288/400][280/346], lr: 0.00000051 	 loss = 0.2736(0.1089)
2023/09/19 16:49:12 - INFO - root -   Epoch: [288/400][300/346], lr: 0.00000051 	 loss = 0.0006(0.1160)
2023/09/19 16:50:13 - INFO - root -   Epoch: [288/400][320/346], lr: 0.00000051 	 loss = 0.0015(0.1231)
2023/09/19 16:50:54 - INFO - root -   Epoch: [288/400][340/346], lr: 0.00000051 	 loss = 0.0164(0.1259)
2023/09/19 16:50:58 - INFO - root -   Epoch: [288/400] 	 loss = 0.1290
2023/09/19 16:50:58 - INFO - root -   train_accuracy = 0.9408
2023/09/19 16:51:19 - INFO - root -   Epoch: [289/400][0/346], lr: 0.00000051 	 loss = 0.0005(0.0005)
2023/09/19 16:52:02 - INFO - root -   Epoch: [289/400][20/346], lr: 0.00000051 	 loss = 0.0305(0.1147)
2023/09/19 16:53:03 - INFO - root -   Epoch: [289/400][40/346], lr: 0.00000051 	 loss = 0.0026(0.1258)
2023/09/19 16:53:46 - INFO - root -   Epoch: [289/400][60/346], lr: 0.00000051 	 loss = 0.0041(0.0869)
2023/09/19 16:54:46 - INFO - root -   Epoch: [289/400][80/346], lr: 0.00000051 	 loss = 0.0044(0.1257)
2023/09/19 16:55:30 - INFO - root -   Epoch: [289/400][100/346], lr: 0.00000051 	 loss = 0.0084(0.1113)
2023/09/19 16:56:30 - INFO - root -   Epoch: [289/400][120/346], lr: 0.00000051 	 loss = 0.3404(0.1307)
2023/09/19 16:57:14 - INFO - root -   Epoch: [289/400][140/346], lr: 0.00000051 	 loss = 0.0278(0.1579)
2023/09/19 16:58:13 - INFO - root -   Epoch: [289/400][160/346], lr: 0.00000051 	 loss = 0.0001(0.1457)
2023/09/19 16:58:58 - INFO - root -   Epoch: [289/400][180/346], lr: 0.00000051 	 loss = 0.0156(0.1458)
2023/09/19 16:59:56 - INFO - root -   Epoch: [289/400][200/346], lr: 0.00000051 	 loss = 0.0013(0.1367)
2023/09/19 17:00:42 - INFO - root -   Epoch: [289/400][220/346], lr: 0.00000051 	 loss = 0.0460(0.1348)
2023/09/19 17:01:39 - INFO - root -   Epoch: [289/400][240/346], lr: 0.00000051 	 loss = 0.0031(0.1273)
2023/09/19 17:02:26 - INFO - root -   Epoch: [289/400][260/346], lr: 0.00000051 	 loss = 0.0494(0.1185)
2023/09/19 17:03:23 - INFO - root -   Epoch: [289/400][280/346], lr: 0.00000051 	 loss = 0.0004(0.1134)
2023/09/19 17:04:10 - INFO - root -   Epoch: [289/400][300/346], lr: 0.00000051 	 loss = 0.0003(0.1092)
2023/09/19 17:05:06 - INFO - root -   Epoch: [289/400][320/346], lr: 0.00000051 	 loss = 0.0020(0.1079)
2023/09/19 17:05:51 - INFO - root -   Epoch: [289/400][340/346], lr: 0.00000051 	 loss = 0.0221(0.1048)
2023/09/19 17:05:55 - INFO - root -   Epoch: [289/400] 	 loss = 0.1034
2023/09/19 17:09:41 - INFO - root -   precision = 0.7126
2023/09/19 17:09:41 - INFO - root -   eval_loss = 1.3854
2023/09/19 17:09:42 - INFO - root -   train_accuracy = 0.9653
2023/09/19 17:10:04 - INFO - root -   Epoch: [290/400][0/346], lr: 0.00000051 	 loss = 0.0060(0.0060)
2023/09/19 17:10:47 - INFO - root -   Epoch: [290/400][20/346], lr: 0.00000051 	 loss = 0.0004(0.0842)
2023/09/19 17:11:48 - INFO - root -   Epoch: [290/400][40/346], lr: 0.00000051 	 loss = 0.1546(0.1023)
2023/09/19 17:12:31 - INFO - root -   Epoch: [290/400][60/346], lr: 0.00000051 	 loss = 0.2259(0.0887)
2023/09/19 17:13:32 - INFO - root -   Epoch: [290/400][80/346], lr: 0.00000051 	 loss = 0.0072(0.1418)
2023/09/19 17:14:15 - INFO - root -   Epoch: [290/400][100/346], lr: 0.00000051 	 loss = 0.0013(0.1373)
2023/09/19 17:15:16 - INFO - root -   Epoch: [290/400][120/346], lr: 0.00000051 	 loss = 0.0094(0.1248)
2023/09/19 17:16:00 - INFO - root -   Epoch: [290/400][140/346], lr: 0.00000051 	 loss = 0.0008(0.1091)
2023/09/19 17:16:59 - INFO - root -   Epoch: [290/400][160/346], lr: 0.00000051 	 loss = 0.0015(0.1119)
2023/09/19 17:17:44 - INFO - root -   Epoch: [290/400][180/346], lr: 0.00000051 	 loss = 0.0060(0.1023)
2023/09/19 17:18:43 - INFO - root -   Epoch: [290/400][200/346], lr: 0.00000051 	 loss = 0.0012(0.0950)
2023/09/19 17:19:29 - INFO - root -   Epoch: [290/400][220/346], lr: 0.00000051 	 loss = 0.0054(0.0965)
2023/09/19 17:20:27 - INFO - root -   Epoch: [290/400][240/346], lr: 0.00000051 	 loss = 0.0001(0.0928)
2023/09/19 17:21:13 - INFO - root -   Epoch: [290/400][260/346], lr: 0.00000051 	 loss = 0.0111(0.0871)
2023/09/19 17:22:10 - INFO - root -   Epoch: [290/400][280/346], lr: 0.00000051 	 loss = 0.0001(0.0838)
2023/09/19 17:22:57 - INFO - root -   Epoch: [290/400][300/346], lr: 0.00000051 	 loss = 0.0009(0.0801)
2023/09/19 17:23:54 - INFO - root -   Epoch: [290/400][320/346], lr: 0.00000051 	 loss = 0.0001(0.0766)
2023/09/19 17:24:39 - INFO - root -   Epoch: [290/400][340/346], lr: 0.00000051 	 loss = 0.0626(0.0744)
2023/09/19 17:24:43 - INFO - root -   Epoch: [290/400] 	 loss = 0.0734
2023/09/19 17:24:43 - INFO - root -   train_accuracy = 0.9725
2023/09/19 17:25:05 - INFO - root -   Epoch: [291/400][0/346], lr: 0.00000052 	 loss = 0.0020(0.0020)
2023/09/19 17:25:48 - INFO - root -   Epoch: [291/400][20/346], lr: 0.00000052 	 loss = 0.0024(0.0133)
2023/09/19 17:26:49 - INFO - root -   Epoch: [291/400][40/346], lr: 0.00000052 	 loss = 0.0161(0.0121)
2023/09/19 17:27:33 - INFO - root -   Epoch: [291/400][60/346], lr: 0.00000052 	 loss = 0.0012(0.0116)
2023/09/19 17:28:34 - INFO - root -   Epoch: [291/400][80/346], lr: 0.00000052 	 loss = 0.0003(0.0147)
2023/09/19 17:29:18 - INFO - root -   Epoch: [291/400][100/346], lr: 0.00000052 	 loss = 0.3689(0.0363)
2023/09/19 17:30:18 - INFO - root -   Epoch: [291/400][120/346], lr: 0.00000052 	 loss = 0.0002(0.0442)
2023/09/19 17:31:02 - INFO - root -   Epoch: [291/400][140/346], lr: 0.00000052 	 loss = 0.0019(0.0434)
2023/09/19 17:32:03 - INFO - root -   Epoch: [291/400][160/346], lr: 0.00000052 	 loss = 0.0003(0.0638)
2023/09/19 17:32:47 - INFO - root -   Epoch: [291/400][180/346], lr: 0.00000052 	 loss = 0.0309(0.0695)
2023/09/19 17:33:47 - INFO - root -   Epoch: [291/400][200/346], lr: 0.00000052 	 loss = 0.0019(0.0695)
2023/09/19 17:34:31 - INFO - root -   Epoch: [291/400][220/346], lr: 0.00000052 	 loss = 0.0007(0.0702)
2023/09/19 17:35:32 - INFO - root -   Epoch: [291/400][240/346], lr: 0.00000052 	 loss = 0.0006(0.0684)
2023/09/19 17:36:16 - INFO - root -   Epoch: [291/400][260/346], lr: 0.00000052 	 loss = 0.0038(0.0698)
2023/09/19 17:37:16 - INFO - root -   Epoch: [291/400][280/346], lr: 0.00000052 	 loss = 0.0005(0.0747)
2023/09/19 17:38:01 - INFO - root -   Epoch: [291/400][300/346], lr: 0.00000052 	 loss = 0.0002(0.0754)
2023/09/19 17:39:00 - INFO - root -   Epoch: [291/400][320/346], lr: 0.00000052 	 loss = 0.0000(0.0727)
2023/09/19 17:39:42 - INFO - root -   Epoch: [291/400][340/346], lr: 0.00000052 	 loss = 0.0073(0.0698)
2023/09/19 17:39:46 - INFO - root -   Epoch: [291/400] 	 loss = 0.0709
2023/09/19 17:39:46 - INFO - root -   train_accuracy = 0.9682
2023/09/19 17:40:08 - INFO - root -   Epoch: [292/400][0/346], lr: 0.00000052 	 loss = 0.7240(0.7240)
2023/09/19 17:40:51 - INFO - root -   Epoch: [292/400][20/346], lr: 0.00000052 	 loss = 0.0025(0.0825)
2023/09/19 17:41:52 - INFO - root -   Epoch: [292/400][40/346], lr: 0.00000052 	 loss = 0.0004(0.0814)
2023/09/19 17:42:36 - INFO - root -   Epoch: [292/400][60/346], lr: 0.00000052 	 loss = 0.0252(0.0634)
2023/09/19 17:43:36 - INFO - root -   Epoch: [292/400][80/346], lr: 0.00000052 	 loss = 0.0027(0.0738)
2023/09/19 17:44:20 - INFO - root -   Epoch: [292/400][100/346], lr: 0.00000052 	 loss = 0.0010(0.0989)
2023/09/19 17:45:20 - INFO - root -   Epoch: [292/400][120/346], lr: 0.00000052 	 loss = 0.0022(0.1032)
2023/09/19 17:46:04 - INFO - root -   Epoch: [292/400][140/346], lr: 0.00000052 	 loss = 0.0031(0.0915)
2023/09/19 17:47:04 - INFO - root -   Epoch: [292/400][160/346], lr: 0.00000052 	 loss = 0.0002(0.1061)
2023/09/19 17:47:49 - INFO - root -   Epoch: [292/400][180/346], lr: 0.00000052 	 loss = 0.0005(0.1266)
2023/09/19 17:48:47 - INFO - root -   Epoch: [292/400][200/346], lr: 0.00000052 	 loss = 0.0014(0.1167)
2023/09/19 17:49:33 - INFO - root -   Epoch: [292/400][220/346], lr: 0.00000052 	 loss = 0.0208(0.1150)
2023/09/19 17:50:31 - INFO - root -   Epoch: [292/400][240/346], lr: 0.00000052 	 loss = 0.0003(0.1299)
2023/09/19 17:51:17 - INFO - root -   Epoch: [292/400][260/346], lr: 0.00000052 	 loss = 0.0012(0.1235)
2023/09/19 17:52:15 - INFO - root -   Epoch: [292/400][280/346], lr: 0.00000052 	 loss = 0.3423(0.1265)
2023/09/19 17:53:01 - INFO - root -   Epoch: [292/400][300/346], lr: 0.00000052 	 loss = 0.0015(0.1225)
2023/09/19 17:53:58 - INFO - root -   Epoch: [292/400][320/346], lr: 0.00000052 	 loss = 0.0060(0.1201)
2023/09/19 17:54:44 - INFO - root -   Epoch: [292/400][340/346], lr: 0.00000052 	 loss = 0.1341(0.1255)
2023/09/19 17:54:47 - INFO - root -   Epoch: [292/400] 	 loss = 0.1301
2023/09/19 17:54:47 - INFO - root -   train_accuracy = 0.9422
2023/09/19 17:55:09 - INFO - root -   Epoch: [293/400][0/346], lr: 0.00000052 	 loss = 0.0019(0.0019)
2023/09/19 17:55:52 - INFO - root -   Epoch: [293/400][20/346], lr: 0.00000052 	 loss = 0.0006(0.1196)
2023/09/19 17:56:53 - INFO - root -   Epoch: [293/400][40/346], lr: 0.00000052 	 loss = 0.0107(0.1175)
2023/09/19 17:57:36 - INFO - root -   Epoch: [293/400][60/346], lr: 0.00000052 	 loss = 0.0066(0.0850)
2023/09/19 17:58:37 - INFO - root -   Epoch: [293/400][80/346], lr: 0.00000052 	 loss = 0.0961(0.0816)
2023/09/19 17:59:20 - INFO - root -   Epoch: [293/400][100/346], lr: 0.00000052 	 loss = 0.0087(0.0989)
2023/09/19 18:00:21 - INFO - root -   Epoch: [293/400][120/346], lr: 0.00000052 	 loss = 0.0008(0.1184)
2023/09/19 18:01:04 - INFO - root -   Epoch: [293/400][140/346], lr: 0.00000052 	 loss = 1.7991(0.1311)
2023/09/19 18:02:05 - INFO - root -   Epoch: [293/400][160/346], lr: 0.00000052 	 loss = 0.0015(0.1278)
2023/09/19 18:02:48 - INFO - root -   Epoch: [293/400][180/346], lr: 0.00000052 	 loss = 0.0005(0.1304)
2023/09/19 18:03:48 - INFO - root -   Epoch: [293/400][200/346], lr: 0.00000052 	 loss = 0.0001(0.1185)
2023/09/19 18:04:31 - INFO - root -   Epoch: [293/400][220/346], lr: 0.00000052 	 loss = 0.0001(0.1308)
2023/09/19 18:05:32 - INFO - root -   Epoch: [293/400][240/346], lr: 0.00000052 	 loss = 0.0048(0.1243)
2023/09/19 18:06:15 - INFO - root -   Epoch: [293/400][260/346], lr: 0.00000052 	 loss = 0.6472(0.1185)
2023/09/19 18:07:16 - INFO - root -   Epoch: [293/400][280/346], lr: 0.00000052 	 loss = 0.0086(0.1199)
2023/09/19 18:07:59 - INFO - root -   Epoch: [293/400][300/346], lr: 0.00000052 	 loss = 0.0200(0.1162)
2023/09/19 18:08:59 - INFO - root -   Epoch: [293/400][320/346], lr: 0.00000052 	 loss = 0.0002(0.1140)
2023/09/19 18:09:40 - INFO - root -   Epoch: [293/400][340/346], lr: 0.00000052 	 loss = 0.0581(0.1104)
2023/09/19 18:09:44 - INFO - root -   Epoch: [293/400] 	 loss = 0.1104
2023/09/19 18:09:44 - INFO - root -   train_accuracy = 0.9538
2023/09/19 18:10:05 - INFO - root -   Epoch: [294/400][0/346], lr: 0.00000052 	 loss = 0.8911(0.8911)
2023/09/19 18:10:48 - INFO - root -   Epoch: [294/400][20/346], lr: 0.00000052 	 loss = 0.0004(0.0963)
2023/09/19 18:11:49 - INFO - root -   Epoch: [294/400][40/346], lr: 0.00000052 	 loss = 1.2949(0.1495)
2023/09/19 18:12:32 - INFO - root -   Epoch: [294/400][60/346], lr: 0.00000052 	 loss = 0.0068(0.1046)
2023/09/19 18:13:32 - INFO - root -   Epoch: [294/400][80/346], lr: 0.00000052 	 loss = 0.1187(0.1016)
2023/09/19 18:14:15 - INFO - root -   Epoch: [294/400][100/346], lr: 0.00000052 	 loss = 0.0018(0.0986)
2023/09/19 18:15:16 - INFO - root -   Epoch: [294/400][120/346], lr: 0.00000052 	 loss = 0.0026(0.0909)
2023/09/19 18:15:59 - INFO - root -   Epoch: [294/400][140/346], lr: 0.00000052 	 loss = 0.0175(0.0907)
2023/09/19 18:17:00 - INFO - root -   Epoch: [294/400][160/346], lr: 0.00000052 	 loss = 0.0031(0.0886)
2023/09/19 18:17:43 - INFO - root -   Epoch: [294/400][180/346], lr: 0.00000052 	 loss = 1.3476(0.1029)
2023/09/19 18:18:43 - INFO - root -   Epoch: [294/400][200/346], lr: 0.00000052 	 loss = 0.0058(0.1010)
2023/09/19 18:19:26 - INFO - root -   Epoch: [294/400][220/346], lr: 0.00000052 	 loss = 0.0001(0.1013)
2023/09/19 18:20:27 - INFO - root -   Epoch: [294/400][240/346], lr: 0.00000052 	 loss = 0.0534(0.1013)
2023/09/19 18:21:10 - INFO - root -   Epoch: [294/400][260/346], lr: 0.00000052 	 loss = 0.0027(0.1041)
2023/09/19 18:22:10 - INFO - root -   Epoch: [294/400][280/346], lr: 0.00000052 	 loss = 0.0020(0.1027)
2023/09/19 18:22:53 - INFO - root -   Epoch: [294/400][300/346], lr: 0.00000052 	 loss = 0.0032(0.0981)
2023/09/19 18:23:53 - INFO - root -   Epoch: [294/400][320/346], lr: 0.00000052 	 loss = 0.0091(0.0941)
2023/09/19 18:24:35 - INFO - root -   Epoch: [294/400][340/346], lr: 0.00000052 	 loss = 0.0016(0.0947)
2023/09/19 18:24:39 - INFO - root -   Epoch: [294/400] 	 loss = 0.0962
2023/09/19 18:28:26 - INFO - root -   precision = 0.6552
2023/09/19 18:28:26 - INFO - root -   eval_loss = 1.4332
2023/09/19 18:28:27 - INFO - root -   train_accuracy = 0.9668
2023/09/19 18:28:49 - INFO - root -   Epoch: [295/400][0/346], lr: 0.00000052 	 loss = 0.0087(0.0087)
2023/09/19 18:29:32 - INFO - root -   Epoch: [295/400][20/346], lr: 0.00000052 	 loss = 0.0004(0.0266)
2023/09/19 18:30:32 - INFO - root -   Epoch: [295/400][40/346], lr: 0.00000052 	 loss = 0.0280(0.0625)
2023/09/19 18:31:15 - INFO - root -   Epoch: [295/400][60/346], lr: 0.00000052 	 loss = 0.4130(0.1049)
2023/09/19 18:32:16 - INFO - root -   Epoch: [295/400][80/346], lr: 0.00000052 	 loss = 0.0001(0.0980)
2023/09/19 18:32:59 - INFO - root -   Epoch: [295/400][100/346], lr: 0.00000052 	 loss = 0.0003(0.0952)
2023/09/19 18:33:59 - INFO - root -   Epoch: [295/400][120/346], lr: 0.00000052 	 loss = 0.0014(0.1471)
2023/09/19 18:34:42 - INFO - root -   Epoch: [295/400][140/346], lr: 0.00000052 	 loss = 0.0029(0.1729)
2023/09/19 18:35:43 - INFO - root -   Epoch: [295/400][160/346], lr: 0.00000052 	 loss = 0.0061(0.1754)
2023/09/19 18:36:26 - INFO - root -   Epoch: [295/400][180/346], lr: 0.00000052 	 loss = 1.3738(0.1800)
2023/09/19 18:37:26 - INFO - root -   Epoch: [295/400][200/346], lr: 0.00000052 	 loss = 0.0000(0.1917)
2023/09/19 18:38:10 - INFO - root -   Epoch: [295/400][220/346], lr: 0.00000052 	 loss = 0.0002(0.2221)
2023/09/19 18:39:10 - INFO - root -   Epoch: [295/400][240/346], lr: 0.00000052 	 loss = 0.0008(0.2126)
2023/09/19 18:39:53 - INFO - root -   Epoch: [295/400][260/346], lr: 0.00000052 	 loss = 0.0029(0.2014)
2023/09/19 18:40:53 - INFO - root -   Epoch: [295/400][280/346], lr: 0.00000052 	 loss = 0.0004(0.1938)
2023/09/19 18:41:37 - INFO - root -   Epoch: [295/400][300/346], lr: 0.00000052 	 loss = 0.0745(0.1846)
2023/09/19 18:42:37 - INFO - root -   Epoch: [295/400][320/346], lr: 0.00000052 	 loss = 0.0013(0.1756)
2023/09/19 18:43:19 - INFO - root -   Epoch: [295/400][340/346], lr: 0.00000052 	 loss = 0.1244(0.1731)
2023/09/19 18:43:24 - INFO - root -   Epoch: [295/400] 	 loss = 0.1821
2023/09/19 18:43:24 - INFO - root -   train_accuracy = 0.9480
2023/09/19 18:43:45 - INFO - root -   Epoch: [296/400][0/346], lr: 0.00000052 	 loss = 0.0042(0.0042)
2023/09/19 18:44:28 - INFO - root -   Epoch: [296/400][20/346], lr: 0.00000052 	 loss = 0.0031(0.1574)
2023/09/19 18:45:29 - INFO - root -   Epoch: [296/400][40/346], lr: 0.00000052 	 loss = 0.0272(0.1327)
2023/09/19 18:46:12 - INFO - root -   Epoch: [296/400][60/346], lr: 0.00000052 	 loss = 0.0109(0.1273)
2023/09/19 18:47:12 - INFO - root -   Epoch: [296/400][80/346], lr: 0.00000052 	 loss = 0.1397(0.1134)
2023/09/19 18:47:56 - INFO - root -   Epoch: [296/400][100/346], lr: 0.00000052 	 loss = 0.0064(0.1156)
2023/09/19 18:48:56 - INFO - root -   Epoch: [296/400][120/346], lr: 0.00000052 	 loss = 0.0005(0.1486)
2023/09/19 18:49:39 - INFO - root -   Epoch: [296/400][140/346], lr: 0.00000052 	 loss = 0.0009(0.1475)
2023/09/19 18:50:39 - INFO - root -   Epoch: [296/400][160/346], lr: 0.00000052 	 loss = 0.0134(0.1358)
2023/09/19 18:51:23 - INFO - root -   Epoch: [296/400][180/346], lr: 0.00000052 	 loss = 0.0012(0.1346)
2023/09/19 18:52:22 - INFO - root -   Epoch: [296/400][200/346], lr: 0.00000052 	 loss = 0.0001(0.1234)
2023/09/19 18:53:07 - INFO - root -   Epoch: [296/400][220/346], lr: 0.00000052 	 loss = 0.0082(0.1233)
2023/09/19 18:54:05 - INFO - root -   Epoch: [296/400][240/346], lr: 0.00000052 	 loss = 0.0097(0.1147)
2023/09/19 18:54:51 - INFO - root -   Epoch: [296/400][260/346], lr: 0.00000052 	 loss = 0.0162(0.1107)
2023/09/19 18:55:48 - INFO - root -   Epoch: [296/400][280/346], lr: 0.00000052 	 loss = 0.0001(0.1099)
2023/09/19 18:56:34 - INFO - root -   Epoch: [296/400][300/346], lr: 0.00000052 	 loss = 0.0001(0.1059)
2023/09/19 18:57:31 - INFO - root -   Epoch: [296/400][320/346], lr: 0.00000052 	 loss = 0.0025(0.1008)
2023/09/19 18:58:15 - INFO - root -   Epoch: [296/400][340/346], lr: 0.00000052 	 loss = 0.0009(0.0993)
2023/09/19 18:58:19 - INFO - root -   Epoch: [296/400] 	 loss = 0.0978
2023/09/19 18:58:19 - INFO - root -   train_accuracy = 0.9523
2023/09/19 18:58:41 - INFO - root -   Epoch: [297/400][0/346], lr: 0.00000052 	 loss = 0.0147(0.0147)
2023/09/19 18:59:24 - INFO - root -   Epoch: [297/400][20/346], lr: 0.00000052 	 loss = 0.0001(0.1125)
2023/09/19 19:00:24 - INFO - root -   Epoch: [297/400][40/346], lr: 0.00000052 	 loss = 0.0329(0.0676)
2023/09/19 19:01:07 - INFO - root -   Epoch: [297/400][60/346], lr: 0.00000052 	 loss = 0.0004(0.0486)
2023/09/19 19:02:08 - INFO - root -   Epoch: [297/400][80/346], lr: 0.00000052 	 loss = 0.0014(0.0567)
2023/09/19 19:02:51 - INFO - root -   Epoch: [297/400][100/346], lr: 0.00000052 	 loss = 0.0132(0.0521)
2023/09/19 19:03:52 - INFO - root -   Epoch: [297/400][120/346], lr: 0.00000052 	 loss = 0.0044(0.0682)
2023/09/19 19:04:35 - INFO - root -   Epoch: [297/400][140/346], lr: 0.00000052 	 loss = 1.0499(0.0758)
2023/09/19 19:05:36 - INFO - root -   Epoch: [297/400][160/346], lr: 0.00000052 	 loss = 0.0201(0.0796)
2023/09/19 19:06:19 - INFO - root -   Epoch: [297/400][180/346], lr: 0.00000052 	 loss = 0.0599(0.0838)
2023/09/19 19:07:19 - INFO - root -   Epoch: [297/400][200/346], lr: 0.00000052 	 loss = 0.0001(0.0781)
2023/09/19 19:08:04 - INFO - root -   Epoch: [297/400][220/346], lr: 0.00000052 	 loss = 0.0002(0.0834)
2023/09/19 19:09:03 - INFO - root -   Epoch: [297/400][240/346], lr: 0.00000052 	 loss = 0.0020(0.0837)
2023/09/19 19:09:47 - INFO - root -   Epoch: [297/400][260/346], lr: 0.00000052 	 loss = 0.0005(0.0868)
2023/09/19 19:10:47 - INFO - root -   Epoch: [297/400][280/346], lr: 0.00000052 	 loss = 0.0002(0.0962)
2023/09/19 19:11:31 - INFO - root -   Epoch: [297/400][300/346], lr: 0.00000052 	 loss = 0.0014(0.0937)
2023/09/19 19:12:31 - INFO - root -   Epoch: [297/400][320/346], lr: 0.00000052 	 loss = 0.0051(0.0889)
2023/09/19 19:13:14 - INFO - root -   Epoch: [297/400][340/346], lr: 0.00000052 	 loss = 0.0087(0.0908)
2023/09/19 19:13:18 - INFO - root -   Epoch: [297/400] 	 loss = 0.0937
2023/09/19 19:13:18 - INFO - root -   train_accuracy = 0.9624
2023/09/19 19:13:39 - INFO - root -   Epoch: [298/400][0/346], lr: 0.00000053 	 loss = 0.0140(0.0140)
2023/09/19 19:14:23 - INFO - root -   Epoch: [298/400][20/346], lr: 0.00000053 	 loss = 0.0012(0.0353)
2023/09/19 19:15:23 - INFO - root -   Epoch: [298/400][40/346], lr: 0.00000053 	 loss = 0.0011(0.0372)
2023/09/19 19:16:06 - INFO - root -   Epoch: [298/400][60/346], lr: 0.00000053 	 loss = 0.0181(0.0286)
2023/09/19 19:17:07 - INFO - root -   Epoch: [298/400][80/346], lr: 0.00000053 	 loss = 0.0015(0.0285)
2023/09/19 19:17:50 - INFO - root -   Epoch: [298/400][100/346], lr: 0.00000053 	 loss = 0.0138(0.0402)
2023/09/19 19:18:50 - INFO - root -   Epoch: [298/400][120/346], lr: 0.00000053 	 loss = 0.0003(0.0366)
2023/09/19 19:19:34 - INFO - root -   Epoch: [298/400][140/346], lr: 0.00000053 	 loss = 0.0004(0.0321)
2023/09/19 19:20:33 - INFO - root -   Epoch: [298/400][160/346], lr: 0.00000053 	 loss = 0.0033(0.0365)
2023/09/19 19:21:18 - INFO - root -   Epoch: [298/400][180/346], lr: 0.00000053 	 loss = 0.0551(0.0482)
2023/09/19 19:22:17 - INFO - root -   Epoch: [298/400][200/346], lr: 0.00000053 	 loss = 0.0051(0.0472)
2023/09/19 19:23:02 - INFO - root -   Epoch: [298/400][220/346], lr: 0.00000053 	 loss = 0.0048(0.0549)
2023/09/19 19:24:00 - INFO - root -   Epoch: [298/400][240/346], lr: 0.00000053 	 loss = 0.0004(0.0573)
2023/09/19 19:24:46 - INFO - root -   Epoch: [298/400][260/346], lr: 0.00000053 	 loss = 0.1044(0.0654)
2023/09/19 19:25:44 - INFO - root -   Epoch: [298/400][280/346], lr: 0.00000053 	 loss = 0.0007(0.0751)
2023/09/19 19:26:30 - INFO - root -   Epoch: [298/400][300/346], lr: 0.00000053 	 loss = 0.0022(0.0724)
2023/09/19 19:27:27 - INFO - root -   Epoch: [298/400][320/346], lr: 0.00000053 	 loss = 0.0000(0.0691)
2023/09/19 19:28:12 - INFO - root -   Epoch: [298/400][340/346], lr: 0.00000053 	 loss = 0.0003(0.0729)
2023/09/19 19:28:16 - INFO - root -   Epoch: [298/400] 	 loss = 0.0718
2023/09/19 19:28:16 - INFO - root -   train_accuracy = 0.9740
2023/09/19 19:28:38 - INFO - root -   Epoch: [299/400][0/346], lr: 0.00000053 	 loss = 0.0153(0.0153)
2023/09/19 19:29:21 - INFO - root -   Epoch: [299/400][20/346], lr: 0.00000053 	 loss = 0.0015(0.0044)
2023/09/19 19:30:22 - INFO - root -   Epoch: [299/400][40/346], lr: 0.00000053 	 loss = 0.0008(0.0338)
2023/09/19 19:31:05 - INFO - root -   Epoch: [299/400][60/346], lr: 0.00000053 	 loss = 0.0007(0.1319)
2023/09/19 19:32:05 - INFO - root -   Epoch: [299/400][80/346], lr: 0.00000053 	 loss = 0.2491(0.1118)
2023/09/19 19:32:49 - INFO - root -   Epoch: [299/400][100/346], lr: 0.00000053 	 loss = 0.2289(0.1071)
2023/09/19 19:33:49 - INFO - root -   Epoch: [299/400][120/346], lr: 0.00000053 	 loss = 0.0520(0.1032)
2023/09/19 19:34:32 - INFO - root -   Epoch: [299/400][140/346], lr: 0.00000053 	 loss = 0.0046(0.1120)
2023/09/19 19:35:32 - INFO - root -   Epoch: [299/400][160/346], lr: 0.00000053 	 loss = 0.1322(0.1083)
2023/09/19 19:36:16 - INFO - root -   Epoch: [299/400][180/346], lr: 0.00000053 	 loss = 0.1388(0.1057)
2023/09/19 19:37:16 - INFO - root -   Epoch: [299/400][200/346], lr: 0.00000053 	 loss = 0.0107(0.1018)
2023/09/19 19:37:59 - INFO - root -   Epoch: [299/400][220/346], lr: 0.00000053 	 loss = 0.5991(0.1052)
2023/09/19 19:39:00 - INFO - root -   Epoch: [299/400][240/346], lr: 0.00000053 	 loss = 0.0032(0.1000)
2023/09/19 19:39:42 - INFO - root -   Epoch: [299/400][260/346], lr: 0.00000053 	 loss = 0.1418(0.0995)
2023/09/19 19:40:43 - INFO - root -   Epoch: [299/400][280/346], lr: 0.00000053 	 loss = 0.0037(0.1164)
2023/09/19 19:41:26 - INFO - root -   Epoch: [299/400][300/346], lr: 0.00000053 	 loss = 0.0020(0.1114)
2023/09/19 19:42:26 - INFO - root -   Epoch: [299/400][320/346], lr: 0.00000053 	 loss = 0.0003(0.1059)
2023/09/19 19:43:08 - INFO - root -   Epoch: [299/400][340/346], lr: 0.00000053 	 loss = 0.0015(0.1015)
2023/09/19 19:43:12 - INFO - root -   Epoch: [299/400] 	 loss = 0.1000
2023/09/19 19:47:03 - INFO - root -   precision = 0.6667
2023/09/19 19:47:03 - INFO - root -   eval_loss = 1.5077
2023/09/19 19:47:04 - INFO - root -   train_accuracy = 0.9624
2023/09/19 19:47:25 - INFO - root -   Epoch: [300/400][0/346], lr: 0.00000053 	 loss = 0.0145(0.0145)
2023/09/19 19:48:08 - INFO - root -   Epoch: [300/400][20/346], lr: 0.00000053 	 loss = 0.0001(0.0908)
2023/09/19 19:49:09 - INFO - root -   Epoch: [300/400][40/346], lr: 0.00000053 	 loss = 0.0076(0.0676)
2023/09/19 19:49:52 - INFO - root -   Epoch: [300/400][60/346], lr: 0.00000053 	 loss = 0.0053(0.0570)
2023/09/19 19:50:53 - INFO - root -   Epoch: [300/400][80/346], lr: 0.00000053 	 loss = 0.0010(0.0462)
2023/09/19 19:51:36 - INFO - root -   Epoch: [300/400][100/346], lr: 0.00000053 	 loss = 0.0017(0.0434)
2023/09/19 19:52:36 - INFO - root -   Epoch: [300/400][120/346], lr: 0.00000053 	 loss = 0.0173(0.0403)
2023/09/19 19:53:21 - INFO - root -   Epoch: [300/400][140/346], lr: 0.00000053 	 loss = 0.0005(0.0377)
2023/09/19 19:54:19 - INFO - root -   Epoch: [300/400][160/346], lr: 0.00000053 	 loss = 0.0023(0.0339)
2023/09/19 19:55:05 - INFO - root -   Epoch: [300/400][180/346], lr: 0.00000053 	 loss = 0.0616(0.0473)
2023/09/19 19:56:03 - INFO - root -   Epoch: [300/400][200/346], lr: 0.00000053 	 loss = 0.0041(0.0437)
2023/09/19 19:56:48 - INFO - root -   Epoch: [300/400][220/346], lr: 0.00000053 	 loss = 0.0003(0.0436)
2023/09/19 19:57:46 - INFO - root -   Epoch: [300/400][240/346], lr: 0.00000053 	 loss = 0.0000(0.0460)
2023/09/19 19:58:32 - INFO - root -   Epoch: [300/400][260/346], lr: 0.00000053 	 loss = 0.0014(0.0486)
2023/09/19 19:59:29 - INFO - root -   Epoch: [300/400][280/346], lr: 0.00000053 	 loss = 0.0002(0.0541)
2023/09/19 20:00:17 - INFO - root -   Epoch: [300/400][300/346], lr: 0.00000053 	 loss = 0.0248(0.0600)
2023/09/19 20:01:13 - INFO - root -   Epoch: [300/400][320/346], lr: 0.00000053 	 loss = 0.0001(0.0611)
2023/09/19 20:01:58 - INFO - root -   Epoch: [300/400][340/346], lr: 0.00000053 	 loss = 0.0056(0.0704)
2023/09/19 20:02:02 - INFO - root -   Epoch: [300/400] 	 loss = 0.0700
2023/09/19 20:02:02 - INFO - root -   train_accuracy = 0.9783
2023/09/19 20:02:23 - INFO - root -   Epoch: [301/400][0/346], lr: 0.00000053 	 loss = 0.0032(0.0032)
2023/09/19 20:03:06 - INFO - root -   Epoch: [301/400][20/346], lr: 0.00000053 	 loss = 0.0001(0.0144)
2023/09/19 20:04:06 - INFO - root -   Epoch: [301/400][40/346], lr: 0.00000053 	 loss = 0.0007(0.0478)
2023/09/19 20:04:50 - INFO - root -   Epoch: [301/400][60/346], lr: 0.00000053 	 loss = 0.2769(0.0400)
2023/09/19 20:05:49 - INFO - root -   Epoch: [301/400][80/346], lr: 0.00000053 	 loss = 0.0061(0.0445)
2023/09/19 20:06:33 - INFO - root -   Epoch: [301/400][100/346], lr: 0.00000053 	 loss = 0.0098(0.0584)
2023/09/19 20:07:33 - INFO - root -   Epoch: [301/400][120/346], lr: 0.00000053 	 loss = 0.0010(0.0691)
2023/09/19 20:08:17 - INFO - root -   Epoch: [301/400][140/346], lr: 0.00000053 	 loss = 0.0242(0.0778)
2023/09/19 20:09:17 - INFO - root -   Epoch: [301/400][160/346], lr: 0.00000053 	 loss = 0.0128(0.0902)
2023/09/19 20:10:00 - INFO - root -   Epoch: [301/400][180/346], lr: 0.00000053 	 loss = 0.0008(0.0862)
2023/09/19 20:11:01 - INFO - root -   Epoch: [301/400][200/346], lr: 0.00000053 	 loss = 0.0001(0.0811)
2023/09/19 20:11:44 - INFO - root -   Epoch: [301/400][220/346], lr: 0.00000053 	 loss = 0.0012(0.0765)
2023/09/19 20:12:44 - INFO - root -   Epoch: [301/400][240/346], lr: 0.00000053 	 loss = 0.0003(0.0746)
2023/09/19 20:13:27 - INFO - root -   Epoch: [301/400][260/346], lr: 0.00000053 	 loss = 0.0135(0.0751)
2023/09/19 20:14:28 - INFO - root -   Epoch: [301/400][280/346], lr: 0.00000053 	 loss = 0.0000(0.0749)
2023/09/19 20:15:11 - INFO - root -   Epoch: [301/400][300/346], lr: 0.00000053 	 loss = 0.0002(0.0753)
2023/09/19 20:16:11 - INFO - root -   Epoch: [301/400][320/346], lr: 0.00000053 	 loss = 0.0433(0.0740)
2023/09/19 20:16:53 - INFO - root -   Epoch: [301/400][340/346], lr: 0.00000053 	 loss = 0.0200(0.0786)
2023/09/19 20:16:58 - INFO - root -   Epoch: [301/400] 	 loss = 0.0777
2023/09/19 20:16:58 - INFO - root -   train_accuracy = 0.9711
2023/09/19 20:17:19 - INFO - root -   Epoch: [302/400][0/346], lr: 0.00000053 	 loss = 0.4300(0.4300)
2023/09/19 20:18:02 - INFO - root -   Epoch: [302/400][20/346], lr: 0.00000053 	 loss = 0.0002(0.2658)
2023/09/19 20:19:03 - INFO - root -   Epoch: [302/400][40/346], lr: 0.00000053 	 loss = 0.0052(0.1884)
2023/09/19 20:19:46 - INFO - root -   Epoch: [302/400][60/346], lr: 0.00000053 	 loss = 0.1058(0.1362)
2023/09/19 20:20:47 - INFO - root -   Epoch: [302/400][80/346], lr: 0.00000053 	 loss = 0.0224(0.1151)
2023/09/19 20:21:30 - INFO - root -   Epoch: [302/400][100/346], lr: 0.00000053 	 loss = 0.0022(0.1377)
2023/09/19 20:22:30 - INFO - root -   Epoch: [302/400][120/346], lr: 0.00000053 	 loss = 0.0003(0.1319)
2023/09/19 20:23:14 - INFO - root -   Epoch: [302/400][140/346], lr: 0.00000053 	 loss = 0.0032(0.1152)
2023/09/19 20:24:14 - INFO - root -   Epoch: [302/400][160/346], lr: 0.00000053 	 loss = 0.0011(0.1120)
2023/09/19 20:24:58 - INFO - root -   Epoch: [302/400][180/346], lr: 0.00000053 	 loss = 0.0057(0.1181)
2023/09/19 20:25:57 - INFO - root -   Epoch: [302/400][200/346], lr: 0.00000053 	 loss = 0.0001(0.1132)
2023/09/19 20:26:41 - INFO - root -   Epoch: [302/400][220/346], lr: 0.00000053 	 loss = 0.0007(0.1041)
2023/09/19 20:27:40 - INFO - root -   Epoch: [302/400][240/346], lr: 0.00000053 	 loss = 0.0028(0.0995)
2023/09/19 20:28:24 - INFO - root -   Epoch: [302/400][260/346], lr: 0.00000053 	 loss = 0.0021(0.0991)
2023/09/19 20:29:24 - INFO - root -   Epoch: [302/400][280/346], lr: 0.00000053 	 loss = 0.0016(0.0944)
2023/09/19 20:30:08 - INFO - root -   Epoch: [302/400][300/346], lr: 0.00000053 	 loss = 0.0884(0.0981)
2023/09/19 20:31:07 - INFO - root -   Epoch: [302/400][320/346], lr: 0.00000053 	 loss = 0.0001(0.0926)
2023/09/19 20:31:51 - INFO - root -   Epoch: [302/400][340/346], lr: 0.00000053 	 loss = 0.0150(0.0881)
2023/09/19 20:31:56 - INFO - root -   Epoch: [302/400] 	 loss = 0.0872
2023/09/19 20:31:56 - INFO - root -   train_accuracy = 0.9711
2023/09/19 20:32:17 - INFO - root -   Epoch: [303/400][0/346], lr: 0.00000053 	 loss = 0.0438(0.0438)
2023/09/19 20:33:00 - INFO - root -   Epoch: [303/400][20/346], lr: 0.00000053 	 loss = 0.0001(0.1107)
2023/09/19 20:34:01 - INFO - root -   Epoch: [303/400][40/346], lr: 0.00000053 	 loss = 0.0340(0.0688)
2023/09/19 20:34:44 - INFO - root -   Epoch: [303/400][60/346], lr: 0.00000053 	 loss = 0.0002(0.0470)
2023/09/19 20:35:45 - INFO - root -   Epoch: [303/400][80/346], lr: 0.00000053 	 loss = 0.0021(0.0456)
2023/09/19 20:36:28 - INFO - root -   Epoch: [303/400][100/346], lr: 0.00000053 	 loss = 0.0018(0.0551)
2023/09/19 20:37:29 - INFO - root -   Epoch: [303/400][120/346], lr: 0.00000053 	 loss = 0.0014(0.0849)
2023/09/19 20:38:12 - INFO - root -   Epoch: [303/400][140/346], lr: 0.00000053 	 loss = 0.6656(0.0950)
2023/09/19 20:39:13 - INFO - root -   Epoch: [303/400][160/346], lr: 0.00000053 	 loss = 0.0089(0.1186)
2023/09/19 20:39:56 - INFO - root -   Epoch: [303/400][180/346], lr: 0.00000053 	 loss = 0.0001(0.1126)
2023/09/19 20:40:56 - INFO - root -   Epoch: [303/400][200/346], lr: 0.00000053 	 loss = 0.0001(0.1118)
2023/09/19 20:41:39 - INFO - root -   Epoch: [303/400][220/346], lr: 0.00000053 	 loss = 0.0004(0.1193)
2023/09/19 20:42:40 - INFO - root -   Epoch: [303/400][240/346], lr: 0.00000053 	 loss = 0.0000(0.1225)
2023/09/19 20:43:23 - INFO - root -   Epoch: [303/400][260/346], lr: 0.00000053 	 loss = 0.0142(0.1261)
2023/09/19 20:44:24 - INFO - root -   Epoch: [303/400][280/346], lr: 0.00000053 	 loss = 0.0039(0.1453)
2023/09/19 20:45:07 - INFO - root -   Epoch: [303/400][300/346], lr: 0.00000053 	 loss = 0.0047(0.1435)
2023/09/19 20:46:08 - INFO - root -   Epoch: [303/400][320/346], lr: 0.00000053 	 loss = 0.0059(0.1439)
2023/09/19 20:46:49 - INFO - root -   Epoch: [303/400][340/346], lr: 0.00000053 	 loss = 0.0079(0.1408)
2023/09/19 20:46:53 - INFO - root -   Epoch: [303/400] 	 loss = 0.1425
2023/09/19 20:46:53 - INFO - root -   train_accuracy = 0.9538
2023/09/19 20:47:15 - INFO - root -   Epoch: [304/400][0/346], lr: 0.00000053 	 loss = 0.0034(0.0034)
2023/09/19 20:47:58 - INFO - root -   Epoch: [304/400][20/346], lr: 0.00000053 	 loss = 0.0001(0.0525)
2023/09/19 20:48:59 - INFO - root -   Epoch: [304/400][40/346], lr: 0.00000053 	 loss = 0.7743(0.0613)
2023/09/19 20:49:42 - INFO - root -   Epoch: [304/400][60/346], lr: 0.00000053 	 loss = 0.0274(0.0465)
2023/09/19 20:50:43 - INFO - root -   Epoch: [304/400][80/346], lr: 0.00000053 	 loss = 0.0001(0.0381)
2023/09/19 20:51:26 - INFO - root -   Epoch: [304/400][100/346], lr: 0.00000053 	 loss = 0.0070(0.0402)
2023/09/19 20:52:27 - INFO - root -   Epoch: [304/400][120/346], lr: 0.00000053 	 loss = 0.0178(0.0907)
2023/09/19 20:53:10 - INFO - root -   Epoch: [304/400][140/346], lr: 0.00000053 	 loss = 0.0426(0.0960)
2023/09/19 20:54:11 - INFO - root -   Epoch: [304/400][160/346], lr: 0.00000053 	 loss = 0.0370(0.1011)
2023/09/19 20:54:54 - INFO - root -   Epoch: [304/400][180/346], lr: 0.00000053 	 loss = 0.0021(0.0952)
2023/09/19 20:55:55 - INFO - root -   Epoch: [304/400][200/346], lr: 0.00000053 	 loss = 0.0251(0.0897)
2023/09/19 20:56:38 - INFO - root -   Epoch: [304/400][220/346], lr: 0.00000053 	 loss = 0.0042(0.0868)
2023/09/19 20:57:39 - INFO - root -   Epoch: [304/400][240/346], lr: 0.00000053 	 loss = 1.5658(0.0870)
2023/09/19 20:58:22 - INFO - root -   Epoch: [304/400][260/346], lr: 0.00000053 	 loss = 0.0310(0.0843)
2023/09/19 20:59:22 - INFO - root -   Epoch: [304/400][280/346], lr: 0.00000053 	 loss = 0.3246(0.0945)
2023/09/19 21:00:05 - INFO - root -   Epoch: [304/400][300/346], lr: 0.00000053 	 loss = 0.0030(0.0953)
2023/09/19 21:01:06 - INFO - root -   Epoch: [304/400][320/346], lr: 0.00000053 	 loss = 0.0100(0.1001)
2023/09/19 21:01:47 - INFO - root -   Epoch: [304/400][340/346], lr: 0.00000053 	 loss = 0.0239(0.1012)
2023/09/19 21:01:51 - INFO - root -   Epoch: [304/400] 	 loss = 0.1009
2023/09/19 21:05:38 - INFO - root -   precision = 0.6667
2023/09/19 21:05:38 - INFO - root -   eval_loss = 1.4714
2023/09/19 21:05:39 - INFO - root -   train_accuracy = 0.9552
2023/09/19 21:06:00 - INFO - root -   Epoch: [305/400][0/346], lr: 0.00000054 	 loss = 0.7286(0.7286)
2023/09/19 21:06:43 - INFO - root -   Epoch: [305/400][20/346], lr: 0.00000054 	 loss = 0.0002(0.0823)
2023/09/19 21:07:43 - INFO - root -   Epoch: [305/400][40/346], lr: 0.00000054 	 loss = 0.0002(0.0961)
2023/09/19 21:08:26 - INFO - root -   Epoch: [305/400][60/346], lr: 0.00000054 	 loss = 0.0017(0.0933)
2023/09/19 21:09:26 - INFO - root -   Epoch: [305/400][80/346], lr: 0.00000054 	 loss = 0.0627(0.0820)
2023/09/19 21:10:09 - INFO - root -   Epoch: [305/400][100/346], lr: 0.00000054 	 loss = 0.0092(0.0874)
2023/09/19 21:11:09 - INFO - root -   Epoch: [305/400][120/346], lr: 0.00000054 	 loss = 0.0010(0.0877)
2023/09/19 21:11:52 - INFO - root -   Epoch: [305/400][140/346], lr: 0.00000054 	 loss = 0.0004(0.0896)
2023/09/19 21:12:52 - INFO - root -   Epoch: [305/400][160/346], lr: 0.00000054 	 loss = 0.0165(0.0821)
2023/09/19 21:13:36 - INFO - root -   Epoch: [305/400][180/346], lr: 0.00000054 	 loss = 0.0004(0.0784)
2023/09/19 21:14:35 - INFO - root -   Epoch: [305/400][200/346], lr: 0.00000054 	 loss = 0.0039(0.0761)
2023/09/19 21:15:19 - INFO - root -   Epoch: [305/400][220/346], lr: 0.00000054 	 loss = 0.0106(0.0823)
2023/09/19 21:16:19 - INFO - root -   Epoch: [305/400][240/346], lr: 0.00000054 	 loss = 0.0004(0.0765)
2023/09/19 21:17:02 - INFO - root -   Epoch: [305/400][260/346], lr: 0.00000054 	 loss = 0.0010(0.0730)
2023/09/19 21:18:03 - INFO - root -   Epoch: [305/400][280/346], lr: 0.00000054 	 loss = 0.0007(0.0745)
2023/09/19 21:18:46 - INFO - root -   Epoch: [305/400][300/346], lr: 0.00000054 	 loss = 0.0023(0.0755)
2023/09/19 21:19:46 - INFO - root -   Epoch: [305/400][320/346], lr: 0.00000054 	 loss = 0.0012(0.0717)
2023/09/19 21:20:28 - INFO - root -   Epoch: [305/400][340/346], lr: 0.00000054 	 loss = 0.0042(0.0723)
2023/09/19 21:20:32 - INFO - root -   Epoch: [305/400] 	 loss = 0.0718
2023/09/19 21:20:32 - INFO - root -   train_accuracy = 0.9725
2023/09/19 21:20:54 - INFO - root -   Epoch: [306/400][0/346], lr: 0.00000054 	 loss = 0.0016(0.0016)
2023/09/19 21:21:37 - INFO - root -   Epoch: [306/400][20/346], lr: 0.00000054 	 loss = 0.0003(0.0841)
2023/09/19 21:22:38 - INFO - root -   Epoch: [306/400][40/346], lr: 0.00000054 	 loss = 1.5356(0.1160)
2023/09/19 21:23:22 - INFO - root -   Epoch: [306/400][60/346], lr: 0.00000054 	 loss = 0.3581(0.0959)
2023/09/19 21:24:21 - INFO - root -   Epoch: [306/400][80/346], lr: 0.00000054 	 loss = 0.0515(0.0752)
2023/09/19 21:25:05 - INFO - root -   Epoch: [306/400][100/346], lr: 0.00000054 	 loss = 0.0330(0.0906)
2023/09/19 21:26:04 - INFO - root -   Epoch: [306/400][120/346], lr: 0.00000054 	 loss = 0.0084(0.0842)
2023/09/19 21:26:50 - INFO - root -   Epoch: [306/400][140/346], lr: 0.00000054 	 loss = 0.0004(0.0791)
2023/09/19 21:27:48 - INFO - root -   Epoch: [306/400][160/346], lr: 0.00000054 	 loss = 0.0002(0.0763)
2023/09/19 21:28:34 - INFO - root -   Epoch: [306/400][180/346], lr: 0.00000054 	 loss = 0.0001(0.0864)
2023/09/19 21:29:31 - INFO - root -   Epoch: [306/400][200/346], lr: 0.00000054 	 loss = 0.0006(0.0880)
2023/09/19 21:30:19 - INFO - root -   Epoch: [306/400][220/346], lr: 0.00000054 	 loss = 0.0007(0.0987)
2023/09/19 21:31:15 - INFO - root -   Epoch: [306/400][240/346], lr: 0.00000054 	 loss = 0.1783(0.0929)
2023/09/19 21:32:03 - INFO - root -   Epoch: [306/400][260/346], lr: 0.00000054 	 loss = 0.6535(0.0930)
2023/09/19 21:32:59 - INFO - root -   Epoch: [306/400][280/346], lr: 0.00000054 	 loss = 0.0122(0.1053)
2023/09/19 21:33:49 - INFO - root -   Epoch: [306/400][300/346], lr: 0.00000054 	 loss = 0.0002(0.1368)
2023/09/19 21:34:42 - INFO - root -   Epoch: [306/400][320/346], lr: 0.00000054 	 loss = 0.0006(0.1517)
2023/09/19 21:35:25 - INFO - root -   Epoch: [306/400][340/346], lr: 0.00000054 	 loss = 0.0342(0.1601)
2023/09/19 21:35:28 - INFO - root -   Epoch: [306/400] 	 loss = 0.1600
2023/09/19 21:35:28 - INFO - root -   train_accuracy = 0.9523
2023/09/19 21:35:49 - INFO - root -   Epoch: [307/400][0/346], lr: 0.00000054 	 loss = 0.0048(0.0048)
2023/09/19 21:36:32 - INFO - root -   Epoch: [307/400][20/346], lr: 0.00000054 	 loss = 0.0405(0.2248)
2023/09/19 21:37:33 - INFO - root -   Epoch: [307/400][40/346], lr: 0.00000054 	 loss = 0.0026(0.2179)
2023/09/19 21:38:16 - INFO - root -   Epoch: [307/400][60/346], lr: 0.00000054 	 loss = 0.1737(0.1697)
2023/09/19 21:39:16 - INFO - root -   Epoch: [307/400][80/346], lr: 0.00000054 	 loss = 0.0011(0.1787)
2023/09/19 21:39:59 - INFO - root -   Epoch: [307/400][100/346], lr: 0.00000054 	 loss = 0.0059(0.1471)
2023/09/19 21:41:00 - INFO - root -   Epoch: [307/400][120/346], lr: 0.00000054 	 loss = 0.0262(0.1392)
2023/09/19 21:41:43 - INFO - root -   Epoch: [307/400][140/346], lr: 0.00000054 	 loss = 0.2552(0.1319)
2023/09/19 21:42:43 - INFO - root -   Epoch: [307/400][160/346], lr: 0.00000054 	 loss = 0.0009(0.1202)
2023/09/19 21:43:27 - INFO - root -   Epoch: [307/400][180/346], lr: 0.00000054 	 loss = 0.1971(0.1171)
2023/09/19 21:44:26 - INFO - root -   Epoch: [307/400][200/346], lr: 0.00000054 	 loss = 0.0001(0.1134)
2023/09/19 21:45:11 - INFO - root -   Epoch: [307/400][220/346], lr: 0.00000054 	 loss = 0.0814(0.1227)
2023/09/19 21:46:10 - INFO - root -   Epoch: [307/400][240/346], lr: 0.00000054 	 loss = 0.0048(0.1156)
2023/09/19 21:46:55 - INFO - root -   Epoch: [307/400][260/346], lr: 0.00000054 	 loss = 0.0367(0.1085)
2023/09/19 21:47:53 - INFO - root -   Epoch: [307/400][280/346], lr: 0.00000054 	 loss = 0.0936(0.1057)
2023/09/19 21:48:39 - INFO - root -   Epoch: [307/400][300/346], lr: 0.00000054 	 loss = 0.0056(0.1047)
2023/09/19 21:49:36 - INFO - root -   Epoch: [307/400][320/346], lr: 0.00000054 	 loss = 0.0002(0.1023)
2023/09/19 21:50:21 - INFO - root -   Epoch: [307/400][340/346], lr: 0.00000054 	 loss = 0.6607(0.1097)
2023/09/19 21:50:25 - INFO - root -   Epoch: [307/400] 	 loss = 0.1088
2023/09/19 21:50:25 - INFO - root -   train_accuracy = 0.9639
2023/09/19 21:50:47 - INFO - root -   Epoch: [308/400][0/346], lr: 0.00000054 	 loss = 0.0071(0.0071)
2023/09/19 21:51:30 - INFO - root -   Epoch: [308/400][20/346], lr: 0.00000054 	 loss = 0.0004(0.0409)
2023/09/19 21:52:31 - INFO - root -   Epoch: [308/400][40/346], lr: 0.00000054 	 loss = 0.0011(0.0299)
2023/09/19 21:53:14 - INFO - root -   Epoch: [308/400][60/346], lr: 0.00000054 	 loss = 0.0006(0.0396)
2023/09/19 21:54:15 - INFO - root -   Epoch: [308/400][80/346], lr: 0.00000054 	 loss = 0.0693(0.0655)
2023/09/19 21:54:58 - INFO - root -   Epoch: [308/400][100/346], lr: 0.00000054 	 loss = 0.1376(0.0594)
2023/09/19 21:56:00 - INFO - root -   Epoch: [308/400][120/346], lr: 0.00000054 	 loss = 0.1690(0.0582)
2023/09/19 21:56:43 - INFO - root -   Epoch: [308/400][140/346], lr: 0.00000054 	 loss = 0.0308(0.0633)
2023/09/19 21:57:44 - INFO - root -   Epoch: [308/400][160/346], lr: 0.00000054 	 loss = 0.0003(0.0600)
2023/09/19 21:58:27 - INFO - root -   Epoch: [308/400][180/346], lr: 0.00000054 	 loss = 0.0489(0.0686)
2023/09/19 21:59:27 - INFO - root -   Epoch: [308/400][200/346], lr: 0.00000054 	 loss = 0.0143(0.0801)
2023/09/19 22:00:11 - INFO - root -   Epoch: [308/400][220/346], lr: 0.00000054 	 loss = 0.0019(0.0754)
2023/09/19 22:01:11 - INFO - root -   Epoch: [308/400][240/346], lr: 0.00000054 	 loss = 0.0004(0.0725)
2023/09/19 22:01:55 - INFO - root -   Epoch: [308/400][260/346], lr: 0.00000054 	 loss = 0.0105(0.0711)
2023/09/19 22:02:55 - INFO - root -   Epoch: [308/400][280/346], lr: 0.00000054 	 loss = 0.0008(0.0769)
2023/09/19 22:03:39 - INFO - root -   Epoch: [308/400][300/346], lr: 0.00000054 	 loss = 0.0267(0.0821)
2023/09/19 22:04:38 - INFO - root -   Epoch: [308/400][320/346], lr: 0.00000054 	 loss = 0.0818(0.0787)
2023/09/19 22:05:20 - INFO - root -   Epoch: [308/400][340/346], lr: 0.00000054 	 loss = 1.3206(0.0842)
2023/09/19 22:05:24 - INFO - root -   Epoch: [308/400] 	 loss = 0.0852
2023/09/19 22:05:24 - INFO - root -   train_accuracy = 0.9624
2023/09/19 22:05:46 - INFO - root -   Epoch: [309/400][0/346], lr: 0.00000054 	 loss = 0.0032(0.0032)
2023/09/19 22:06:29 - INFO - root -   Epoch: [309/400][20/346], lr: 0.00000054 	 loss = 0.0220(0.0253)
2023/09/19 22:07:30 - INFO - root -   Epoch: [309/400][40/346], lr: 0.00000054 	 loss = 0.0005(0.0629)
2023/09/19 22:08:13 - INFO - root -   Epoch: [309/400][60/346], lr: 0.00000054 	 loss = 0.0671(0.0552)
2023/09/19 22:09:14 - INFO - root -   Epoch: [309/400][80/346], lr: 0.00000054 	 loss = 0.0034(0.1258)
2023/09/19 22:09:58 - INFO - root -   Epoch: [309/400][100/346], lr: 0.00000054 	 loss = 0.3055(0.1280)
2023/09/19 22:10:58 - INFO - root -   Epoch: [309/400][120/346], lr: 0.00000054 	 loss = 0.0020(0.1376)
2023/09/19 22:11:42 - INFO - root -   Epoch: [309/400][140/346], lr: 0.00000054 	 loss = 0.9073(0.1293)
2023/09/19 22:12:42 - INFO - root -   Epoch: [309/400][160/346], lr: 0.00000054 	 loss = 0.3018(0.1227)
2023/09/19 22:13:25 - INFO - root -   Epoch: [309/400][180/346], lr: 0.00000054 	 loss = 0.2043(0.1135)
2023/09/19 22:14:26 - INFO - root -   Epoch: [309/400][200/346], lr: 0.00000054 	 loss = 0.0015(0.1061)
2023/09/19 22:15:09 - INFO - root -   Epoch: [309/400][220/346], lr: 0.00000054 	 loss = 0.1551(0.1052)
2023/09/19 22:16:10 - INFO - root -   Epoch: [309/400][240/346], lr: 0.00000054 	 loss = 0.0612(0.1008)
2023/09/19 22:16:53 - INFO - root -   Epoch: [309/400][260/346], lr: 0.00000054 	 loss = 0.3362(0.0954)
2023/09/19 22:17:54 - INFO - root -   Epoch: [309/400][280/346], lr: 0.00000054 	 loss = 0.0003(0.0891)
2023/09/19 22:18:37 - INFO - root -   Epoch: [309/400][300/346], lr: 0.00000054 	 loss = 0.0009(0.0869)
2023/09/19 22:19:38 - INFO - root -   Epoch: [309/400][320/346], lr: 0.00000054 	 loss = 0.0003(0.0846)
2023/09/19 22:20:20 - INFO - root -   Epoch: [309/400][340/346], lr: 0.00000054 	 loss = 0.0259(0.0882)
2023/09/19 22:20:24 - INFO - root -   Epoch: [309/400] 	 loss = 0.0912
2023/09/19 22:24:10 - INFO - root -   precision = 0.6667
2023/09/19 22:24:10 - INFO - root -   eval_loss = 1.5517
2023/09/19 22:24:11 - INFO - root -   train_accuracy = 0.9697
2023/09/19 22:24:33 - INFO - root -   Epoch: [310/400][0/346], lr: 0.00000054 	 loss = 0.0021(0.0021)
2023/09/19 22:25:16 - INFO - root -   Epoch: [310/400][20/346], lr: 0.00000054 	 loss = 0.0001(0.0973)
2023/09/19 22:26:17 - INFO - root -   Epoch: [310/400][40/346], lr: 0.00000054 	 loss = 0.0033(0.0715)
2023/09/19 22:27:00 - INFO - root -   Epoch: [310/400][60/346], lr: 0.00000054 	 loss = 0.0043(0.0514)
2023/09/19 22:28:01 - INFO - root -   Epoch: [310/400][80/346], lr: 0.00000054 	 loss = 0.0005(0.0509)
2023/09/19 22:28:44 - INFO - root -   Epoch: [310/400][100/346], lr: 0.00000054 	 loss = 0.0012(0.0520)
2023/09/19 22:29:45 - INFO - root -   Epoch: [310/400][120/346], lr: 0.00000054 	 loss = 0.0061(0.0712)
2023/09/19 22:30:28 - INFO - root -   Epoch: [310/400][140/346], lr: 0.00000054 	 loss = 0.0030(0.0646)
2023/09/19 22:31:29 - INFO - root -   Epoch: [310/400][160/346], lr: 0.00000054 	 loss = 0.0021(0.0668)
2023/09/19 22:32:12 - INFO - root -   Epoch: [310/400][180/346], lr: 0.00000054 	 loss = 0.0011(0.0809)
2023/09/19 22:33:13 - INFO - root -   Epoch: [310/400][200/346], lr: 0.00000054 	 loss = 0.0025(0.0834)
2023/09/19 22:33:56 - INFO - root -   Epoch: [310/400][220/346], lr: 0.00000054 	 loss = 0.0031(0.0797)
2023/09/19 22:34:57 - INFO - root -   Epoch: [310/400][240/346], lr: 0.00000054 	 loss = 0.0026(0.0757)
2023/09/19 22:35:40 - INFO - root -   Epoch: [310/400][260/346], lr: 0.00000054 	 loss = 0.0058(0.0744)
2023/09/19 22:36:41 - INFO - root -   Epoch: [310/400][280/346], lr: 0.00000054 	 loss = 0.0001(0.0774)
2023/09/19 22:37:24 - INFO - root -   Epoch: [310/400][300/346], lr: 0.00000054 	 loss = 0.0024(0.0751)
2023/09/19 22:38:25 - INFO - root -   Epoch: [310/400][320/346], lr: 0.00000054 	 loss = 0.0004(0.0759)
2023/09/19 22:39:06 - INFO - root -   Epoch: [310/400][340/346], lr: 0.00000054 	 loss = 0.0009(0.0776)
2023/09/19 22:39:10 - INFO - root -   Epoch: [310/400] 	 loss = 0.0765
2023/09/19 22:39:10 - INFO - root -   train_accuracy = 0.9711
2023/09/19 22:39:32 - INFO - root -   Epoch: [311/400][0/346], lr: 0.00000054 	 loss = 0.0003(0.0003)
2023/09/19 22:40:15 - INFO - root -   Epoch: [311/400][20/346], lr: 0.00000054 	 loss = 0.0003(0.0674)
2023/09/19 22:41:16 - INFO - root -   Epoch: [311/400][40/346], lr: 0.00000054 	 loss = 0.0034(0.1307)
2023/09/19 22:41:59 - INFO - root -   Epoch: [311/400][60/346], lr: 0.00000054 	 loss = 0.0013(0.0932)
2023/09/19 22:43:01 - INFO - root -   Epoch: [311/400][80/346], lr: 0.00000054 	 loss = 0.0007(0.0993)
2023/09/19 22:43:45 - INFO - root -   Epoch: [311/400][100/346], lr: 0.00000054 	 loss = 0.0023(0.1030)
2023/09/19 22:44:46 - INFO - root -   Epoch: [311/400][120/346], lr: 0.00000054 	 loss = 0.0149(0.1003)
2023/09/19 22:45:29 - INFO - root -   Epoch: [311/400][140/346], lr: 0.00000054 	 loss = 1.1237(0.1227)
2023/09/19 22:46:30 - INFO - root -   Epoch: [311/400][160/346], lr: 0.00000054 	 loss = 0.0028(0.1128)
2023/09/19 22:47:13 - INFO - root -   Epoch: [311/400][180/346], lr: 0.00000054 	 loss = 0.5719(0.1077)
2023/09/19 22:48:14 - INFO - root -   Epoch: [311/400][200/346], lr: 0.00000054 	 loss = 0.0002(0.1035)
2023/09/19 22:48:57 - INFO - root -   Epoch: [311/400][220/346], lr: 0.00000054 	 loss = 0.0015(0.1029)
2023/09/19 22:49:58 - INFO - root -   Epoch: [311/400][240/346], lr: 0.00000054 	 loss = 0.0157(0.0996)
2023/09/19 22:50:41 - INFO - root -   Epoch: [311/400][260/346], lr: 0.00000054 	 loss = 0.0018(0.0961)
2023/09/19 22:51:42 - INFO - root -   Epoch: [311/400][280/346], lr: 0.00000054 	 loss = 0.0002(0.0994)
2023/09/19 22:52:26 - INFO - root -   Epoch: [311/400][300/346], lr: 0.00000054 	 loss = 0.0151(0.0948)
2023/09/19 22:53:27 - INFO - root -   Epoch: [311/400][320/346], lr: 0.00000054 	 loss = 0.0171(0.0899)
2023/09/19 22:54:09 - INFO - root -   Epoch: [311/400][340/346], lr: 0.00000054 	 loss = 0.0017(0.0867)
2023/09/19 22:54:13 - INFO - root -   Epoch: [311/400] 	 loss = 0.0866
2023/09/19 22:54:13 - INFO - root -   train_accuracy = 0.9639
2023/09/19 22:54:35 - INFO - root -   Epoch: [312/400][0/346], lr: 0.00000055 	 loss = 0.0024(0.0024)
2023/09/19 22:55:18 - INFO - root -   Epoch: [312/400][20/346], lr: 0.00000055 	 loss = 0.0003(0.0015)
2023/09/19 22:56:19 - INFO - root -   Epoch: [312/400][40/346], lr: 0.00000055 	 loss = 0.0094(0.0551)
2023/09/19 22:57:03 - INFO - root -   Epoch: [312/400][60/346], lr: 0.00000055 	 loss = 0.0042(0.0435)
2023/09/19 22:58:04 - INFO - root -   Epoch: [312/400][80/346], lr: 0.00000055 	 loss = 0.0019(0.0770)
2023/09/19 22:58:48 - INFO - root -   Epoch: [312/400][100/346], lr: 0.00000055 	 loss = 0.6611(0.0721)
2023/09/19 22:59:49 - INFO - root -   Epoch: [312/400][120/346], lr: 0.00000055 	 loss = 0.0008(0.0819)
2023/09/19 23:00:32 - INFO - root -   Epoch: [312/400][140/346], lr: 0.00000055 	 loss = 0.0316(0.0741)
2023/09/19 23:01:33 - INFO - root -   Epoch: [312/400][160/346], lr: 0.00000055 	 loss = 0.0001(0.0677)
2023/09/19 23:02:17 - INFO - root -   Epoch: [312/400][180/346], lr: 0.00000055 	 loss = 0.1396(0.0626)
2023/09/19 23:03:18 - INFO - root -   Epoch: [312/400][200/346], lr: 0.00000055 	 loss = 0.0001(0.0579)
2023/09/19 23:04:01 - INFO - root -   Epoch: [312/400][220/346], lr: 0.00000055 	 loss = 0.0010(0.0572)
2023/09/19 23:05:03 - INFO - root -   Epoch: [312/400][240/346], lr: 0.00000055 	 loss = 0.0470(0.0548)
2023/09/19 23:05:46 - INFO - root -   Epoch: [312/400][260/346], lr: 0.00000055 	 loss = 0.0188(0.0549)
2023/09/19 23:06:47 - INFO - root -   Epoch: [312/400][280/346], lr: 0.00000055 	 loss = 0.0002(0.0605)
2023/09/19 23:07:30 - INFO - root -   Epoch: [312/400][300/346], lr: 0.00000055 	 loss = 0.0001(0.0657)
2023/09/19 23:08:31 - INFO - root -   Epoch: [312/400][320/346], lr: 0.00000055 	 loss = 0.0007(0.0642)
2023/09/19 23:09:13 - INFO - root -   Epoch: [312/400][340/346], lr: 0.00000055 	 loss = 0.2071(0.0645)
2023/09/19 23:09:17 - INFO - root -   Epoch: [312/400] 	 loss = 0.0720
2023/09/19 23:09:17 - INFO - root -   train_accuracy = 0.9697
2023/09/19 23:09:39 - INFO - root -   Epoch: [313/400][0/346], lr: 0.00000055 	 loss = 0.0030(0.0030)
2023/09/19 23:10:22 - INFO - root -   Epoch: [313/400][20/346], lr: 0.00000055 	 loss = 0.0001(0.0529)
2023/09/19 23:11:23 - INFO - root -   Epoch: [313/400][40/346], lr: 0.00000055 	 loss = 1.0965(0.0745)
2023/09/19 23:12:06 - INFO - root -   Epoch: [313/400][60/346], lr: 0.00000055 	 loss = 0.0029(0.0724)
2023/09/19 23:13:06 - INFO - root -   Epoch: [313/400][80/346], lr: 0.00000055 	 loss = 0.0014(0.0619)
2023/09/19 23:13:49 - INFO - root -   Epoch: [313/400][100/346], lr: 0.00000055 	 loss = 0.0078(0.0620)
2023/09/19 23:14:49 - INFO - root -   Epoch: [313/400][120/346], lr: 0.00000055 	 loss = 0.1008(0.0826)
2023/09/19 23:15:33 - INFO - root -   Epoch: [313/400][140/346], lr: 0.00000055 	 loss = 0.0010(0.0884)
2023/09/19 23:16:33 - INFO - root -   Epoch: [313/400][160/346], lr: 0.00000055 	 loss = 0.0001(0.0787)
2023/09/19 23:17:17 - INFO - root -   Epoch: [313/400][180/346], lr: 0.00000055 	 loss = 0.0003(0.0728)
2023/09/19 23:18:16 - INFO - root -   Epoch: [313/400][200/346], lr: 0.00000055 	 loss = 0.0022(0.0724)
2023/09/19 23:19:00 - INFO - root -   Epoch: [313/400][220/346], lr: 0.00000055 	 loss = 0.0288(0.0680)
2023/09/19 23:19:59 - INFO - root -   Epoch: [313/400][240/346], lr: 0.00000055 	 loss = 0.0078(0.0682)
2023/09/19 23:20:44 - INFO - root -   Epoch: [313/400][260/346], lr: 0.00000055 	 loss = 0.0602(0.0638)
2023/09/19 23:21:42 - INFO - root -   Epoch: [313/400][280/346], lr: 0.00000055 	 loss = 0.0063(0.0655)
2023/09/19 23:22:28 - INFO - root -   Epoch: [313/400][300/346], lr: 0.00000055 	 loss = 0.0005(0.0687)
2023/09/19 23:23:25 - INFO - root -   Epoch: [313/400][320/346], lr: 0.00000055 	 loss = 0.0002(0.0709)
2023/09/19 23:24:10 - INFO - root -   Epoch: [313/400][340/346], lr: 0.00000055 	 loss = 0.0051(0.0700)
2023/09/19 23:24:14 - INFO - root -   Epoch: [313/400] 	 loss = 0.0694
2023/09/19 23:24:14 - INFO - root -   train_accuracy = 0.9769
2023/09/19 23:24:36 - INFO - root -   Epoch: [314/400][0/346], lr: 0.00000055 	 loss = 0.0135(0.0135)
2023/09/19 23:25:19 - INFO - root -   Epoch: [314/400][20/346], lr: 0.00000055 	 loss = 0.0004(0.0116)
2023/09/19 23:26:20 - INFO - root -   Epoch: [314/400][40/346], lr: 0.00000055 	 loss = 0.0001(0.0559)
2023/09/19 23:27:04 - INFO - root -   Epoch: [314/400][60/346], lr: 0.00000055 	 loss = 0.0002(0.0423)
2023/09/19 23:28:04 - INFO - root -   Epoch: [314/400][80/346], lr: 0.00000055 	 loss = 0.0048(0.0380)
2023/09/19 23:28:48 - INFO - root -   Epoch: [314/400][100/346], lr: 0.00000055 	 loss = 0.0133(0.0357)
2023/09/19 23:29:48 - INFO - root -   Epoch: [314/400][120/346], lr: 0.00000055 	 loss = 0.0007(0.0356)
2023/09/19 23:30:32 - INFO - root -   Epoch: [314/400][140/346], lr: 0.00000055 	 loss = 0.0480(0.0545)
2023/09/19 23:31:32 - INFO - root -   Epoch: [314/400][160/346], lr: 0.00000055 	 loss = 0.0014(0.0552)
2023/09/19 23:32:16 - INFO - root -   Epoch: [314/400][180/346], lr: 0.00000055 	 loss = 0.0021(0.0762)
2023/09/19 23:33:16 - INFO - root -   Epoch: [314/400][200/346], lr: 0.00000055 	 loss = 0.0001(0.0802)
2023/09/19 23:34:00 - INFO - root -   Epoch: [314/400][220/346], lr: 0.00000055 	 loss = 0.2477(0.1023)
2023/09/19 23:35:00 - INFO - root -   Epoch: [314/400][240/346], lr: 0.00000055 	 loss = 0.0011(0.1080)
2023/09/19 23:35:44 - INFO - root -   Epoch: [314/400][260/346], lr: 0.00000055 	 loss = 0.0013(0.1295)
2023/09/19 23:36:44 - INFO - root -   Epoch: [314/400][280/346], lr: 0.00000055 	 loss = 0.0002(0.1362)
2023/09/19 23:37:28 - INFO - root -   Epoch: [314/400][300/346], lr: 0.00000055 	 loss = 0.0006(0.1358)
2023/09/19 23:38:28 - INFO - root -   Epoch: [314/400][320/346], lr: 0.00000055 	 loss = 0.1071(0.1340)
2023/09/19 23:39:09 - INFO - root -   Epoch: [314/400][340/346], lr: 0.00000055 	 loss = 0.0046(0.1276)
2023/09/19 23:39:13 - INFO - root -   Epoch: [314/400] 	 loss = 0.1265
2023/09/19 23:43:01 - INFO - root -   precision = 0.6839
2023/09/19 23:43:01 - INFO - root -   eval_loss = 1.4816
2023/09/19 23:43:02 - INFO - root -   train_accuracy = 0.9523
2023/09/19 23:43:24 - INFO - root -   Epoch: [315/400][0/346], lr: 0.00000055 	 loss = 0.0057(0.0057)
2023/09/19 23:44:07 - INFO - root -   Epoch: [315/400][20/346], lr: 0.00000055 	 loss = 0.0003(0.0376)
2023/09/19 23:45:07 - INFO - root -   Epoch: [315/400][40/346], lr: 0.00000055 	 loss = 1.0522(0.0887)
2023/09/19 23:45:50 - INFO - root -   Epoch: [315/400][60/346], lr: 0.00000055 	 loss = 0.0005(0.1422)
2023/09/19 23:46:51 - INFO - root -   Epoch: [315/400][80/346], lr: 0.00000055 	 loss = 0.0002(0.1401)
2023/09/19 23:47:34 - INFO - root -   Epoch: [315/400][100/346], lr: 0.00000055 	 loss = 0.0076(0.1433)
2023/09/19 23:48:34 - INFO - root -   Epoch: [315/400][120/346], lr: 0.00000055 	 loss = 0.0001(0.1413)
2023/09/19 23:49:18 - INFO - root -   Epoch: [315/400][140/346], lr: 0.00000055 	 loss = 0.0009(0.1500)
2023/09/19 23:50:17 - INFO - root -   Epoch: [315/400][160/346], lr: 0.00000055 	 loss = 0.2697(0.1466)
2023/09/19 23:51:02 - INFO - root -   Epoch: [315/400][180/346], lr: 0.00000055 	 loss = 0.0790(0.1711)
2023/09/19 23:52:01 - INFO - root -   Epoch: [315/400][200/346], lr: 0.00000055 	 loss = 0.0047(0.1792)
2023/09/19 23:52:45 - INFO - root -   Epoch: [315/400][220/346], lr: 0.00000055 	 loss = 0.0094(0.1939)
2023/09/19 23:53:44 - INFO - root -   Epoch: [315/400][240/346], lr: 0.00000055 	 loss = 0.0597(0.1875)
2023/09/19 23:54:29 - INFO - root -   Epoch: [315/400][260/346], lr: 0.00000055 	 loss = 0.4063(0.1769)
2023/09/19 23:55:27 - INFO - root -   Epoch: [315/400][280/346], lr: 0.00000055 	 loss = 0.0068(0.1729)
2023/09/19 23:56:13 - INFO - root -   Epoch: [315/400][300/346], lr: 0.00000055 	 loss = 0.0321(0.1685)
2023/09/19 23:57:11 - INFO - root -   Epoch: [315/400][320/346], lr: 0.00000055 	 loss = 0.0013(0.1660)
2023/09/19 23:57:55 - INFO - root -   Epoch: [315/400][340/346], lr: 0.00000055 	 loss = 0.0202(0.1612)
2023/09/19 23:57:58 - INFO - root -   Epoch: [315/400] 	 loss = 0.1625
2023/09/19 23:57:58 - INFO - root -   train_accuracy = 0.9364
2023/09/19 23:58:20 - INFO - root -   Epoch: [316/400][0/346], lr: 0.00000055 	 loss = 0.0042(0.0042)
2023/09/19 23:59:03 - INFO - root -   Epoch: [316/400][20/346], lr: 0.00000055 	 loss = 0.0014(0.0405)
2023/09/20 00:00:03 - INFO - root -   Epoch: [316/400][40/346], lr: 0.00000055 	 loss = 0.0006(0.0852)
2023/09/20 00:00:46 - INFO - root -   Epoch: [316/400][60/346], lr: 0.00000055 	 loss = 0.0023(0.0811)
2023/09/20 00:01:46 - INFO - root -   Epoch: [316/400][80/346], lr: 0.00000055 	 loss = 0.0518(0.0857)
2023/09/20 00:02:30 - INFO - root -   Epoch: [316/400][100/346], lr: 0.00000055 	 loss = 0.2860(0.1144)
2023/09/20 00:03:29 - INFO - root -   Epoch: [316/400][120/346], lr: 0.00000055 	 loss = 0.0197(0.0999)
2023/09/20 00:04:14 - INFO - root -   Epoch: [316/400][140/346], lr: 0.00000055 	 loss = 0.0027(0.0926)
2023/09/20 00:05:13 - INFO - root -   Epoch: [316/400][160/346], lr: 0.00000055 	 loss = 0.0043(0.1000)
2023/09/20 00:05:57 - INFO - root -   Epoch: [316/400][180/346], lr: 0.00000055 	 loss = 0.0072(0.0992)
2023/09/20 00:06:55 - INFO - root -   Epoch: [316/400][200/346], lr: 0.00000055 	 loss = 0.0004(0.0951)
2023/09/20 00:07:41 - INFO - root -   Epoch: [316/400][220/346], lr: 0.00000055 	 loss = 0.0060(0.0887)
2023/09/20 00:08:39 - INFO - root -   Epoch: [316/400][240/346], lr: 0.00000055 	 loss = 0.0003(0.0828)
2023/09/20 00:09:24 - INFO - root -   Epoch: [316/400][260/346], lr: 0.00000055 	 loss = 0.0357(0.0811)
2023/09/20 00:10:22 - INFO - root -   Epoch: [316/400][280/346], lr: 0.00000055 	 loss = 0.0018(0.0834)
2023/09/20 00:11:08 - INFO - root -   Epoch: [316/400][300/346], lr: 0.00000055 	 loss = 0.0029(0.0812)
2023/09/20 00:12:05 - INFO - root -   Epoch: [316/400][320/346], lr: 0.00000055 	 loss = 0.0003(0.0802)
2023/09/20 00:12:50 - INFO - root -   Epoch: [316/400][340/346], lr: 0.00000055 	 loss = 0.0063(0.0787)
2023/09/20 00:12:54 - INFO - root -   Epoch: [316/400] 	 loss = 0.0791
2023/09/20 00:12:54 - INFO - root -   train_accuracy = 0.9711
2023/09/20 00:13:15 - INFO - root -   Epoch: [317/400][0/346], lr: 0.00000055 	 loss = 0.0007(0.0007)
2023/09/20 00:13:59 - INFO - root -   Epoch: [317/400][20/346], lr: 0.00000055 	 loss = 0.0005(0.0288)
2023/09/20 00:15:00 - INFO - root -   Epoch: [317/400][40/346], lr: 0.00000055 	 loss = 0.0063(0.0440)
2023/09/20 00:15:43 - INFO - root -   Epoch: [317/400][60/346], lr: 0.00000055 	 loss = 0.0093(0.0504)
2023/09/20 00:16:45 - INFO - root -   Epoch: [317/400][80/346], lr: 0.00000055 	 loss = 0.2084(0.0525)
2023/09/20 00:17:28 - INFO - root -   Epoch: [317/400][100/346], lr: 0.00000055 	 loss = 0.0030(0.0584)
2023/09/20 00:18:29 - INFO - root -   Epoch: [317/400][120/346], lr: 0.00000055 	 loss = 0.0004(0.0679)
2023/09/20 00:19:13 - INFO - root -   Epoch: [317/400][140/346], lr: 0.00000055 	 loss = 0.0008(0.0660)
2023/09/20 00:20:14 - INFO - root -   Epoch: [317/400][160/346], lr: 0.00000055 	 loss = 0.0045(0.0692)
2023/09/20 00:20:57 - INFO - root -   Epoch: [317/400][180/346], lr: 0.00000055 	 loss = 0.3882(0.0844)
2023/09/20 00:21:58 - INFO - root -   Epoch: [317/400][200/346], lr: 0.00000055 	 loss = 0.0000(0.0961)
2023/09/20 00:22:41 - INFO - root -   Epoch: [317/400][220/346], lr: 0.00000055 	 loss = 0.0034(0.0990)
2023/09/20 00:23:42 - INFO - root -   Epoch: [317/400][240/346], lr: 0.00000055 	 loss = 0.0001(0.0955)
2023/09/20 00:24:26 - INFO - root -   Epoch: [317/400][260/346], lr: 0.00000055 	 loss = 0.0112(0.0888)
2023/09/20 00:25:27 - INFO - root -   Epoch: [317/400][280/346], lr: 0.00000055 	 loss = 0.0322(0.0884)
2023/09/20 00:26:10 - INFO - root -   Epoch: [317/400][300/346], lr: 0.00000055 	 loss = 0.0121(0.0873)
2023/09/20 00:27:11 - INFO - root -   Epoch: [317/400][320/346], lr: 0.00000055 	 loss = 0.0532(0.0845)
2023/09/20 00:27:52 - INFO - root -   Epoch: [317/400][340/346], lr: 0.00000055 	 loss = 0.0213(0.0883)
2023/09/20 00:27:56 - INFO - root -   Epoch: [317/400] 	 loss = 0.0874
2023/09/20 00:27:56 - INFO - root -   train_accuracy = 0.9682
2023/09/20 00:28:18 - INFO - root -   Epoch: [318/400][0/346], lr: 0.00000055 	 loss = 0.2667(0.2667)
2023/09/20 00:29:01 - INFO - root -   Epoch: [318/400][20/346], lr: 0.00000055 	 loss = 0.0001(0.0563)
2023/09/20 00:30:02 - INFO - root -   Epoch: [318/400][40/346], lr: 0.00000055 	 loss = 0.2220(0.0712)
2023/09/20 00:30:45 - INFO - root -   Epoch: [318/400][60/346], lr: 0.00000055 	 loss = 0.0004(0.0533)
2023/09/20 00:31:46 - INFO - root -   Epoch: [318/400][80/346], lr: 0.00000055 	 loss = 0.1267(0.0548)
2023/09/20 00:32:29 - INFO - root -   Epoch: [318/400][100/346], lr: 0.00000055 	 loss = 0.0007(0.0481)
2023/09/20 00:33:29 - INFO - root -   Epoch: [318/400][120/346], lr: 0.00000055 	 loss = 0.0003(0.0522)
2023/09/20 00:34:13 - INFO - root -   Epoch: [318/400][140/346], lr: 0.00000055 	 loss = 0.0070(0.0460)
2023/09/20 00:35:13 - INFO - root -   Epoch: [318/400][160/346], lr: 0.00000055 	 loss = 0.0000(0.0611)
2023/09/20 00:35:56 - INFO - root -   Epoch: [318/400][180/346], lr: 0.00000055 	 loss = 0.0791(0.0625)
